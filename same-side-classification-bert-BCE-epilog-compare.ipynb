{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gluon-nlp.mxnet.io/install.html\n",
    "\n",
    "```\n",
    "pip install --upgrade 'mxnet>=1.3.0'\n",
    "pip install gluonnlp\n",
    "wget https://gluon-nlp.mxnet.io/_downloads/sentence_embedding.zip\n",
    "unzip sentence_embedding.zip\n",
    "ln -s sentence_embedding/bert bert\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T16:51:15.058362Z",
     "start_time": "2019-12-17T16:51:14.073855Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from mxboard import SummaryWriter\n",
    "\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T16:51:15.086414Z",
     "start_time": "2019-12-17T16:51:15.082902Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T16:51:15.325926Z",
     "start_time": "2019-12-17T16:51:15.234671Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9a91cfe0ea4fc0b79434cda782827d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils_data import Timer\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "from utils_data import configure_logging\n",
    "configure_logging()\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# set repeatable random state\n",
    "from utils_data import init_random\n",
    "init_random()\n",
    "\n",
    "# --------------------------------\n",
    "\n",
    "# make tqdm jupyter friendly\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "# for .progress_apply() we have to hack it like this?\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task : Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T16:51:19.397693Z",
     "start_time": "2019-12-17T16:51:19.393335Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# paths in utils_data.py\n",
    "\n",
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'\n",
    "new_within_test = 'data/same-side-classification/within-topic/within_test.csv'\n",
    "fn_art_eval = \"data/artificial_evalset/artificial_evalset.tsv\"\n",
    "\n",
    "# from utils_data import names_columns_X, names_columns_X_arteval, names_columns_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics / cross-topics data - distinct train dev sets - artifical evalset data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T16:53:39.271316Z",
     "start_time": "2019-12-17T16:51:20.789497Z"
    },
    "code_folding": [
     3
    ],
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start on [read S3C cross train/dev] ...\n",
      "Time for [read S3C cross train/dev]: 0:00:00.868659\n",
      "Start on [tag cross train/dev] ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d99de7b252e4201b0334132e073ea87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61048), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bf8e5523fad4366b09e3cfec5bf572c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag cross train/dev]: 0:00:37.083706\n",
      "Start on [read S3C within train/dev] ...\n",
      "Time for [read S3C within train/dev]: 0:00:01.216661\n",
      "Start on [tag within train/dev] ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580b8224e7cd49809807ce12af8765fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63903), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c796a25b3142f69eaa5ad0e0ab2556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag within train/dev]: 0:00:52.351022\n",
      "Start on [tag distinct cross train/dev] ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3e5b6a082047a589a77a89278179d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=57825), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03228c3e08a6435fa9deb4b35dd888b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3195), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag distinct cross train/dev]: 0:00:33.804329\n",
      "Start on [tag distinct within train/dev] ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e77f648de2e404db8c0196802409539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=21841), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff04755d2ea4818ba81ee43e6ac4aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1278), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag distinct within train/dev]: 0:00:12.722429\n",
      "Start on [read artificial evalset] ...\n",
      "Time for [read artificial evalset]: 0:00:00.258056\n",
      "Start on [tag artificial evalset] ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cbbc58812a4031bf7027b6a91ea8e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=175), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag artificial evalset]: 0:00:00.109695\n"
     ]
    }
   ],
   "source": [
    "from utils_data import load_and_prepare_official_data\n",
    "from utils_data import load_distinct_df_raw, load_distinct_data\n",
    "from utils_data import load_artificial_dataset\n",
    "\n",
    "cross_traindev_df, cross_test_df = load_and_prepare_official_data(\"cross\")\n",
    "within_traindev_df, within_test_df = load_and_prepare_official_data(\"within\")\n",
    "\n",
    "distinct_cross_train_df, distinct_cross_dev_df = load_distinct_df_raw(\"cross\")\n",
    "distinct_within_train_df, distinct_within_dev_df = load_distinct_df_raw(\"within\")\n",
    "\n",
    "artificial_evalset_df = load_artificial_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T16:53:39.731978Z",
     "start_time": "2019-12-17T16:53:39.729992Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "stats = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T17:29:32.451809Z",
     "start_time": "2019-12-17T16:53:40.186562Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30f6b344454486e8c52704324587c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61048), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d24f2b945d41b38219f3d77b1f3850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63903), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f7cf2a1bc84b4d8821279444705ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b577ddc9b8634e4e88ac5e1b5199dd32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49468d58f8e489c88b69970d0446a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61048), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2e27fe5b1d4f0992b423a28db61a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63903), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005381e2c7ad4d158e22749f59a40c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33176ba521ed4d639199c99b1d8b4860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if stats:\n",
    "    from utils_data import add_bert_tokens, add_sentence_segments\n",
    "\n",
    "    cross_traindev_df = add_bert_tokens(cross_traindev_df)\n",
    "    within_traindev_df = add_bert_tokens(within_traindev_df)\n",
    "    cross_test_df = add_bert_tokens(cross_test_df)\n",
    "    within_test_df = add_bert_tokens(within_test_df)\n",
    "    \n",
    "    cross_traindev_df = add_sentence_segments(cross_traindev_df)\n",
    "    within_traindev_df = add_sentence_segments(within_traindev_df)\n",
    "    cross_test_df = add_sentence_segments(cross_test_df)\n",
    "    within_test_df = add_sentence_segments(within_test_df)\n",
    "    \n",
    "    import pickle\n",
    "\n",
    "    with open(\"data/same-side-classification/cross_traindev_df_stats.p\", \"wb\") as fp:\n",
    "        pickle.dump(cross_traindev_df, fp, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"data/same-side-classification/within_traindev_df_stats.p\", \"wb\") as fp:\n",
    "        pickle.dump(within_traindev_df, fp, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"data/same-side-classification/cross_test_df_stats.p\", \"wb\") as fp:\n",
    "        pickle.dump(cross_test_df, fp, pickle.HIGHEST_PROTOCOL)\n",
    "    with open(\"data/same-side-classification/within_test_df_stats.p\", \"wb\") as fp:\n",
    "        pickle.dump(within_test_df, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T17:29:36.857415Z",
     "start_time": "2019-12-17T17:29:34.541187Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df53706959bc42a0aee970032d479a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=175), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5132d6e351704abcab2271d4584baae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=175), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if stats:\n",
    "    from utils_data import add_bert_tokens, add_sentence_segments\n",
    "    \n",
    "    artificial_evalset_df = add_bert_tokens(artificial_evalset_df)\n",
    "    artificial_evalset_df = add_sentence_segments(artificial_evalset_df)\n",
    "    \n",
    "    import pickle\n",
    "\n",
    "    with open(\"data/same-side-classification/arteval_test_df_stats.p\", \"wb\") as fp:\n",
    "        pickle.dump(artificial_evalset_df, fp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T16:44:23.214164Z",
     "start_time": "2019-12-17T16:44:11.984424Z"
    },
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:  same-side\n",
      "within_traindev_df\n",
      "======================================== \n",
      "\n",
      "Total instances:  63903 \n",
      "\n",
      "For each topic:\n",
      "abortion :  40840  instances\n",
      "\n",
      "\t\tUnique argument1: 7107\n",
      "\t\tUnique argument2: 7068\n",
      "\t\tUnique total arguments: 9192 \n",
      "\n",
      "\t\t False :  20006  instances\n",
      "\t\t True :  20834  instances\n",
      "gay marriage :  23063  instances\n",
      "\n",
      "\t\tUnique argument1: 3406\n",
      "\t\tUnique argument2: 3392\n",
      "\t\tUnique total arguments: 4391 \n",
      "\n",
      "\t\t False :  9786  instances\n",
      "\t\t True :  13277  instances\n",
      "\n",
      "\n",
      "For each class value:\n",
      "False :  29792  instances\n",
      "\t\tUnique argument1: 9445\n",
      "\t\tUnique argument2: 9127\n",
      "\t\tUnique total arguments: 12938 \n",
      "\n",
      "True :  34111  instances\n",
      "\t\tUnique argument1: 7660\n",
      "\t\tUnique argument2: 7645\n",
      "\t\tUnique total arguments: 11891 \n",
      "\n",
      "\n",
      "\n",
      "Unique argument1: 10508\n",
      "Unique argument2: 10453\n",
      "Unique total arguments: 13574 \n",
      "\n",
      "---------------------------------------- \n",
      "\n",
      "Words:\n",
      "\tshortest argument: 3  words\n",
      "\tlongest argument: 2964  words\n",
      "\targument average length: 235.68447490728136  words\n",
      "Task:  same-side\n",
      "cross_traindev_df\n",
      "======================================== \n",
      "\n",
      "Total instances:  61048 \n",
      "\n",
      "For each topic:\n",
      "abortion :  61048  instances\n",
      "\n",
      "\t\tUnique argument1: 7828\n",
      "\t\tUnique argument2: 7806\n",
      "\t\tUnique total arguments: 9361 \n",
      "\n",
      "\t\t False :  29853  instances\n",
      "\t\t True :  31195  instances\n",
      "\n",
      "\n",
      "For each class value:\n",
      "False :  29853  instances\n",
      "\t\tUnique argument1: 7691\n",
      "\t\tUnique argument2: 7369\n",
      "\t\tUnique total arguments: 9336 \n",
      "\n",
      "True :  31195  instances\n",
      "\t\tUnique argument1: 6286\n",
      "\t\tUnique argument2: 6270\n",
      "\t\tUnique total arguments: 8911 \n",
      "\n",
      "\n",
      "\n",
      "Unique argument1: 7828\n",
      "Unique argument2: 7806\n",
      "Unique total arguments: 9361 \n",
      "\n",
      "---------------------------------------- \n",
      "\n",
      "Words:\n",
      "\tshortest argument: 3  words\n",
      "\tlongest argument: 2964  words\n",
      "\targument average length: 246.67835965142183  words\n",
      "       argument1_len  argument2_len  argument12_len_sum  \\\n",
      "count   63903.000000   63903.000000        63903.000000   \n",
      "mean      252.189647     219.179303          471.368950   \n",
      "std       425.471105     393.925258          730.211134   \n",
      "min         3.000000       4.000000            8.000000   \n",
      "25%        15.000000      14.000000           80.000000   \n",
      "50%        85.000000      73.000000          164.000000   \n",
      "75%       222.000000     179.000000          469.000000   \n",
      "max      2825.000000    2964.000000         4998.000000   \n",
      "\n",
      "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \n",
      "count             63903.000000         63903.000000             63903.000000  \n",
      "mean                235.684475            33.010344               190.980486  \n",
      "std                 365.105567           373.091463               322.199974  \n",
      "min                   4.000000         -2837.000000                 0.000000  \n",
      "25%                  40.000000           -58.000000                23.000000  \n",
      "50%                  82.000000             2.000000                75.000000  \n",
      "75%                 234.500000            91.000000               178.000000  \n",
      "max                2499.000000          2724.000000              2837.000000  \n",
      "       argument1_len  argument2_len  argument12_len_sum  \\\n",
      "count   61048.000000   61048.000000        61048.000000   \n",
      "mean      264.863337     228.493382          493.356719   \n",
      "std       438.187823     405.800206          750.101186   \n",
      "min         3.000000       4.000000            8.000000   \n",
      "25%        18.000000      17.000000           80.000000   \n",
      "50%        83.000000      72.000000          162.000000   \n",
      "75%       258.000000     197.000000          538.000000   \n",
      "max      2964.000000    2964.000000         5789.000000   \n",
      "\n",
      "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \n",
      "count             61048.000000         61048.000000             61048.000000  \n",
      "mean                246.678360            36.369955               199.451563  \n",
      "std                 375.050593           388.217671               335.043546  \n",
      "min                   4.000000         -2837.000000                 0.000000  \n",
      "25%                  40.000000           -55.000000                23.000000  \n",
      "50%                  81.000000             3.000000                71.000000  \n",
      "75%                 269.000000            88.000000               199.000000  \n",
      "max                2894.500000          2926.000000              2926.000000  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if stats:\n",
    "    import pickle\n",
    "\n",
    "    with open(\"data/same-side-classification/cross_traindev_df_stats.p\", \"rb\") as fp:\n",
    "        cross_traindev_df = pickle.load(fp)\n",
    "    with open(\"data/same-side-classification/within_traindev_df_stats.p\", \"rb\") as fp:\n",
    "        within_traindev_df = pickle.load(fp)\n",
    "    with open(\"data/same-side-classification/cross_test_df_stats.p\", \"rb\") as fp:\n",
    "        cross_test_df = pickle.load(fp)\n",
    "    with open(\"data/same-side-classification/within_test_df_stats.p\", \"rb\") as fp:\n",
    "        within_test_df = pickle.load(fp)\n",
    "\n",
    "    pass\n",
    "\n",
    "    from utils_data import get_overview, plot_lengths\n",
    "\n",
    "    get_overview(within_traindev_df, description=\"within_traindev_df\")\n",
    "    get_overview(cross_traindev_df, description=\"cross_traindev_df\")\n",
    "    \n",
    "    print()\n",
    "    print(within_traindev_df.describe())\n",
    "    print(cross_traindev_df.describe())\n",
    "    \n",
    "    plot_lengths(within_traindev_df, slice(None, None, 500), title='Length of arguments within train/dev, every 500')\n",
    "    plot_lengths(cross_traindev_df, slice(None, None, 500), title='Length of arguments cross train/dev, every 500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T20:35:26.738558Z",
     "start_time": "2019-12-17T20:35:26.663962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_sum</th>\n",
       "      <th>argument12_len_sum_half</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "      <th>argument1_sent_num</th>\n",
       "      <th>argument2_sent_num</th>\n",
       "      <th>argument12_sent_num_sum</th>\n",
       "      <th>argument12_sent_num_sum_half</th>\n",
       "      <th>argument12_sent_num_diff</th>\n",
       "      <th>argument12_sent_num_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.000000</td>\n",
       "      <td>61048.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>264.863337</td>\n",
       "      <td>228.493382</td>\n",
       "      <td>493.356719</td>\n",
       "      <td>246.678360</td>\n",
       "      <td>36.369955</td>\n",
       "      <td>199.451563</td>\n",
       "      <td>10.888285</td>\n",
       "      <td>9.469139</td>\n",
       "      <td>20.357424</td>\n",
       "      <td>10.178712</td>\n",
       "      <td>1.419146</td>\n",
       "      <td>8.05933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>438.187823</td>\n",
       "      <td>405.800206</td>\n",
       "      <td>750.101186</td>\n",
       "      <td>375.050593</td>\n",
       "      <td>388.217671</td>\n",
       "      <td>335.043546</td>\n",
       "      <td>17.874152</td>\n",
       "      <td>16.260619</td>\n",
       "      <td>30.214838</td>\n",
       "      <td>15.107419</td>\n",
       "      <td>15.964010</td>\n",
       "      <td>13.85315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2837.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-146.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>258.000000</td>\n",
       "      <td>197.000000</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85%</th>\n",
       "      <td>544.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>525.500000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>844.000000</td>\n",
       "      <td>687.000000</td>\n",
       "      <td>1535.000000</td>\n",
       "      <td>767.500000</td>\n",
       "      <td>342.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>61.300000</td>\n",
       "      <td>30.650000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2964.000000</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>5789.000000</td>\n",
       "      <td>2894.500000</td>\n",
       "      <td>2926.000000</td>\n",
       "      <td>2926.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>146.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_sum  \\\n",
       "count   61048.000000   61048.000000        61048.000000   \n",
       "mean      264.863337     228.493382          493.356719   \n",
       "std       438.187823     405.800206          750.101186   \n",
       "min         3.000000       4.000000            8.000000   \n",
       "50%        83.000000      72.000000          162.000000   \n",
       "75%       258.000000     197.000000          538.000000   \n",
       "85%       544.000000     429.000000         1051.000000   \n",
       "90%       844.000000     687.000000         1535.000000   \n",
       "max      2964.000000    2964.000000         5789.000000   \n",
       "\n",
       "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \\\n",
       "count             61048.000000         61048.000000             61048.000000   \n",
       "mean                246.678360            36.369955               199.451563   \n",
       "std                 375.050593           388.217671               335.043546   \n",
       "min                   4.000000         -2837.000000                 0.000000   \n",
       "50%                  81.000000             3.000000                71.000000   \n",
       "75%                 269.000000            88.000000               199.000000   \n",
       "85%                 525.500000           200.000000               385.000000   \n",
       "90%                 767.500000           342.000000               567.000000   \n",
       "max                2894.500000          2926.000000              2926.000000   \n",
       "\n",
       "       argument1_sent_num  argument2_sent_num  argument12_sent_num_sum  \\\n",
       "count        61048.000000        61048.000000             61048.000000   \n",
       "mean            10.888285            9.469139                20.357424   \n",
       "std             17.874152           16.260619                30.214838   \n",
       "min              1.000000            1.000000                 2.000000   \n",
       "50%              3.000000            3.000000                 7.000000   \n",
       "75%             11.000000            8.000000                22.000000   \n",
       "85%             23.000000           18.000000                44.000000   \n",
       "90%             34.000000           28.000000                61.300000   \n",
       "max            151.000000          151.000000               292.000000   \n",
       "\n",
       "       argument12_sent_num_sum_half  argument12_sent_num_diff  \\\n",
       "count                  61048.000000              61048.000000   \n",
       "mean                      10.178712                  1.419146   \n",
       "std                       15.107419                 15.964010   \n",
       "min                        1.000000               -146.000000   \n",
       "50%                        3.500000                  0.000000   \n",
       "75%                       11.000000                  3.000000   \n",
       "85%                       22.000000                  8.000000   \n",
       "90%                       30.650000                 14.000000   \n",
       "max                      146.000000                130.000000   \n",
       "\n",
       "       argument12_sent_num_diff_abs  \n",
       "count                   61048.00000  \n",
       "mean                        8.05933  \n",
       "std                        13.85315  \n",
       "min                         0.00000  \n",
       "50%                         3.00000  \n",
       "75%                         8.00000  \n",
       "85%                        16.00000  \n",
       "90%                        24.00000  \n",
       "max                       146.00000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_traindev_df.describe(percentiles=[.75, .85, .90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T20:48:51.364253Z",
     "start_time": "2019-12-17T20:48:51.282227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_sum</th>\n",
       "      <th>argument12_len_sum_half</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "      <th>argument1_sent_num</th>\n",
       "      <th>argument2_sent_num</th>\n",
       "      <th>argument12_sent_num_sum</th>\n",
       "      <th>argument12_sent_num_sum_half</th>\n",
       "      <th>argument12_sent_num_diff</th>\n",
       "      <th>argument12_sent_num_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>252.189647</td>\n",
       "      <td>219.179303</td>\n",
       "      <td>471.368950</td>\n",
       "      <td>235.684475</td>\n",
       "      <td>33.010344</td>\n",
       "      <td>190.980486</td>\n",
       "      <td>10.460307</td>\n",
       "      <td>9.186079</td>\n",
       "      <td>19.646386</td>\n",
       "      <td>9.823193</td>\n",
       "      <td>1.274228</td>\n",
       "      <td>7.758337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>425.471105</td>\n",
       "      <td>393.925258</td>\n",
       "      <td>730.211134</td>\n",
       "      <td>365.105567</td>\n",
       "      <td>373.091463</td>\n",
       "      <td>322.199974</td>\n",
       "      <td>17.225524</td>\n",
       "      <td>15.812931</td>\n",
       "      <td>29.325628</td>\n",
       "      <td>14.662814</td>\n",
       "      <td>15.282098</td>\n",
       "      <td>13.227754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2837.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-143.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>222.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85%</th>\n",
       "      <td>509.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>986.000000</td>\n",
       "      <td>493.000000</td>\n",
       "      <td>176.700000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>806.000000</td>\n",
       "      <td>653.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>735.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>536.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2825.000000</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>4998.000000</td>\n",
       "      <td>2499.000000</td>\n",
       "      <td>2724.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_sum  \\\n",
       "count   63903.000000   63903.000000        63903.000000   \n",
       "mean      252.189647     219.179303          471.368950   \n",
       "std       425.471105     393.925258          730.211134   \n",
       "min         3.000000       4.000000            8.000000   \n",
       "50%        85.000000      73.000000          164.000000   \n",
       "75%       222.000000     179.000000          469.000000   \n",
       "85%       509.000000     407.000000          986.000000   \n",
       "90%       806.000000     653.000000         1470.000000   \n",
       "max      2825.000000    2964.000000         4998.000000   \n",
       "\n",
       "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \\\n",
       "count             63903.000000         63903.000000             63903.000000   \n",
       "mean                235.684475            33.010344               190.980486   \n",
       "std                 365.105567           373.091463               322.199974   \n",
       "min                   4.000000         -2837.000000                 0.000000   \n",
       "50%                  82.000000             2.000000                75.000000   \n",
       "75%                 234.500000            91.000000               178.000000   \n",
       "85%                 493.000000           176.700000               351.000000   \n",
       "90%                 735.000000           304.000000               536.000000   \n",
       "max                2499.000000          2724.000000              2837.000000   \n",
       "\n",
       "       argument1_sent_num  argument2_sent_num  argument12_sent_num_sum  \\\n",
       "count        63903.000000        63903.000000             63903.000000   \n",
       "mean            10.460307            9.186079                19.646386   \n",
       "std             17.225524           15.812931                29.325628   \n",
       "min              1.000000            1.000000                 2.000000   \n",
       "50%              4.000000            3.000000                 7.000000   \n",
       "75%              9.000000            8.000000                20.000000   \n",
       "85%             21.000000           16.000000                41.000000   \n",
       "90%             32.000000           26.000000                58.000000   \n",
       "max            151.000000          148.000000               292.000000   \n",
       "\n",
       "       argument12_sent_num_sum_half  argument12_sent_num_diff  \\\n",
       "count                  63903.000000              63903.000000   \n",
       "mean                       9.823193                  1.274228   \n",
       "std                       14.662814                 15.282098   \n",
       "min                        1.000000               -143.000000   \n",
       "50%                        3.500000                  0.000000   \n",
       "75%                       10.000000                  4.000000   \n",
       "85%                       20.500000                  7.000000   \n",
       "90%                       29.000000                 12.000000   \n",
       "max                      146.000000                129.000000   \n",
       "\n",
       "       argument12_sent_num_diff_abs  \n",
       "count                  63903.000000  \n",
       "mean                       7.758337  \n",
       "std                       13.227754  \n",
       "min                        0.000000  \n",
       "50%                        3.000000  \n",
       "75%                        7.000000  \n",
       "85%                       14.000000  \n",
       "90%                       22.000000  \n",
       "max                      143.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_traindev_df.describe(percentiles=[.75, .85, .90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T17:29:42.239281Z",
     "start_time": "2019-12-17T17:29:42.183200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_sum</th>\n",
       "      <th>argument12_len_sum_half</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "      <th>argument1_sent_num</th>\n",
       "      <th>argument2_sent_num</th>\n",
       "      <th>argument12_sent_num_sum</th>\n",
       "      <th>argument12_sent_num_sum_half</th>\n",
       "      <th>argument12_sent_num_diff</th>\n",
       "      <th>argument12_sent_num_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "      <td>63903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>252.189647</td>\n",
       "      <td>219.179303</td>\n",
       "      <td>471.368950</td>\n",
       "      <td>235.684475</td>\n",
       "      <td>33.010344</td>\n",
       "      <td>190.980486</td>\n",
       "      <td>10.460307</td>\n",
       "      <td>9.186079</td>\n",
       "      <td>19.646386</td>\n",
       "      <td>9.823193</td>\n",
       "      <td>1.274228</td>\n",
       "      <td>7.758337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>425.471105</td>\n",
       "      <td>393.925258</td>\n",
       "      <td>730.211134</td>\n",
       "      <td>365.105567</td>\n",
       "      <td>373.091463</td>\n",
       "      <td>322.199974</td>\n",
       "      <td>17.225524</td>\n",
       "      <td>15.812931</td>\n",
       "      <td>29.325628</td>\n",
       "      <td>14.662814</td>\n",
       "      <td>15.282098</td>\n",
       "      <td>13.227754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2837.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-143.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>-58.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>222.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>469.000000</td>\n",
       "      <td>234.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2825.000000</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>4998.000000</td>\n",
       "      <td>2499.000000</td>\n",
       "      <td>2724.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_sum  \\\n",
       "count   63903.000000   63903.000000        63903.000000   \n",
       "mean      252.189647     219.179303          471.368950   \n",
       "std       425.471105     393.925258          730.211134   \n",
       "min         3.000000       4.000000            8.000000   \n",
       "25%        15.000000      14.000000           80.000000   \n",
       "50%        85.000000      73.000000          164.000000   \n",
       "75%       222.000000     179.000000          469.000000   \n",
       "max      2825.000000    2964.000000         4998.000000   \n",
       "\n",
       "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \\\n",
       "count             63903.000000         63903.000000             63903.000000   \n",
       "mean                235.684475            33.010344               190.980486   \n",
       "std                 365.105567           373.091463               322.199974   \n",
       "min                   4.000000         -2837.000000                 0.000000   \n",
       "25%                  40.000000           -58.000000                23.000000   \n",
       "50%                  82.000000             2.000000                75.000000   \n",
       "75%                 234.500000            91.000000               178.000000   \n",
       "max                2499.000000          2724.000000              2837.000000   \n",
       "\n",
       "       argument1_sent_num  argument2_sent_num  argument12_sent_num_sum  \\\n",
       "count        63903.000000        63903.000000             63903.000000   \n",
       "mean            10.460307            9.186079                19.646386   \n",
       "std             17.225524           15.812931                29.325628   \n",
       "min              1.000000            1.000000                 2.000000   \n",
       "25%              1.000000            1.000000                 4.000000   \n",
       "50%              4.000000            3.000000                 7.000000   \n",
       "75%              9.000000            8.000000                20.000000   \n",
       "max            151.000000          148.000000               292.000000   \n",
       "\n",
       "       argument12_sent_num_sum_half  argument12_sent_num_diff  \\\n",
       "count                  63903.000000              63903.000000   \n",
       "mean                       9.823193                  1.274228   \n",
       "std                       14.662814                 15.282098   \n",
       "min                        1.000000               -143.000000   \n",
       "25%                        2.000000                 -2.000000   \n",
       "50%                        3.500000                  0.000000   \n",
       "75%                       10.000000                  4.000000   \n",
       "max                      146.000000                129.000000   \n",
       "\n",
       "       argument12_sent_num_diff_abs  \n",
       "count                  63903.000000  \n",
       "mean                       7.758337  \n",
       "std                       13.227754  \n",
       "min                        0.000000  \n",
       "25%                        1.000000  \n",
       "50%                        3.000000  \n",
       "75%                        7.000000  \n",
       "max                      143.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T20:45:48.529725Z",
     "start_time": "2019-12-17T20:45:48.407448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abortion \n",
      " ######################################## \n",
      "        argument1_len  argument2_len  argument12_len_sum  \\\n",
      "count   40840.000000   40840.000000        40840.000000   \n",
      "mean      264.362659     227.446572          491.809231   \n",
      "std       437.414485     404.893154          749.603628   \n",
      "min         3.000000       4.000000            8.000000   \n",
      "50%        83.000000      71.000000          161.000000   \n",
      "75%       258.000000     195.000000          537.000000   \n",
      "80%       372.000000     289.000000          746.000000   \n",
      "85%       541.150000     429.000000         1043.000000   \n",
      "90%       845.000000     680.000000         1528.000000   \n",
      "max      2825.000000    2964.000000         4998.000000   \n",
      "\n",
      "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \\\n",
      "count             40840.000000         40840.000000             40840.000000   \n",
      "mean                245.904616            36.916087               198.034794   \n",
      "std                 374.801814           385.531056               332.833722   \n",
      "min                   4.000000         -2837.000000                 0.000000   \n",
      "50%                  80.500000             3.000000                71.000000   \n",
      "75%                 268.500000            89.000000               197.000000   \n",
      "80%                 373.000000           122.000000               268.000000   \n",
      "85%                 521.500000           198.000000               382.000000   \n",
      "90%                 764.000000           339.000000               563.000000   \n",
      "max                2499.000000          2365.000000              2837.000000   \n",
      "\n",
      "       argument1_sent_num  argument2_sent_num  argument12_sent_num_sum  \\\n",
      "count        40840.000000        40840.000000             40840.000000   \n",
      "mean            10.865548            9.439863                20.305411   \n",
      "std             17.818285           16.250809                30.184747   \n",
      "min              1.000000            1.000000                 2.000000   \n",
      "50%              3.000000            3.000000                 7.000000   \n",
      "75%             11.000000            8.000000                22.000000   \n",
      "80%             14.000000           12.000000                31.000000   \n",
      "85%             23.000000           18.000000                43.000000   \n",
      "90%             34.000000           27.000000                61.000000   \n",
      "max            151.000000          148.000000               292.000000   \n",
      "\n",
      "       argument12_sent_num_sum_half  argument12_sent_num_diff  \\\n",
      "count                  40840.000000              40840.000000   \n",
      "mean                      10.152706                  1.425686   \n",
      "std                       15.092374                 15.875805   \n",
      "min                        1.000000               -143.000000   \n",
      "50%                        3.500000                  0.000000   \n",
      "75%                       11.000000                  3.000000   \n",
      "80%                       15.500000                  5.000000   \n",
      "85%                       21.500000                  8.000000   \n",
      "90%                       30.500000                 14.000000   \n",
      "max                      146.000000                129.000000   \n",
      "\n",
      "       argument12_sent_num_diff_abs  \n",
      "count                  40840.000000  \n",
      "mean                       8.021915  \n",
      "std                       13.773930  \n",
      "min                        0.000000  \n",
      "50%                        3.000000  \n",
      "75%                        8.000000  \n",
      "80%                       11.000000  \n",
      "85%                       15.000000  \n",
      "90%                       24.000000  \n",
      "max                      143.000000   \n",
      "\n",
      "\n",
      "gay marriage \n",
      " ######################################## \n",
      "        argument1_len  argument2_len  argument12_len_sum  \\\n",
      "count   23063.000000   23063.000000        23063.000000   \n",
      "mean      230.633656     204.539609          435.173265   \n",
      "std       402.562537     373.274100          693.082367   \n",
      "min         4.000000       4.000000            8.000000   \n",
      "50%        92.000000      75.000000          168.000000   \n",
      "75%       190.000000     165.000000          348.000000   \n",
      "80%       225.600000     203.000000          545.600000   \n",
      "85%       418.000000     334.000000          866.000000   \n",
      "90%       729.800000     602.600000         1356.800000   \n",
      "max      2776.000000    2743.000000         4946.000000   \n",
      "\n",
      "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \\\n",
      "count             23063.000000         23063.000000             23063.000000   \n",
      "mean                217.586632            26.094047               178.488705   \n",
      "std                 346.541183           349.881597               302.057050   \n",
      "min                   4.000000         -2202.000000                 0.000000   \n",
      "50%                  84.000000             2.000000                84.000000   \n",
      "75%                 174.000000            95.000000               159.000000   \n",
      "80%                 272.800000           117.000000               195.000000   \n",
      "85%                 433.000000           157.000000               288.000000   \n",
      "90%                 678.400000           230.000000               483.800000   \n",
      "max                2473.000000          2724.000000              2724.000000   \n",
      "\n",
      "       argument1_sent_num  argument2_sent_num  argument12_sent_num_sum  \\\n",
      "count        23063.000000        23063.000000             23063.000000   \n",
      "mean             9.742705            8.736678                18.479383   \n",
      "std             16.097854           14.996036                27.701299   \n",
      "min              1.000000            1.000000                 2.000000   \n",
      "50%              4.000000            4.000000                 8.000000   \n",
      "75%              8.000000            7.000000                16.000000   \n",
      "80%             10.000000            9.000000                23.000000   \n",
      "85%             17.000000           14.000000                35.000000   \n",
      "90%             29.000000           24.000000                53.000000   \n",
      "max            145.000000          145.000000               285.000000   \n",
      "\n",
      "       argument12_sent_num_sum_half  argument12_sent_num_diff  \\\n",
      "count                  23063.000000              23063.000000   \n",
      "mean                       9.239691                  1.006027   \n",
      "std                       13.850650                 14.166227   \n",
      "min                        1.000000               -110.000000   \n",
      "50%                        4.000000                  0.000000   \n",
      "75%                        8.000000                  4.000000   \n",
      "80%                       11.500000                  5.000000   \n",
      "85%                       17.500000                  7.000000   \n",
      "90%                       26.500000                 10.000000   \n",
      "max                      142.500000                128.000000   \n",
      "\n",
      "       argument12_sent_num_diff_abs  \n",
      "count                  23063.000000  \n",
      "mean                       7.291593  \n",
      "std                       12.187063  \n",
      "min                        0.000000  \n",
      "50%                        3.000000  \n",
      "75%                        7.000000  \n",
      "80%                        9.000000  \n",
      "85%                       12.000000  \n",
      "90%                       20.000000  \n",
      "max                      128.000000   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for v, sdf in within_traindev_df.groupby(\"tag\"):\n",
    "    print(v, \"\\n\", \"#\" * 40, \"\\n\", sdf.describe(percentiles=[.75, .80, .85, .90]), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T16:41:53.509656Z",
     "start_time": "2019-12-17T16:41:52.268974Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "if stats:\n",
    "    from utils_data import get_overview, plot_lengths\n",
    "\n",
    "    get_overview(within_traindev_df, description=\"within_traindev_df\")\n",
    "    get_overview(cross_traindev_df, description=\"cross_traindev_df\")\n",
    "    get_overview(artificial_evalset_df, description=\"artificial_evalset_df\")\n",
    "\n",
    "    print()\n",
    "    print(within_traindev_df.describe())\n",
    "    print()\n",
    "    print(cross_traindev_df.describe())\n",
    "    print()\n",
    "    print(artificial_evalset_df.describe())\n",
    "    \n",
    "    plot_lengths(within_traindev_df, slice(None, None, 500), title='Length of arguments within train/dev, every 500')\n",
    "    plot_lengths(cross_traindev_df, slice(None, None, 500), title='Length of arguments cross train/dev, every 500')\n",
    "    plot_lengths(within_test_df, slice(None, None, 1), title='Length of arguments within test')\n",
    "    plot_lengths(artificial_evalset_df, slice(None, None, 1), title='Length of arguments artificial evalset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T15:27:32.390627Z",
     "start_time": "2019-12-10T15:27:32.388673Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! head -n 5 data/same-side-classification/within-topic/test.csv\n",
    "# ! head -n 5 data/same-side-classification/within-topic/within_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T15:27:33.260885Z",
     "start_time": "2019-12-10T15:27:33.258465Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "if stats:\n",
    "    distinct_cross_train_df, distinct_cross_dev_df = load_distinct_df_raw(\"cross\")\n",
    "    distinct_within_train_df, distinct_within_dev_df = load_distinct_df_raw(\"within\")\n",
    "\n",
    "    get_overview(distinct_cross_train_df, task=\"same-side distinct cross train\")\n",
    "    get_overview(distinct_cross_dev_df, task=\"same-side distinct cross dev\")\n",
    "    get_overview(distinct_within_train_df, task=\"same-side distinct within train\")\n",
    "    get_overview(distinct_within_dev_df, task=\"same-side distinct within dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T15:27:34.092133Z",
     "start_time": "2019-12-10T15:27:34.090187Z"
    },
    "code_folding": [],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils_data import get_train_test_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### within as a dev set for cross etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T15:27:34.904950Z",
     "start_time": "2019-12-10T15:27:34.903279Z"
    },
    "code_folding": [],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils_data import split_within_by_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "- https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### my own `BERTDatasetTransform` for extracting chunks from arguments or last part etc.\n",
    "\n",
    "```python\n",
    "transform = dataset.BERTDatasetTransform(bert_tokenizer, 512,\n",
    "                                         labels=['0', '1'],\n",
    "                                         label_dtype='int32',\n",
    "                                         pad=True,\n",
    "                                         pair=True)\n",
    "```\n",
    "\n",
    "http://localhost:9001/edit/bert/dataset.py @454\n",
    "```python\n",
    "# substitute with my own (e. g. last part, many parts etc.)\n",
    "def __init__(...):\n",
    "    self._bert_xform = BERTSentenceTransform(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "```\n",
    "https://gluon-nlp.mxnet.io/master/_modules/gluonnlp/data/transforms.html#BERTSentenceTransform\n",
    "```python\n",
    "# substitute with my own (e. g. only last part (trim from start))\n",
    "self._truncate_seq_pair(tokens_a, tokens_b, self._max_seq_length - 3)\n",
    "```\n",
    "\n",
    "https://mxnet.incubator.apache.org/_modules/mxnet/gluon/data/dataset.html#Dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T15:27:35.765707Z",
     "start_time": "2019-12-10T15:27:35.740210Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from utils_gluon import MyBERTDataset\n",
    "from utils_gluon import LastPartBERTDatasetTransform\n",
    "from utils_gluon import FirstAndLastPartBERTDatasetTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T15:27:36.590042Z",
     "start_time": "2019-12-10T15:27:36.587945Z"
    },
    "code_folding": [],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils_gluon import setup_bert\n",
    "from utils_gluon import setup_bert_epi128bce, setup_bert_epi512bce\n",
    "from utils_gluon import setup_bert_pro128bce, setup_bert_pro512bce\n",
    "from utils_gluon import setup_bert_proepi512bce\n",
    "\n",
    "from utils_gluon import transform_dataset\n",
    "from utils_gluon import predict_out_to_ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-GPU?\n",
    "- https://gluon.mxnet.io/chapter07_distributed-learning/multiple-gpus-gluon.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T15:27:37.434725Z",
     "start_time": "2019-12-10T15:27:37.432019Z"
    },
    "code_folding": [],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from utils_gluon import train, train_proepi\n",
    "from utils_gluon import train_multi, train_multi_proepi\n",
    "\n",
    "from utils_gluon import predict, predict_proepi\n",
    "from utils_gluon import predict_unknown, predict_unknown_proepi\n",
    "\n",
    "from utils_gluon import print_infos, print_infos_proepi\n",
    "from utils_gluon import plot_train_stats\n",
    "\n",
    "from utils_gluon import compute_metrics, compute_metrics_old, heatconmat, report_training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B.1) Within distinct datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = load_distinct_data(\"within\")\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    # print_infos(vocabulary, data_train_raw, data_train)\n",
    "\n",
    "run_name = \"within_traindev_epi512_BCE_distinct\"\n",
    "! mkdir data/within_traindev_epi512_BCE_distinct\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    # print_infos(vocabulary, data_dev_raw, data_dev)\n",
    "\n",
    "for epoch_id in range(3):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - distinct within BCE epilog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"within_traindev_epi512_BCE_distinct\"\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - distinct within BCE epilog\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:00:57.187743\n",
    "\n",
    "Accuracy: 0.6220657276995305\n",
    "\n",
    "Confusion Matrix:\n",
    "[[368 224]\n",
    " [259 427]]\n",
    "\n",
    "Accuracy:  0.62 \n",
    "\n",
    "Report for [BERTClassifier - distinct within 512 BCE epilog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.59      0.62      0.60       592\n",
    "           1       0.66      0.62      0.64       686\n",
    "\n",
    "    accuracy                           0.62      1278\n",
    "   macro avg       0.62      0.62      0.62      1278\n",
    "weighted avg       0.62      0.62      0.62      1278\n",
    "\n",
    "Time for [6 - evaluate]: 0:00:57.491961\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B.2) Cross distinct datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     13,
     17
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = load_distinct_data(\"cross\")\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    # print_infos(vocabulary, data_train_raw, data_train)\n",
    "\n",
    "run_name = \"cross_traindev_epi512_BCE_distinct\"\n",
    "! mkdir data/cross_traindev_epi512_BCE_distinct\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    # print_infos(vocabulary, data_dev_raw, data_dev)\n",
    "\n",
    "for epoch_id in range(3):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - distinct cross BCE epilog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"cross_traindev_epi512_BCE_distinct\"\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - distinct cross BCE epilog\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:02:32.090311\n",
    "Accuracy: 0.7154929577464789\n",
    "\n",
    "Confusion Matrix:\n",
    "[[1449  386]\n",
    " [ 523  837]]\n",
    "\n",
    "Accuracy:  0.72 \n",
    "\n",
    "Report for [BERTClassifier - distinct cross BCE 512 epilog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.73      0.79      0.76      1835\n",
    "           1       0.68      0.62      0.65      1360\n",
    "\n",
    "    accuracy                           0.72      3195\n",
    "   macro avg       0.71      0.70      0.70      3195\n",
    "weighted avg       0.71      0.72      0.71      3195\n",
    "\n",
    "Time for [6 - evaluate]: 0:02:32.553864\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics([[1449, 386], [523, 837]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (B.3) within, cluster distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T20:20:56.038028Z",
     "start_time": "2019-12-08T20:20:55.957736Z"
    }
   },
   "outputs": [],
   "source": [
    "fn_cluster_distinct_within = \"data/distinct_sets_gw/within_split_by_clusters.pkl\"\n",
    "\n",
    "with open(fn_cluster_distinct_within, \"rb\") as fp:\n",
    "    within_train_df = pickle.load(fp)\n",
    "    within_dev_df = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     15,
     22,
     26
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load within cluster distinct test/train\"):\n",
    "    fn_cluster_distinct_within = \"data/distinct_sets_gw/within_split_by_clusters.pkl\"\n",
    "\n",
    "    with open(fn_cluster_distinct_within, \"rb\") as fp:\n",
    "        within_train_df = pickle.load(fp)\n",
    "        within_dev_df = pickle.load(fp)\n",
    "    \n",
    "    X_train = within_train_df[names_columns_X]\n",
    "    y_train = within_train_df[names_columns_y]\n",
    "    X_dev = within_dev_df[names_columns_X]\n",
    "    y_dev = within_dev_df[names_columns_y]\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    # print_infos(vocabulary, data_train_raw, data_train)\n",
    "\n",
    "run_name = \"within_traindev_epi512_BCE_distinct_cluster\"\n",
    "! mkdir data/within_traindev_epi512_BCE_distinct_cluster\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    # print_infos(vocabulary, data_dev_raw, data_dev)\n",
    "\n",
    "for epoch_id in range(3):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - distinct cluster within BCE 512 epilog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T20:21:35.555051Z",
     "start_time": "2019-12-08T20:21:31.968366Z"
    },
    "code_folding": [
     0,
     15
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load within cluster distinct test/train\"):\n",
    "    fn_cluster_distinct_within = \"data/distinct_sets_gw/within_split_by_clusters.pkl\"\n",
    "\n",
    "    with open(fn_cluster_distinct_within, \"rb\") as fp:\n",
    "        within_train_df = pickle.load(fp)\n",
    "        within_dev_df = pickle.load(fp)\n",
    "    \n",
    "    X_train = within_train_df[names_columns_X]\n",
    "    y_train = within_train_df[names_columns_y]\n",
    "    X_dev = within_dev_df[names_columns_X]\n",
    "    y_dev = within_dev_df[names_columns_y]\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T20:39:06.129156Z",
     "start_time": "2019-12-08T20:21:46.016247Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"within_traindev_epi512_BCE_distinct_cluster\"\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - distinct cluster within BCE 512 epilog (3 epochs)\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:17:08.991174\n",
    "Accuracy: 0.6497847321883247\n",
    "\n",
    "Confusion Matrix:\n",
    "[[8815 3593]\n",
    " [3972 5221]]\n",
    "\n",
    "Accuracy:  0.65 \n",
    "\n",
    "Report for [BERTClassifier - distinct cluster within BCE 512 epilog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.69      0.71      0.70     12408\n",
    "           1       0.59      0.57      0.58      9193\n",
    "\n",
    "    accuracy                           0.65     21601\n",
    "   macro avg       0.64      0.64      0.64     21601\n",
    "weighted avg       0.65      0.65      0.65     21601\n",
    "\n",
    "Time for [6 - evaluate]: 0:17:11.581655\n",
    "```\n",
    "\n",
    "```\n",
    "#### new metrics, macro\n",
    "Time for [prediction]: 0:17:17.679074\n",
    "Accuracy: 0.6497847321883247\n",
    "\n",
    "2019-12-08 21:39:06,126 : INFO : wrote 363 events to disk\n",
    "\n",
    "Confusion Matrix:\n",
    "[[8815 3593]\n",
    " [3972 5221]]\n",
    "\n",
    "  accuracy: 0.650\n",
    " precision: 0.641\n",
    "    recall: 0.639\n",
    "  f1-score: 0.640\n",
    "\n",
    "Accuracy:  0.65 \n",
    "\n",
    "Report for [BERTClassifier - distinct cluster within BCE 512 epilog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.69      0.71      0.70     12408\n",
    "           1       0.59      0.57      0.58      9193\n",
    "\n",
    "    accuracy                           0.65     21601\n",
    "   macro avg       0.64      0.64      0.64     21601\n",
    "weighted avg       0.65      0.65      0.65     21601\n",
    "\n",
    "Time for [6 - evaluate]: 0:17:20.109318\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics([[8815, 3593], [3972, 5221]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistics for cluster distinct set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T21:00:41.743350Z",
     "start_time": "2019-12-08T20:47:46.197297Z"
    },
    "code_folding": [
     1,
     9,
     30,
     48
    ]
   },
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "_, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                    dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                    pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                                    use_decoder=False, use_classifier=False)\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "tokenizer = bert_tokenizer\n",
    "\n",
    "# tokenizer from BERT\n",
    "def tokenize_arguments(row):\n",
    "    # tokenize\n",
    "    row['argument1_tokens'] = tokenizer(row['argument1'])\n",
    "    row['argument2_tokens'] = tokenizer(row['argument2'])\n",
    "\n",
    "    # count tokens\n",
    "    row['argument1_len'] = len(row['argument1_tokens'])\n",
    "    row['argument2_len'] = len(row['argument2_tokens'])\n",
    "    # token number diff\n",
    "    row['argument12_len_sum'] = row['argument1_len'] + row['argument2_len']\n",
    "    row['argument12_len_sum_half'] = row['argument12_len_sum'] / 2\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    row['argument12_len_diff_abs'] = np.abs(row['argument12_len_diff'])\n",
    "    return row\n",
    "\n",
    "within_train_df = within_train_df.progress_apply(tokenize_arguments, axis=1)\n",
    "within_dev_df = within_dev_df.progress_apply(tokenize_arguments, axis=1)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# nltk.download('punct')\n",
    "\n",
    "def sentenize_arguments(row):\n",
    "    # tokenize\n",
    "    row['argument1_sentences'] = sent_tokenize(row['argument1'])\n",
    "    row['argument2_sentences'] = sent_tokenize(row['argument2'])\n",
    "\n",
    "    # count tokens\n",
    "    row['argument1_sent_num'] = len(row['argument1_sentences'])\n",
    "    row['argument2_sent_num'] = len(row['argument2_sentences'])\n",
    "    # token number diff\n",
    "    row['argument12_sent_num_sum'] = row['argument1_sent_num'] + row['argument2_sent_num']\n",
    "    row['argument12_sent_num_sum_half'] = row['argument12_sent_num_sum'] / 2\n",
    "    row['argument12_sent_num_diff'] = row['argument1_sent_num'] - row['argument2_sent_num']\n",
    "    row['argument12_sent_num_diff_abs'] = np.abs(row['argument12_sent_num_diff'])\n",
    "    return row\n",
    "\n",
    "within_train_df = within_train_df.progress_apply(sentenize_arguments, axis=1)\n",
    "within_dev_df = within_dev_df.progress_apply(sentenize_arguments, axis=1)\n",
    "\n",
    "def get_overview(df, task='same-side', class_name='is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task)\n",
    "    print('=' * 40, '\\n')\n",
    "\n",
    "    print('Total instances: ', total)\n",
    "    print('\\n')\n",
    "\n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        print('')\n",
    "        print('\\t\\tUnique argument1:', len(tag_df['argument1'].unique()))\n",
    "        print('\\t\\tUnique argument2:', len(tag_df['argument2'].unique()))\n",
    "        arguments = np.concatenate([tag_df['argument1'].values, tag_df['argument2'].values])\n",
    "        print('\\t\\tUnique total arguments:', len(set(list(arguments))), '\\n')\n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t', is_same_side, ': ', len(side_df), ' instances')\n",
    "    print('\\n')\n",
    "\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "            print('\\t\\tUnique argument1:', len(class_df['argument1'].unique()))\n",
    "            print('\\t\\tUnique argument2:', len(class_df['argument2'].unique()))\n",
    "            arguments = np.concatenate([class_df['argument1'].values, class_df['argument2'].values])\n",
    "            print('\\t\\tUnique total arguments:', len(set(list(arguments))), '\\n')\n",
    "        print('\\n')\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))), '\\n')\n",
    "\n",
    "    print('-' * 40, '\\n')\n",
    "\n",
    "    arguments_length_lst = [x for x in df['argument1_len'].values]\n",
    "    arguments_length_lst.extend([x for x in df['argument2_len'].values])\n",
    "    print('Words:')\n",
    "    print('\\tshortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('\\tlongest argument:', max(arguments_length_lst), ' words')\n",
    "    print('\\targument average length:', np.mean(arguments_length_lst),\n",
    "          ' words')\n",
    "\n",
    "    arguments_sent_length_lst = [x for x in df['argument1_sent_num'].values]\n",
    "    arguments_sent_length_lst.extend([x for x in df['argument2_sent_num'].values])\n",
    "    print('Sentences:')\n",
    "    print('\\tshortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\tlongest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\targument average length:', np.mean(arguments_sent_length_lst),\n",
    "          ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T21:08:52.094441Z",
     "start_time": "2019-12-08T21:08:14.896370Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "within_train_df = within_train_df.progress_apply(add_tag, axis=1)\n",
    "within_dev_df = within_dev_df.progress_apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T21:13:32.566591Z",
     "start_time": "2019-12-08T21:13:31.944977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task:  cluster distinct train\n",
      "======================================== \n",
      "\n",
      "Total instances:  42302\n",
      "\n",
      "\n",
      "For each topic:\n",
      "abortion :  26136  instances\n",
      "\n",
      "\t\tUnique argument1: 1107\n",
      "\t\tUnique argument2: 1105\n",
      "\t\tUnique total arguments: 1303 \n",
      "\n",
      "\t\t False :  11543  instances\n",
      "\t\t True :  14593  instances\n",
      "gay marriage :  16166  instances\n",
      "\n",
      "\t\tUnique argument1: 630\n",
      "\t\tUnique argument2: 645\n",
      "\t\tUnique total arguments: 742 \n",
      "\n",
      "\t\t False :  5841  instances\n",
      "\t\t True :  10325  instances\n",
      "\n",
      "\n",
      "For each class value:\n",
      "False :  17384  instances\n",
      "\t\tUnique argument1: 1629\n",
      "\t\tUnique argument2: 1611\n",
      "\t\tUnique total arguments: 1999 \n",
      "\n",
      "True :  24918  instances\n",
      "\t\tUnique argument1: 1462\n",
      "\t\tUnique argument2: 1456\n",
      "\t\tUnique total arguments: 1907 \n",
      "\n",
      "\n",
      "\n",
      "Unique argument1: 1735\n",
      "Unique argument2: 1747\n",
      "Unique total arguments: 2042 \n",
      "\n",
      "---------------------------------------- \n",
      "\n",
      "Words:\n",
      "\tshortest argument: 4  words\n",
      "\tlongest argument: 2540  words\n",
      "\targument average length: 97.98490615100941  words\n",
      "Sentences:\n",
      "\tshortest argument: 1  sentences\n",
      "\tlongest argument: 145  sentences\n",
      "\targument average length: 4.172391376294265  sentences\n",
      "Task:  cluster distinct dev\n",
      "======================================== \n",
      "\n",
      "Total instances:  21601\n",
      "\n",
      "\n",
      "For each topic:\n",
      "abortion :  14704  instances\n",
      "\n",
      "\t\tUnique argument1: 6000\n",
      "\t\tUnique argument2: 5963\n",
      "\t\tUnique total arguments: 7889 \n",
      "\n",
      "\t\t False :  8463  instances\n",
      "\t\t True :  6241  instances\n",
      "gay marriage :  6897  instances\n",
      "\n",
      "\t\tUnique argument1: 2776\n",
      "\t\tUnique argument2: 2747\n",
      "\t\tUnique total arguments: 3649 \n",
      "\n",
      "\t\t False :  3945  instances\n",
      "\t\t True :  2952  instances\n",
      "\n",
      "\n",
      "For each class value:\n",
      "False :  12408  instances\n",
      "\t\tUnique argument1: 7816\n",
      "\t\tUnique argument2: 7516\n",
      "\t\tUnique total arguments: 10939 \n",
      "\n",
      "True :  9193  instances\n",
      "\t\tUnique argument1: 6198\n",
      "\t\tUnique argument2: 6189\n",
      "\t\tUnique total arguments: 9984 \n",
      "\n",
      "\n",
      "\n",
      "Unique argument1: 8773\n",
      "Unique argument2: 8706\n",
      "Unique total arguments: 11532 \n",
      "\n",
      "---------------------------------------- \n",
      "\n",
      "Words:\n",
      "\tshortest argument: 3  words\n",
      "\tlongest argument: 2964  words\n",
      "\targument average length: 505.34639600018517  words\n",
      "Sentences:\n",
      "\tshortest argument: 1  sentences\n",
      "\tlongest argument: 151  sentences\n",
      "\targument average length: 20.889356974214156  sentences\n"
     ]
    }
   ],
   "source": [
    "get_overview(within_train_df, task=\"cluster distinct train\")\n",
    "get_overview(within_dev_df, task=\"cluster distinct dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T21:16:58.506751Z",
     "start_time": "2019-12-08T21:16:58.438765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_sum</th>\n",
       "      <th>argument12_len_sum_half</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "      <th>argument1_sent_num</th>\n",
       "      <th>argument2_sent_num</th>\n",
       "      <th>argument12_sent_num_sum</th>\n",
       "      <th>argument12_sent_num_sum_half</th>\n",
       "      <th>argument12_sent_num_diff</th>\n",
       "      <th>argument12_sent_num_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "      <td>42302.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>104.872914</td>\n",
       "      <td>91.096898</td>\n",
       "      <td>195.969812</td>\n",
       "      <td>97.984906</td>\n",
       "      <td>13.776015</td>\n",
       "      <td>89.326769</td>\n",
       "      <td>4.377405</td>\n",
       "      <td>3.967377</td>\n",
       "      <td>8.344783</td>\n",
       "      <td>4.172391</td>\n",
       "      <td>0.410028</td>\n",
       "      <td>3.387618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>226.107466</td>\n",
       "      <td>207.270436</td>\n",
       "      <td>393.111390</td>\n",
       "      <td>196.555695</td>\n",
       "      <td>183.397587</td>\n",
       "      <td>160.763795</td>\n",
       "      <td>8.400407</td>\n",
       "      <td>7.779184</td>\n",
       "      <td>14.585351</td>\n",
       "      <td>7.292676</td>\n",
       "      <td>7.030833</td>\n",
       "      <td>6.174505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>-2274.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2341.000000</td>\n",
       "      <td>2540.000000</td>\n",
       "      <td>4579.000000</td>\n",
       "      <td>2289.500000</td>\n",
       "      <td>2277.000000</td>\n",
       "      <td>2277.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>142.500000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>124.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_sum  \\\n",
       "count   42302.000000   42302.000000        42302.000000   \n",
       "mean      104.872914      91.096898          195.969812   \n",
       "std       226.107466     207.270436          393.111390   \n",
       "min         4.000000       4.000000            9.000000   \n",
       "25%        12.000000      12.000000           50.000000   \n",
       "50%        53.000000      30.000000          113.000000   \n",
       "75%       112.000000     100.000000          188.000000   \n",
       "max      2341.000000    2540.000000         4579.000000   \n",
       "\n",
       "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \\\n",
       "count             42302.000000         42302.000000             42302.000000   \n",
       "mean                 97.984906            13.776015                89.326769   \n",
       "std                 196.555695           183.397587               160.763795   \n",
       "min                   4.500000         -2274.000000                 0.000000   \n",
       "25%                  25.000000           -45.000000                 9.000000   \n",
       "50%                  56.500000             1.000000                55.000000   \n",
       "75%                  94.000000            64.000000               103.000000   \n",
       "max                2289.500000          2277.000000              2277.000000   \n",
       "\n",
       "       argument1_sent_num  argument2_sent_num  argument12_sent_num_sum  \\\n",
       "count        42302.000000        42302.000000             42302.000000   \n",
       "mean             4.377405            3.967377                 8.344783   \n",
       "std              8.400407            7.779184                14.585351   \n",
       "min              1.000000            1.000000                 2.000000   \n",
       "25%              1.000000            1.000000                 3.000000   \n",
       "50%              2.000000            1.000000                 5.000000   \n",
       "75%              5.000000            5.000000                 8.000000   \n",
       "max            145.000000          145.000000               285.000000   \n",
       "\n",
       "       argument12_sent_num_sum_half  argument12_sent_num_diff  \\\n",
       "count                  42302.000000              42302.000000   \n",
       "mean                       4.172391                  0.410028   \n",
       "std                        7.292676                  7.030833   \n",
       "min                        1.000000                -98.000000   \n",
       "25%                        1.500000                 -2.000000   \n",
       "50%                        2.500000                  0.000000   \n",
       "75%                        4.000000                  2.000000   \n",
       "max                      142.500000                124.000000   \n",
       "\n",
       "       argument12_sent_num_diff_abs  \n",
       "count                  42302.000000  \n",
       "mean                       3.387618  \n",
       "std                        6.174505  \n",
       "min                        0.000000  \n",
       "25%                        0.000000  \n",
       "50%                        2.000000  \n",
       "75%                        4.000000  \n",
       "max                      124.000000  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T21:17:48.729596Z",
     "start_time": "2019-12-08T21:17:48.672039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_sum</th>\n",
       "      <th>argument12_len_sum_half</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "      <th>argument1_sent_num</th>\n",
       "      <th>argument2_sent_num</th>\n",
       "      <th>argument12_sent_num_sum</th>\n",
       "      <th>argument12_sent_num_sum_half</th>\n",
       "      <th>argument12_sent_num_diff</th>\n",
       "      <th>argument12_sent_num_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "      <td>21601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>540.685200</td>\n",
       "      <td>470.007592</td>\n",
       "      <td>1010.692792</td>\n",
       "      <td>505.346396</td>\n",
       "      <td>70.677608</td>\n",
       "      <td>390.052544</td>\n",
       "      <td>22.372668</td>\n",
       "      <td>19.406046</td>\n",
       "      <td>41.778714</td>\n",
       "      <td>20.889357</td>\n",
       "      <td>2.966622</td>\n",
       "      <td>16.317670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>556.501512</td>\n",
       "      <td>529.055808</td>\n",
       "      <td>914.000069</td>\n",
       "      <td>457.000035</td>\n",
       "      <td>586.337646</td>\n",
       "      <td>443.440368</td>\n",
       "      <td>22.918281</td>\n",
       "      <td>21.527845</td>\n",
       "      <td>37.250610</td>\n",
       "      <td>18.625305</td>\n",
       "      <td>24.285458</td>\n",
       "      <td>18.229263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2837.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-143.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>101.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>148.500000</td>\n",
       "      <td>-142.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>323.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>708.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>216.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>838.000000</td>\n",
       "      <td>674.000000</td>\n",
       "      <td>1507.000000</td>\n",
       "      <td>753.500000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>555.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2825.000000</td>\n",
       "      <td>2964.000000</td>\n",
       "      <td>4998.000000</td>\n",
       "      <td>2499.000000</td>\n",
       "      <td>2724.000000</td>\n",
       "      <td>2837.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_sum  \\\n",
       "count   21601.000000   21601.000000        21601.000000   \n",
       "mean      540.685200     470.007592         1010.692792   \n",
       "std       556.501512     529.055808          914.000069   \n",
       "min         3.000000       4.000000            8.000000   \n",
       "25%       101.000000      81.000000          297.000000   \n",
       "50%       323.000000     239.000000          708.000000   \n",
       "75%       838.000000     674.000000         1507.000000   \n",
       "max      2825.000000    2964.000000         4998.000000   \n",
       "\n",
       "       argument12_len_sum_half  argument12_len_diff  argument12_len_diff_abs  \\\n",
       "count             21601.000000         21601.000000             21601.000000   \n",
       "mean                505.346396            70.677608               390.052544   \n",
       "std                 457.000035           586.337646               443.440368   \n",
       "min                   4.000000         -2837.000000                 0.000000   \n",
       "25%                 148.500000          -142.000000                65.000000   \n",
       "50%                 354.000000            22.000000               216.000000   \n",
       "75%                 753.500000           296.000000               555.000000   \n",
       "max                2499.000000          2724.000000              2837.000000   \n",
       "\n",
       "       argument1_sent_num  argument2_sent_num  argument12_sent_num_sum  \\\n",
       "count        21601.000000        21601.000000             21601.000000   \n",
       "mean            22.372668           19.406046                41.778714   \n",
       "std             22.918281           21.527845                37.250610   \n",
       "min              1.000000            1.000000                 2.000000   \n",
       "25%              5.000000            4.000000                13.000000   \n",
       "50%             14.000000           10.000000                30.000000   \n",
       "75%             33.000000           27.000000                60.000000   \n",
       "max            151.000000          148.000000               292.000000   \n",
       "\n",
       "       argument12_sent_num_sum_half  argument12_sent_num_diff  \\\n",
       "count                  21601.000000              21601.000000   \n",
       "mean                      20.889357                  2.966622   \n",
       "std                       18.625305                 24.285458   \n",
       "min                        1.000000               -143.000000   \n",
       "25%                        6.500000                 -6.000000   \n",
       "50%                       15.000000                  1.000000   \n",
       "75%                       30.000000                 13.000000   \n",
       "max                      146.000000                129.000000   \n",
       "\n",
       "       argument12_sent_num_diff_abs  \n",
       "count                  21601.000000  \n",
       "mean                      16.317670  \n",
       "std                       18.229263  \n",
       "min                        0.000000  \n",
       "25%                        3.000000  \n",
       "50%                       10.000000  \n",
       "75%                       23.000000  \n",
       "max                      143.000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "within_dev_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (C.1) Within Pro 128 BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     12,
     15
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro128bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "\n",
    "run_name = \"within_traindev_pro128_BCE\"\n",
    "! mkdir data/within_traindev_pro128_BCE\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - within BCE 128 prolog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     5,
     8,
     11
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"within_traindev_pro128_BCE\"\n",
    "\n",
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro128bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within BCE 128 prolog\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:01:02.161065\n",
    "Accuracy in epoch 2: 0.8490064152714755\n",
    "Confusion Matrix:\n",
    "[[2669  290]\n",
    " [ 675 2757]]\n",
    "\n",
    "Accuracy:  0.85 \n",
    "\n",
    "Report for [BERTClassifier - within 0.1 BCE 128 prolog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.90      0.85      2959\n",
    "           1       0.90      0.80      0.85      3432\n",
    "\n",
    "    accuracy                           0.85      6391\n",
    "   macro avg       0.85      0.85      0.85      6391\n",
    "weighted avg       0.86      0.85      0.85      6391\n",
    "\n",
    "Time for [6 - evaluate - 2]: 0:01:02.227211\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:00:59.388592\n",
    "Accuracy in epoch 5: 0.8662181192301674\n",
    "Confusion Matrix:\n",
    "[[2587  372]\n",
    " [ 483 2949]]\n",
    "\n",
    "  accuracy: 0.866\n",
    " precision: 0.888\n",
    "    recall: 0.859\n",
    "  f1-score: 0.873\n",
    "\n",
    "Accuracy:  0.87 \n",
    "\n",
    "Report for [BERTClassifier - within BCE 128 prolog (5 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.87      0.86      2959\n",
    "           1       0.89      0.86      0.87      3432\n",
    "\n",
    "    accuracy                           0.87      6391\n",
    "   macro avg       0.87      0.87      0.87      6391\n",
    "weighted avg       0.87      0.87      0.87      6391\n",
    "\n",
    "Time for [6 - evaluate]: 0:00:59.567344\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (C.2) Cross Pro 128 BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     12,
     15
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro128bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "\n",
    "run_name = \"cross_traindev_pro128_BCE\"\n",
    "! mkdir data/cross_traindev_pro128_BCE\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 128 prolog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     5,
     8,
     11
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"cross_traindev_pro128_BCE\"\n",
    "\n",
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro128bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 128 prolog\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:00:58.160635\n",
    "Accuracy in epoch 4: 0.8014742014742015\n",
    "Confusion Matrix:\n",
    "[[2606  418]\n",
    " [ 794 2287]]\n",
    "\n",
    "Accuracy:  0.8 \n",
    "\n",
    "Report for [BERTClassifier - cross BCE 128 prolog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.77      0.86      0.81      3024\n",
    "           1       0.85      0.74      0.79      3081\n",
    "\n",
    "    accuracy                           0.80      6105\n",
    "   macro avg       0.81      0.80      0.80      6105\n",
    "weighted avg       0.81      0.80      0.80      6105\n",
    "\n",
    "Time for [6 - evaluate - 4]: 0:00:58.344300\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:00:59.223507\n",
    "Accuracy in epoch 4: 0.8134316134316134\n",
    "Confusion Matrix:\n",
    "[[2439  585]\n",
    " [ 554 2527]]\n",
    "\n",
    "  accuracy: 0.813\n",
    " precision: 0.812\n",
    "    recall: 0.820\n",
    "  f1-score: 0.816\n",
    "\n",
    "Accuracy:  0.81 \n",
    "\n",
    "Report for [BERTClassifier - cross BCE 128 prolog (5 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.81      0.81      0.81      3024\n",
    "           1       0.81      0.82      0.82      3081\n",
    "\n",
    "    accuracy                           0.81      6105\n",
    "   macro avg       0.81      0.81      0.81      6105\n",
    "weighted avg       0.81      0.81      0.81      6105\n",
    "\n",
    "Time for [6 - evaluate - 4]: 0:00:59.415538\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (C.3) Within Epi 128 BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     12,
     15
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi128bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "\n",
    "run_name = \"within_traindev_epi128_BCE\"\n",
    "! mkdir data/within_traindev_epi128_BCE\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - within BCE 128 epilog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     5,
     8,
     11
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"within_traindev_epi128_BCE\"\n",
    "\n",
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi128bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within BCE 128 epilog\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:01:01.648894\n",
    "Accuracy in epoch 4: 0.8543263964950711\n",
    "Confusion Matrix:\n",
    "[[2603  356]\n",
    " [ 575 2857]]\n",
    "\n",
    "Accuracy:  0.85 \n",
    "\n",
    "Report for [BERTClassifier - within BCE 128 epilog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.88      0.85      2959\n",
    "           1       0.89      0.83      0.86      3432\n",
    "\n",
    "    accuracy                           0.85      6391\n",
    "   macro avg       0.85      0.86      0.85      6391\n",
    "weighted avg       0.86      0.85      0.85      6391\n",
    "\n",
    "Time for [6 - evaluate - 4]: 0:01:01.835131\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:00:59.473044\n",
    "Accuracy in epoch 5: 0.8709122203098106\n",
    "Confusion Matrix:\n",
    "[[2577  382]\n",
    " [ 443 2989]]\n",
    "\n",
    "  accuracy: 0.871\n",
    " precision: 0.887\n",
    "    recall: 0.871\n",
    "  f1-score: 0.879\n",
    "\n",
    "Accuracy:  0.87 \n",
    "\n",
    "Report for [BERTClassifier - within BCE 128 epilog (5 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.85      0.87      0.86      2959\n",
    "           1       0.89      0.87      0.88      3432\n",
    "\n",
    "    accuracy                           0.87      6391\n",
    "   macro avg       0.87      0.87      0.87      6391\n",
    "weighted avg       0.87      0.87      0.87      6391\n",
    "\n",
    "Time for [6 - evaluate]: 0:00:59.655873\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (C.4) Cross Epi 128 BCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     12,
     15
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi128bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "\n",
    "run_name = \"cross_traindev_epi128_BCE\"\n",
    "! mkdir data/cross_traindev_epi128_BCE\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 128 epilog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     5,
     8,
     11
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"cross_traindev_epi128_BCE\"\n",
    "\n",
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi128bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 128 epilog\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:01:02.160098\n",
    "Accuracy in epoch 2: 0.8610974610974611\n",
    "Confusion Matrix:\n",
    "[[2679  345]\n",
    " [ 503 2578]]\n",
    "\n",
    "Accuracy:  0.86 \n",
    "\n",
    "Report for [BERTClassifier - cross BCE 128 epilog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.89      0.86      3024\n",
    "           1       0.88      0.84      0.86      3081\n",
    "\n",
    "    accuracy                           0.86      6105\n",
    "   macro avg       0.86      0.86      0.86      6105\n",
    "weighted avg       0.86      0.86      0.86      6105\n",
    "\n",
    "Time for [6 - evaluate - 4]: 0:01:02.347843\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:00:59.955945\n",
    "Accuracy in epoch 5: 0.884029484029484\n",
    "Confusion Matrix:\n",
    "[[2652  372]\n",
    " [ 336 2745]]\n",
    "\n",
    "  accuracy: 0.884\n",
    " precision: 0.881\n",
    "    recall: 0.891\n",
    "  f1-score: 0.886\n",
    "\n",
    "Accuracy:  0.88 \n",
    "\n",
    "Report for [BERTClassifier - cross BCE 128 epilog (5 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.88      0.88      3024\n",
    "           1       0.88      0.89      0.89      3081\n",
    "\n",
    "    accuracy                           0.88      6105\n",
    "   macro avg       0.88      0.88      0.88      6105\n",
    "weighted avg       0.88      0.88      0.88      6105\n",
    "\n",
    "Time for [6 - evaluate]: 0:01:00.147448\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (D.1) Within 512 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     12,
     15
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro512bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "\n",
    "run_name = \"within_traindev_pro512_BCE\"\n",
    "! mkdir data/within_traindev_pro512_BCE\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - within BCE 512 prolog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     5,
     8,
     11
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"within_traindev_pro512_BCE\"\n",
    "\n",
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro512bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within BCE 512 prolog (5 epochs)\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:03:17.058585\n",
    "Accuracy in epoch 5: 0.9184791112501955\n",
    "Confusion Matrix:\n",
    "[[2736  223]\n",
    " [ 298 3134]]\n",
    "\n",
    "  accuracy: 0.918\n",
    " precision: 0.934\n",
    "    recall: 0.913\n",
    "  f1-score: 0.923\n",
    "\n",
    "Accuracy:  0.92 \n",
    "\n",
    "Report for [BERTClassifier - within BCE 512 prolog (5 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.92      0.91      2959\n",
    "           1       0.93      0.91      0.92      3432\n",
    "\n",
    "    accuracy                           0.92      6391\n",
    "   macro avg       0.92      0.92      0.92      6391\n",
    "weighted avg       0.92      0.92      0.92      6391\n",
    "\n",
    "Time for [6 - evaluate]: 0:03:17.400522\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (D.3) Within 512 Epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     12,
     15
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "\n",
    "run_name = \"within_traindev_epi512_BCE\"\n",
    "! mkdir data/within_traindev_epi512_BCE\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - within BCE 512 epilog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"within_traindev_epi512_BCE\"\n",
    "\n",
    "with Timer(\"1 - load within test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within BCE 512 epilog (5 epochs)\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:03:17.296830\n",
    "Accuracy in epoch 5: 0.9139414802065404\n",
    "Confusion Matrix:\n",
    "[[2772  187]\n",
    " [ 363 3069]]\n",
    "\n",
    "  accuracy: 0.914\n",
    " precision: 0.943\n",
    "    recall: 0.894\n",
    "  f1-score: 0.918\n",
    "\n",
    "Accuracy:  0.91 \n",
    "\n",
    "Report for [BERTClassifier - within BCE 512 epilog (5 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.94      0.91      2959\n",
    "           1       0.94      0.89      0.92      3432\n",
    "\n",
    "    accuracy                           0.91      6391\n",
    "   macro avg       0.91      0.92      0.91      6391\n",
    "weighted avg       0.92      0.91      0.91      6391\n",
    "\n",
    "Time for [6 - evaluate]: 0:03:17.540352\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (D.2) Cross 512 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6,
     12,
     15
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro512bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "\n",
    "run_name = \"cross_traindev_pro512_BCE\"\n",
    "! mkdir data/cross_traindev_pro512_BCE\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 512 prolog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     5,
     8,
     11
    ]
   },
   "outputs": [],
   "source": [
    "run_name = \"cross_traindev_pro512_BCE\"\n",
    "\n",
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro512bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 512 prolog (5 epochs)\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint2.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 3:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 512 prolog (3 epochs)\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:03:12.088763\n",
    "Accuracy in epoch 3: 0.8520884520884521\n",
    "Confusion Matrix:\n",
    "[[2608  416]\n",
    " [ 487 2594]]\n",
    "\n",
    "  accuracy: 0.852\n",
    " precision: 0.862\n",
    "    recall: 0.842\n",
    "  f1-score: 0.852\n",
    "\n",
    "Accuracy:  0.85 \n",
    "\n",
    "Report for [BERTClassifier - cross BCE 512 prolog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.84      0.86      0.85      3024\n",
    "           1       0.86      0.84      0.85      3081\n",
    "\n",
    "    accuracy                           0.85      6105\n",
    "   macro avg       0.85      0.85      0.85      6105\n",
    "weighted avg       0.85      0.85      0.85      6105\n",
    "\n",
    "Time for [6 - evaluate]: 0:03:12.321989\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:03:29.716794\n",
    "Accuracy in epoch 5: 0.8665028665028665\n",
    "\n",
    "Confusion Matrix:\n",
    "[[2766  258]\n",
    " [ 557 2524]]\n",
    "\n",
    "  accuracy: 0.867\n",
    " precision: 0.907\n",
    "    recall: 0.819\n",
    "  f1-score: 0.861\n",
    "\n",
    "Accuracy:  0.87 \n",
    "\n",
    "Report for [BERTClassifier - cross BCE 512 prolog (5 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.83      0.91      0.87      3024\n",
    "           1       0.91      0.82      0.86      3081\n",
    "\n",
    "    accuracy                           0.87      6105\n",
    "   macro avg       0.87      0.87      0.87      6105\n",
    "weighted avg       0.87      0.87      0.87      6105\n",
    "\n",
    "Time for [6 - evaluate - 4]: 0:03:29.954158\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (D.4) Cross 512 Epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()\n",
    "\n",
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "\n",
    "run_name = \"cross_traindev_epi512_BCE\"\n",
    "! mkdir data/cross_traindev_epi512_BCE\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 512 epilog\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"cross_traindev_epi512_BCE\"\n",
    "\n",
    "with Timer(\"1 - load cross test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 512 epilog (5 epochs)\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint2.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=32, sw=sw)\n",
    "    print(\"Accuracy in epoch 3:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE 512 epilog (3 epochs)\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:03:11.561386\n",
    "Accuracy in epoch 3: 0.9117117117117117\n",
    "Confusion Matrix:\n",
    "[[2728  296]\n",
    " [ 243 2838]]\n",
    "\n",
    "  accuracy: 0.912\n",
    " precision: 0.906\n",
    "    recall: 0.921\n",
    "  f1-score: 0.913\n",
    "\n",
    "Accuracy:  0.91 \n",
    "\n",
    "Report for [BERTClassifier - cross BCE 512 epilog (3 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.92      0.90      0.91      3024\n",
    "           1       0.91      0.92      0.91      3081\n",
    "\n",
    "    accuracy                           0.91      6105\n",
    "   macro avg       0.91      0.91      0.91      6105\n",
    "weighted avg       0.91      0.91      0.91      6105\n",
    "\n",
    "Time for [6 - evaluate]: 0:03:11.798735\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:03:13.333221\n",
    "Accuracy in epoch 5: 0.9257985257985258\n",
    "Confusion Matrix:\n",
    "[[2840  184]\n",
    " [ 269 2812]]\n",
    "\n",
    "  accuracy: 0.926\n",
    " precision: 0.939\n",
    "    recall: 0.913\n",
    "  f1-score: 0.925\n",
    "\n",
    "Accuracy:  0.93 \n",
    "\n",
    "Report for [BERTClassifier - cross BCE 512 epilog (5 epochs)]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.94      0.93      3024\n",
    "           1       0.94      0.91      0.93      3081\n",
    "\n",
    "    accuracy                           0.93      6105\n",
    "   macro avg       0.93      0.93      0.93      6105\n",
    "weighted avg       0.93      0.93      0.93      6105\n",
    "\n",
    "Time for [6 - evaluate]: 0:03:13.563441\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E - artificial evalset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_columns_X2 = ['argument1', 'argument2']\n",
    "# X_arteval_dev = artificial_evalset_df[names_columns_X]\n",
    "# y_arteval_dev = artificial_evalset_df[names_columns_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     9,
     12,
     15,
     18,
     21,
     28
    ]
   },
   "outputs": [],
   "source": [
    "fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "exp_name = \"within_traindev_epi512_BCE\"\n",
    "run_name = \"artificial_evalset_\" + exp_name\n",
    "\n",
    "! mkdir data/artificial_evalset/within_traindev_epi512_BCE\n",
    "\n",
    "if os.path.exists(fn):\n",
    "    artificial_evalset_df = pd.DataFrame.from_csv(fn, sep='\\t')\n",
    "\n",
    "with Timer(\"1 - load artificial test\"):\n",
    "    X_dev, y_dev = artificial_evalset_df[names_columns_X2], artificial_evalset_df[names_columns_y]\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()\n",
    "\n",
    "with Timer(\"2 - load BERT model: {}\".format(exp_name)):\n",
    "    model.load_parameters(\"data/\" + exp_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy in epoch 5:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - {} - artificial evalset\".format(exp_name), heatmap=False)\n",
    "\n",
    "with Timer(\"9 - store results\"):\n",
    "    col_name = \"preds-{}\".format(exp_name)\n",
    "    artificial_evalset_df[col_name] = y_pred\n",
    "    fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "    artificial_evalset_df.to_csv(fn, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     9,
     12,
     15,
     18,
     21,
     28
    ],
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "exp_name = \"cross_traindev_epi512_BCE\"\n",
    "run_name = \"artificial_evalset_\" + exp_name\n",
    "\n",
    "! mkdir data/artificial_evalset/cross_traindev_epi512_BCE\n",
    "\n",
    "if os.path.exists(fn):\n",
    "    artificial_evalset_df = pd.DataFrame.from_csv(fn, sep='\\t')\n",
    "\n",
    "with Timer(\"1 - load artificial test\"):\n",
    "    X_dev, y_dev = artificial_evalset_df[names_columns_X2], artificial_evalset_df[names_columns_y]\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()\n",
    "\n",
    "with Timer(\"2 - load BERT model: {}\".format(exp_name)):\n",
    "    model.load_parameters(\"data/\" + exp_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - {} - artificial evalset\".format(exp_name), heatmap=False)\n",
    "\n",
    "with Timer(\"9 - store results\"):\n",
    "    col_name = \"preds-{}\".format(exp_name)\n",
    "    artificial_evalset_df[col_name] = y_pred\n",
    "    fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "    artificial_evalset_df.to_csv(fn, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     9,
     15,
     18,
     21,
     28
    ]
   },
   "outputs": [],
   "source": [
    "fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "exp_name = \"within_traindev_epi128_BCE\"\n",
    "run_name = \"artificial_evalset_\" + exp_name\n",
    "\n",
    "! mkdir data/artificial_evalset/within_traindev_epi128_BCE\n",
    "\n",
    "if os.path.exists(fn):\n",
    "    artificial_evalset_df = pd.DataFrame.from_csv(fn, sep='\\t')\n",
    "\n",
    "with Timer(\"1 - load artificial test\"):\n",
    "    X_dev, y_dev = artificial_evalset_df[names_columns_X2], artificial_evalset_df[names_columns_y]\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi128bce()\n",
    "\n",
    "with Timer(\"2 - load BERT model: {}\".format(exp_name)):\n",
    "    model.load_parameters(\"data/\" + exp_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - {} - artificial evalset\".format(exp_name), heatmap=False)\n",
    "\n",
    "with Timer(\"9 - store results\"):\n",
    "    col_name = \"preds-{}\".format(exp_name)\n",
    "    artificial_evalset_df[col_name] = y_pred\n",
    "    fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "    artificial_evalset_df.to_csv(fn, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     9,
     15,
     18,
     21,
     28
    ]
   },
   "outputs": [],
   "source": [
    "fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "exp_name = \"within_traindev_pro128_BCE\"\n",
    "run_name = \"artificial_evalset_\" + exp_name\n",
    "\n",
    "! mkdir data/artificial_evalset/within_traindev_pro128_BCE\n",
    "\n",
    "if os.path.exists(fn):\n",
    "    artificial_evalset_df = pd.DataFrame.from_csv(fn, sep='\\t')\n",
    "\n",
    "with Timer(\"1 - load artificial test\"):\n",
    "    X_dev, y_dev = artificial_evalset_df[names_columns_X2], artificial_evalset_df[names_columns_y]\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro128bce()\n",
    "\n",
    "with Timer(\"2 - load BERT model: {}\".format(exp_name)):\n",
    "    model.load_parameters(\"data/\" + exp_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - {} - artificial evalset\".format(exp_name), heatmap=False)\n",
    "\n",
    "with Timer(\"9 - store results\"):\n",
    "    col_name = \"preds-{}\".format(exp_name)\n",
    "    artificial_evalset_df[col_name] = y_pred\n",
    "    fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "    artificial_evalset_df.to_csv(fn, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     9,
     15,
     18,
     21,
     28
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "exp_name = \"cross_traindev_epi128_BCE\"\n",
    "run_name = \"artificial_evalset_\" + exp_name\n",
    "\n",
    "! mkdir data/artificial_evalset/cross_traindev_epi128_BCE\n",
    "\n",
    "if os.path.exists(fn):\n",
    "    artificial_evalset_df = pd.DataFrame.from_csv(fn, sep='\\t')\n",
    "\n",
    "with Timer(\"1 - load artificial test\"):\n",
    "    X_dev, y_dev = artificial_evalset_df[names_columns_X2], artificial_evalset_df[names_columns_y]\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi128bce()\n",
    "\n",
    "with Timer(\"2 - load BERT model: {}\".format(exp_name)):\n",
    "    model.load_parameters(\"data/\" + exp_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - {} - artificial evalset\".format(exp_name), heatmap=False)\n",
    "\n",
    "with Timer(\"9 - store results\"):\n",
    "    col_name = \"preds-{}\".format(exp_name)\n",
    "    artificial_evalset_df[col_name] = y_pred\n",
    "    fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "    artificial_evalset_df.to_csv(fn, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     9,
     15,
     18,
     21,
     28
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "exp_name = \"cross_traindev_pro128_BCE\"\n",
    "run_name = \"artificial_evalset_\" + exp_name\n",
    "\n",
    "! mkdir data/artificial_evalset/cross_traindev_pro128_BCE\n",
    "\n",
    "if os.path.exists(fn):\n",
    "    artificial_evalset_df = pd.DataFrame.from_csv(fn, sep='\\t')\n",
    "\n",
    "with Timer(\"1 - load artificial test\"):\n",
    "    X_dev, y_dev = artificial_evalset_df[names_columns_X2], artificial_evalset_df[names_columns_y]\n",
    "\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_pro128bce()\n",
    "\n",
    "with Timer(\"2 - load BERT model: {}\".format(exp_name)):\n",
    "    model.load_parameters(\"data/\" + exp_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "\n",
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "\n",
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - {} - artificial evalset\".format(exp_name), heatmap=False)\n",
    "\n",
    "with Timer(\"9 - store results\"):\n",
    "    col_name = \"preds-{}\".format(exp_name)\n",
    "    artificial_evalset_df[col_name] = y_pred\n",
    "    fn = \"data/artificial_evalset/artificial_evalset.pred.tsv\"\n",
    "    artificial_evalset_df.to_csv(fn, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T20:20:15.327113Z",
     "start_time": "2019-12-08T20:20:15.316399Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def dump_art_eval_results(artificial_evalset_df):\n",
    "    cols = [c for c in artificial_evalset_df.columns.tolist() if c.startswith(\"preds-\")]\n",
    "    \n",
    "    for col in cols:\n",
    "        model_name = col[6:]\n",
    "        print(\"Model:\", model_name, \"\\n\")\n",
    "        \n",
    "        for crit, crit_df in artificial_evalset_df.groupby(\"type\"):\n",
    "            crit_df = crit_df[[\"is_same_side\", col]].astype({\"is_same_side\": \"int32\"})\n",
    "            labels = crit_df[\"is_same_side\"].values\n",
    "            preds = crit_df[col].values\n",
    "\n",
    "            conf_mat = confusion_matrix(labels, preds)\n",
    "            print(\"Criterion:\", crit)\n",
    "            # print(conf_mat)\n",
    "            compute_metrics2(labels, preds)\n",
    "            print()\n",
    "        \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_art_eval_results(artificial_evalset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gi = iter(artificial_evalset_df.groupby(\"type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit, df = next(gi)\n",
    "print(crit)\n",
    "df = df[[\"is_same_side\", \"preds-cross_traindev_epi512_BCE_0.1\"]].astype({\"is_same_side\": \"int32\"})\n",
    "df = df[\"is_same_side\"].values, df[\"preds-cross_traindev_epi512_BCE_0.1\"].values\n",
    "tn, fp, fn, tp = confusion_matrix(*df).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(*df), recall_score(*df), tp / (tp + fp), tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A.1) Within topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within_traindev_df = within_traindev_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    # X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "    X_train, X_dev, y_train, y_dev = load_distinct_data(\"within\")\n",
    "\n",
    "    # X_abortion, X_gay_marriage, y_abortion, y_gay_marriage = split_within_by_topic(within_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"within_traindev_epi512_BCE_0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data/within_traindev_epi512_BCE_0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=600) as sw:\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=2, lr=5e-6, num_epochs=5, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        # stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=2, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        # stats = train_multi(model, data_train, ctx, metric, loss_function, batch_size=4, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        # all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)  # seq_len: 512\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - last part\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A.2) Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df, ratio=0.1)\n",
    "    # X_train, X_dev, y_train, y_dev = load_distinct_data(\"cross\")\n",
    "\n",
    "    X_abortion, X_gay_marriage, y_abortion, y_gay_marriage = split_within_by_topic(within_traindev_df)\n",
    "    \n",
    "    # cross:  abortion\n",
    "    # within: abortion + gay marriage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert_epi512bce()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"cross_traindev_epi512_BCE_0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir data/cross_traindev_epi512_BCE_0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=600) as sw:\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=5, sw=sw, checkpoint_dir=\"data/\" + run_name)\n",
    "    model.save_parameters(\"data/\" + run_name + \"/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - cross BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (A.3) cross with distinct topics from within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"7 - prepare eval data - for within foreign topic\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_gay_marriage, y_gay_marriage, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"8 - evaluate - within foreign topic\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within foreign topic BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "### RESULTS on untrained model!\n",
    "Time for [prediction]: 0:16:02.711887\n",
    "Accuracy: 0.5775050947404934\n",
    "\n",
    "Confusion Matrix:\n",
    "[[  123  9663]\n",
    " [   81 13196]]\n",
    "\n",
    "  accuracy: 0.578\n",
    " precision: 0.590\n",
    "    recall: 0.503\n",
    "  f1-score: 0.377\n",
    "\n",
    "Accuracy:  0.58 \n",
    "\n",
    "Report for [BERTClassifier - within foreign topic BCE epilog 0.1 split]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.60      0.01      0.02      9786\n",
    "           1       0.58      0.99      0.73     13277\n",
    "\n",
    "    accuracy                           0.58     23063\n",
    "   macro avg       0.59      0.50      0.38     23063\n",
    "weighted avg       0.59      0.58      0.43     23063\n",
    "\n",
    "Time for [8 - evaluate - within foreign topic]: 0:16:04.970854\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:12:55.132169\n",
    "Accuracy: 0.6531240515110783\n",
    "\n",
    "Confusion Matrix:\n",
    "[[6455 3331]\n",
    " [4669 8608]]\n",
    "\n",
    "  accuracy: 0.653\n",
    " precision: 0.651\n",
    "    recall: 0.654\n",
    "  f1-score: 0.650\n",
    "\n",
    "Accuracy:  0.65 \n",
    "\n",
    "Report for [BERTClassifier - within foreign topic BCE epilog 0.1 split]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.58      0.66      0.62      9786\n",
    "           1       0.72      0.65      0.68     13277\n",
    "\n",
    "    accuracy                           0.65     23063\n",
    "   macro avg       0.65      0.65      0.65     23063\n",
    "weighted avg       0.66      0.65      0.66     23063\n",
    "\n",
    "Time for [8 - evaluate - within foreign topic]: 0:12:56.282341\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"7 - prepare eval data - for within same topic\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_abortion, y_abortion, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"8 - evaluate - within same topic\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    model.load_parameters(\"data/\" + run_name + \"/bert.model.checkpoint4.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within same topic BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:23:12.102163\n",
    "Accuracy: 0.9829578844270324\n",
    "\n",
    "Confusion Matrix:\n",
    "[[19698   308]\n",
    " [  388 20446]]\n",
    "\n",
    "  accuracy: 0.983\n",
    " precision: 0.983\n",
    "    recall: 0.983\n",
    "  f1-score: 0.983\n",
    "\n",
    "Accuracy:  0.98 \n",
    "\n",
    "Report for [BERTClassifier - within same topic BCE epilog 0.1 split]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.98      0.98     20006\n",
    "           1       0.99      0.98      0.98     20834\n",
    "\n",
    "    accuracy                           0.98     40840\n",
    "   macro avg       0.98      0.98      0.98     40840\n",
    "weighted avg       0.98      0.98      0.98     40840\n",
    "\n",
    "Time for [8 - evaluate - within same topic]: 0:23:13.881916\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"1 - test/train split (within)\"):\n",
    "    _, X_dev_within, _, y_dev_within = get_train_test_sets(within_traindev_df, ratio=0.1)\n",
    "\n",
    "with Timer(\"7 - prepare eval data - for within both topics (0.1 split)\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev_within, y_dev_within, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with Timer(\"8 - evaluate - within both topics\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within both topics topic BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"1 - test/train split (within)\"):\n",
    "    _, X_dev_within, _, y_dev_within = get_train_test_sets(within_traindev_df, ratio=0.3)\n",
    "\n",
    "with Timer(\"7 - prepare eval data - for within both topics (0.3 split)\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev_within, y_dev_within, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"8 - evaluate - within both topics (0.3 split)\"), SummaryWriter(logdir=\"data/\" + run_name, flush_secs=60) as sw:\n",
    "    # model.load_parameters(\"data/\" + run_name + \"/bert.model.params\", ctx=ctx)\n",
    "    # bert.model.checkpoint4.params\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2, sw=sw)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier - within both topics topic (0.3 within) BCE epilog 0.1 split\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     14,
     22
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        stats = train(model,\n",
    "                      data_train,\n",
    "                      ctx,\n",
    "                      metric,\n",
    "                      loss_function,\n",
    "                      batch_size=2,\n",
    "                      lr=5e-6,\n",
    "                      num_epochs=epoch_id + 1,\n",
    "                      checkpoint_dir='data/cross_traindev_epi512_BCE')\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        all_predictions, cum_loss = predict(model,\n",
    "                                            data_dev,\n",
    "                                            ctx,\n",
    "                                            metric,\n",
    "                                            loss_function,\n",
    "                                            batch_size=2)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true,\n",
    "                                y_pred,\n",
    "                                name=\"BERTClassifier\",\n",
    "                                heatmap=False)\n",
    "\n",
    "    model.save_parameters(\n",
    "        \"data/cross_traindev_epi512_BCE/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"11 - test/train split\"):\n",
    "    # evaluate on \"within\" test-data\n",
    "    _, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "with Timer(\"12 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)\n",
    "\n",
    "with Timer(\"13 - evaluate\"):\n",
    "    # model from \"cross\"\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier cross with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Cross-Model with Within-Test\n",
    "\n",
    "5 epochs of cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/cross_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier cross with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:24:48.940295\n",
    "Accuracy: 0.8536330916488446\n",
    "Confusion Matrix:\n",
    "[[7659 1174]\n",
    " [1632 8706]]\n",
    "\n",
    "Accuracy:  0.85 \n",
    "\n",
    "Report for [BERTClassifier cross with within]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.87      0.85      8833\n",
    "           1       0.88      0.84      0.86     10338\n",
    "\n",
    "    accuracy                           0.85     19171\n",
    "   macro avg       0.85      0.85      0.85     19171\n",
    "weighted avg       0.85      0.85      0.85     19171\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Within-Model with Cross-Test\n",
    "\n",
    "5 epochs of within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/within_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"evaluate within with cross\"):\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier within with cross\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:22:17.542674\n",
    "Accuracy: 0.9379197379197379\n",
    "Confusion Matrix:\n",
    "[[8397  539]\n",
    " [ 598 8781]]\n",
    "\n",
    "Accuracy:  0.94 \n",
    "\n",
    "Report for [BERTClassifier]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.94      0.94      8936\n",
    "           1       0.94      0.94      0.94      9379\n",
    "\n",
    "    accuracy                           0.94     18315\n",
    "   macro avg       0.94      0.94      0.94     18315\n",
    "weighted avg       0.94      0.94      0.94     18315\n",
    "\n",
    "Time for [6 - evaluate]: 0:22:19.841677\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Within-Model with Within-Test\n",
    "\n",
    "5 epochs of within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/within_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"evaluate within with within\"):\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier within with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:19:51.733113\n",
    "Accuracy: 0.9069427781545042\n",
    "Confusion Matrix:\n",
    "[[7972  861]\n",
    " [ 923 9415]]\n",
    "\n",
    "Accuracy:  0.91 \n",
    "\n",
    "Report for [BERTClassifier within with within]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.90      0.90      8833\n",
    "           1       0.92      0.91      0.91     10338\n",
    "\n",
    "    accuracy                           0.91     19171\n",
    "   macro avg       0.91      0.91      0.91     19171\n",
    "weighted avg       0.91      0.91      0.91     19171\n",
    "\n",
    "Time for [evaluate within with cross]: 0:19:52.352049\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Cross-Model with Cross-Test\n",
    "\n",
    "5 epochs of cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/cross_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier cross\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:23:28.845010\n",
    "Accuracy: 0.9197925197925197\n",
    "Confusion Matrix:\n",
    "[[8329  607]\n",
    " [ 862 8517]]\n",
    "\n",
    "Accuracy:  0.92 \n",
    "\n",
    "Report for [BERTClassifier cross]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.93      0.92      8936\n",
    "           1       0.93      0.91      0.92      9379\n",
    "\n",
    "    accuracy                           0.92     18315\n",
    "   macro avg       0.92      0.92      0.92     18315\n",
    "weighted avg       0.92      0.92      0.92     18315\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Details to wrong classified arguments\n",
    "\n",
    "within_traindev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()\n",
    "\n",
    "model.load_parameters('data/within_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "# print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier within-within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions to dataframe\n",
    "dev_pred_df = pd.DataFrame(data=y_pred, columns=[\"prediction\"], dtype=\"bool\")\n",
    "\n",
    "# merge all dataframes\n",
    "dev_df = X_dev.join(y_dev)\n",
    "dev_df = dev_df.reset_index()\n",
    "dev_df = pd.merge(dev_df, dev_pred_df, left_index=True, right_index=True, how='inner')\n",
    "dev_df.set_index('id', inplace=True)\n",
    "\n",
    "# re-apply tag value\n",
    "dev_df = dev_df.progress_apply(add_tag, axis=1)\n",
    "# info\n",
    "dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "dev_df_ser_file = \"data/within_traindev_epi512_BCE/eval_dev_df.pickle\"\n",
    "\n",
    "\n",
    "with open(dev_df_ser_file, \"wb\") as f:\n",
    "    pickle.dump(dev_df, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(dev_df_ser_file, \"rb\") as f:\n",
    "    dev_df = pickle.load(f)\n",
    "\n",
    "\n",
    "dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPFN_df = dev_df[(dev_df['is_same_side'] != dev_df['prediction'])]  #  and (dev_df['tag'] != 'abortion')\n",
    "FPFN_df.info()\n",
    "FPFN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import re\n",
    "#import tabulate\n",
    "#display(HTML(tabulate.tabulate(table, tablefmt='html')))\n",
    "\n",
    "\n",
    "def print_args(df, idx, add_linebreaks=True):\n",
    "    row = df.iloc[idx]\n",
    "    print('IDX: {}, tag: {}, topics: {}'.format(idx, row['tag'], row['topic']))\n",
    "    print('Is-Same-Side: {}'.format(row['is_same_side']))\n",
    "\n",
    "    arg1 = row['argument1']\n",
    "    arg2 = row['argument2']\n",
    "    if add_linebreaks:\n",
    "        pat = re.compile(r'(?P<c>(\\.|\\?|\\!|\\:)+\\\"?)')\n",
    "        arg1 = pat.sub(r'\\1<br/>', arg1)\n",
    "        arg2 = pat.sub(r'\\1<br/>', arg2)\n",
    "\n",
    "    display(HTML('''<table>\n",
    "        <tr>\n",
    "            <td style=\"border-right:1px dashed black;\">{arg1}</td>\n",
    "            <td>{arg2}</td>\n",
    "        </tr>\n",
    "    </table>'''.format(arg1=arg1, arg2=arg2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = {print_args(FPFN_df, i) for i in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# tokenizer from BERT\n",
    "def tokenize_arguments(row):\n",
    "    # tokenize\n",
    "    row['argument1_tokens'] = tokenizer(row['argument1'])\n",
    "    row['argument2_tokens'] = tokenizer(row['argument2'])\n",
    "\n",
    "    # count tokens\n",
    "    row['argument1_len'] = len(row['argument1_tokens'])\n",
    "    row['argument2_len'] = len(row['argument2_tokens'])\n",
    "    # token number diff\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    row['argument12_len_diff_abs'] = np.abs(row['argument12_len_diff'])\n",
    "    return row\n",
    "\n",
    "\n",
    "FPFN_df = FPFN_df.progress_apply(tokenize_arguments, axis=1)\n",
    "FPFN_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPFN_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make final results/predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_parameters('data/within_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)\n",
    "# model.load_parameters('data/cross_traindev_epi512_BCE/bert.model.checkpoint4.params', ctx=ctx)\n",
    "model.load_parameters('data/within_traindev_epi512_BCE_0.1/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_pred = within_test_df[['argument1', 'argument2', 'topic']]\n",
    "#X_pred = cross_test_df[['argument1', 'argument2', 'topic']]\n",
    "X_pred = new_within_test_df[['argument1', 'argument2', 'topic']]\n",
    "y_pred = None\n",
    "\n",
    "data_pred_raw, data_pred = transform_dataset(X_pred, y_pred, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# data_pred_raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# label_map=all_labels\n",
    "predictions = predict_unknown(model, data_pred, ctx, label_map=None, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data_pred) == len(predictions) == len(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert predictions to dataframe\n",
    "# bool works because we mapped 0 to False, 1 to True, is default conversion\n",
    "test_pred_df = pd.DataFrame(data=predictions, columns=[\"prediction\"], dtype=\"bool\")\n",
    "\n",
    "# merge all dataframes\n",
    "# test_df = X_pred.join(y_pred)\n",
    "test_df = X_pred.reset_index()\n",
    "test_df = pd.merge(test_df, test_pred_df, left_index=True, right_index=True, how='inner')\n",
    "test_df.set_index('id', inplace=True)\n",
    "\n",
    "# re-apply tag value\n",
    "test_df = test_df.progress_apply(add_tag, axis=1)\n",
    "# info\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# ser_fn = \"data/within_traindev_epi512_BCE/within_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/cross_traindev_epi512_BCE/cross_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/cross_traindev_epi512_BCE/within_with_cross_model_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/within_traindev_epi512_BCE/cross_with_within_model_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/within_traindev_epi512_BCE_0.1/within_test_pred_df.pickle\"\n",
    "# ser_fn = \"data/within_traindev_epi512_BCE_0.1/cross_with_within_model_test_pred_df.pickle\"\n",
    "ser_fn = \"data/within_traindev_epi512_BCE_0.1/new_within_test_pred_df.pickle\"\n",
    "\n",
    "with open(ser_fn, \"wb\") as f:\n",
    "    pickle.dump(test_df, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(test_df.itertuples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res_fn = \"data/within_traindev_epi512_BCE/within_results.csv\"\n",
    "# res_fn = \"data/cross_traindev_epi512_BCE/cross_results.csv\"\n",
    "# res_fn = \"data/cross_traindev_epi512_BCE/within_with_cross_model_results.csv\"\n",
    "# res_fn = \"data/within_traindev_epi512_BCE/cross_with_within_model_results.csv\"\n",
    "# res_fn = \"data/within_traindev_epi512_BCE_0.1/within_results.csv\"\n",
    "# res_fn = \"data/within_traindev_epi512_BCE_0.1/cross_with_within_model_results.csv\"\n",
    "res_fn = \"data/within_traindev_epi512_BCE_0.1/new_within_results.csv\"\n",
    "\n",
    "with open(res_fn, \"w\") as of:\n",
    "    of.write('\"id\",\"label\"\\n')\n",
    "    for row_id, row in test_df.iterrows():\n",
    "        of.write('{},\"{}\"\\n'.format(row_id, str(row['prediction'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/within_traindev_epi512_BCE_0.1/\n",
    "cp cross_with_within_model_results.csv cross.csv\n",
    "cp within_results.csv within.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/within_traindev_epi512_BCE_0.1/\n",
    "gzip cross.csv\n",
    "gzip within.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd data/within_traindev_epi512_BCE_0.1/\n",
    "gzip new_within_results.csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: do this for within and cross !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test read\n",
    "# temp_test_df = pd.read_csv(\"data/within_traindev_epi512_BCE_0.1/cross_with_within_model_results.csv\", index_col='id')\n",
    "temp_test_df = pd.read_csv(\"data/within_traindev_epi512_BCE_0.1/new_within_results.csv\", index_col='id')\n",
    "temp_test_df.info()\n",
    "temp_test_df.iloc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
