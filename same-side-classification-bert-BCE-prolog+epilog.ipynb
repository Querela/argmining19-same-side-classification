{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gluon-nlp.mxnet.io/install.html\n",
    "\n",
    "```\n",
    "pip install --upgrade 'mxnet>=1.3.0'\n",
    "pip install gluonnlp\n",
    "wget https://gluon-nlp.mxnet.io/_downloads/sentence_embedding.zip\n",
    "unzip sentence_embedding.zip\n",
    "ln -s sentence_embedding/bert bert\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:51:14.132615Z",
     "start_time": "2019-07-07T20:51:12.028496Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import csv\n",
    "import gluonnlp as nlp\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from bert import *\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon.data import Dataset, SimpleDataset\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:10:36.955771Z",
     "start_time": "2019-07-07T20:10:36.951601Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:51:14.136205Z",
     "start_time": "2019-07-07T20:51:14.134095Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:51:14.151086Z",
     "start_time": "2019-07-07T20:51:14.137456Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# set repeatable random state\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:51:14.157088Z",
     "start_time": "2019-07-07T20:51:14.152105Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:51:14.167476Z",
     "start_time": "2019-07-07T20:51:14.158153Z"
    },
    "code_folding": [
     0,
     4
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:51:14.178805Z",
     "start_time": "2019-07-07T20:51:14.168473Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:51:16.574885Z",
     "start_time": "2019-07-07T20:51:14.180008Z"
    },
    "code_folding": [
     11,
     18,
     29,
     36
    ],
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:01.230329\n",
      "Time for [read within]: 0:00:01.147553\n"
     ]
    }
   ],
   "source": [
    "# escapechar to detect quoting escapes, else it fails\n",
    "\n",
    "# na_filter=False, because pandas automatic \"nan\" detection fails with the topic column, too\n",
    "# cross_test_df['topic'].astype(str)[9270]\n",
    "\n",
    "# within has \"is_same_side\" as string (boolean after latest update)\n",
    "# cross has \"is_same_side\" as boolean (auto cast?)\n",
    "\n",
    "with Timer(\"read cross\"):\n",
    "    # cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                    quotechar='\"',\n",
    "                                    quoting=csv.QUOTE_ALL,\n",
    "                                    encoding='utf-8',\n",
    "                                    escapechar='\\\\',\n",
    "                                    doublequote=False,\n",
    "                                    index_col='id')\n",
    "    cross_test_df = pd.read_csv(data_cross_path.format('test'),\n",
    "                                quotechar='\"',\n",
    "                                quoting=csv.QUOTE_ALL,\n",
    "                                encoding='utf-8',\n",
    "                                escapechar='\\\\',\n",
    "                                doublequote=False,\n",
    "                                index_col='id')\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    # within_traindev_df = pd.read_csv(data_within_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    within_traindev_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                     quotechar='\"',\n",
    "                                     quoting=csv.QUOTE_ALL,\n",
    "                                     encoding='utf-8',\n",
    "                                     escapechar='\\\\',\n",
    "                                     doublequote=False,\n",
    "                                     index_col='id')\n",
    "    within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "                                 quotechar='\"',\n",
    "                                 quoting=csv.QUOTE_ALL,\n",
    "                                 encoding='utf-8',\n",
    "                                 escapechar='\\\\',\n",
    "                                 doublequote=False,\n",
    "                                 index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.538434Z",
     "start_time": "2019-07-07T20:51:16.577201Z"
    },
    "code_folding": [],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61048/61048 [00:37<00:00, 1639.99it/s]\n",
      "  1%|          | 204/34330 [00:00<00:16, 2033.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag cross traindev]: 0:00:37.228385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34330/34330 [00:20<00:00, 1684.46it/s]\n",
      "  0%|          | 135/63903 [00:00<00:47, 1341.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag cross test]: 0:00:20.382879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63903/63903 [00:39<00:00, 1630.67it/s]\n",
      "  0%|          | 112/31475 [00:00<00:28, 1116.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag within traindev]: 0:00:39.191730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31475/31475 [00:19<00:00, 1644.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag within test]: 0:00:19.151194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross traindev\"):\n",
    "    cross_traindev_df = cross_traindev_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag cross test\"):\n",
    "    cross_test_df = cross_test_df.progress_apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within traindev\"):\n",
    "    within_traindev_df = within_traindev_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag within test\"):\n",
    "    within_test_df = within_test_df.progress_apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.548758Z",
     "start_time": "2019-07-07T20:53:12.540491Z"
    },
    "code_folding": [
     4
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# requires nltk  wordtokenize\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# model uses BERT Tokenizer ...\n",
    "\n",
    "def get_overview(df, task='same-side', class_name='is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task)\n",
    "    print('=' * 40, '\\n')\n",
    "\n",
    "    print('Total instances: ', total)\n",
    "    print('\\n')\n",
    "\n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t', is_same_side, ': ', len(side_df), ' instances')\n",
    "    print('\\n')\n",
    "\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "        print('\\n')\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))), '\\n')\n",
    "    \n",
    "    return\n",
    "\n",
    "    print('-' * 40, '\\n')\n",
    "\n",
    "    arguments_length_lst = [\n",
    "        len(word_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_length_lst.extend(\n",
    "        [len(word_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Words:')\n",
    "    print('\\tshortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('\\tlongest argument:', max(arguments_length_lst), ' words')\n",
    "    print('\\targument average length:', np.mean(arguments_length_lst),\n",
    "          ' words')\n",
    "\n",
    "    arguments_sent_length_lst = [\n",
    "        len(sent_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_sent_length_lst.extend(\n",
    "        [len(sent_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Sentences:')\n",
    "    print('\\tshortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\tlongest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\targument average length:', np.mean(arguments_sent_length_lst),\n",
    "          ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:24:56.318501Z",
     "start_time": "2019-07-07T19:24:56.104215Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"overview cross\"):\n",
    "    get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:25:00.920503Z",
     "start_time": "2019-07-07T19:25:00.672089Z"
    }
   },
   "outputs": [],
   "source": [
    "with Timer(\"overview within\"):\n",
    "    get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count raw length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:30:21.301924Z",
     "start_time": "2019-07-07T19:25:05.647540Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_arg_len(row):\n",
    "    row['argument1_len'] = len(row['argument1'])\n",
    "    row['argument2_len'] = len(row['argument2'])\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    return row\n",
    "\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.progress_apply(compute_arg_len, axis=1)\n",
    "within_traindev_df = within_traindev_df.progress_apply(compute_arg_len, axis=1)\n",
    "cross_test_df = cross_test_df.progress_apply(compute_arg_len, axis=1)\n",
    "within_test_df = within_test_df.progress_apply(compute_arg_len, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:30:21.714926Z",
     "start_time": "2019-07-07T19:30:21.685804Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:30:22.279641Z",
     "start_time": "2019-07-07T19:30:22.238824Z"
    }
   },
   "outputs": [],
   "source": [
    "within_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize and count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:30:25.287154Z",
     "start_time": "2019-07-07T19:30:22.843561Z"
    }
   },
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "_, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                    dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                    pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                                    use_decoder=False, use_classifier=False)\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "tokenizer = bert_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:52:36.136414Z",
     "start_time": "2019-07-07T19:31:42.853374Z"
    },
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# nltk.download('punct')\n",
    "\n",
    "\n",
    "# tokenizer from BERT\n",
    "def tokenize_arguments(row):\n",
    "    # tokenize\n",
    "    row['argument1_tokens'] = tokenizer(row['argument1'])\n",
    "    row['argument2_tokens'] = tokenizer(row['argument2'])\n",
    "\n",
    "    # count tokens\n",
    "    row['argument1_len'] = len(row['argument1_tokens'])\n",
    "    row['argument2_len'] = len(row['argument2_tokens'])\n",
    "    # token number diff\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    return row\n",
    "\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.progress_apply(tokenize_arguments, axis=1)\n",
    "within_traindev_df = within_traindev_df.progress_apply(tokenize_arguments, axis=1)\n",
    "cross_test_df = cross_test_df.progress_apply(tokenize_arguments, axis=1)\n",
    "within_test_df = within_test_df.progress_apply(tokenize_arguments, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:52:37.149489Z",
     "start_time": "2019-07-07T19:52:37.131400Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T19:52:38.153821Z",
     "start_time": "2019-07-07T19:52:38.134764Z"
    }
   },
   "outputs": [],
   "source": [
    "within_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:10:44.966823Z",
     "start_time": "2019-07-07T20:10:44.289932Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_lengths(df, slicen=None, abs_diff=True, title=None):\n",
    "    if df is None:\n",
    "        print(\"no lengths to plot\")\n",
    "        return\n",
    "    \n",
    "    arg1_lens = df['argument1_len']\n",
    "    arg2_lens = df['argument2_len']\n",
    "    arg_diff_len = df['argument12_len_diff']\n",
    "    \n",
    "    if abs_diff:\n",
    "        arg_diff_len = np.abs(arg_diff_len)\n",
    "    \n",
    "    if slicen is not None:\n",
    "        arg1_lens = arg1_lens[slicen]\n",
    "        arg2_lens = arg2_lens[slicen]\n",
    "        arg_diff_len = arg_diff_len[slicen]\n",
    "\n",
    "    x = np.arange(len(arg1_lens))  # arange/linspace\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, arg1_lens, label='argument1')  # Linie: '-', 'o-', '.-'\n",
    "    plt.plot(x, arg2_lens, label='argument2')  # Linie: '-', 'o-', '.-'\n",
    "    plt.legend()\n",
    "    plt.title('Lengths of arguments' if not title else title)\n",
    "    plt.ylabel('Lengths of arguments 1 and 2')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x, arg_diff_len)\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Differences')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_lengths(within_traindev_df, slice(None, None, 500), title='Length of arguments within train/dev, every 500')\n",
    "plot_lengths(cross_traindev_df, slice(None, None, 500), title='Length of arguments cross train/dev, every 500')\n",
    "plot_lengths(within_test_df, slice(None, None, 1), title='Length of arguments within test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.561505Z",
     "start_time": "2019-07-07T20:53:12.549921Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "- https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.578912Z",
     "start_time": "2019-07-07T20:53:12.564232Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyBERTDataset(SimpleDataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        super(MyBERTDataset, self).__init__(self._convert())\n",
    "\n",
    "    def _convert(self):\n",
    "        allsamples = list()\n",
    "\n",
    "        if self._y is not None:\n",
    "            df = self._X.merge(self._y, left_index=True, right_index=True)\n",
    "            for _, row in df.iterrows():\n",
    "                allsamples.append([\n",
    "                    row['argument1'], row['argument2'],\n",
    "                    \"1\" if str(row['is_same_side']) == \"True\" else \"0\"\n",
    "                ])\n",
    "                #allsamples.append([row['argument1'], row['argument2'], 1 if str(row['is_same_side']) == \"True\" else 0])\n",
    "\n",
    "        else:\n",
    "            for _, row in self._X.iterrows():\n",
    "                allsamples.append([row['argument1'], row['argument2'], None])\n",
    "\n",
    "        return allsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: my own `BERTDatasetTransform` for extracting chunks from arguments or last part etc.\n",
    "\n",
    "```python\n",
    "transform = dataset.BERTDatasetTransform(bert_tokenizer, 512,\n",
    "                                         labels=['0', '1'],\n",
    "                                         label_dtype='int32',\n",
    "                                         pad=True,\n",
    "                                         pair=True)\n",
    "```\n",
    "\n",
    "http://localhost:9001/edit/bert/dataset.py @454\n",
    "```python\n",
    "# substitute with my own (e. g. last part, many parts etc.)\n",
    "def __init__(...):\n",
    "    self._bert_xform = BERTSentenceTransform(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "```\n",
    "https://gluon-nlp.mxnet.io/master/_modules/gluonnlp/data/transforms.html#BERTSentenceTransform\n",
    "```python\n",
    "# substitute with my own (e. g. only last part (trim from start))\n",
    "self._truncate_seq_pair(tokens_a, tokens_b, self._max_seq_length - 3)\n",
    "```\n",
    "\n",
    "https://mxnet.incubator.apache.org/_modules/mxnet/gluon/data/dataset.html#Dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.607780Z",
     "start_time": "2019-07-07T20:53:12.581158Z"
    },
    "code_folding": [
     3
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from gluonnlp.data import BERTSentenceTransform\n",
    "\n",
    "\n",
    "class FirstAndLastPartBERTSentenceTransform(BERTSentenceTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, pad=True, pair=True):\n",
    "        super(FirstAndLastPartBERTSentenceTransform,\n",
    "              self).__init__(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "    def __call__(self, line):\n",
    "        # convert to unicode\n",
    "        text_a = line[0]\n",
    "        if self._pair:\n",
    "            assert len(line) == 2\n",
    "            text_b = line[1]\n",
    "\n",
    "        tokens_a = self._tokenizer(text_a)\n",
    "        tokens_a_epi = tokens_a.copy()\n",
    "        tokens_b = None\n",
    "        tokens_b_epi = None\n",
    "\n",
    "        if self._pair:\n",
    "            tokens_b = self._tokenizer(text_b)\n",
    "            tokens_b_epi = tokens_b.copy()\n",
    "\n",
    "        if tokens_b:\n",
    "            self._truncate_seq_pair_prolog(tokens_a, tokens_b,\n",
    "                                           self._max_seq_length - 3)\n",
    "            self._truncate_seq_pair_epilog(tokens_a_epi, tokens_b_epi,\n",
    "                                           self._max_seq_length - 3)\n",
    "        else:\n",
    "            if len(tokens_a) > self._max_seq_length - 2:\n",
    "                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n",
    "            if len(tokens_a_epi) > self._max_seq_length - 2:\n",
    "                tokens_a_epi = tokens_a_epi[0:(self._max_seq_length - 2)]\n",
    "\n",
    "        vocab = self._tokenizer.vocab\n",
    "        tokens, tokens_epi = [], []\n",
    "        tokens.append(vocab.cls_token)\n",
    "        tokens_epi.append(vocab.cls_token)\n",
    "        tokens.extend(tokens_a)\n",
    "        tokens_epi.extend(tokens_a_epi)\n",
    "        tokens.append(vocab.sep_token)\n",
    "        tokens_epi.append(vocab.sep_token)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        segment_ids_epi = [0] * len(tokens_epi)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens.extend(tokens_b)\n",
    "            tokens_epi.extend(tokens_b_epi)\n",
    "            tokens.append(vocab.sep_token)\n",
    "            tokens_epi.append(vocab.sep_token)\n",
    "            segment_ids.extend([1] * (len(tokens) - len(segment_ids)))\n",
    "            segment_ids_epi.extend([1] * (len(tokens) - len(segment_ids_epi)))\n",
    "\n",
    "        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_ids_epi = self._tokenizer.convert_tokens_to_ids(tokens_epi)\n",
    "        valid_length = len(input_ids)\n",
    "        valid_length_epi = len(input_ids_epi)\n",
    "\n",
    "        if self._pad:\n",
    "            padding_length = self._max_seq_length - valid_length\n",
    "            padding_length_epi = self._max_seq_length - valid_length_epi\n",
    "            input_ids.extend([vocab[vocab.padding_token]] * padding_length)\n",
    "            input_ids_epi.extend([vocab[vocab.padding_token]] *\n",
    "                                 padding_length_epi)\n",
    "            segment_ids.extend([0] * padding_length)\n",
    "            segment_ids_epi.extend([0] * padding_length_epi)\n",
    "\n",
    "        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n",
    "            np.array(segment_ids, dtype='int32'), np.array(input_ids_epi, dtype='int32'),\\\n",
    "            np.array(valid_length_epi, dtype='int32'), np.array(segment_ids_epi, dtype='int32')\n",
    "\n",
    "    def _truncate_seq_pair_prolog(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "\n",
    "    def _truncate_seq_pair_epilog(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\n",
    "        Removes from end of token list.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop(0)\n",
    "            else:\n",
    "                tokens_b.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.620532Z",
     "start_time": "2019-07-07T20:53:12.609183Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "class FirstAndLastPartBERTDatasetTransform(dataset.BERTDatasetTransform):\n",
    "    def __init__(self,\n",
    "                 tokenizer,\n",
    "                 max_seq_length,\n",
    "                 labels=None,\n",
    "                 pad=True,\n",
    "                 pair=True,\n",
    "                 label_dtype='float32'):\n",
    "        super(FirstAndLastPartBERTDatasetTransform,\n",
    "              self).__init__(tokenizer,\n",
    "                             max_seq_length,\n",
    "                             labels=labels,\n",
    "                             pad=pad,\n",
    "                             pair=pair,\n",
    "                             label_dtype=label_dtype)\n",
    "        self._bert_xform = FirstAndLastPartBERTSentenceTransform(\n",
    "            tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "    def __call__(self, line):\n",
    "        input_ids, valid_length, segment_ids, input_ids_epi, valid_length_epi, segment_ids_epi = self._bert_xform(\n",
    "            line[:-1])\n",
    "\n",
    "        label = line[-1]\n",
    "        if self.labels:  # for classification task\n",
    "            label = self._label_map[label]\n",
    "        label = np.array([label], dtype=self.label_dtype)\n",
    "\n",
    "        return input_ids, valid_length, segment_ids, input_ids_epi, valid_length_epi, segment_ids_epi, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.638841Z",
     "start_time": "2019-07-07T20:53:12.621926Z"
    },
    "code_folding": [
     4,
     25,
     39
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import Block\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "\n",
    "class BERTProEpiClassifier(Block):\n",
    "    \"\"\"Model for sentence (pair) classification task with BERT.\n",
    "\n",
    "    The model feeds token ids and token type ids into BERT to get the\n",
    "    pooled BERT sequence representation, then apply a Dense layer for\n",
    "    classification. Does this also for an adversarial classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bert: BERTModel\n",
    "        Bidirectional encoder with transformer.\n",
    "    num_classes : int, default is 2\n",
    "        The number of target classes.\n",
    "    dropout : float or None, default 0.0.\n",
    "        Dropout probability for the bert output.\n",
    "    prefix : str or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    params : ParameterDict or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 num_classes=2,\n",
    "                 dropout=0.0,\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(BERTProEpiClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(nn.Dense(units=num_classes))\n",
    "\n",
    "    def forward(self,\n",
    "                inputs,\n",
    "                token_types,\n",
    "                valid_length=None,\n",
    "                inputs_epi=None,\n",
    "                token_types_epi=None,\n",
    "                valid_length_epi=None):  # pylint: disable=arguments-differ\n",
    "        \"\"\"Generate the unnormalized scores for the given the input sequences.\n",
    "        From both classifiers (classifier + adversarial_classifier).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : NDArray, shape (batch_size, seq_length)\n",
    "            Input words for the sequences.\n",
    "        token_types : NDArray, shape (batch_size, seq_length)\n",
    "            Token types for the sequences, used to indicate whether the word belongs to the\n",
    "            first sentence or the second one.\n",
    "        valid_length : NDArray or None, shape (batch_size)\n",
    "            Valid length of the sequence. This is used to mask the padded tokens.\n",
    "        inputs_epi : NDArray or None, shape (batch_size, seq_length)\n",
    "            Input words for the sequences. If None then same as inputs.\n",
    "        token_types_epi : NDArray or None, shape (batch_size, seq_length)\n",
    "            Token types for the sequences, used to indicate whether the word belongs to the\n",
    "            first sentence or the second one. If None then same as token_types.\n",
    "        valid_length_epi : NDArray or None, shape (batch_size)\n",
    "            Valid length of the sequence. This is used to mask the padded tokens.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : NDArray\n",
    "            Shape (batch_size, num_classes), outputs of classifier.\n",
    "        \"\"\"\n",
    "        # if inputs_epi is None and token_types_epi is None:\n",
    "        #     inputs_epi = inputs\n",
    "        #     token_types_epi = token_types\n",
    "        #     valid_length_epi = valid_length\n",
    "\n",
    "        _, pooler_out = self.bert(inputs, token_types, valid_length)\n",
    "        _, pooler_out_epi = self.bert(inputs_epi, token_types_epi, valid_length_epi)\n",
    "        pooler_concat = mx.nd.concat(pooler_out, pooler_out_epi, dim=1)\n",
    "        return self.classifier(pooler_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.656373Z",
     "start_time": "2019-07-07T20:53:12.640477Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_bert():\n",
    "    # change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "    ctx = mx.gpu(0)\n",
    "    # ctx =  mx.gpu() if mx.context.num_gpus() else mx.cpu()\n",
    "    # ctx = mx.cpu()\n",
    "\n",
    "    bert_base, vocabulary = nlp.model.get_model(\n",
    "        'bert_12_768_12',\n",
    "        dataset_name='book_corpus_wiki_en_uncased',\n",
    "        pretrained=True,\n",
    "        ctx=ctx,\n",
    "        use_pooler=True,\n",
    "        use_decoder=False,\n",
    "        use_classifier=False)\n",
    "    print(bert_base)\n",
    "\n",
    "    model = BERTProEpiClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "    #model = BERTProEpiClassifier(bert_base, num_classes=1, dropout=0.1)\n",
    "    # only need to initialize the classifier layer.\n",
    "    model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "    model.hybridize(static_alloc=True)\n",
    "\n",
    "    # softmax cross entropy loss for classification\n",
    "    loss_function = gluon.loss.SoftmaxCELoss()\n",
    "    #loss_function = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "    loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "    metric = mx.metric.Accuracy()\n",
    "\n",
    "    # use the vocabulary from pre-trained model for tokenization\n",
    "    bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "    # maximum sequence length\n",
    "    # max_len = 128  # + batch_size: 32\n",
    "    # 384 - 12\n",
    "    max_len = 512  # + batch_size: 6 ?\n",
    "    # the labels for the two classes\n",
    "    all_labels = [\"0\", \"1\"]\n",
    "    #all_labels = [0, 1]\n",
    "    # whether to transform the data as sentence pairs.\n",
    "    # for single sentence classification, set pair=False\n",
    "    transform = FirstAndLastPartBERTDatasetTransform(bert_tokenizer,\n",
    "                                                     max_len,\n",
    "                                                     labels=all_labels,\n",
    "                                                     label_dtype='int32',\n",
    "                                                     pad=True,\n",
    "                                                     pair=True)\n",
    "\n",
    "    return model, vocabulary, ctx, bert_tokenizer, transform, loss_function, metric, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.673476Z",
     "start_time": "2019-07-07T20:53:12.658664Z"
    },
    "code_folding": [
     0,
     6
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def transform_dataset(X, y, transform):\n",
    "    data_train_raw = MyBERTDataset(X, y)\n",
    "    data_train = data_train_raw.transform(transform)\n",
    "    return data_train_raw, data_train\n",
    "\n",
    "\n",
    "def predict_out_to_ys(all_predictions, all_labels):\n",
    "    y_true, y_pred = list(), list()\n",
    "\n",
    "    for _, y_true_many, y_pred_many in all_predictions:\n",
    "        y_true_many = y_true_many.T[0].asnumpy()\n",
    "        # https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.SoftmaxCrossEntropyLoss\n",
    "        # pred: the prediction tensor, where the batch_axis dimension ranges over batch size and axis dimension ranges over the number of classes.\n",
    "        y_pred_many = np.argmax(y_pred_many, axis=1).asnumpy()\n",
    "\n",
    "        y_true.extend(list(y_true_many))\n",
    "        y_pred.extend(list(y_pred_many))\n",
    "        # TODO: convert label_id to label?\n",
    "        # y_pred.extend(all_labels[c] for c in list(y_pred_many))\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.700472Z",
     "start_time": "2019-07-07T20:53:12.676386Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          data_train,\n",
    "          ctx,\n",
    "          metric,\n",
    "          loss_function,\n",
    "          batch_size=32,\n",
    "          lr=5e-6,\n",
    "          num_epochs=3,\n",
    "          checkpoint_dir=\"data\",\n",
    "          use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(\n",
    "            lengths=[int(item[1]) for item in tqdm(data_train)],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(), 'adam', {\n",
    "            'learning_rate': lr,\n",
    "            'epsilon': 1e-9\n",
    "        })\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [\n",
    "            p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "        ]\n",
    "\n",
    "    log_interval = 10\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(\n",
    "                    epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(\n",
    "                        checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               token_ids_epi, valid_length_epi,\n",
    "                               segment_ids_epi,\n",
    "                               label) in enumerate(bert_dataloader):\n",
    "                    with mx.autograd.record():\n",
    "\n",
    "                        # load data to GPU\n",
    "                        token_ids = token_ids.as_in_context(ctx)\n",
    "                        valid_length = valid_length.as_in_context(ctx)\n",
    "                        segment_ids = segment_ids.as_in_context(ctx)\n",
    "                        token_ids_epi = token_ids_epi.as_in_context(ctx)\n",
    "                        valid_length_epi = valid_length_epi.as_in_context(ctx)\n",
    "                        segment_ids_epi = segment_ids_epi.as_in_context(ctx)\n",
    "                        label = label.as_in_context(ctx)\n",
    "\n",
    "                        # forward computation\n",
    "                        out = model(token_ids, segment_ids,\n",
    "                                    valid_length.astype('float32'),\n",
    "                                    token_ids_epi, segment_ids_epi,\n",
    "                                    valid_length_epi.astype('float32'))\n",
    "                        #label = label.astype('float32')\n",
    "                        ls = loss_function(out, label).mean()\n",
    "\n",
    "                    # backward computation\n",
    "                    ls.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1)\n",
    "\n",
    "                    step_loss += ls.asscalar()\n",
    "                    #out = out.sigmoid().round().astype('int32')\n",
    "                    #label = label.astype('int32')\n",
    "                    metric.update([label], [out])\n",
    "                    stats.append((metric.get()[1], ls.asscalar()))\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f} - time {}'\n",
    "                            .format(\n",
    "                                epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                step_loss / log_interval,\n",
    "                                trainer.learning_rate,\n",
    "                                metric.get()[1],\n",
    "                                datetime.timedelta(seconds=(time.time() -\n",
    "                                                            t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.712967Z",
     "start_time": "2019-07-07T20:53:12.702073Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def predict(model, data_predict, ctx, metric, loss_function, batch_size=32):\n",
    "    bert_dataloader = mx.gluon.data.DataLoader(data_predict,\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "    all_predictions = list()\n",
    "\n",
    "    with Timer(\"prediction\"):\n",
    "        metric.reset()\n",
    "        cum_loss = 0\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, token_ids_epi,\n",
    "                       valid_length_epi, segment_ids_epi,\n",
    "                       label) in enumerate(tqdm(bert_dataloader)):\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            token_ids_epi = token_ids_epi.as_in_context(ctx)\n",
    "            valid_length_epi = valid_length_epi.as_in_context(ctx)\n",
    "            segment_ids_epi = segment_ids_epi.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'),\n",
    "                        token_ids_epi, segment_ids_epi,\n",
    "                        valid_length_epi.astype('float32'))\n",
    "            #label = label.astype('float32')\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "            #out = out.sigmoid().round().astype('int32')\n",
    "            #label = label.astype('int32')\n",
    "            metric.update([label], [out])\n",
    "            cum_loss += ls.asscalar()  # .sum() ?\n",
    "            all_predictions.append((batch_id, label, out))\n",
    "\n",
    "    return all_predictions, cum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.730671Z",
     "start_time": "2019-07-07T20:53:12.714462Z"
    },
    "code_folding": [
     0,
     24
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def print_infos(vocabulary, data_train_raw, data_train):\n",
    "    sample_id = 0\n",
    "\n",
    "    # sentence a\n",
    "    print(data_train_raw[sample_id][0])\n",
    "    # sentence b\n",
    "    print(data_train_raw[sample_id][1])\n",
    "    # 1 means equivalent, 0 means not equivalent\n",
    "    print(data_train_raw[sample_id][2])\n",
    "\n",
    "    print('vocabulary used for tokenization = \\n%s' % vocabulary)\n",
    "    print('[PAD] token id = %s' % (vocabulary['[PAD]']))\n",
    "    print('[CLS] token id = %s' % (vocabulary['[CLS]']))\n",
    "    print('[SEP] token id = %s' % (vocabulary['[SEP]']))\n",
    "\n",
    "    print('token ids = \\n%s' % data_train[sample_id][0])\n",
    "    print('valid length = \\n%s' % data_train[sample_id][1])\n",
    "    print('segment ids = \\n%s' % data_train[sample_id][2])\n",
    "    print('epi token ids = \\n%s' % data_train[sample_id][3])\n",
    "    print('epi valid length = \\n%s' % data_train[sample_id][4])\n",
    "    print('epi segment ids = \\n%s' % data_train[sample_id][5])\n",
    "    print('label = \\n%s' % data_train[sample_id][6])\n",
    "\n",
    "\n",
    "def plot_train_stats(stats):\n",
    "    if not stats:\n",
    "        print(\"no stats to plot\")\n",
    "        return\n",
    "\n",
    "    x = np.arange(len(stats))  # arange/linspace\n",
    "\n",
    "    acc_dots, loss_dots = zip(*stats)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, acc_dots)  # Linie: '-', 'o-', '.-'\n",
    "    plt.title('Training BERTClassifier')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x, loss_dots)\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:12.748521Z",
     "start_time": "2019-07-07T20:53:12.732049Z"
    },
    "code_folding": [
     0,
     12
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def heatconmat(y_test, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(np.unique(y_test)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, name=None, heatmap=True):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    if heatmap:\n",
    "        heatconmat(y_test, y_pred)\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2), '\\n')  #\n",
    "\n",
    "    print('Report{}:'.format(\"\" if not name else \" for [{}]\".format(name)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    f1_dic = {}\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:26.471698Z",
     "start_time": "2019-07-07T20:53:26.468912Z"
    }
   },
   "outputs": [],
   "source": [
    "within_traindev_df = within_traindev_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:27.733744Z",
     "start_time": "2019-07-07T20:53:27.721434Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train split]: 0:00:00.009893\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:31.856726Z",
     "start_time": "2019-07-07T20:53:29.229619Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTModel(\n",
      "  (encoder): BERTEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (1): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (2): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (3): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (4): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (5): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (6): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (7): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (8): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (9): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (10): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (11): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_embed): HybridSequential(\n",
      "    (0): Embedding(30522 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (token_type_embed): HybridSequential(\n",
      "    (0): Embedding(2 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (pooler): Dense(768 -> 768, Activation(tanh))\n",
      ")\n",
      "Time for [2 - setup BERT model]: 0:00:02.623507\n"
     ]
    }
   ],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:32.589640Z",
     "start_time": "2019-07-07T20:53:32.585724Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTProEpiClassifier(\n",
      "  (bert): BERTModel(\n",
      "    (encoder): BERTEncoder(\n",
      "      (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "      (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      (transformer_cells): HybridSequential(\n",
      "        (0): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (1): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (2): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (3): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (4): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (5): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (6): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (7): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (8): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (9): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (10): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (11): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_embed): HybridSequential(\n",
      "      (0): Embedding(30522 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (token_type_embed): HybridSequential(\n",
      "      (0): Embedding(2 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (pooler): Dense(768 -> 768, Activation(tanh))\n",
      "  )\n",
      "  (classifier): HybridSequential(\n",
      "    (0): Dropout(p = 0.1, axes=())\n",
      "    (1): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:33.411995Z",
     "start_time": "2019-07-07T20:53:33.294141Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro: pro-choice con: pro-life i would consider my views regarding abortion more on the pro life side, and here is why. for one, abortion is murder, murder is wrong. secondly, no woman has the right to terminate another life, this is not an issue of body autonomy or woman\"s rights, it\"s about whether women have the right to end another life because it\"s more convenient for her to do so. lastly, i do not believe that abortions should be illegal all together, there should be exceptions, just like every other law that operates in today\"s society. the only cases where abortion should be an option for women is when: 1-it is the product of rape/incest. 2- it is apparent that having the child poses a deadly threat to the mother, i. e, it is predictable that the mother will be seriously harmed/killed in the process of giving birth to the baby. women should not have the right to end the life of another because it is more convienient for her to end its life.\n",
      "i hope to change your mind on this topic, although people seem to be deeply rooted with their beliefs, i hope my arguments make sense so that you may change your mind on this issue. to answer your questions, yes i am vegetarian because i do find value in life, whether it is human life or animal life. do i think it\"s right to kill others while defending our country? yes and no, i think there are solutions other than war but when it comes to the safety of the people of this country there is a legitimate reason to take the life of others, because in the end it is protecting ours. and yes, in the case of rape and incest it may seem odd how it should be okay to kill the fetus in this situation if abortion is so morally wrong, but because a woman would be forced into this situation and she didn\"t knowingly get herself into this situation, then i don\"t think the government at least should have the right to tell her what to do in these situations. do i think it is morally right to still abort a fetus even in these cases? no. but do i think it would be extereme if our government told women who were raped or involved in cases of incest to carry the baby to term? yes. sometimes there isn\"t a good answer to every question, and in any case it is tragic if a fetus is aborted, but would it infringe upon the rights of the women if in every case we told her as a society that she has to carry to term? probably so. i don\"t see this is a flaw in judgement, i see this as finding a way to respect the rights of women and the rights of the unborn. just because there are exceptions to rules it doesn\"t mean that it makes the basis of that argument invalid. for example, the death penalty and the right of police officers to use lethal force when necessary is a great example. we as a society have established that murder is bad an not morally right. i can\"t just walk to my local store and just start shooting people. but, we as a society have agreed that in some cases that extreme criminals should face the death penalty because of their crimes. similar to this example, police officers carry weapons and are allowed to use lethal force if they feel necessary, i. e. they fell as if there life is threatened and they do not have a choice. just because there are instances where it is deemed okay to murder another person doesn\"t mean our overarching idea of murder being bad is flawed. just because we are allowed to kill in these circumstances doesn\"t mean it should be okay for everyone/anyone to do so, i think we can agree on that, hopefully. in deeper response to your vegan/vegetarian question, as i said before i am vegetarian because i do not believe in killing other life\"s for my own personal gain. if i am able to live and be healthy without killing an animal in the process, i don\"t see how that is a bad thing. i don\"t think we can compare animal lives however to human lives for the sake of argument, but yes i do value all life. the reason my views may come off as selective and hypocritical is because i say that in some cases the female should at least have the option to abort a fetus, but only because there needs to be a \"middle ground\" where women\"s rights aren\"t being infringed upon, but at the same time they are being held accountable for their actions. on this note, i think other things in our current system need to change to support this as well, such as free birth care. i challenge anyone of the pro-choice stance to really evaluate why they have the beliefs on this topic that they do, to actually look at this philosophically and judge then if people should have the right to end another life if it\"s just \"too inconvient\" for them to have a child. there isn\"t going to be a perfect answer to this issue, but i truly believe that this is good answer for both sides.\n",
      "1\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  4013  1024  4013  1011  3601  9530  1024  4013  1011  2166  1045\n",
      "  2052  5136  2026  5328  4953 11324  2062  2006  1996  4013  2166  2217\n",
      "  1010  1998  2182  2003  2339  1012  2005  2028  1010 11324  2003  4028\n",
      "  1010  4028  2003  3308  1012 16378  1010  2053  2450  2038  1996  2157\n",
      "  2000 20320  2178  2166  1010  2023  2003  2025  2019  3277  1997  2303\n",
      " 12645  2030  2450  1000  1055  2916  1010  2009  1000  1055  2055  3251\n",
      "  2308  2031  1996  2157  2000  2203  2178  2166  2138  2009  1000  1055\n",
      "  2062 14057  2005  2014  2000  2079  2061  1012 22267  1010  1045  2079\n",
      "  2025  2903  2008 11324  2015  2323  2022  6206  2035  2362  1010  2045\n",
      "  2323  2022 11790  1010  2074  2066  2296  2060  2375  2008  5748  1999\n",
      "  2651  1000  1055  2554  1012  1996  2069  3572  2073 11324  2323  2022\n",
      "  2019  5724  2005  2308  2003  2043  1024  1015  1011  2009  2003  1996\n",
      "  4031  1997  9040  1013  4297  4355  1012  1016  1011  2009  2003  6835\n",
      "  2008  2383  1996  2775 22382  1037  9252  5081  2000  1996  2388  1010\n",
      "  1045  1012  1041  1010  2009  2003 21425  2008  1996  2388  2097  2022\n",
      "  5667 25596  1013  2730  1999  1996  2832  1997  3228  4182  2000  1996\n",
      "  3336  1012  2308  2323  2025  2031  1996  2157  2000  2203  1996  2166\n",
      "  1997  2178  2138  2009  2003  2062  9530 13469  8034  3372  2005  2014\n",
      "  2000  2203  2049  2166  1012     3  1045  3246  2000  2689  2115  2568\n",
      "  2006  2023  8476  1010  2348  2111  4025  2000  2022  6171 15685  2007\n",
      "  2037  9029  1010  1045  3246  2026  9918  2191  3168  2061  2008  2017\n",
      "  2089  2689  2115  2568  2006  2023  3277  1012  2000  3437  2115  3980\n",
      "  1010  2748  1045  2572 23566  2138  1045  2079  2424  3643  1999  2166\n",
      "  1010  3251  2009  2003  2529  2166  2030  4111  2166  1012  2079  1045\n",
      "  2228  2009  1000  1055  2157  2000  3102  2500  2096  6984  2256  2406\n",
      "  1029  2748  1998  2053  1010  1045  2228  2045  2024  7300  2060  2084\n",
      "  2162  2021  2043  2009  3310  2000  1996  3808  1997  1996  2111  1997\n",
      "  2023  2406  2045  2003  1037 11476  3114  2000  2202  1996  2166  1997\n",
      "  2500  1010  2138  1999  1996  2203  2009  2003  8650 14635  1012  1998\n",
      "  2748  1010  1999  1996  2553  1997  9040  1998  4297  4355  2009  2089\n",
      "  4025  5976  2129  2009  2323  2022  3100  2000  3102  1996 10768  5809\n",
      "  1999  2023  3663  2065 11324  2003  2061 28980  3308  1010  2021  2138\n",
      "  1037  2450  2052  2022  3140  2046  2023  3663  1998  2016  2134  1000\n",
      "  1056  4209  2135  2131  2841  2046  2023  3663  1010  2059  1045  2123\n",
      "  1000  1056  2228  1996  2231  2012  2560  2323  2031  1996  2157  2000\n",
      "  2425  2014  2054  2000  2079  1999  2122  8146  1012  2079  1045  2228\n",
      "  2009  2003 28980  2157  2000  2145 11113 11589  1037 10768  5809  2130\n",
      "  1999  2122  3572  1029  2053  1012  2021  2079  1045  2228  2009  2052\n",
      "  2022  4654  3334 21382  2065  2256  2231  2409  2308  2040  2020 15504\n",
      "  2030  2920  1999  3572  1997  4297  4355  2000  4287  1996  3336  2000\n",
      "  2744  1029  2748  1012  2823  2045  3475  1000  1056  1037  2204  3437\n",
      "  2000  2296  3160  1010  1998  1999  2151  2553  2009  2003 13800  2065\n",
      "  1037 10768  5809  2003 11113 15613  1010     3]\n",
      "valid length = \n",
      "512\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "epi token ids = \n",
      "[    2  4013  1024  4013  1011  3601  9530  1024  4013  1011  2166  1045\n",
      "  2052  5136  2026  5328  4953 11324  2062  2006  1996  4013  2166  2217\n",
      "  1010  1998  2182  2003  2339  1012  2005  2028  1010 11324  2003  4028\n",
      "  1010  4028  2003  3308  1012 16378  1010  2053  2450  2038  1996  2157\n",
      "  2000 20320  2178  2166  1010  2023  2003  2025  2019  3277  1997  2303\n",
      " 12645  2030  2450  1000  1055  2916  1010  2009  1000  1055  2055  3251\n",
      "  2308  2031  1996  2157  2000  2203  2178  2166  2138  2009  1000  1055\n",
      "  2062 14057  2005  2014  2000  2079  2061  1012 22267  1010  1045  2079\n",
      "  2025  2903  2008 11324  2015  2323  2022  6206  2035  2362  1010  2045\n",
      "  2323  2022 11790  1010  2074  2066  2296  2060  2375  2008  5748  1999\n",
      "  2651  1000  1055  2554  1012  1996  2069  3572  2073 11324  2323  2022\n",
      "  2019  5724  2005  2308  2003  2043  1024  1015  1011  2009  2003  1996\n",
      "  4031  1997  9040  1013  4297  4355  1012  1016  1011  2009  2003  6835\n",
      "  2008  2383  1996  2775 22382  1037  9252  5081  2000  1996  2388  1010\n",
      "  1045  1012  1041  1010  2009  2003 21425  2008  1996  2388  2097  2022\n",
      "  5667 25596  1013  2730  1999  1996  2832  1997  3228  4182  2000  1996\n",
      "  3336  1012  2308  2323  2025  2031  1996  2157  2000  2203  1996  2166\n",
      "  1997  2178  2138  2009  2003  2062  9530 13469  8034  3372  2005  2014\n",
      "  2000  2203  2049  2166  1012     3  1012  1999  6748  3433  2000  2115\n",
      " 15942  2078  1013 23566  3160  1010  2004  1045  2056  2077  1045  2572\n",
      " 23566  2138  1045  2079  2025  2903  1999  4288  2060  2166  1000  1055\n",
      "  2005  2026  2219  3167  5114  1012  2065  1045  2572  2583  2000  2444\n",
      "  1998  2022  7965  2302  4288  2019  4111  1999  1996  2832  1010  1045\n",
      "  2123  1000  1056  2156  2129  2008  2003  1037  2919  2518  1012  1045\n",
      "  2123  1000  1056  2228  2057  2064 12826  4111  3268  2174  2000  2529\n",
      "  3268  2005  1996  8739  1997  6685  1010  2021  2748  1045  2079  3643\n",
      "  2035  2166  1012  1996  3114  2026  5328  2089  2272  2125  2004 13228\n",
      "  1998  1044 22571 10085 14778  7476  2003  2138  1045  2360  2008  1999\n",
      "  2070  3572  1996  2931  2323  2012  2560  2031  1996  5724  2000 11113\n",
      " 11589  1037 10768  5809  1010  2021  2069  2138  2045  3791  2000  2022\n",
      "  1037  1000  2690  2598  1000  2073  2308  1000  1055  2916  4995  1000\n",
      "  1056  2108  1999 19699 23496  2094  2588  1010  2021  2012  1996  2168\n",
      "  2051  2027  2024  2108  2218 26771  2005  2037  4506  1012  2006  2023\n",
      "  3602  1010  1045  2228  2060  2477  1999  2256  2783  2291  2342  2000\n",
      "  2689  2000  2490  2023  2004  2092  1010  2107  2004  2489  4182  2729\n",
      "  1012  1045  4119  3087  1997  1996  4013  1011  3601 11032  2000  2428\n",
      " 16157  2339  2027  2031  1996  9029  2006  2023  8476  2008  2027  2079\n",
      "  1010  2000  2941  2298  2012  2023  9569  2135  1998  3648  2059  2065\n",
      "  2111  2323  2031  1996  2157  2000  2203  2178  2166  2065  2009  1000\n",
      "  1055  2074  1000  2205  4297  2239 13469  3372  1000  2005  2068  2000\n",
      "  2031  1037  2775  1012  2045  3475  1000  1056  2183  2000  2022  1037\n",
      "  3819  3437  2000  2023  3277  1010  2021  1045  5621  2903  2008  2023\n",
      "  2003  2204  3437  2005  2119  3903  1012     3]\n",
      "epi valid length = \n",
      "512\n",
      "epi segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "label = \n",
      "[1]\n",
      "Time for [3 - prepare training data]: 0:00:00.113653\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"):\n",
    "    # train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3)\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=2)\n",
    "    # model.save_parameters(\"data/same-side-classification/within-topic/bert.model.params\")\n",
    "    model.save_parameters(\"data/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:53:38.470038Z",
     "start_time": "2019-07-07T20:53:38.362305Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marriage is not about love, but starting family margarette somerville. \"the case against gay marriage.\" mcgill center for medicine, ethics and law. april 29, 2003: \"jonathan rauch, in his recent book gay marriage: why it is good for gays, good for straights, and good for america, defines marriage as essentially a legally enforced, long-term relation of mutual aid and support between two sexual partners. marriage, he says, \"is putting one person ahead of all others.\" according to rauch, \"if marriage means anything at all,\" it is knowing \"that there is someone out there for whom you are always first in line.\" we can here leave aside how odd this definition will sound to any married couple with young children, partners whose first responsibility is not obviously spousal.\"\n",
      "denying marriage to infertile would be too costly adam kolasinksi. \"the secular case against gay marriage.\" the tech (m.i.t.) february 20th, 2004: \"a small minority of married couples are infertile. however, excluding sterile couples from marriage, in all but the most obvious cases such as those of blood relatives, would be costly. few people who are sterile know it, and fertility tests are too expensive and burdensome to mandate.\"\n",
      "1\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  3510  2003  2025  2055  2293  1010  2021  3225  2155  5545  2618\n",
      " 27209  1012  1000  1996  2553  2114  5637  3510  1012  1000 17919  2415\n",
      "  2005  4200  1010  9615  1998  2375  1012  2258  2756  1010  2494  1024\n",
      "  1000  5655 10958 10875  1010  1999  2010  3522  2338  5637  3510  1024\n",
      "  2339  2009  2003  2204  2005  5637  2015  1010  2204  2005  3442  2015\n",
      "  1010  1998  2204  2005  2637  1010 11859  3510  2004  7687  1037 10142\n",
      " 16348  1010  2146  1011  2744  7189  1997  8203  4681  1998  2490  2090\n",
      "  2048  4424  5826  1012  3510  1010  2002  2758  1010  1000  2003  5128\n",
      "  2028  2711  3805  1997  2035  2500  1012  1000  2429  2000 10958 10875\n",
      "  1010  1000  2065  3510  2965  2505  2012  2035  1010  1000  2009  2003\n",
      "  4209  1000  2008  2045  2003  2619  2041  2045  2005  3183  2017  2024\n",
      "  2467  2034  1999  2240  1012  1000  2057  2064  2182  2681  4998  2129\n",
      "  5976  2023  6210  2097  2614  2000  2151  2496  3232  2007  2402  2336\n",
      "  1010  5826  3005  2034  5368  2003  2025  5525 11867  3560  2389  1012\n",
      "  1000     3 16039  3510  2000  1999  7512 15286  2052  2022  2205 17047\n",
      "  4205 12849  8523 19839  5332  1012  1000  1996 10644  2553  2114  5637\n",
      "  3510  1012  1000  1996  6627  1006  1049  1012  1045  1012  1056  1012\n",
      "  1007  2337  3983  1010  2432  1024  1000  1037  2235  7162  1997  2496\n",
      "  6062  2024  1999  7512 15286  1012  2174  1010 13343 25403  6062  2013\n",
      "  3510  1010  1999  2035  2021  1996  2087  5793  3572  2107  2004  2216\n",
      "  1997  2668  9064  1010  2052  2022 17047  1012  2261  2111  2040  2024\n",
      " 25403  2113  2009  1010  1998 17376  5852  2024  2205  6450  1998 10859\n",
      " 14045  2000 11405  1012  1000     3     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "270\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "epi token ids = \n",
      "[    2  3510  2003  2025  2055  2293  1010  2021  3225  2155  5545  2618\n",
      " 27209  1012  1000  1996  2553  2114  5637  3510  1012  1000 17919  2415\n",
      "  2005  4200  1010  9615  1998  2375  1012  2258  2756  1010  2494  1024\n",
      "  1000  5655 10958 10875  1010  1999  2010  3522  2338  5637  3510  1024\n",
      "  2339  2009  2003  2204  2005  5637  2015  1010  2204  2005  3442  2015\n",
      "  1010  1998  2204  2005  2637  1010 11859  3510  2004  7687  1037 10142\n",
      " 16348  1010  2146  1011  2744  7189  1997  8203  4681  1998  2490  2090\n",
      "  2048  4424  5826  1012  3510  1010  2002  2758  1010  1000  2003  5128\n",
      "  2028  2711  3805  1997  2035  2500  1012  1000  2429  2000 10958 10875\n",
      "  1010  1000  2065  3510  2965  2505  2012  2035  1010  1000  2009  2003\n",
      "  4209  1000  2008  2045  2003  2619  2041  2045  2005  3183  2017  2024\n",
      "  2467  2034  1999  2240  1012  1000  2057  2064  2182  2681  4998  2129\n",
      "  5976  2023  6210  2097  2614  2000  2151  2496  3232  2007  2402  2336\n",
      "  1010  5826  3005  2034  5368  2003  2025  5525 11867  3560  2389  1012\n",
      "  1000     3 16039  3510  2000  1999  7512 15286  2052  2022  2205 17047\n",
      "  4205 12849  8523 19839  5332  1012  1000  1996 10644  2553  2114  5637\n",
      "  3510  1012  1000  1996  6627  1006  1049  1012  1045  1012  1056  1012\n",
      "  1007  2337  3983  1010  2432  1024  1000  1037  2235  7162  1997  2496\n",
      "  6062  2024  1999  7512 15286  1012  2174  1010 13343 25403  6062  2013\n",
      "  3510  1010  1999  2035  2021  1996  2087  5793  3572  2107  2004  2216\n",
      "  1997  2668  9064  1010  2052  2022 17047  1012  2261  2111  2040  2024\n",
      " 25403  2113  2009  1010  1998 17376  5852  2024  2205  6450  1998 10859\n",
      " 14045  2000 11405  1012  1000     3     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "epi valid length = \n",
      "270\n",
      "epi segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[1]\n",
      "Time for [5 - prepare eval data]: 0:00:00.105086\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"):\n",
    "    # model.load_parameters(\"data/same-side-classification/within-topic/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T20:57:55.912963Z",
     "start_time": "2019-07-07T20:53:44.026168Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [00:02<00:00, 238.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [setup training]: 0:00:02.945971\n",
      "[Epoch 0 Batch 10/353] loss=0.7496, lr=0.0000050, acc=0.500 - time 0:00:07.286613\n",
      "[Epoch 0 Batch 20/353] loss=0.7705, lr=0.0000050, acc=0.487 - time 0:00:05.740098\n",
      "[Epoch 0 Batch 30/353] loss=0.7293, lr=0.0000050, acc=0.525 - time 0:00:06.516846\n",
      "[Epoch 0 Batch 40/353] loss=0.7326, lr=0.0000050, acc=0.506 - time 0:00:06.150889\n",
      "[Epoch 0 Batch 50/353] loss=0.6718, lr=0.0000050, acc=0.505 - time 0:00:06.745883\n",
      "[Epoch 0 Batch 60/353] loss=0.8377, lr=0.0000050, acc=0.471 - time 0:00:06.122975\n",
      "[Epoch 0 Batch 70/353] loss=0.8019, lr=0.0000050, acc=0.460 - time 0:00:06.686329\n",
      "[Epoch 0 Batch 80/353] loss=0.6848, lr=0.0000050, acc=0.484 - time 0:00:06.073261\n",
      "[Epoch 0 Batch 90/353] loss=0.6448, lr=0.0000050, acc=0.492 - time 0:00:06.653632\n",
      "[Epoch 0 Batch 100/353] loss=0.7408, lr=0.0000050, acc=0.480 - time 0:00:05.907560\n",
      "[Epoch 0 Batch 110/353] loss=0.7660, lr=0.0000050, acc=0.463 - time 0:00:06.727626\n",
      "[Epoch 0 Batch 120/353] loss=0.6827, lr=0.0000050, acc=0.471 - time 0:00:06.134780\n",
      "[Epoch 0 Batch 130/353] loss=0.7509, lr=0.0000050, acc=0.469 - time 0:00:06.857106\n",
      "[Epoch 0 Batch 140/353] loss=0.6955, lr=0.0000050, acc=0.464 - time 0:00:06.047660\n",
      "[Epoch 0 Batch 150/353] loss=0.7074, lr=0.0000050, acc=0.470 - time 0:00:06.558745\n",
      "[Epoch 0 Batch 160/353] loss=0.7332, lr=0.0000050, acc=0.467 - time 0:00:05.823416\n",
      "[Epoch 0 Batch 170/353] loss=0.7147, lr=0.0000050, acc=0.460 - time 0:00:06.861773\n",
      "[Epoch 0 Batch 180/353] loss=0.7645, lr=0.0000050, acc=0.454 - time 0:00:06.069972\n",
      "[Epoch 0 Batch 190/353] loss=0.6633, lr=0.0000050, acc=0.464 - time 0:00:06.830320\n",
      "[Epoch 0 Batch 200/353] loss=0.7044, lr=0.0000050, acc=0.466 - time 0:00:06.022621\n",
      "[Epoch 0 Batch 210/353] loss=0.7524, lr=0.0000050, acc=0.460 - time 0:00:06.910436\n",
      "[Epoch 0 Batch 220/353] loss=0.6696, lr=0.0000050, acc=0.465 - time 0:00:06.046026\n",
      "[Epoch 0 Batch 230/353] loss=0.6446, lr=0.0000050, acc=0.475 - time 0:00:06.917966\n",
      "[Epoch 0 Batch 240/353] loss=0.7219, lr=0.0000050, acc=0.477 - time 0:00:05.757057\n",
      "[Epoch 0 Batch 250/353] loss=0.7470, lr=0.0000050, acc=0.474 - time 0:00:06.838749\n",
      "[Epoch 0 Batch 260/353] loss=0.6964, lr=0.0000050, acc=0.474 - time 0:00:05.802696\n",
      "[Epoch 0 Batch 270/353] loss=0.8024, lr=0.0000050, acc=0.469 - time 0:00:06.653764\n",
      "[Epoch 0 Batch 280/353] loss=0.7364, lr=0.0000050, acc=0.465 - time 0:00:06.238369\n",
      "[Epoch 0 Batch 290/353] loss=0.7260, lr=0.0000050, acc=0.464 - time 0:00:06.771306\n",
      "[Epoch 0 Batch 300/353] loss=0.6637, lr=0.0000050, acc=0.466 - time 0:00:06.529682\n",
      "[Epoch 0 Batch 310/353] loss=0.7331, lr=0.0000050, acc=0.467 - time 0:00:06.377731\n",
      "[Epoch 0 Batch 320/353] loss=0.7222, lr=0.0000050, acc=0.466 - time 0:00:06.639320\n",
      "[Epoch 0 Batch 330/353] loss=0.6518, lr=0.0000050, acc=0.471 - time 0:00:05.954520\n",
      "[Epoch 0 Batch 340/353] loss=0.6496, lr=0.0000050, acc=0.476 - time 0:00:06.324551\n",
      "[Epoch 0 Batch 350/353] loss=0.7488, lr=0.0000050, acc=0.480 - time 0:00:06.287927\n",
      "Time for [epoch 0]: 0:03:45.741484\n",
      "Time for [training]: 0:03:46.275557\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [4 - train model - 0]: 0:03:49.378720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:20<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [prediction]: 0:00:20.243516\n",
      "Accuracy in epoch 0: 0.5666666666666667\n",
      "Confusion Matrix:\n",
      "[[  0 124]\n",
      " [  6 170]]\n",
      "\n",
      "Accuracy:  0.57 \n",
      "\n",
      "Report for [BERTClassifier - last part]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       124\n",
      "           1       0.58      0.97      0.72       176\n",
      "\n",
      "    accuracy                           0.57       300\n",
      "   macro avg       0.29      0.48      0.36       300\n",
      "weighted avg       0.34      0.57      0.42       300\n",
      "\n",
      "Time for [6 - evaluate - 0]: 0:00:20.271037\n"
     ]
    }
   ],
   "source": [
    "for epoch_id in range(1):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        # stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=2, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        # all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6)  # seq_len: 512\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - last part\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*may need to use **binary_cross_entrophy**?* (can I use a single label or do I have to use \"0\" and \"1\"?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"):\n",
    "    # train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3)\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=2)\n",
    "    # model.save_parameters(\"data/same-side-classification/cross-topic/bert.model.params\")\n",
    "    model.save_parameters(\"data/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"):\n",
    "    # model.load_parameters(\"data/same-side-classification/cross-topic/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
