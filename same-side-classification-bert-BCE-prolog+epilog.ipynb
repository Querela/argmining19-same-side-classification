{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gluon-nlp.mxnet.io/install.html\n",
    "\n",
    "```\n",
    "pip install --upgrade 'mxnet>=1.3.0'\n",
    "pip install gluonnlp\n",
    "wget https://gluon-nlp.mxnet.io/_downloads/sentence_embedding.zip\n",
    "unzip sentence_embedding.zip\n",
    "ln -s sentence_embedding/bert bert\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:26:03.789993Z",
     "start_time": "2019-07-17T10:26:03.433071Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import csv\n",
    "import gluonnlp as nlp\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from bert import *\n",
    "from mxboard import SummaryWriter\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon.data import Dataset, SimpleDataset\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:26:04.081942Z",
     "start_time": "2019-07-17T10:26:04.075501Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:26:06.141511Z",
     "start_time": "2019-07-17T10:26:06.136975Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:26:06.475065Z",
     "start_time": "2019-07-17T10:26:06.470570Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# set repeatable random state\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:26:06.903465Z",
     "start_time": "2019-07-17T10:26:06.899960Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:26:09.028211Z",
     "start_time": "2019-07-17T10:26:08.996769Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c93a394937a4486af82839f2a6b7350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make tqdm jupyter friendly\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# for .progress_apply() we have to hack it like this?\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:26:11.313747Z",
     "start_time": "2019-07-17T10:26:11.304908Z"
    },
    "code_folding": [
     0,
     4
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:26:19.536805Z",
     "start_time": "2019-07-17T10:26:19.533091Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:28:17.362473Z",
     "start_time": "2019-07-17T10:28:15.599755Z"
    },
    "code_folding": [
     9,
     19
    ],
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:00.877454\n",
      "Time for [read within]: 0:00:00.875571\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"read cross\"):\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                    quotechar='\"',\n",
    "                                    quoting=csv.QUOTE_ALL,\n",
    "                                    encoding='utf-8',\n",
    "                                    escapechar='\\\\',\n",
    "                                    doublequote=False,\n",
    "                                    index_col='id')\n",
    "    cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id')\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    within_traindev_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                     quotechar='\"',\n",
    "                                     quoting=csv.QUOTE_ALL,\n",
    "                                     encoding='utf-8',\n",
    "                                     escapechar='\\\\',\n",
    "                                     doublequote=False,\n",
    "                                     index_col='id')\n",
    "    # within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "    #                              quotechar='\"',\n",
    "    #                              quoting=csv.QUOTE_ALL,\n",
    "    #                              encoding='utf-8',\n",
    "    #                              escapechar='\\\\',\n",
    "    #                              doublequote=True,  # <-- change, \"\" as quote escape in text?\n",
    "    #                              index_col='id')\n",
    "    within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:28:21.819958Z",
     "start_time": "2019-07-17T10:28:21.676595Z"
    }
   },
   "outputs": [],
   "source": [
    "! head -n 5 data/same-side-classification/within-topic/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.258540Z",
     "start_time": "2019-07-17T10:28:42.029654Z"
    },
    "code_folding": [
     1
    ],
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b23cac2c4e74144bd4df929a1141b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61048), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag cross traindev]: 0:00:34.638482\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e085cb5a46a3456faa24b0c0d761ea1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=6163), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag cross test]: 0:00:03.395477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dcbc2869ee409b8e46df18c2028d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63903), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag within traindev]: 0:00:36.199224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1c4c6159a04013846af51fbfccb484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag within test]: 0:00:01.984679\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross traindev\"):\n",
    "    cross_traindev_df = cross_traindev_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag cross test\"):\n",
    "    cross_test_df = cross_test_df.progress_apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within traindev\"):\n",
    "    within_traindev_df = within_traindev_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag within test\"):\n",
    "    within_test_df = within_test_df.progress_apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.298375Z",
     "start_time": "2019-07-17T10:29:58.289895Z"
    },
    "code_folding": [
     4
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# requires nltk  wordtokenize\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# model uses BERT Tokenizer ...\n",
    "\n",
    "def get_overview(df, task='same-side', class_name='is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task)\n",
    "    print('=' * 40, '\\n')\n",
    "\n",
    "    print('Total instances: ', total)\n",
    "    print('\\n')\n",
    "\n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t', is_same_side, ': ', len(side_df), ' instances')\n",
    "    print('\\n')\n",
    "\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "        print('\\n')\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))), '\\n')\n",
    "    \n",
    "    return\n",
    "\n",
    "    print('-' * 40, '\\n')\n",
    "\n",
    "    arguments_length_lst = [\n",
    "        len(word_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_length_lst.extend(\n",
    "        [len(word_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Words:')\n",
    "    print('\\tshortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('\\tlongest argument:', max(arguments_length_lst), ' words')\n",
    "    print('\\targument average length:', np.mean(arguments_length_lst),\n",
    "          ' words')\n",
    "\n",
    "    arguments_sent_length_lst = [\n",
    "        len(sent_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_sent_length_lst.extend(\n",
    "        [len(sent_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Sentences:')\n",
    "    print('\\tshortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\tlongest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\targument average length:', np.mean(arguments_sent_length_lst),\n",
    "          ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"overview cross\"):\n",
    "    get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"overview within\"):\n",
    "    get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count raw length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def compute_arg_len(row):\n",
    "    row['argument1_len'] = len(row['argument1'])\n",
    "    row['argument2_len'] = len(row['argument2'])\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    return row\n",
    "\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.progress_apply(compute_arg_len, axis=1)\n",
    "within_traindev_df = within_traindev_df.progress_apply(compute_arg_len, axis=1)\n",
    "#cross_test_df = cross_test_df.progress_apply(compute_arg_len, axis=1)\n",
    "within_test_df = within_test_df.progress_apply(compute_arg_len, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokenize and count tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx = mx.cpu()\n",
    "_, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                    dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                    pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                                    use_decoder=False, use_classifier=False)\n",
    "bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "tokenizer = bert_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# nltk.download('punct')\n",
    "\n",
    "\n",
    "# tokenizer from BERT\n",
    "def tokenize_arguments(row):\n",
    "    # tokenize\n",
    "    row['argument1_tokens'] = tokenizer(row['argument1'])\n",
    "    row['argument2_tokens'] = tokenizer(row['argument2'])\n",
    "\n",
    "    # count tokens\n",
    "    row['argument1_len'] = len(row['argument1_tokens'])\n",
    "    row['argument2_len'] = len(row['argument2_tokens'])\n",
    "    # token number diff\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    return row\n",
    "\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.progress_apply(tokenize_arguments, axis=1)\n",
    "within_traindev_df = within_traindev_df.progress_apply(tokenize_arguments, axis=1)\n",
    "#cross_test_df = cross_test_df.progress_apply(tokenize_arguments, axis=1)\n",
    "within_test_df = within_test_df.progress_apply(tokenize_arguments, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_traindev_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_lengths(df, slicen=None, abs_diff=True, title=None):\n",
    "    if df is None:\n",
    "        print(\"no lengths to plot\")\n",
    "        return\n",
    "    \n",
    "    arg1_lens = df['argument1_len']\n",
    "    arg2_lens = df['argument2_len']\n",
    "    arg_diff_len = df['argument12_len_diff']\n",
    "    \n",
    "    if abs_diff:\n",
    "        arg_diff_len = np.abs(arg_diff_len)\n",
    "    \n",
    "    if slicen is not None:\n",
    "        arg1_lens = arg1_lens[slicen]\n",
    "        arg2_lens = arg2_lens[slicen]\n",
    "        arg_diff_len = arg_diff_len[slicen]\n",
    "\n",
    "    x = np.arange(len(arg1_lens))  # arange/linspace\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, arg1_lens, label='argument1')  # Linie: '-', 'o-', '.-'\n",
    "    plt.plot(x, arg2_lens, label='argument2')  # Linie: '-', 'o-', '.-'\n",
    "    plt.legend()\n",
    "    plt.title('Lengths of arguments' if not title else title)\n",
    "    plt.ylabel('Lengths of arguments 1 and 2')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x, arg_diff_len)\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Differences')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_lengths(within_traindev_df, slice(None, None, 500), title='Length of arguments within train/dev, every 500')\n",
    "plot_lengths(cross_traindev_df, slice(None, None, 500), title='Length of arguments cross train/dev, every 500')\n",
    "plot_lengths(within_test_df, slice(None, None, 1), title='Length of arguments within test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.330306Z",
     "start_time": "2019-07-17T10:29:58.327370Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "- https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.364166Z",
     "start_time": "2019-07-17T10:29:58.359843Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyBERTDataset(SimpleDataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        super(MyBERTDataset, self).__init__(self._convert())\n",
    "\n",
    "    def _convert(self):\n",
    "        allsamples = list()\n",
    "\n",
    "        if self._y is not None:\n",
    "            df = self._X.merge(self._y, left_index=True, right_index=True)\n",
    "            for _, row in df.iterrows():\n",
    "                # allsamples.append([\n",
    "                #     row['argument1'], row['argument2'],\n",
    "                #     \"1\" if str(row['is_same_side']) == \"True\" else \"0\"\n",
    "                # ])\n",
    "                allsamples.append([\n",
    "                    row['argument1'], row['argument2'],\n",
    "                    1 if str(row['is_same_side']) == \"True\" else 0\n",
    "                ])\n",
    "\n",
    "        else:\n",
    "            for _, row in self._X.iterrows():\n",
    "                allsamples.append([row['argument1'], row['argument2'], None])\n",
    "\n",
    "        return allsamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: my own `BERTDatasetTransform` for extracting chunks from arguments or last part etc.\n",
    "\n",
    "```python\n",
    "transform = dataset.BERTDatasetTransform(bert_tokenizer, 512,\n",
    "                                         labels=['0', '1'],\n",
    "                                         label_dtype='int32',\n",
    "                                         pad=True,\n",
    "                                         pair=True)\n",
    "```\n",
    "\n",
    "http://localhost:9001/edit/bert/dataset.py @454\n",
    "```python\n",
    "# substitute with my own (e. g. last part, many parts etc.)\n",
    "def __init__(...):\n",
    "    self._bert_xform = BERTSentenceTransform(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "```\n",
    "https://gluon-nlp.mxnet.io/master/_modules/gluonnlp/data/transforms.html#BERTSentenceTransform\n",
    "```python\n",
    "# substitute with my own (e. g. only last part (trim from start))\n",
    "self._truncate_seq_pair(tokens_a, tokens_b, self._max_seq_length - 3)\n",
    "```\n",
    "\n",
    "https://mxnet.incubator.apache.org/_modules/mxnet/gluon/data/dataset.html#Dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.407303Z",
     "start_time": "2019-07-17T10:29:58.394764Z"
    },
    "code_folding": [
     3
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from gluonnlp.data import BERTSentenceTransform\n",
    "\n",
    "\n",
    "class FirstAndLastPartBERTSentenceTransform(BERTSentenceTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, pad=True, pair=True):\n",
    "        super(FirstAndLastPartBERTSentenceTransform,\n",
    "              self).__init__(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "    def __call__(self, line):\n",
    "        # convert to unicode\n",
    "        text_a = line[0]\n",
    "        if self._pair:\n",
    "            assert len(line) == 2\n",
    "            text_b = line[1]\n",
    "\n",
    "        tokens_a = self._tokenizer(text_a)\n",
    "        tokens_a_epi = tokens_a.copy()\n",
    "        tokens_b = None\n",
    "        tokens_b_epi = None\n",
    "\n",
    "        if self._pair:\n",
    "            tokens_b = self._tokenizer(text_b)\n",
    "            tokens_b_epi = tokens_b.copy()\n",
    "\n",
    "        if tokens_b:\n",
    "            self._truncate_seq_pair_prolog(tokens_a, tokens_b,\n",
    "                                           self._max_seq_length - 3)\n",
    "            self._truncate_seq_pair_epilog(tokens_a_epi, tokens_b_epi,\n",
    "                                           self._max_seq_length - 3)\n",
    "        else:\n",
    "            if len(tokens_a) > self._max_seq_length - 2:\n",
    "                tokens_a = tokens_a[0:(self._max_seq_length - 2)]\n",
    "            if len(tokens_a_epi) > self._max_seq_length - 2:\n",
    "                tokens_a_epi = tokens_a_epi[0:(self._max_seq_length - 2)]\n",
    "\n",
    "        vocab = self._tokenizer.vocab\n",
    "        tokens, tokens_epi = [], []\n",
    "        tokens.append(vocab.cls_token)\n",
    "        tokens_epi.append(vocab.cls_token)\n",
    "        tokens.extend(tokens_a)\n",
    "        tokens_epi.extend(tokens_a_epi)\n",
    "        tokens.append(vocab.sep_token)\n",
    "        tokens_epi.append(vocab.sep_token)\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        segment_ids_epi = [0] * len(tokens_epi)\n",
    "\n",
    "        if tokens_b:\n",
    "            tokens.extend(tokens_b)\n",
    "            tokens_epi.extend(tokens_b_epi)\n",
    "            tokens.append(vocab.sep_token)\n",
    "            tokens_epi.append(vocab.sep_token)\n",
    "            segment_ids.extend([1] * (len(tokens) - len(segment_ids)))\n",
    "            segment_ids_epi.extend([1] * (len(tokens) - len(segment_ids_epi)))\n",
    "\n",
    "        input_ids = self._tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_ids_epi = self._tokenizer.convert_tokens_to_ids(tokens_epi)\n",
    "        valid_length = len(input_ids)\n",
    "        valid_length_epi = len(input_ids_epi)\n",
    "\n",
    "        if self._pad:\n",
    "            padding_length = self._max_seq_length - valid_length\n",
    "            padding_length_epi = self._max_seq_length - valid_length_epi\n",
    "            input_ids.extend([vocab[vocab.padding_token]] * padding_length)\n",
    "            input_ids_epi.extend([vocab[vocab.padding_token]] *\n",
    "                                 padding_length_epi)\n",
    "            segment_ids.extend([0] * padding_length)\n",
    "            segment_ids_epi.extend([0] * padding_length_epi)\n",
    "\n",
    "        return np.array(input_ids, dtype='int32'), np.array(valid_length, dtype='int32'),\\\n",
    "            np.array(segment_ids, dtype='int32'), np.array(input_ids_epi, dtype='int32'),\\\n",
    "            np.array(valid_length_epi, dtype='int32'), np.array(segment_ids_epi, dtype='int32')\n",
    "\n",
    "    def _truncate_seq_pair_prolog(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "\n",
    "    def _truncate_seq_pair_epilog(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\n",
    "        Removes from end of token list.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop(0)\n",
    "            else:\n",
    "                tokens_b.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.441118Z",
     "start_time": "2019-07-17T10:29:58.436929Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "class FirstAndLastPartBERTDatasetTransform(dataset.BERTDatasetTransform):\n",
    "    def __init__(self,\n",
    "                 tokenizer,\n",
    "                 max_seq_length,\n",
    "                 labels=None,\n",
    "                 pad=True,\n",
    "                 pair=True,\n",
    "                 label_dtype='float32'):\n",
    "        super(FirstAndLastPartBERTDatasetTransform,\n",
    "              self).__init__(tokenizer,\n",
    "                             max_seq_length,\n",
    "                             labels=labels,\n",
    "                             pad=pad,\n",
    "                             pair=pair,\n",
    "                             label_dtype=label_dtype)\n",
    "        self._bert_xform = FirstAndLastPartBERTSentenceTransform(\n",
    "            tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "    def __call__(self, line):\n",
    "        input_ids, valid_length, segment_ids, input_ids_epi, valid_length_epi, segment_ids_epi = self._bert_xform(\n",
    "            line[:-1])\n",
    "\n",
    "        label = line[-1]\n",
    "        if self.labels:  # for classification task\n",
    "            label = self._label_map[label]\n",
    "        label = np.array([label], dtype=self.label_dtype)\n",
    "\n",
    "        return input_ids, valid_length, segment_ids, input_ids_epi, valid_length_epi, segment_ids_epi, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.476209Z",
     "start_time": "2019-07-17T10:29:58.470525Z"
    },
    "code_folding": [
     4
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import Block\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "\n",
    "class BERTProEpiClassifier(Block):\n",
    "    \"\"\"Model for sentence (pair) classification task with BERT.\n",
    "\n",
    "    The model feeds token ids and token type ids into BERT to get the\n",
    "    pooled BERT sequence representation, then apply a Dense layer for\n",
    "    classification. Does this also for an adversarial classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bert: BERTModel\n",
    "        Bidirectional encoder with transformer.\n",
    "    num_classes : int, default is 2\n",
    "        The number of target classes.\n",
    "    dropout : float or None, default 0.0.\n",
    "        Dropout probability for the bert output.\n",
    "    prefix : str or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    params : ParameterDict or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 num_classes=2,\n",
    "                 dropout=0.0,\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(BERTProEpiClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(nn.Dense(units=num_classes))\n",
    "\n",
    "    def forward(self,\n",
    "                inputs,\n",
    "                token_types,\n",
    "                valid_length=None,\n",
    "                inputs_epi=None,\n",
    "                token_types_epi=None,\n",
    "                valid_length_epi=None):  # pylint: disable=arguments-differ\n",
    "        \"\"\"Generate the unnormalized scores for the given the input sequences.\n",
    "        From both classifiers (classifier + adversarial_classifier).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : NDArray, shape (batch_size, seq_length)\n",
    "            Input words for the sequences.\n",
    "        token_types : NDArray, shape (batch_size, seq_length)\n",
    "            Token types for the sequences, used to indicate whether the word belongs to the\n",
    "            first sentence or the second one.\n",
    "        valid_length : NDArray or None, shape (batch_size)\n",
    "            Valid length of the sequence. This is used to mask the padded tokens.\n",
    "        inputs_epi : NDArray or None, shape (batch_size, seq_length)\n",
    "            Input words for the sequences. If None then same as inputs.\n",
    "        token_types_epi : NDArray or None, shape (batch_size, seq_length)\n",
    "            Token types for the sequences, used to indicate whether the word belongs to the\n",
    "            first sentence or the second one. If None then same as token_types.\n",
    "        valid_length_epi : NDArray or None, shape (batch_size)\n",
    "            Valid length of the sequence. This is used to mask the padded tokens.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : NDArray\n",
    "            Shape (batch_size, num_classes), outputs of classifier.\n",
    "        \"\"\"\n",
    "        # if inputs_epi is None and token_types_epi is None:\n",
    "        #     inputs_epi = inputs\n",
    "        #     token_types_epi = token_types\n",
    "        #     valid_length_epi = valid_length\n",
    "\n",
    "        _, pooler_out = self.bert(inputs, token_types, valid_length)\n",
    "        _, pooler_out_epi = self.bert(inputs_epi, token_types_epi, valid_length_epi)\n",
    "        pooler_concat = mx.nd.concat(pooler_out, pooler_out_epi, dim=1)\n",
    "        return self.classifier(pooler_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.510652Z",
     "start_time": "2019-07-17T10:29:58.505605Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_bert():\n",
    "    # change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "    ctx = mx.gpu(0)\n",
    "    # ctx = [mx.gpu(i) for i in range(2)]\n",
    "    # ctx =  mx.gpu() if mx.context.num_gpus() else mx.cpu()\n",
    "    # ctx = mx.cpu()\n",
    "\n",
    "    bert_base, vocabulary = nlp.model.get_model(\n",
    "        'bert_12_768_12',\n",
    "        dataset_name='book_corpus_wiki_en_uncased',\n",
    "        pretrained=True,\n",
    "        ctx=ctx,\n",
    "        use_pooler=True,\n",
    "        use_decoder=False,\n",
    "        use_classifier=False)\n",
    "    print(bert_base)\n",
    "\n",
    "    #model = BERTProEpiClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "    model = BERTProEpiClassifier(bert_base, num_classes=1, dropout=0.1)\n",
    "    # only need to initialize the classifier layer.\n",
    "    model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "    model.hybridize(static_alloc=True)\n",
    "\n",
    "    # softmax cross entropy loss for classification\n",
    "    #loss_function = gluon.loss.SoftmaxCELoss()\n",
    "    loss_function = gluon.loss.SigmoidBinaryCrossEntropyLoss(from_sigmoid=False)\n",
    "    loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "    metric = mx.metric.Accuracy()\n",
    "\n",
    "    # use the vocabulary from pre-trained model for tokenization\n",
    "    bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "    # maximum sequence length\n",
    "    # max_len = 128  # + batch_size: 32\n",
    "    # 384 - 12\n",
    "    max_len = 512  # + batch_size: 6 ?\n",
    "    # the labels for the two classes\n",
    "    #all_labels = [\"0\", \"1\"]\n",
    "    all_labels = [0, 1]\n",
    "    # whether to transform the data as sentence pairs.\n",
    "    # for single sentence classification, set pair=False\n",
    "    transform = FirstAndLastPartBERTDatasetTransform(bert_tokenizer,\n",
    "                                                     max_len,\n",
    "                                                     labels=all_labels,\n",
    "                                                     label_dtype='int32',\n",
    "                                                     pad=True,\n",
    "                                                     pair=True)\n",
    "\n",
    "    return model, vocabulary, ctx, bert_tokenizer, transform, loss_function, metric, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.543252Z",
     "start_time": "2019-07-17T10:29:58.539763Z"
    },
    "code_folding": [
     0,
     6
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def transform_dataset(X, y, transform):\n",
    "    data_train_raw = MyBERTDataset(X, y)\n",
    "    data_train = data_train_raw.transform(transform)\n",
    "    return data_train_raw, data_train\n",
    "\n",
    "\n",
    "def predict_out_to_ys(all_predictions, all_labels):\n",
    "    y_true, y_pred = list(), list()\n",
    "\n",
    "    for _, y_true_many, y_pred_many in all_predictions:\n",
    "        y_true_many = y_true_many.T[0].asnumpy()\n",
    "        # https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.SoftmaxCrossEntropyLoss\n",
    "        # pred: the prediction tensor, where the batch_axis dimension ranges over batch size and axis dimension ranges over the number of classes.\n",
    "        #y_pred_many = np.argmax(y_pred_many, axis=1).asnumpy()\n",
    "        y_pred_many = y_pred_many.asnumpy()\n",
    "\n",
    "        y_true.extend(list(y_true_many))\n",
    "        y_pred.extend(list(y_pred_many))\n",
    "        # TODO: convert label_id to label?\n",
    "        # y_pred.extend(all_labels[c] for c in list(y_pred_many))\n",
    "\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-GPU?\n",
    "- https://gluon.mxnet.io/chapter07_distributed-learning/multiple-gpus-gluon.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.583001Z",
     "start_time": "2019-07-17T10:29:58.572382Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          data_train,\n",
    "          ctx,\n",
    "          metric,\n",
    "          loss_function,\n",
    "          batch_size=32,\n",
    "          lr=5e-6,\n",
    "          num_epochs=3,\n",
    "          checkpoint_dir=\"data\",\n",
    "          use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(\n",
    "            lengths=[int(item[1]) for item in tqdm(data_train)],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(), 'adam', {\n",
    "            'learning_rate': lr,\n",
    "            'epsilon': 1e-9\n",
    "        })\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [\n",
    "            p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "        ]\n",
    "\n",
    "    log_interval = 500\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(\n",
    "                    epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(\n",
    "                        checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               token_ids_epi, valid_length_epi,\n",
    "                               segment_ids_epi,\n",
    "                               label) in enumerate(bert_dataloader):\n",
    "                    with mx.autograd.record():\n",
    "                        # load data to GPU\n",
    "                        token_ids = token_ids.as_in_context(ctx)\n",
    "                        valid_length = valid_length.as_in_context(ctx)\n",
    "                        segment_ids = segment_ids.as_in_context(ctx)\n",
    "                        token_ids_epi = token_ids_epi.as_in_context(ctx)\n",
    "                        valid_length_epi = valid_length_epi.as_in_context(ctx)\n",
    "                        segment_ids_epi = segment_ids_epi.as_in_context(ctx)\n",
    "                        label = label.as_in_context(ctx)\n",
    "\n",
    "                        # forward computation\n",
    "                        out = model(token_ids, segment_ids,\n",
    "                                    valid_length.astype('float32'),\n",
    "                                    token_ids_epi, segment_ids_epi,\n",
    "                                    valid_length_epi.astype('float32'))\n",
    "                        label = label.astype('float32')\n",
    "                        ls = loss_function(out, label).mean()\n",
    "\n",
    "                    # backward computation\n",
    "                    ls.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1)\n",
    "\n",
    "                    step_loss += ls.asscalar()\n",
    "                    out = out.sigmoid().round().astype('int32')\n",
    "                    label = label.astype('int32')\n",
    "                    metric.update([label], [out])\n",
    "                    stats.append((metric.get()[1], ls.asscalar()))\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f} - time {}'\n",
    "                            .format(\n",
    "                                epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                step_loss / log_interval,\n",
    "                                trainer.learning_rate,\n",
    "                                metric.get()[1],\n",
    "                                datetime.timedelta(seconds=(time.time() -\n",
    "                                                            t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.625406Z",
     "start_time": "2019-07-17T10:29:58.612886Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_multi(model,\n",
    "                data_train,\n",
    "                ctx,\n",
    "                metric,\n",
    "                loss_function,\n",
    "                batch_size=32,\n",
    "                lr=5e-6,\n",
    "                num_epochs=3,\n",
    "                checkpoint_dir=\"data\",\n",
    "                use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(\n",
    "            lengths=[int(item[1]) for item in tqdm(data_train)],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(),\n",
    "                                'adam', {\n",
    "                                    'learning_rate': lr,\n",
    "                                    'epsilon': 1e-9\n",
    "                                },\n",
    "                                update_on_kvstore=False)\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [\n",
    "            p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "        ]\n",
    "\n",
    "    log_interval = 500\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(\n",
    "                    epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(\n",
    "                        checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               token_ids_epi, valid_length_epi,\n",
    "                               segment_ids_epi,\n",
    "                               label) in enumerate(bert_dataloader):\n",
    "                    with mx.autograd.record():\n",
    "                        # load data to GPU\n",
    "                        token_ids = gluon.utils.split_and_load(\n",
    "                            token_ids, ctx, even_split=False)\n",
    "                        valid_length = gluon.utils.split_and_load(\n",
    "                            valid_length, ctx, even_split=False)\n",
    "                        segment_ids = gluon.utils.split_and_load(\n",
    "                            segment_ids, ctx, even_split=False)\n",
    "                        token_ids_epi = gluon.utils.split_and_load(\n",
    "                            token_ids_epi, ctx, even_split=False)\n",
    "                        valid_length_epi = gluon.utils.split_and_load(\n",
    "                            valid_length_epi, ctx, even_split=False)\n",
    "                        segment_ids_epi = gluon.utils.split_and_load(\n",
    "                            segment_ids_epi, ctx, even_split=False)\n",
    "                        label = gluon.utils.split_and_load(label,\n",
    "                                                           ctx,\n",
    "                                                           even_split=False)\n",
    "\n",
    "                        # forward computation\n",
    "                        out = [\n",
    "                            model(t1, s1, v1.astype('float32'), t2, s2,\n",
    "                                  v2.astype('float32'))\n",
    "                            for t1, s1, v1, t2, s2, v2 in zip(\n",
    "                                token_ids, segment_ids, valid_length,\n",
    "                                token_ids_epi, segment_ids_epi,\n",
    "                                valid_length_epi)\n",
    "                        ]\n",
    "                        ls = [\n",
    "                            loss_function(o, l.astype('float32')).mean()\n",
    "                            for o, l in zip(out, label)\n",
    "                        ]\n",
    "\n",
    "                    # backward computation\n",
    "                    for l in ls:\n",
    "                        l.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1)\n",
    "\n",
    "                    for l in ls:\n",
    "                        step_loss += l.asscalar()\n",
    "                    for o, l in zip(out, label):\n",
    "                        metric.update([l.astype('int32')],\n",
    "                                      [o.sigmoid().round().astype('int32')])\n",
    "                    stats.append((metric.get()[1], [l.asscalar() for l in ls]))\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f} - time {}'\n",
    "                            .format(\n",
    "                                epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                step_loss / log_interval,\n",
    "                                trainer.learning_rate,\n",
    "                                metric.get()[1],\n",
    "                                datetime.timedelta(seconds=(time.time() -\n",
    "                                                            t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.660521Z",
     "start_time": "2019-07-17T10:29:58.655349Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def predict(model, data_predict, ctx, metric, loss_function, batch_size=32):\n",
    "    bert_dataloader = mx.gluon.data.DataLoader(data_predict,\n",
    "                                               batch_size=batch_size)\n",
    "\n",
    "    all_predictions = list()\n",
    "\n",
    "    with Timer(\"prediction\"):\n",
    "        metric.reset()\n",
    "        cum_loss = 0\n",
    "        for batch_id, (token_ids, valid_length, segment_ids, token_ids_epi,\n",
    "                       valid_length_epi, segment_ids_epi,\n",
    "                       label) in enumerate(tqdm(bert_dataloader)):\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            token_ids_epi = token_ids_epi.as_in_context(ctx)\n",
    "            valid_length_epi = valid_length_epi.as_in_context(ctx)\n",
    "            segment_ids_epi = segment_ids_epi.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids, valid_length.astype('float32'),\n",
    "                        token_ids_epi, segment_ids_epi,\n",
    "                        valid_length_epi.astype('float32'))\n",
    "            label = label.astype('float32')\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "            out = out.sigmoid().round().astype('int32')\n",
    "            label = label.astype('int32')\n",
    "            metric.update([label], [out])\n",
    "            cum_loss += ls.asscalar()  # .sum() ?\n",
    "            all_predictions.append((batch_id, label, out))\n",
    "\n",
    "    return all_predictions, cum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.695603Z",
     "start_time": "2019-07-17T10:29:58.689806Z"
    },
    "code_folding": [
     0,
     24
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def print_infos(vocabulary, data_train_raw, data_train):\n",
    "    sample_id = 0\n",
    "\n",
    "    # sentence a\n",
    "    print(data_train_raw[sample_id][0])\n",
    "    # sentence b\n",
    "    print(data_train_raw[sample_id][1])\n",
    "    # 1 means equivalent, 0 means not equivalent\n",
    "    print(data_train_raw[sample_id][2])\n",
    "\n",
    "    print('vocabulary used for tokenization = \\n%s' % vocabulary)\n",
    "    print('[PAD] token id = %s' % (vocabulary['[PAD]']))\n",
    "    print('[CLS] token id = %s' % (vocabulary['[CLS]']))\n",
    "    print('[SEP] token id = %s' % (vocabulary['[SEP]']))\n",
    "\n",
    "    print('token ids = \\n%s' % data_train[sample_id][0])\n",
    "    print('valid length = \\n%s' % data_train[sample_id][1])\n",
    "    print('segment ids = \\n%s' % data_train[sample_id][2])\n",
    "    print('epi token ids = \\n%s' % data_train[sample_id][3])\n",
    "    print('epi valid length = \\n%s' % data_train[sample_id][4])\n",
    "    print('epi segment ids = \\n%s' % data_train[sample_id][5])\n",
    "    print('label = \\n%s' % data_train[sample_id][6])\n",
    "\n",
    "\n",
    "def plot_train_stats(stats):\n",
    "    if not stats:\n",
    "        print(\"no stats to plot\")\n",
    "        return\n",
    "\n",
    "    x = np.arange(len(stats))  # arange/linspace\n",
    "\n",
    "    acc_dots, loss_dots = zip(*stats)\n",
    "    # if isinstance(loss_dots, tuple):\n",
    "    #     loss_dots, loss_dots2 = zip(*loss_dots)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, acc_dots)  # Linie: '-', 'o-', '.-'\n",
    "    plt.title('Training BERTClassifier')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x, loss_dots)\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:29:58.732681Z",
     "start_time": "2019-07-17T10:29:58.727235Z"
    },
    "code_folding": [
     0,
     12
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def heatconmat(y_test, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(np.unique(y_test)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, name=None, heatmap=True):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    if heatmap:\n",
    "        heatconmat(y_test, y_pred)\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2), '\\n')  #\n",
    "\n",
    "    print('Report{}:'.format(\"\" if not name else \" for [{}]\".format(name)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    f1_dic = {}\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#within_traindev_df = within_traindev_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"):\n",
    "    # train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3)\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=2)\n",
    "    # model.save_parameters(\"data/same-side-classification/within-topic/bert.model.params\")\n",
    "    model.save_parameters(\"data/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"):\n",
    "    # model.load_parameters(\"data/same-side-classification/within-topic/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/bert.model.params\", ctx=ctx)\n",
    "    # model.load_parameters('data/within_traindev_proepi512_BCE/bert.model.checkpoint4.params', ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        # stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=2, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        # stats = train_multi(model, data_train, ctx, metric, loss_function, batch_size=4, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        # all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)  # seq_len: 512\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - last part\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*may need to use **binary_cross_entrophy**?* (can I use a single label or do I have to use \"0\" and \"1\"?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"):\n",
    "    # train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3)\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=2)\n",
    "    # model.save_parameters(\"data/same-side-classification/cross-topic/bert.model.params\")\n",
    "    model.save_parameters(\"data/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"):\n",
    "    # model.load_parameters(\"data/same-side-classification/cross-topic/bert.model.params\", ctx=ctx)\n",
    "    #model.load_parameters(\"data/bert.model.params\", ctx=ctx)\n",
    "    # load model from \"within\" to evaluate with \"cross\" test-data\n",
    "    #model.load_parameters('data/within_traindev_proepi512_BCE/bert.model.checkpoint4.params', ctx=ctx)\n",
    "    model.load_parameters('data/cross_traindev_proepi512_BCE/bert.model.checkpoint4.params', ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     14,
     22
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        stats = train(model,\n",
    "                      data_train,\n",
    "                      ctx,\n",
    "                      metric,\n",
    "                      loss_function,\n",
    "                      batch_size=2,\n",
    "                      lr=5e-6,\n",
    "                      num_epochs=epoch_id + 1,\n",
    "                      checkpoint_dir='data/cross_traindev_proepi512_BCE')\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        all_predictions, cum_loss = predict(model,\n",
    "                                            data_dev,\n",
    "                                            ctx,\n",
    "                                            metric,\n",
    "                                            loss_function,\n",
    "                                            batch_size=2)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true,\n",
    "                                y_pred,\n",
    "                                name=\"BERTClassifier\",\n",
    "                                heatmap=False)\n",
    "\n",
    "    model.save_parameters(\n",
    "        \"data/cross_traindev_proepi512_BCE/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"11 - test/train split\"):\n",
    "    # evaluate on \"within\" test-data\n",
    "    _, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "with Timer(\"12 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)\n",
    "\n",
    "with Timer(\"13 - evaluate\"):\n",
    "    # model from \"cross\"\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier cross with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Cross-Model with Within-Test\n",
    "\n",
    "5 epochs of cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/cross_traindev_proepi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier cross with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:24:48.940295\n",
    "Accuracy: 0.8536330916488446\n",
    "Confusion Matrix:\n",
    "[[7659 1174]\n",
    " [1632 8706]]\n",
    "\n",
    "Accuracy:  0.85 \n",
    "\n",
    "Report for [BERTClassifier cross with within]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.82      0.87      0.85      8833\n",
    "           1       0.88      0.84      0.86     10338\n",
    "\n",
    "    accuracy                           0.85     19171\n",
    "   macro avg       0.85      0.85      0.85     19171\n",
    "weighted avg       0.85      0.85      0.85     19171\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Within-Model with Cross-Test\n",
    "\n",
    "5 epochs of within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/within_traindev_proepi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"evaluate within with cross\"):\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier within with cross\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:22:17.542674\n",
    "Accuracy: 0.9379197379197379\n",
    "Confusion Matrix:\n",
    "[[8397  539]\n",
    " [ 598 8781]]\n",
    "\n",
    "Accuracy:  0.94 \n",
    "\n",
    "Report for [BERTClassifier]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.94      0.94      8936\n",
    "           1       0.94      0.94      0.94      9379\n",
    "\n",
    "    accuracy                           0.94     18315\n",
    "   macro avg       0.94      0.94      0.94     18315\n",
    "weighted avg       0.94      0.94      0.94     18315\n",
    "\n",
    "Time for [6 - evaluate]: 0:22:19.841677\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Within-Model with Within-Test\n",
    "\n",
    "5 epochs of within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/within_traindev_proepi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"evaluate within with within\"):\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier within with within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:19:51.733113\n",
    "Accuracy: 0.9069427781545042\n",
    "Confusion Matrix:\n",
    "[[7972  861]\n",
    " [ 923 9415]]\n",
    "\n",
    "Accuracy:  0.91 \n",
    "\n",
    "Report for [BERTClassifier within with within]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.90      0.90      0.90      8833\n",
    "           1       0.92      0.91      0.91     10338\n",
    "\n",
    "    accuracy                           0.91     19171\n",
    "   macro avg       0.91      0.91      0.91     19171\n",
    "weighted avg       0.91      0.91      0.91     19171\n",
    "\n",
    "Time for [evaluate within with cross]: 0:19:52.352049\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Cross-Model with Cross-Test\n",
    "\n",
    "5 epochs of cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_parameters('data/cross_traindev_proepi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier cross\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Time for [prediction]: 0:23:28.845010\n",
    "Accuracy: 0.9197925197925197\n",
    "Confusion Matrix:\n",
    "[[8329  607]\n",
    " [ 862 8517]]\n",
    "\n",
    "Accuracy:  0.92 \n",
    "\n",
    "Report for [BERTClassifier cross]:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.93      0.92      8936\n",
    "           1       0.93      0.91      0.92      9379\n",
    "\n",
    "    accuracy                           0.92     18315\n",
    "   macro avg       0.92      0.92      0.92     18315\n",
    "weighted avg       0.92      0.92      0.92     18315\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Details to wrong classified arguments\n",
    "\n",
    "within_traindev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:30:03.399774Z",
     "start_time": "2019-07-17T10:29:58.769416Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTModel(\n",
      "  (encoder): BERTEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (1): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (2): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (3): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (4): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (5): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (6): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (7): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (8): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (9): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (10): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (11): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_embed): HybridSequential(\n",
      "    (0): Embedding(30522 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (token_type_embed): HybridSequential(\n",
      "    (0): Embedding(2 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (pooler): Dense(768 -> 768, Activation(tanh))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()\n",
    "\n",
    "model.load_parameters('data/within_traindev_proepi512_BCE/bert.model.checkpoint4.params', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:30:04.522345Z",
     "start_time": "2019-07-17T10:30:03.443731Z"
    }
   },
   "outputs": [],
   "source": [
    "_, X_dev, _, y_dev = get_train_test_sets(within_traindev_df)\n",
    "\n",
    "data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "# print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:54:14.872096Z",
     "start_time": "2019-07-17T10:30:04.561721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffdc16e2fae4924a41b3b182e81f396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9586), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [prediction]: 0:24:08.494613\n",
      "Accuracy: 0.9069427781545042\n",
      "Confusion Matrix:\n",
      "[[7972  861]\n",
      " [ 923 9415]]\n",
      "\n",
      "Accuracy:  0.91 \n",
      "\n",
      "Report for [BERTClassifier within-within]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90      8833\n",
      "           1       0.92      0.91      0.91     10338\n",
      "\n",
      "    accuracy                           0.91     19171\n",
      "   macro avg       0.91      0.91      0.91     19171\n",
      "weighted avg       0.91      0.91      0.91     19171\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'macro': 0.91, 'micro': 0.91}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=2)\n",
    "print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "report_training_results(y_true, y_pred, name=\"BERTClassifier within-within\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:54:27.587091Z",
     "start_time": "2019-07-17T10:54:16.772447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e646d63bc4e4186a10c427791e498dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=19171), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19171 entries, 56125 to 56919\n",
      "Data columns (total 8 columns):\n",
      "argument1       19171 non-null object\n",
      "argument2       19171 non-null object\n",
      "argument1_id    19171 non-null object\n",
      "argument2_id    19171 non-null object\n",
      "topic           19171 non-null object\n",
      "is_same_side    19171 non-null bool\n",
      "prediction      19171 non-null bool\n",
      "tag             19171 non-null object\n",
      "dtypes: bool(2), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# convert predictions to dataframe\n",
    "dev_pred_df = pd.DataFrame(data=y_pred, columns=[\"prediction\"], dtype=\"bool\")\n",
    "\n",
    "# merge all dataframes\n",
    "dev_df = X_dev.join(y_dev)\n",
    "dev_df = dev_df.reset_index()\n",
    "dev_df = pd.merge(dev_df, dev_pred_df, left_index=True, right_index=True, how='inner')\n",
    "dev_df.set_index('id', inplace=True)\n",
    "\n",
    "# re-apply tag value\n",
    "dev_df = dev_df.progress_apply(add_tag, axis=1)\n",
    "# info\n",
    "dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:54:35.869058Z",
     "start_time": "2019-07-17T10:54:35.791442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19171 entries, 56125 to 56919\n",
      "Data columns (total 8 columns):\n",
      "argument1       19171 non-null object\n",
      "argument2       19171 non-null object\n",
      "argument1_id    19171 non-null object\n",
      "argument2_id    19171 non-null object\n",
      "topic           19171 non-null object\n",
      "is_same_side    19171 non-null bool\n",
      "prediction      19171 non-null bool\n",
      "tag             19171 non-null object\n",
      "dtypes: bool(2), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "dev_df_ser_file = \"data/within_traindev_proepi512_BCE/eval_dev_df.pickle\"\n",
    "\n",
    "\n",
    "with open(dev_df_ser_file, \"wb\") as f:\n",
    "    pickle.dump(dev_df, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(dev_df_ser_file, \"rb\") as f:\n",
    "    dev_df = pickle.load(f)\n",
    "\n",
    "\n",
    "dev_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:54:37.695758Z",
     "start_time": "2019-07-17T10:54:37.671050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1784 entries, 25082 to 29490\n",
      "Data columns (total 8 columns):\n",
      "argument1       1784 non-null object\n",
      "argument2       1784 non-null object\n",
      "argument1_id    1784 non-null object\n",
      "argument2_id    1784 non-null object\n",
      "topic           1784 non-null object\n",
      "is_same_side    1784 non-null bool\n",
      "prediction      1784 non-null bool\n",
      "tag             1784 non-null object\n",
      "dtypes: bool(2), object(6)\n",
      "memory usage: 101.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1</th>\n",
       "      <th>argument2</th>\n",
       "      <th>argument1_id</th>\n",
       "      <th>argument2_id</th>\n",
       "      <th>topic</th>\n",
       "      <th>is_same_side</th>\n",
       "      <th>prediction</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25082</th>\n",
       "      <td>i thank my opponent for her* reply.according t...</td>\n",
       "      <td>i thank my opponent for his reply.in his openi...</td>\n",
       "      <td>81e66960-2019-04-18T17:23:33Z-00000-000</td>\n",
       "      <td>81e66960-2019-04-18T17:23:33Z-00000-000</td>\n",
       "      <td>abortion</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92434</th>\n",
       "      <td>i don't have enough time to do the debate with...</td>\n",
       "      <td>in this debate i contend abortion, a procedure...</td>\n",
       "      <td>e9044509-2019-04-18T18:17:01Z-00002-000</td>\n",
       "      <td>e9044509-2019-04-18T18:17:01Z-00002-000</td>\n",
       "      <td>abortion is generally immoral</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33394</th>\n",
       "      <td>thank you for accepting this debate. first of ...</td>\n",
       "      <td>hello con, i'd like to first point out that th...</td>\n",
       "      <td>b1861fe8-2019-04-18T15:14:30Z-00007-000</td>\n",
       "      <td>b1861fe8-2019-04-18T15:14:30Z-00007-000</td>\n",
       "      <td>abortion</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30907</th>\n",
       "      <td>kimo vs. pono; social issues, gay marriage ok ...</td>\n",
       "      <td>kimo vs. pono; social issues, gay marriage \" a...</td>\n",
       "      <td>b1077c8f-2019-04-18T18:07:45Z-00007-000</td>\n",
       "      <td>b1077c8f-2019-04-18T18:07:45Z-00007-000</td>\n",
       "      <td>kimo vs. pono; social issues, gay marriage</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>gay marriage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21939</th>\n",
       "      <td>incest should not be considered in the legalit...</td>\n",
       "      <td>incest should not be considered in the legalit...</td>\n",
       "      <td>684fcb10-2019-04-18T11:45:47Z-00001-000</td>\n",
       "      <td>684fcb10-2019-04-18T11:45:47Z-00001-000</td>\n",
       "      <td>incest should not be considered in the legalit...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>abortion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               argument1  \\\n",
       "id                                                         \n",
       "25082  i thank my opponent for her* reply.according t...   \n",
       "92434  i don't have enough time to do the debate with...   \n",
       "33394  thank you for accepting this debate. first of ...   \n",
       "30907  kimo vs. pono; social issues, gay marriage ok ...   \n",
       "21939  incest should not be considered in the legalit...   \n",
       "\n",
       "                                               argument2  \\\n",
       "id                                                         \n",
       "25082  i thank my opponent for his reply.in his openi...   \n",
       "92434  in this debate i contend abortion, a procedure...   \n",
       "33394  hello con, i'd like to first point out that th...   \n",
       "30907  kimo vs. pono; social issues, gay marriage \" a...   \n",
       "21939  incest should not be considered in the legalit...   \n",
       "\n",
       "                                  argument1_id  \\\n",
       "id                                               \n",
       "25082  81e66960-2019-04-18T17:23:33Z-00000-000   \n",
       "92434  e9044509-2019-04-18T18:17:01Z-00002-000   \n",
       "33394  b1861fe8-2019-04-18T15:14:30Z-00007-000   \n",
       "30907  b1077c8f-2019-04-18T18:07:45Z-00007-000   \n",
       "21939  684fcb10-2019-04-18T11:45:47Z-00001-000   \n",
       "\n",
       "                                  argument2_id  \\\n",
       "id                                               \n",
       "25082  81e66960-2019-04-18T17:23:33Z-00000-000   \n",
       "92434  e9044509-2019-04-18T18:17:01Z-00002-000   \n",
       "33394  b1861fe8-2019-04-18T15:14:30Z-00007-000   \n",
       "30907  b1077c8f-2019-04-18T18:07:45Z-00007-000   \n",
       "21939  684fcb10-2019-04-18T11:45:47Z-00001-000   \n",
       "\n",
       "                                                   topic  is_same_side  \\\n",
       "id                                                                       \n",
       "25082                                           abortion          True   \n",
       "92434                      abortion is generally immoral         False   \n",
       "33394                                           abortion         False   \n",
       "30907         kimo vs. pono; social issues, gay marriage         False   \n",
       "21939  incest should not be considered in the legalit...          True   \n",
       "\n",
       "       prediction           tag  \n",
       "id                               \n",
       "25082       False      abortion  \n",
       "92434        True      abortion  \n",
       "33394        True      abortion  \n",
       "30907        True  gay marriage  \n",
       "21939       False      abortion  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FPFN_df = dev_df[(dev_df['is_same_side'] != dev_df['prediction'])]  #  and (dev_df['tag'] != 'abortion')\n",
    "FPFN_df.info()\n",
    "FPFN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:54:39.774650Z",
     "start_time": "2019-07-17T10:54:39.770592Z"
    },
    "code_folding": [
     6
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import re\n",
    "#import tabulate\n",
    "#display(HTML(tabulate.tabulate(table, tablefmt='html')))\n",
    "\n",
    "\n",
    "def print_args(df, idx, add_linebreaks=True):\n",
    "    row = df.iloc[idx]\n",
    "    print('IDX: {}, tag: {}, topics: {}'.format(idx, row['tag'], row['topic']))\n",
    "    print('Is-Same-Side: {}'.format(row['is_same_side']))\n",
    "\n",
    "    arg1 = row['argument1']\n",
    "    arg2 = row['argument2']\n",
    "    if add_linebreaks:\n",
    "        pat = re.compile(r'(?P<c>(\\.|\\?|\\!|\\:)+\\\"?)')\n",
    "        arg1 = pat.sub(r'\\1<br/>', arg1)\n",
    "        arg2 = pat.sub(r'\\1<br/>', arg2)\n",
    "\n",
    "    display(HTML('''<table>\n",
    "        <tr>\n",
    "            <td style=\"border-right:1px dashed black;\">{arg1}</td>\n",
    "            <td>{arg2}</td>\n",
    "        </tr>\n",
    "    </table>'''.format(arg1=arg1, arg2=arg2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T10:54:41.732033Z",
     "start_time": "2019-07-17T10:54:41.695902Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 0, tag: abortion, topics: abortion\n",
      "Is-Same-Side: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">i thank my opponent for her* reply.<br/>according to her profile, her gender is male.<br/> that's why i referred to her as a male.<br/> and i didn't understand that she got pregnant at 15 from her previous round.<br/> anyhow, my opponent has not presented any argument supporting her position, and only raised one obection to a2, a3 and a4.<br/> she claims that the girls could get an adoption, but that doesn't solve the issue.<br/> a girl who is not ready for motherhood would be attached to the baby if she gave birth to it, even though she is not ready to raise it.<br/> giving your baby out is not an easy thing, but aborting the fertilized egg before it becomes a baby is much easier.<br/> moreover, a girl in dire economic conditions might not even afford to be pregnant, so it doesn't make sense for her to give birth and then give the child away because she is too poor to support it.<br/> finally, a mother in a culture that punishes for premarital sex would be really stupid if she allowed everyone to see her pregnant, because that would mean that she would be killed for her pregnancy.<br/>my opponent then says, \" i'm talking about the abortion cases where they got pregnant and just aborted it because they didn't want the responsibility.\"<br/> it seems to me that my opponent shifts goalposts in every round.<br/> i do agree that such abortion cases must not be permitted, but my opponent never made it clear in the previous rounds that she is arguing against those cases.<br/>in summary, my opponent has not provided a clear resolution and argument and has shifted goal posts in the two rounds.<br/> http:<br/>//www.<br/>debate.<br/>org...<br/></td>\n",
       "            <td>i thank my opponent for his reply.<br/>in his opening statement he states, \"who ever[sp] got an abortion or is for abortion should deserve to get killed the same way they kill the poor inocennt[sp] babies i have no regert[sp] saying what i just said.\"<br/> since he didn't provide a clear resolution, i decided to argue against that by claiming that abortion should be allowed in some cases, and that pro-choice supporters should not be killed.<br/> my opponent then shifted the goal posts in round 2 and said that he is with abortion in \"some major cases.\"<br/> doesn't that contradict his sentence in the opening statement which says, \"who ever got an abortion or is for abortion should deserve to get killed...?\"<br/> in addition to this, it seems that he willingly ignored the part about getting pro-choice supporters killed in this round.<br/>furthermore, my opponent says in the second round, \"for all you people who are not clear i am debating that it[abortion] should not be used so much as it is.\"<br/> note that this resolution was neither mentioned in the title or the opening statement.<br/> my opponent seems to think that he can list what he is arguing in the second round, after his opponent accepted the debate based on the opening statement.<br/> even if my opponent believes that abortion should be allowed only in some major cases, there is still room for argument on whether abortion should be allowed in the early stages of pregnancy.<br/> i'm assuming he is against that, because that represents the majority of abortion cases[1].<br/>a- abortion should be allowed in the early stages of pregnancyaborting a fertilized egg is not the equivalent of killing a child, similarly to how breaking an egg is not the equivalent of killing a chicken.<br/> i'm with allowing the mother to perform abortion as long as the fetus is not conscious yet and the case satisfies one of those conditions:<br/>a1- rapeit doesn't make sense for a mother to raise the child of her rapist.<br/> she has the choice to keep it, but also she must have the choice to abort it when it still is a fertilized egg.<br/>a2- not ready for motherhoodif a girl had sex, this doesn't necessarily mean she is mature enough to raise kids.<br/> having sex is a lot easier than taking care of a baby, and the girl could have performed unsafe sex because of her immaturity to begin witha3- not enough moneyif the baby is going to starve or suffer from malnutrition because of dire economic conditions, then i don't see why the mother should keep the fertilized egg.<br/>a4- life conditionsif the mother or the baby are going to be killed because of traditional customs that condemn premarital sex in certain cultures and societies, then it is better for the mother to abort the fertilized egg and save herself and her future child from a horrific death.<br/>b- refutation of my opponent:<br/>my opponent's argument is simply anecdotal evidence that supports his position.<br/>b1- contention 1:<br/> \"...<br/>but she stuck by her baby and let it pass away when it was ready to she wanted god to take it on his time not at a scheduled time so i feel it shouldn't be a popular as it is...\"<br/>not everyone believes in god and has that particular belief.<br/> as his sister's friend chose to follow her belief, why can't others choose to follow their beliefs?<br/> to make this argument, my opponent has to prove that god exists, and not just that, but that this particular god wants fetuses to have a natural death.<br/>b2- contention 2:<br/> \" i'm not to mature for a baby well you were old enough to have sex...\"<br/>being old enough to have sex doesn't entail being ready for motherhood.<br/> this is a non-sequitur logical fallacy which i dealt with above in a2.<br/>in summary, my opponent has failed to explain clearly what he is arguing against and shifted goal posts in round 2.<br/> i tried to understand his position which changed in round 2, and argued against it by saying that abortion should not just be allowed in some major situations, but also in the early stages of pregnancy under certain conditions i listed.<br/>[1] cdc.<br/>gov/mmwr/preview/mmwrhtml/ss6108a1.<br/>htm</td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 1, tag: abortion, topics: abortion is generally immoral\n",
      "Is-Same-Side: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">i don't have enough time to do the debate with finals.<br/> vote pro</td>\n",
       "            <td>in this debate i contend abortion, a procedure that removes and kills the fetus, is generally immoral.<br/> immoral and abortion needn't be defined, we know what those mean.<br/> any semantics or trolling equates forfeiting the debate.<br/> the words in the resolution are common knowledge.<br/> 1st round for acceptance.<br/> bop even.<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 2, tag: abortion, topics: abortion\n",
      "Is-Same-Side: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">thank you for accepting this debate.<br/> first of all, there is a scientific definition of life.<br/> life:<br/> 1) a distinctive characteristic of a living organism from dead organism or non-living thing, as specifically distinguished by the capacity to grow, metabolize, respond (to stimuli), adapt, and reproduce < http:<br/>//www.<br/>biology-online.<br/>org...<br/> >.<br/> so yes there is a scientific definition of life.<br/> furthermore, your extraterrestrial point is entirely irrelevant because abortion deals with the living human being on earth.<br/> and since science can definitively define life on earth, i then do not understand why the \"extraterrestrial\" argument was included due to its inherent irrelevancy.<br/> also, you say that life can never be defined by science, and because life cannot be defined by science, then the fetus does not have the right to life.<br/> well if science cannot define life (as you said), then no one has the right to life because science, according to your argument, does not definitively prove either you or me to be alive.<br/> and since we both agree we are scientifically alive, then obviously science can and does define what life is.<br/> so do you accept that there is a scientific vindication of life?<br/> also you say abortion is the \"intentional termination of a developing fetus\".<br/> according to my definition, you left out a key word.<br/> here is the definition of abortion abortion:<br/> \"a medical procedure used to end a pregnancy and cause the death of the fetus.<br/> < http:<br/>//www.<br/>merriam-webster.<br/>com...<br/> >.<br/> abortion causes the death of the fetus.<br/> lets now look at the definition of death.<br/> death:<br/> \"the end of life :<br/> the time when someone or something dies\" < http:<br/>//www.<br/>merriam-webster.<br/>com...<br/> >.<br/> death can only occur when something was alive prior.<br/> therefore, because abortion results in the death of the fetus, the fetus must have had life before the abortion took place.<br/> therefore the fetus is alive.<br/> also, again let us look scientifically at how the fetus is alive.<br/> first, i must make a key point.<br/> a newborn baby does not have the capacity or ability to reproduce, yet the ability to reproduce is a defining characteristic of scientific life.<br/> however, science and logic both know that a newborn baby is alive.<br/> why?<br/> well the baby has not yet grown into enough biological complexity to reproduce, but the baby has the potential to reproduce.<br/> the same argument is applied for determining that the fetus is alive.<br/> the fetus, from the moment of conception, begins biological growth from biological simplicity into biological complexity.<br/> nothing is conceived in its full potential, therefore, by showing the fundamental sign of life from which all other characteristics of life stem, the fetus is alive.<br/> biological growth from simplicity into complexity is enough for the fetus to be considered alive.<br/> here is the same argument stated another way.<br/> as a commenter on this debate advised me, i am trying to avoid saying the same things i used in my previous abortion debate.<br/> but i will quote this paragraph merely because it was never refuted and also because it is worded in a different way that might make more sense:<br/> \"now, a fetus shows scientific signs of life starting with the most simplistic from which other signs can stem (i.<br/>e.<br/> reproduction, respiration etc.<br/>).<br/> this foundation is the ability to grow.<br/> no being is created in its full potential at the moment of its conception.<br/> everything has a beginning from which, due to growth towards more complex potential, life exists.<br/> by the mere fact the fetus is growing from biological simplicity into biological complexity we can soundly say the being must be alive.<br/> biological growth, which a fetus possesses, is the foundation by which life is marked, for without growth, none of the other factors pointing towards life could exist.\"<br/> can you now agree the fetus is alive?<br/> also, note that i have not yet shown the fetus is uniquely human.<br/> i will do that now while also responding to your next argument.<br/> next you say the fetus and the mother \"are one.\"<br/> tell me, if the body of the mother and the body of the fetus are the same, then why does the human dna of the fetus differ from the human dna of the mother?<br/> by the mere fact that the dna differs between the fetus and the mother, science proves that the fetus and mother are not the same.<br/> no human being biologically produces cells that have different human dna from the body that produced it.<br/> a fetus therefore is not the same as the mother.<br/> a sperm cell is not, in itself, genetically unique from the father.<br/> an egg cell is not, in itself, genetically unique from the mother.<br/> however, when the egg and sperm meet at conception, they form a new being with entirely unique human dna that has never existed before, separate even from the mother and father.<br/> this proves the fetus is uniquely human and different from the mother.<br/> furthermore, of course the fetus is connected to the mother.<br/> the fetus is dependent on the mother for survival.<br/> but a new born baby is also dependent on the mother/father/doctor for survival.<br/> the dependency of the fetus on the mother does not then make the fetus not living or not human.<br/> innocence and guilt can only be applied to beings with free will.<br/> the only beings with free will are human beings.<br/> that is why a tumor can neither be innocent nor guilty because the tumor has no free will on which to act upon.<br/> this eliminates your \"tumors are innocent\" argument.<br/> there are varying levels on which humans use free will.<br/> it is safe to say humans are conceived with the potential to access their latent ability to use free will just as any human is conceived with all the genetic latent potential to access and use a strong mental acuity.<br/> therefore, every fetus (because the fetus is a human being) has free will, and because the fetus has not acted in a wrong manner, then the fetus is innocent.<br/> also innocence is not subjective, because innocence can only correspond with an objective morality.<br/> here is why innocence and then morality can be objective.<br/> i will take the same argument i used in my last debate because the argument was never refuted and then expand upon the argument and tie it in with innocence.<br/> \"1.<br/>for everything, there is a standard by which everything else can be relevant towards.<br/> for example there is cold, which is the absence of heat.<br/> there is a minimum heat capacity by which coldness is measured, which is absolute zero.<br/> there is a heat capacity by which heat is measured.<br/> so there are certain levels of perfection.<br/> if something morally exists, then is there not a perfect standard by which we judge such morality?<br/> there must be.<br/> otherwise, our lives our meaningless for nothing can truly be justified or condemned.<br/> you can call this perfect standard \"god\" if you so choose, but there must be, by necessity, some perfect moral standard from which actions can all be judged.<br/> 2.<br/>if you believe no perfect moral authority/standard exists, then you must admit we should be free to do whatever we wish without repercussion.<br/> with no morality, there are no rights, and without rights there would be no true law.<br/> so therefore, by believing there is no morality, or that morality is subjective, the nazi genocides are acceptable and equally permissible for they cannot be held responsible for their wrong actions.<br/> however, since obviously the nazi\"s actions were atrocious, it would be well within logical reason to say a perfect moral authority must exist.\"<br/> since i have shown there must be, by necessity, an objective, perfect moral standard, we then judge innocence based on that morality.<br/> and because morality is an objective truth, then innocence also must be an objective truth.<br/> if innocence did not exist, then we could no longer protect people by condemning the unjust.<br/> without innocence, there would also be no guilt.<br/> without guilt, we could not convict or protect.<br/> innocence and guilt are both objective.<br/> also i never said in my opening argument anything about the legality of abortion.<br/> i merely said abortion is wrong and breaks the inalienable right to life.<br/> however, if you would like me to do so, i will argue why abortion should be illegal in my next argument because i do not have sufficient room to do so here.<br/></td>\n",
       "            <td>hello con, i'd like to first point out that there is no actual scientific definition of the terms \"life\" and/or \"living\".<br/> while all \"living\" species on earth have the same characteristics (made of cells, adapt to their environment.<br/> reproduce offspring, require energy, and provide immediate or near immediate responses to stimuli), it is impossible to say that extraterrestrial life would, if in existence, abide by the same rules.<br/> this is one of what i'm sure are several reasons scientists cannot \"define\" life.<br/> so you're saying that abortion (the intentional termination of a developing fetus) is violating a right to life, when life cannot be defined.<br/> in the womb of the mother, the fetus receives nutrients necessary to its survival through its mother via the blood in the umbilical cord.<br/> should the fetus not be considered part of the mother, even though it shares a blood supply?<br/> the mother's body even goes so far as to break down and renew muscle, fat, and bones.<br/> this process, called \"turnover\", releases fat, calcium, and protein into the mother's bloodstream.<br/> at this point, it is clear to see that the fetus and the mother are one.<br/> innocence is subjective.<br/> what is innocent by one person's standards may be guilty by another's.<br/> one would share a blood supply with a tumor as well, but it is that person's option to either live with the tumor, or have it removed.<br/> the tumor, by your argument, would be innocent (as innocence is subjective, as i afore mentioned), and only be allowed to be removed if a biopsy showed it to be malignant.<br/> a benign tumor however, could not be removed, as it poses no threat t the host's well being.<br/> therefore, if the mother of a fetus would like to legally abort it, it is within her bounds to do so.<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 3, tag: gay marriage, topics: kimo vs. pono; social issues, gay marriage\n",
      "Is-Same-Side: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">kimo vs.<br/> pono; social issues, gay marriage ok my laptop screwed up.<br/> but what is wrong with gay marriage?<br/> if you think it's wrong give me reasons.<br/> i did say i need it to finish a paper.<br/> i need others opinions, i don't care if nobody agrees.<br/> but if you post thx.<br/> back to the point is there is nothing wrong with gay marriage, when you get married to some one you love them,(hopefully), and the gays out in the world most likely love their partner too!<br/></td>\n",
       "            <td>kimo vs.<br/> pono; social issues, gay marriage \" am not against gayshould choose who they want to marry there is nothing wrong with being gay, exclaim it to the world its not a bad thing.<br/> marriage because people , but i need ore opinions to finish.\"<br/> an incoherent statement, especially the last few line.<br/> here's my statement:<br/> gay marriage is not something we should allow.<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 4, tag: abortion, topics: incest should not be considered in the legality of abortion.\n",
      "Is-Same-Side: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">incest should not be considered in the legality of abortion.<br/> con doesn't understand how a debate works.<br/></td>\n",
       "            <td>incest should not be considered in the legality of abortion.<br/> it being a disgusting and immoral act is purely from a societal standpoint and has only been considered a taboo recently.<br/> historically, it has been entirely acceptable behavior.<br/> do something merely being a social taboo constitute it being used solely as reasoning for something so controversial and important as abortion?<br/> my point is that a child conceived in incest (which, despite what was stated before, is most frequently between cousins and similar distant family rather than within a \"nuclear\" family) should be treated no differently than any other consequentially conceived child.<br/> from experience with observing my local feline populations, it takes between four and seven generations of inbreeding before any major genetic deficiencies become prevalent.<br/> many modern genetic studies on both animals and humans also confirm that the likelihood of a defect due to incest to be significantly lower than is generally believed.<br/> the chances of a birth defect formed from a first generation incestual relationship is 4%, not significantly higher than the non-incestual chances of 2%.<br/> this applies to difficulties in pregnancy and p.<br/>n.<br/> depression as well.<br/> the social side of your argument is wholly invalid.<br/> americans have the right to choose to engage in incestuous activities and can choose to be open about it or keep it a secret if they want.<br/> this argument is ceteris paribus to a baby conceived legally and consensually in every other respect.<br/> this is a question of if the abortion of a consensually conceived child that is a product of incest should be handled any differently than if a child was not conceived in incest.<br/> this isn't a question of if incest is moral or ethical but rather if the law should treat incest pregnancies any differently when it comes to abortion.<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 5, tag: abortion, topics: resolved: in the us, unwanted pregnancy abortion is an unjust medical practice.\n",
      "Is-Same-Side: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">resolved:<br/> in the us, unwanted pregnancy abortion is an unjust medical practice.<br/> \"my response:<br/> the ci only can be applied to humans because we have:<br/> a) free will, b) intellect, and c) have some sort of moral conscience.<br/> also, you are referring to necessity, i.<br/>e.<br/> survival, rather then morality or justice.<br/> the resolution asks for the value of justice not necessity.<br/> on a different note, you have not explained how abortion is therefore justified.\"<br/> but why should any of those things give more value to life?<br/> furthermore, you have essentially negated your own argument.<br/> fetuses do not have free will, intellect, or a moral conscience.<br/> \"my response:<br/> well, good question.<br/> however he is by far the greatest of all enlightenment philosophers when it comes to ethics.<br/> oh and kant is very interesting, you should read more of him.\"<br/> so you're arguing not from logic, but from the moral opinions of one man.<br/> no matter how hihgly regarded a philosopher may be, they are still opinions.<br/> unless backed up by logic, opinions are just opinions.<br/> \"my response:<br/> good, i was actually going to use that argument.<br/> thx for bringing it up.<br/> women also, are effected by abortion.<br/> 70% of women after an abortion go through some mental trauma.<br/> the women must know the consequences and say no.\"<br/> it is true that women often suffer emotional anguish from this decision.<br/> but that does not change the fact that it is their decision to make.<br/> more often than not, the emotional consequences of choosing an abortion are not greater than the practical consequences of having a baby.<br/></td>\n",
       "            <td>resolved:<br/> in the us, unwanted pregnancy abortion is an unjust medical practice.<br/> \"i.<br/> \"act only according to that maxim whereby you can at the same time will that it should become a universal law.\"<br/> essentially, the first way kant tells us how to determine a just action is universality.<br/> this means that whatever action you do must be able to become universalized.<br/> i.<br/>e.<br/> killing is wrong because you yourself/people you love should not be killed.<br/> therefore killing another person cannot be universalized.\"<br/> but all animal life is dependant upn some form of killing in order to survive.<br/> lifeforms must devour other lifeforms.<br/> should we not kill and eat living animals and plants simply because we ourselves wish to live?<br/> that would be contradictory.<br/> we cannot live without doing so.<br/> while i realize that elective abortion is not a matter of physical survival, my statements nonetheless show that kant's statement is not valid (or at least not universally true.<br/>) \"now referring this maxim to your questions.<br/> you ask why should life be due to anyone?<br/> obviously, you yourself would like to live, me also, and the members of the debate community (unless your suicidal).<br/> we all look for survival.<br/> therefore, universalize the action of life.\"<br/> so life should be due to any living thing, no matter what they have done, on the basis that i would like to live?<br/> \"ii.<br/> \"act in such a way that you treat humanity, whether in your own person or in the person of any other, always at the same time as an end and never merely as a means to an end.\"<br/> kant then goes on to use this maxim.<br/> he is saying that an action is just if it doesn't use a living creature as a means to an end.<br/> a person is always an end in and of itself.<br/> therefore abortion uses the baby as a means to the mothers own pleasure of getting rid of a child.\"<br/> but who is kant to dictate morals?<br/> what proof is provided that these moral statements are of value?<br/> i admit that i have not read much kant, as i find it rather trying.<br/> furthermore, ask any woman who has had an abortion and she will tell you that there is no pleasure involved.<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 6, tag: abortion, topics: abortion is morally wrong.\n",
      "Is-Same-Side: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">thank you for that very...<br/> eh, interesting response.<br/>counter-rebuttals \"so tell me con, is a woman killing a baby before it has a chance to live whenever she has her period and looses an egg?<br/> well, you must think so if you think \"we are killing fetuses before them have a chance to live.\"<br/>please use proper english next time so i can understand you.<br/>well, that seemed pretty understandable to me.<br/> every time a woman has a period, she looses an egg.<br/> so, does that qualify as \"murder\" in your mind?\"<br/>the reason we are not giving fetuses a choice is because they would be incapable of choosing if we happened to ask them.\"<br/>but who would choose to die?<br/> nobody would want to be aborted as a fetus.<br/>you missed the point!<br/> no one would want to die, the reason i said that is because if a fetus is aborted, then it never will be a human, therefore it was never and will never be able to make a choice rationally!<br/> so your argument basically makes no sense!<br/> \"for that matter, they are incapable of feeling pain, thinking, digestion, or self awareness.\"<br/> a fetus can feel pain at 8 weeks.<br/> at 8 weeks, it has all the musles and organs needed to feel pain.<br/> scientists even did studies that proved fetuses can feel pain.<br/> souces at the bottom.<br/> no, a fetus can not feel pain until 20 weeks!<br/> i looked at one of your sources, and here's what it said.\"<br/>a new nebraska law bans abortions after 20 weeks, based on the idea that pain begins then.\"<br/> that's right!<br/> your source said that!<br/> so what, are you just making these facts up?<br/> please, i would really like to know!\"<br/>where, may i ask, are you getting these \"facts?\"<br/>\"i will post them at the bottom of this round.<br/>hmm...<br/> i didn't happen to see your fact about \"fifteen percent of men are sterile\" in any of those sources!<br/> nor did i see your fact \"only half of assailants penetrate her body and/or deposit sperm in her vagina\" anywhere!<br/> so again, we see you simply making this stuff up!\"<br/>there are many methods of birth control in today's world.<br/> you can attempt natural birth control, by only having sex during ovulation.<br/> or condoms can be used to prevent the flow of sperm.<br/> also, pills such as daily pills or morning after supplements can eliminate the zygote.<br/> however, what if the girl ovulates at an unexpected time?<br/> or what if your condom breaks, like some 4% of them do?<br/> maybe the pill doesn't work either, as the chances of failure are always there?<br/> abortion is a last resort for many people.<br/> a common \"misconception\" (no pun intended!<br/>) is that pro-choice people love abortion.<br/> abortion is not a great thing, but in situations like teen pregnancies, it can be necessary.\"<br/>again, a fetus is biologically a member of the human species, therefore you cannot morally kill an innocent fetus.<br/> there are cases when birth control fails, but they will just have to deal with it.<br/> besides, it was their idea to have sex in the first place.<br/>no, no, no!<br/> a fetus is not biologically human.<br/> the fetus has a heart, skin, muscles, cartilage, a \"brain,\" minor organs, and several other small parts similar to humans.<br/> but hey, so do dogs!<br/> so are dogs \"biologically human?\"<br/> no!<br/> also,definition of a parasite:<br/>parasite ( ) n.<br/> biology .<br/> an organism that grows, feeds, and is sheltered on or in a different organism while contributing nothing to the survival of.<br/>does the fetus grow, feed, and have shelter in the mother?<br/> yes!<br/> does it contribute to the mother's survival?<br/> no!<br/> so a fetus, technically speaking, is 100% parasite.<br/> is it murder when you remove an unwanted parasite from your body?<br/> of course not!<br/>and it is not the user's fault when birth control fails.<br/> they should not \"just have to deal with it,\" because if the fetus does become a human, it will probably have a poor life in the hands of inexperienced kids who may not even get to college in order to care for the child!<br/> rebuttalsnew point- a fetus can feel paina fetus can feel pain at 8 weeks, and abortion causes alot of pain.<br/> well, it was your source (http:<br/>//news.<br/>discovery.<br/>com......<br/>) that said it takes 20, maybe up to 29 weeks!<br/> so you basically proved yourself wrong, and attempted to fudge false information!<br/> that should get you disqualified right there, my friend.<br/>conclusionthank you, folks, for listening to this heated debate for the past week or so.<br/> to wrap things up,-abortion is not murder.<br/> the definition of murder clearly states that murder is \"of another human being,\" and according to nearly every source below (as well as my opponent's sources), a fetus is not by any means human.<br/>-when you really take a good look at it, abortion is nothing more than a choice between a woman and her doctor.<br/> it is not the government's choice, not her parent's choice, and certainly not your choice, con.<br/>-rape is something that happens a lot in today's society, and unfortunately, many of these victims become pregnant (contrary to the made up statistics of my opponent).<br/> so abortion, while not always happy, must happen if the woman does not want to continue to carry some random dude's seed.<br/> -birth control does not always work, but that is not the user's fault.<br/> the parents (and the baby) should not be punished for something they can't stop!<br/>-my opponent uses made up info for his case!<br/>thank you.<br/> vote con</td>\n",
       "            <td>i see that you are for abortion.<br/> i would like to debate this with you.<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 7, tag: abortion, topics: abortion\n",
      "Is-Same-Side: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">pennsylvania is a good thing.<br/> the swing states will be vital.<br/> *waits and watches*</td>\n",
       "            <td>my opponent's first argument begins with an over-rationalization.<br/> she maintains that because killing is \"wrong\", therefore abortion is also \"wrong\".<br/> however, this assumption is wrong -- killing in it of itself is perfectly okay.<br/> from hunting, to fishing, to the zooplankton in our toothpastes, killing occurs all the time.<br/> what i believe my opponent was trying to say though, was that the forced termination of human life is \"wrong\".<br/> that it true, and i will not attempt to argue that point.<br/> however, a fetus is not a human being.<br/> wiktionary, for instance, defines a human being as, \"a human being, whether man, woman, or child; of or belonging to the species homo sapiens or its closest relatives.\"<br/> there is no mention of fetuses anywhere in that definition.<br/> and in fact, if you can find a mainstream, unbiased source (from a dictionary, online dictionary, or otherwise) that defines humans to include fetuses, i will forfeit the sources vote.<br/> furthermore, your conception of the word \"killing\" is also flawed.<br/> if we can assume that preventing life to become life is in fact killing, then every moment you are not engaging in the act of reproduction, you are killing potential life.<br/> that notion, however, is quite ridiculous; your idea of disallowing abortion is similarly outlandish.<br/> therefore, the idea of \"potential life\" is neither equatable, nor comparable with actual life.<br/> but even if a fetus were a human being, its \"rights\" still would not trump the rights of the mother.<br/> who are we to expect pregnant women to voluntarily donate their body and life support systems to something else?<br/> who are we to force a mother to devote eighteen years to taking care of a child?<br/> that is both unreasonable, and, arguably, sexist.<br/> therefore, my opponent's argument that abortions deprive the rights of future humans should be ignored.<br/> besides, even if abortions were made illegal, women would still seek them, and this would be extremely dangerous.<br/> according to planned parenthood, \"in 1972 there were 1,000,000 illegal abortions and 5,000 to 10,000 women died from them.\"<br/> when roe v.<br/> wade passed in 1973 (a year after the above-mentioned statistic), deaths from abortion drastically dropped.<br/> this is supported by the national center for health statistics' own statistics.<br/> her third point is that some women will feel sad for having an abortion...<br/> um...<br/> so what?!<br/> feeling bad is not reason to disallow abortion.<br/> to bring unwanted children in this world.<br/> to force women to bear a child.<br/> that is absurd, and only an appeal to emotion.<br/> but above all, the fundamental reason darkprincess expresses her opinion this way in her oppening argument, is because she wants to inflict her morals upon the different people around her.<br/> (that is the basis to her second point.<br/>) the government has absolutely no right to control the morals of its people, and above all, that is why you must allow abortions.<br/> and that is why i strongly urge the audience to vote pro.<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 8, tag: gay marriage, topics: gay marriage is morally acceptable even within christianity\n",
      "Is-Same-Side: False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">gay marriage is morally acceptable even within christianity everything you say here is good and reasonable.<br/> there is just one thing that you assume.<br/> you are assuming that every single thing in the bible is god's will.<br/> don't be offended by the following, this is just my point of view.<br/> not everything in the bible is a fact or a rule.<br/> now, jesus himself never says that homosexuality is wrong, nor does any heavenly figure (he does say personally that divorce is a sin, but we allow that!<br/>).<br/> paul is the one who argues against homosexuality.<br/> unless you convince yourself that every time someone wrote something that would later appear in the bible, god took control of the writer's hand and made the writer write his will, what paul says is just what paul says.<br/> it is not really god's will, but paul's.<br/> and if it were god's will, and he will judge the gays, is it our place to prevent them from marriage?<br/> we should let god judge them, not us.<br/> if they will be punished for their acts by god, we still have no place to judge them ourselves.<br/> the bible is not a rulebook for our religion, it is literally a bunch of historical accounts brought together in one place and translated so we can read its wisdom.<br/> most of it is there for us to think about.<br/> however, it contradicts itself.<br/> leviticus 20:<br/>13 says:<br/> \"if a man lies with a male as with a woman, both of them have committed an abomination; they shall surely be put to death; their blood is upon them.\"<br/> if your assumption is correct, then all gays who have had gay sex should die.<br/> but this contradicts everything we know about our religion.<br/> so in general we have to separate the big picture from the bible's main themes, rather than harsh details.<br/> in the passage about the woman who escapes punishment, yes, he says \"sin no more\", but she is still forgiven and is not punished.<br/> in the comments, someone said that there was no such thing as a gay christian.<br/> however, there are many gays christians and christian lgbt supporters.<br/> ( http:<br/>//www.<br/>notalllikethat.<br/>org...<br/> ) the same commenter said to show where a bible passage said that a gay person went to heaven.<br/> that brings up another point.<br/> one might say jesus thinks people should not be gay because of matthew 19:<br/>4-5, which says:<br/> \"jesus answered, \"have you not read that the one who made them at the beginning made them male and female, and said, \"for this reason a man shall leave his father and mother and be joined to his wife and the two shall become one flesh\"?<br/> therefore, what god has joined together, let no one separate.\"<br/> \" people use this passage against homosexuality.<br/> but they forget the rest:<br/> \"not everyone can accept this teaching, but only those to whom it is given.<br/> for there are eunuchs who have been so from birth, and there are eunuchs who have been made eunuchs by others, and there are eunuchs who have made themselves eunuchs for the sake of the kingdom of heaven.<br/> let anyone accept this who can.\"<br/> (matthew 19:<br/>11-12).<br/> he says this in response to his disciples reaction to his strict ideas about divorce (see first paragraph).<br/> nowadays and ever since ancient times in some places, the term \"eunuch\" is used to refer to a man who had his testicles removed before puberty, so that he can think differently from other people.<br/> in those parts and times, the term was used to refer to an especially feminine or homosexual man.<br/> http:<br/>//www.<br/>wouldjesusdiscriminate.<br/>org...<br/> i have no more arguments for the time being.<br/></td>\n",
       "            <td>gay marriage is morally acceptable even within christianity i accept...<br/> as con, i will argue the fact that the bible does not condone same sex marriage or relations.<br/> i would also argue that what the old testament says does still matter in context of all 66 books of protestant canon, though the new testament should suffice in proving my point.<br/> paul does record multiple times in letters to the corinthians, romans, timothy, and others that homosexuality is a sin that will be punished at judgment.<br/> pro claims that paul was simply referring to the sin of homosexual rape that would be condemned as much as heterosexual rape.<br/> while paul certainly would have condemned homosexual rape, this would not have been the main action he was referring to.<br/> scholars believe that as early as the second century before christ, rome had outlawed homosexual rape.<br/> if outlawed, it would not have been prevalent enough for paul to use the term homosexuality and it not be accepted as everything under that umbrella term, whether rape or love.<br/> in fact, homosexual marriage was a known fact and practiced in the empire.<br/> emperor nero was involved in three gay unions.<br/> in one of these he is even reported to have worn a wedding veil, and he would choose whether to be the male or female in the relationship.<br/> http:<br/>//historynewsnetwork.<br/>org...<br/> many use jesus' command not to judge as reason for the bible's acceptance of homosexuality, or at least lack of condemnation.<br/> unfortunately, they do not continue reading the passage.<br/> he says we will be judged as we judge others.<br/> this passage is saying that we should not base our judgment on prejudice and preconceived notions or we will be judged by those ourselves.<br/> however, according to the bible we will all be judged according to god's word.<br/> therefore it is not the christian judging, it is actually the bible.<br/> another passage that is often referenced is that in which the adulterous woman is brought before jesus.<br/> in an act of great mercy he declares that the one without sin should be first to cast a stone.<br/> those who wanted to stone her quickly realized that they were at fault and left.<br/> jesus then says that he would not condemn her either.<br/> when using this verse to support homosexuality, most stop there.<br/> one small sentence is usually forgotten in this story.<br/> he says,\"go, and sin no more.\"<br/> though he forgives her and does not condemn, he still recognizes her sin and commands her to stop with his authority and that of scripture.<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDX: 9, tag: abortion, topics: prolife folks should agree that abortionist tiller should have been shot\n",
      "Is-Same-Side: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "        <tr>\n",
       "            <td style=\"border-right:1px dashed black;\">prolife folks should agree that abortionist tiller should have been shot my opponent's comment comes a day after she posted her counter-argument.<br/> i'm having a hard time believing she \"accidentally\" hit accept too early.<br/>but never let it be said that i am one to stifle intellectual discussion on the basis of a technicality.<br/> i'll still rebut the arguments posted in the comments section.\"<br/>it's not about law per se, it's about the moral thing to do.<br/>so why bring up the idea that im being hypocritical?\"<br/>because if it is about morality, and not law, your first argument (that what he did was unlawful) is meaningless.<br/> you trying to justify his murder by saying \"he broke the law\", while simultaneously saying \"it's not about what's legal\", is hypocrisy.\"<br/>too many children?<br/> they can always adopt.<br/> even if they couldnt, they are responisble for having the child, particluarly not aborting earlier when itd be more morallly gray.\"<br/>the problem is, i have presented a clear-cut case for why it is morally justifiable to do so (self-defence).<br/> a case which you did not contest.\"<br/>also u didnt address the rock concert example\"i did, in that i provided a moral argument for why abortion is alwyas justifiable, under any circumstance; self-defence.<br/> an argument you did not dispute, which means you dropped it.\"<br/>but as said, she had plenty of time to abort earlier when more morally gray, and she is responsible for the conception so she does not have absolute right here.\"<br/>1) how do you know it was her who was responsible for the conception?<br/>2) at what point does the mother lose sovereignty over her own body?<br/> consequently, at what point do we, as human beings, lose sovereignty over our own body?<br/> is there a point in time where it is okay for me to rape you, because you've lost soveriengty over your body?<br/> or to take, against your will, your bodily organs?<br/> i propose there is never sucha point, as allowing such a point would lead to barabric and disatrous moral results for society.\"<br/>you say society cant do this...<br/> but it always has and must sometimes by necessity sometimes.<br/> civil war, revolutions, defending others etc...<br/> killing is sometimes necessary.\"<br/>you say society has always killed, but that does not justify the killings it has done.<br/> further more, saying \"people kill in war\" does not negate my claim that \"the only just time to kill is in self-defence\".<br/> after all, at one point or another, all sides of a war are killing \"in self-defence\".\"<br/>you didnt address the two year old hypothetical.<br/> almost everyone would agree that should be a moral necessity to defend them.\"<br/>because they are a living child, no longer infringing upon someone's bodily sovereinty.<br/>this is not comparable to a fetus, which is.<br/> \"the only distinction you could make is body soverignty arguments.<br/> but if u do make this argument....<br/> how is it not her responsibility that the child was conceived, and how not her fault she did not abort sooner when morally grayer?\"<br/>whether or not it was her hoice to concieve the child, doesn't change the face that she should be able to boot it out when she wants.<br/> if i invite you into my house, does htat mean i have no right to tell you to leave, and force you out of my house, if you choose not to go or are incapable of not leaving?<br/> \"i could see if he did them for trivial reasons at a point where it's legal, and for nontrivial when it's not illegal.<br/> the only thing that is not trivial and not the mom's life, is a deformed baby.<br/> i could understand if that was the reason he did them, i may need more information....<br/> it sounds like he was not this scrupulous.<br/>and we see he aborted at 26 weeks for too many kids.<br/> far as i can tell, that's into 3rd trimester and pushing if not illegal.<br/> not an expert, i admit\" once again, legality here is not the issue; it's the morality.<br/>and it was completely immoral, and logically unjustifiable, to murder this man, simply because he respected women's bodily sovereignty, and aborted their babies.<br/>vote con.<br/></td>\n",
       "            <td>prolife folks should agree that abortionist tiller should have been shot why is everyone forfeiting?<br/></td>\n",
       "        </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = {print_args(FPFN_df, i) for i in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T11:09:54.332972Z",
     "start_time": "2019-07-17T11:09:34.803468Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada03ca45d4c47cda704126ef5b04ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1784), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument1_len</th>\n",
       "      <th>argument2_len</th>\n",
       "      <th>argument12_len_diff</th>\n",
       "      <th>argument12_len_diff_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1784.000000</td>\n",
       "      <td>1784.000000</td>\n",
       "      <td>1784.000000</td>\n",
       "      <td>1784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>471.911435</td>\n",
       "      <td>394.099776</td>\n",
       "      <td>77.811659</td>\n",
       "      <td>380.988789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>531.535292</td>\n",
       "      <td>487.483849</td>\n",
       "      <td>577.798488</td>\n",
       "      <td>441.220213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-2331.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>-126.250000</td>\n",
       "      <td>59.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>699.500000</td>\n",
       "      <td>543.500000</td>\n",
       "      <td>300.500000</td>\n",
       "      <td>550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2724.000000</td>\n",
       "      <td>2415.000000</td>\n",
       "      <td>2704.000000</td>\n",
       "      <td>2704.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       argument1_len  argument2_len  argument12_len_diff  \\\n",
       "count    1784.000000    1784.000000          1784.000000   \n",
       "mean      471.911435     394.099776            77.811659   \n",
       "std       531.535292     487.483849           577.798488   \n",
       "min         3.000000       4.000000         -2331.000000   \n",
       "25%        80.000000      59.000000          -126.250000   \n",
       "50%       243.000000     174.000000            26.000000   \n",
       "75%       699.500000     543.500000           300.500000   \n",
       "max      2724.000000    2415.000000          2704.000000   \n",
       "\n",
       "       argument12_len_diff_abs  \n",
       "count              1784.000000  \n",
       "mean                380.988789  \n",
       "std                 441.220213  \n",
       "min                   0.000000  \n",
       "25%                  59.750000  \n",
       "50%                 210.000000  \n",
       "75%                 550.000000  \n",
       "max                2704.000000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer from BERT\n",
    "def tokenize_arguments(row):\n",
    "    # tokenize\n",
    "    row['argument1_tokens'] = tokenizer(row['argument1'])\n",
    "    row['argument2_tokens'] = tokenizer(row['argument2'])\n",
    "\n",
    "    # count tokens\n",
    "    row['argument1_len'] = len(row['argument1_tokens'])\n",
    "    row['argument2_len'] = len(row['argument2_tokens'])\n",
    "    # token number diff\n",
    "    row['argument12_len_diff'] = row['argument1_len'] - row['argument2_len']\n",
    "    row['argument12_len_diff_abs'] = np.abs(row['argument12_len_diff'])\n",
    "    return row\n",
    "\n",
    "\n",
    "FPFN_df = FPFN_df.progress_apply(tokenize_arguments, axis=1)\n",
    "FPFN_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T11:09:56.868107Z",
     "start_time": "2019-07-17T11:09:56.469901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f81ac0cf748>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOydd3gcxfnHP7vX73R36r3LarblKveGC8Y2mG4bMMFAgCQQakggyS+QQgiEkoQWQm+hQ2yDMRhs3HCVe5Wt3rt0ve/8/jhZsrDpEALc53nu0WlvZnb2bna+877zzqwkhCBChAgRIkQ4hvxtVyBChAgRIvxvERGGCBEiRIgwgIgwRIgQIUKEAUSEIUKECBEiDCAiDBEiRIgQYQDqb7sCX5X4+HiRnZ39bVcjQoQIEb5T7Nixo0MIkXCyz77zwpCdnU1ZWdm3XY0IESJE+E4hSVLtJ30WcSVFiBAhQoQBRIQhQoQIESIMICIMESJEiBBhABFhiBAhQoQIA4gIQ4QIESJEGEBEGCJEiBAhwgAiwhAhQoQIEQYQEYYfICv2NrPhaDuRLdcjRIhwMr7zC9wifHH23fVjnJKae4ov4PyZEzl3VDpRukhTiBAhQphIb/ADZEJlHYm2EAt3/4mN2+K5OG8OI6afzZKJ2eTEm77t6kWIEOFbJiIMP0CaM2KJ8rRTP7mA8RuPMP3ICxzZ9Tp3LB9LaNyPWDK1gGn5Cciy9G1XNUKECN8CkTmGHyChokKMfjBe/FtyPlxN9eUziQ4EuXnjeq569Cd8ePtVnPXnV3hqYzV2b+Dbrm6ECBH+y0SE4QdI7qRTADi8YQUxcanM+9VDTFy3g/Y7fkpnppkLd5dz50t/wH/XEn50y338bul+Ktoc326lI0SI8F9D+q5HppSWlorI7qpfDLezh8qxE1gzPp/rn1p+wucHd3/A4Sf+Ttb6Sox+OJpkYHnuOPzjLuJHUwuYUZSIKuJmihDhO40kSTuEEKUn/SwiDD9MVp4yAodGxYJVZUjSyTv5to46Nj95J5blG0nuDNFjlHk3v5Cy4kWcPWMMC0szsBo1/+WaR4gQ4esgIgwRTuCFS+dSvLOGuNWbyU6I/tS0voCXDUsfwvniq+QfcqDIsCkniZU58yiePodLJ+VQmGz+zHMqisAfUtBrVF/XZUSIEOFL8mnCEJlj+IFiGD4Cox8+Wv/+Z6bVafTMWnAzZ725Fd+L93FoejajG1r5ywdPM/Hvl3HvLb9m8SPreHd/M8GQ8onlPLmxmlPuWYuifLcHIxEifN+JCMMPlJJT5gLQWrb2c+eRJIlRo+ax8OGVpLz/NvsvnYhReLlp62quffxqtvzhWs78/ev8c20l3S7/Cfn3NPTQYvfS2OP5ui4jQoQI3wCRdQw/UPKGTWSnDoyVh79U/rTEPBbc+iSum1ys/c8DeF5+gwX7DnD+/tvZXJbMZTmnUzB9Fksm5TAk1QpAfZcbgCOtDjJijV/btUSIEOHrJSIMP1BUKjX1aWaymtrxBxW06i9nPJq0Jk5f9GuUhbewpWwZVU8/wohNDUyufpLqvS/xj+WTcYw7h8VTC6hqdwFwtM3JzOKkr/NyIkT4XhNSBOU1dbjL11EyYyE6nf4bPV9EGH7AuPJzKVy1h91HqxlbnPeVypIlmYljzmHimHOobDnIlmfuJnFFGTduX4Vj32re/XAwurT5OIyxbKnq5KfTvtr5IkT4PuMPKuxrtLGtuouKo4cY1vAS5/EBRnw05paQUTjyGz1/RBh+wCSOGY/83h52rXuLscU3DPzQ3QWSDIZPj1g6GXnJg8m79Vl6buhhzdJ/EHhlGecd3Me5B/exJSuFpV3zuMmo4dJJOQxL/+LlR4jwfcPjD7Grvptt1V1sq+5iZ103WcEarlK/zRWqzagkhcbkWbhn/JKMgm9WFCASrvrDQgmhfPQv8HQhj1xAR0BD+4zTeXfmCG58+KX+dPZm+NcUiMuHy1d+5dMGlSD/XPoUjjee5tQDPUR5oSbOxLKcKXSNmc/iaYXMHZrypd1ZESJ813B4A5TV9gvB3oYeAiEBCCarD/EL03uM9G1HSCpEyfnIU34BCYVfax0+LVw1YjH8UHC0EnrxMmqeOELAo8KS/jjWUUm0WyUSaqv604UC8Nql4GoPv9rLv3KDVMtqNHEzeSwjDelCaHzrIeYfrOX6sndx7H+f99YN5ZHCc5g7cyQXjcsk0fzN+k8jRPhv0+Xys72mq08IDjTZOD5quzDBwBUJBzit5xUsXfsgqIXRlyFNuh4pNue/Xt+IMHzX6amHfa/ChJ+DWnfyNFVrEa9dSeN7Ar9bh2XWdBzrN2B700ECkGCz475zCsbpF0LDdqjfAnPugvd+C7tegNl/+srVrOtyE2PUMGtoKQs2wqkP57Jr/wuI11dw7qE9nHtoD1t3pPKvnEHkj0il4PTrGJkR/YmrsiNE+F+m1e5la3UX26o72VbdxZFW54DP40xaJufHMzUnilm+1Vh3PQpV1aA2wPhrYOLPwZL6LdU+IgzfbfxueOlCaN0HsgYmXTfwcyUE6+6GdX+lvSILV5Of5N//jpgLLkDxenGuWUPjTb8AoPa5DvRv34c1240lS0at1kH6GNjzMsy8DVRfbeuL+i43mXEmBiVEAdDao+Wqi/6Mf9HtrN72MvXPPc7wLU1MqGvCvk/hiQ02WseczkVTCzljeAo6dWS1dIT/TYQQNHR72FIVFoFtNV3UdroHpNGqZcZmxzIlP57J+fEUW4LIZU/AusfA3QE6C0z5BYy/Gkzx39KV9BMRBgCvDZ6cDWOugLFXftu1+XwIAW9dB637Ib4Q1t8LIy8GY2z4c3szvHkl1GzArp5NZ9l+ohecT/SiRQDIej2WefMo17mIuuY22jKTyLA30LozmtbdELXtj1izPUSlepFfvwzOehj01i9d3dpON8MzookxaYmP0nG0dwSlVWmZmzEEUWRnV1oX6zqTydzh59qdK3EeWMV764bxr8L5nDZzFIvHZZFsjbiZIny7CCGobHf2WgThV7PNe0K6omQzUwsSmDwonrE5seGtYLprYfOfYdfzEHCDMQ5m/C7c73yF++vrJiIMgNBE4eqwYlz+S+S2QzD37q88Qv7G2foo7HsNpv8fFJ0Oj06C9ffAnL9AxWp48yoIuPGO/iNNtz+HYfhwkn73uxNcM8MmzqVcdRsdMa2MmxbEf+oTeNZuw7b0Pzg/6kHWKlh2rSd6UzH68acglZwPBXNA+/kXqAVDCo09HuYPTwGgICmKI23OsEWz8W+w9i9I5hRG/WgpozzdNL52MatSzkH1znbOPrSLc8p3sW1nOldnzyXllGlcOimH0qyYiJspwn+FkCI41GzvE4FtNV10nWRlf4JZx5T8eKbkxzNpUPzAubKm3bDpATiwFEQIzCkw4/9g9KWg/d97amJEGADF5aL+1SZ0CXlk+J9G01kBC57pH33/r1GzMez/Lzw9bH7KMoxYHBYLZyvsfxMSiwnNeYiGn/4G2WQk7YEHkLXaE4rS6U00J8pEdYS4w302q94PcsOsCzj/+hvwb9uG7dE/YttdS0+FjHbzTiyZ67Dmg3b0HCg5H/JmfPLcRi/NNi8hRZAVG74B8hOj2LhjN+LZPyPVfgRDz4PT7w+HxjbvIS0U4rKJZ+Je8iDvbvs3zS88TemWBsbXP079/pd45u1p/Hn0HC6aVsiZI1Ijm/JF+Fo5fg3BtupOymq6cfiCJ6TTa2TG5cT1ikECBUlRAwcrQkDVh/DRP6BqbfhYdBZMviF8v37GffNtEglXBa59aRdDKncy7ZUHUOshfXwjhvxMuOgViM//mmr6NWFrhMemhc3OKz9E6Mw09nhIdx+Cx2eE04y6BHHqndRf9wtcW7aQ9eyzGEd9Quzztsd5+56/kn5YzZBzmvhbaCHPhk7DhYE7zylhYbYb6YHxOCwXYjvgwr1tOwDGpBDWTAfmfA2q4fPDnXv2VFCdONbYeLSDi5/cyktXjmdCXhzrlj7O8F23Y9GCfPp9MPwCOHZDuTrhnlzWZN/IG9ozKUg0k59kwqfspX75o+StLie3BVw6Fe9lDWd90enMmDGKi8dnkRZt+Ca+8Qjfc7yBELvqenqtgU521vbgCYROmnZomoUp+QlMGRTPqKyYkw9KQkE4uBQ++ju07Asfiy+EKTfB0PNPeo98EVy+IOv2VtC2+TUMSoBFN/zxS5UTCVf9DOyeAHc5k1kx9nL+tP0Zaj5MIs3ViMU9M2w55M34tqsYJuiDV38EAQ9cugL0Fu5eeZjDG97gcfPj9Dm/Ri2h/Z9P4NqwgeQ//IGunEK0IQW16mPrBOq3w7u/RpuUjG5fiEq3nl9FvcoV6nd4PHgGd/zHy2/Qszp6MKnarWz42Zss+osG21tvYVu6lObttbTskjFveg9r5muY8ixIQ88Oi0TGuLAlQzgiCSDLLGDZz5m2+3l2i1x8cx5j3IgxfdVps3t5bF0LNwsNlRXlrAg2s4Lmvs+N2p+StcBJjuNtSrfu4MzynZx9ZCdlO9O5Nus0EqedwpJJOYzPjY24mb6LtB2G928DWz1c+DLEZH0jp3F4A+w4bg3Bnr41BCeSYtX3ThgnMCkvjrioTxnl+12w83nY/DDY6sLHkofB1JuhaH7f/fBl8PhDbNh9GNuqp8nav47BLZ3ktmuRVQLxs1uRdF/v3mPfeYuhaOgIcfcLK5hWkEC08URXyWdR3eFid0Utv367Gm8QRnhb+dWH/yTG5yShxE7sEA/yvLv/Nyall18HO5+Fhc/D4DPZdKSZPc/9kp+p36JSzibzsqfRvLwQe0cKjcs6iF64EN91v+KUe9di0auZkp/AtMIETilIIFHlhH9NBVnN20wk79F1NE728EbiJTxUfABV5Qd0YebRwBn40XCz/AI39yxk9mW/Y2ZxEha9Gu/evdiWLce+YgUhmw1VlAZrhh1rpgN9VjIMPQeGnsddu/W0bnqRv6kfACQ846+nZO0obj29hCum5NJs8/Do2kpe2l5PSBG8Jt1M4x4Vxi44Em/lUGwGBy1DqNIPIdZiRhGCLo+NJM16Tq/dyKl7PUS7od4axbLsU1idMYFbzhnJBWMyMWgjbqb/eVwd8OGdsOMZhCYKSSYcpbNkOcTmfuXiP2sNwfEYtSom5MYxudc9lJdg+uxBhrMdtj0G2x8HT3f4WMb4sCAMmtVvDX9BvIEQmzeX4Vn2OKmHyzA1uwm6w+1ZHS2jUXnxdGrJX/Um6sziL1z+9/pBPTFZRcJ64X3IEpRmxTKjOJFZxYnkJUR9rlHjJU9t47J/XUaXScvdI66kTZvFLIuPi16/jxR3F+YsD6lju3GOWILl7Pu+vUnpHc/AW9fD5Jtg1u30NFdT+9gihoty6nIWceqhudw0dxhLOl+j5ran0eflkPnachRZxS233caH3mychnT8IQUZhTei7qUkdJDyM96k64P70L1cTnt2kPeLz+eXv7qNNMd+WHsnVK7BI7Ss3hVDYp2KhXPuASSmFiQwd2gypw5OIk4r4Vy/HtuyZTg+XAvBILokPdbUDiyZTjSG457RcP5TMPQ8Rv/pfYpSzGTFmXi9rAFFCM4fbGRs2cPkr9pPQA0t+XHE1nRhdYXbqFcDFYkGalNSCBWNIqV0Nh5DMpvqVhO961Vm7WxmUAu4tCrezxrB8qxTaY6KZ2FpOjOLkyhOtpAeY0COPJb0f4OANzwvtuE+Qi43ttB0unc5CXV3kTC0i+hiNdKlb31hd+5nrSE4HlmCkvRopgwKTxqPzIz5/CvwOyth80Ow+0UI9kYl5U4PC0LWpC8lCF5/gJ3LVxBY8QJxFYdRdQRBSKAWaNL1ROfpsca1o5E7sNUYaNoSQ+6z96MbN/cLn+sbFQZJkjKA54BkQAEeE0L8Q5KkWOAVIBuoARYKIbp78/wa+DEQAq4TQrzXe3w08AxgAN4BrhefUcHB2UnipounUzP0Ona2hjjYbAcgM9bIjKJEZhYnMjYn9hPj4Gs7Xfz7pkWcs7USpx7+MW46G2NOJ8Zr545Nj5Nrb0YX5ydzShdl+iG4z3qS6SMK/ruuioYyeHouZE+Gxa8jjq7C9cqVEArSPfMeMqb+iCue3c7eQ/U8X/ZP5K5Gshfq0fxyKxX7NxFY9FMUoDLVQGjyWGIsPk5xvsktwat4JXgKH+muZc9WDUaHROP0wTxovIYtv5kJgK96E+88cD1FK53sG6xQUzyVJ0Pz8BG2zmQJxmTHMmdoMqcNSSZReLGvXIlt2TK8e/aCJDAl+7BmezCneZHVgn2F13HN3hzqRBJalcyCUclMaH6D+Gf+g9WpcGiojpGDnWT9/iggqDpUxqo3X8W7dzf5be1kt/tR92pNa7SKluwEokYNQwzJZU/9HpLe38b4QyFkBXakZrA0aza7EgsRkoxRq6IgyUxRcvhVmGyhKNlMjOmLW5sRviRCwIH/wAe346trpLtjMLb9bhS3B/3QoUhaLZ6dOzEkKaRMUtDdsBwSTz4iPraG4HghqPnYGoKPkx5jCM8T5MczMS/ui3saGnbApn/AweVAb/dUOA+m3Azpo79YWYCnvZMDL71IaM1bmGsakLy9ZcaAnGUmrsBEXFQTkrsFkCBnCgy/EGd5B/W3/5Osu2/CeNYX92h808KQAqQIIXZKkmQGdgBnA5cCXUKIuyRJuhWIEULcIknSYOAlYCyQCnwAFAghQpIkbQOuB7YQFoYHhBCfulnPqGyr2HkpuHSJmM7+G82pM1lzuI01h9rYWNGBL6hg0qqYkp/AjOJEphcmkmAe6Cds6bGzZvEpjKwMP0Bm5eBkon/+D1yOIIUP/pGMhnJUxhCZUztpssRzReBmqkQqt8wpYlxuLINTLN9cZIyzDf41LTxh9eMPwiFvmx9iv5LNwUl/Z+Fp0wGoabPz0YJLGN5eQe6dV2Pc/WuYdy9K6Y/58NTRJDd6qUlUk9sWjq7oiFfhnTIO18j5nHVgCSur4sjariNwDpwt7uWqqbnMHpzE7986wOLlNzKi3sXec10s0tpw6xL4Z+gsHnNO7hOIYwzPiGbOkGTOM+7CuvSX2I5AXVUMJrcHWa1gzvBgzfFgTPCzR+SywpbD0L2VFDT7OZqk5Z/DzmaOtZZr1Uvx3tKM0dA/oWxzB3hkXQX/Xr+fXPsuiu3lDO5qJL/FTkyvVeFTQ0O6noYoH5ntgqzW8NOoGixRLM+ezgcZ4/Bo9GjVMv5gvyWTaNZRlBIWicIkM4XJZgYlRkUinr5uGsoQ79yKc/teumuTcNUFQaPBMncOsYsXYxg+HKEo2P7zH9ruvpuQw05cSYj4v76EnF36qWsITFoValX4d/UFQ33uIrNOzYS8/uihrDjjFx/YCQFH3w9HGNVuDB+TZBhyTjgyMGnI5y8qGMSxew9Vr78Gm9eibbUhASptiGCyhkB2LElFVpKoQrI3hjPFF4SDNEoWQnQGAN6PVlL945tIu/lCLFfc9sWuh/+yK0mSpGXAQ72vU4QQzb3isVYIUdhrLSCE+Etv+veA3xO2Kj4UQhT1Hr+wN/9PPu18pYVpouxCJ82qFFJCzVB0Bsz9K1jT8PhDbK7qYPWhNtYcbutrQMMzoplZlMiMokSGpFqQJIlD1btovmgxKd3h76M+XkPG3+6nsGQyjTfdhHPNh0hqQdrELpQUFdcErmejUtJXj6JkMyVpVkrSrZSkWSn+OsQiFIDnzoLGnXD+k7Dhfmgs49/KbFZnXscTl0/uc4u03XcfnY8/wT9GnM9lf76ecesvCe9zdN0u1j/1RxIeWEHjLMiydLK/IxZ1o5GcKg8qAfYoQUgNMT0Srll2roi6jx7Cz3Aebf+QO9asoCkWakvgzLhWmo3FpLkPsb48kV1Zo3hJu5DEGAtDUi10dvdwbtvDXKRewxHVIN4rvIM3djaywvZrbDVGOurNaIIhgioZde9jQO1GqBmtZW/CNFYqE5itKuMuzRP8Iu0FrMl55CaYyI03kZsQRZJFR7PNy/3vH+GNnQ2YdWpmFiYQ662mbccHZLQcoai9g5zjrIqPsyJ3JKuK5lJQOoRxObF4AiEOtzgob3FwtM3ZJxgqWSIn3kRhspmiJHOfcKRFR9xRX5ieOkLL/4+edz6gu9JCwCGhTkwk+oJFxCxciDr+xNW+we5uWv/4O+wrV6OOUlg/ezGPGCbQ2buGIMGsI86kxR9S8AUUulx+PIEQKlliREY0kwfFM7UgnuHp0ScGXnxegn7Y/0Z4QNZ2MHxMVoc76ck3Qdzn2z4+0NKCfd16mlcsR9qzB9kXBElgiPNjT47ClplCap6ZbH85qmMT14bYcEj48AsgddQJrqlA1SEq5p1L8qUzibn1oU+vQHcttB+GvJl9UVH/NWGQJCkbWA8MBeqEENHHfdYthIiRJOkhYIsQ4oXe408CKwkLw11CiFm9x6cAtwghzvi0c5aWFIiy81pZ4r+FB6ersWy9P/zDzfxdeCWzHO6chRAcanaw5nArqw+3sbu+ByEg2aJnelEiM4sS6ap5kfxbHkMTBLdOQhsUdFx1JjN+dgctt/8e25tvgiRIGmEnutDLU+afcEf75JPWSyVLFCSZKUmzUJIezbA0K4XJ5i8mFitvha3/hMFnQ9WHCKFwp/oa3vCW8u71U0i0hBfQ2FeupPHGmzAvWMgi0zTMejVvn2dE/eRMmHIz1SKZxt/ej9cgmDGtGVkCJXU0Vclj2XWgHjbtYOjR/ka3Iy+WdxOmsyNuOPdu/xO5bQH2Z0kMrRX41VCdoKewOSyyDWN9lBao+KtnPgeVLB7QP0aGaOSJ0BncE1hAADVnyJt5SPsgAA94ziDroyoKOnr6zueNMWLMcTMoqxlJJyMTDhX8fdTtvGIbPCB00KRVkZNgIjc+iqCi8M6+FgCijRp+M6+YnHgTK/Y28+6uo8S3lzHMcZiSnmYyG7uIPYmr+d1BBZTP/hEXnDaVqfkJKEJQ0+nqE4pDzQ7KW+3Ud3kG1KEg+Zg7yhIWjmTzlwp++N7jteN95Xa6X12KrUaHCEkYRo0g9keXYJ41C0kzcM4uEDp+DUEX22u6GNO4hVt2v4TikGjIL+SNmT+lS2+lvtvdN9jLjjP2TRhPyIvDov+Kc4FeezjQY/Mj4GgKH1PrYdQlMPG6vlH7J6H4/Xh27MCxfgOd77+H3BAuQ20IYUr20ZwcR31qJtnJRoqDB9HZqsMZVdrwAtLhF4YnrtWf3KYUj5vykaNJmD+c+HteDi8Y7e3vCPrDe54deS9s6XSUg6SC63ZCTDbwXxIGSZKigHXAn4UQb0qS1PMJwvAwsPljwvAOUAf85WPC8CshxPyTnOsq4CqAjIy00Q+PNFKbmMkT6b9k80/zMKz6JVSugbTRMP8fkFzy8SLocPpYW97OmsOtrD/SgdMXRKeWmBt4kJ8sq2FTeg4GuY2RdS6qRiYx8R/PEXj+NToffwKA6DwXyaNtuEdeyqP6K3lhexPd7gAWvZrS7Fhy400caXOyr6GHbncAALUsUdhrWQxNszIsPSwWJ53/2PMK/Oeq/v9TRvBQ3G+5tyzAk0tK+56A5i0vp+aCC9EXF5P1zNO8W97Jz/69kz+cOYQlTX+CwytYqj4N09F1pH9koOHHpezq0bPYuo8096G+4islNf6XEgGwG8DysccyvzBNzcXrTlzksz/TyKDxMFKu6Du2xH8L65Thff/fqn6Ry1TvsrXbQrDMQEqXYFemiVdzziCvw8XM+jJy7C0IlQoGxZORcIioFC+SCrozTqUhbS77TROoc8k093hosnlp7PbQZPNwsuabHmPg0onZtNq97G+0s7ehB5cvQIG6mSlyGSn7NzLp0IkZd+dYcQwfyshT5zJ84ly0hv4QQKcvyJFWB4ebHZS32MPC0eqgp/e3BUiy6CjqnbMoTO53R/0Q93kSXg+OJ39P92tLcbfISBoZ67zTiLn0SvTF/fMFn7aGIC/BxIiMGFQyRDnquXjlzfj2g1fW8tKw+bjmns2kgiSm5Md/fY+KdbSEJ8S3PwU+W/iYNgrG/Di8UWVU4idm9dfW4tywEeeGDTg3b0by+0EWmBL8GJJ9VCSlc9iSTU6sllIOEmXvv2dIHxu2DIac89kLawNe6DgCbYcoX3wb0blukmZEQ08dFPd2l5Vrwe8AwB07GP3wc5GHnD1gIv8bFwZJkjTA28B7Qoj7e4+V819wJY0YOVw8GfJj9MPBZDMvjb6ccxfMZZF+M6pVvw2Hj038OUy79RO3cfAHFbZVd7H6cCvvl1dw+p7bOHu7n7+NPBer+jCX7DiI3azCdOf/kVHnpe3uuwEwJvpIn9yFqnAq3nOeZnm5m6c+quZwi4MYo4YLx2Zy8fgsFCHY12BjX2P/61iHolEdE4toSo6JhahB88TU/gqO+ynrs6/lkmf3cMmELP541lAAQj09VJ+/AOH3k/PG66gTEhBC8KMnt7G3oYd1V+YS89RECPlxhSQOvJ1CY2Y094y/gyabl2fOTWX0+ssxO6sICVi5O4mEehWJZ7dxb/cEfr6y8hO/9w+Lo5h+KDwEr8yQSCy2URrjRJagTkngwdA5vBmaQggVD4f+gHaHk/QmQbsV/jliFpujZ4d9tOHGQK6tiZn1O5jVUIbF50alDWHJ8hDMUpMW14UHHR8oo3grNIF1ynACkuZY1i+H5CcpZiuL9ixn7o4TC/GroTndRGhwLtbRY8mffDpJWQMnQIUQtNp9HG6xU95rYRxucVDR5sQf6ndH5R5zRx1nYaTHGL6Xay2CnZ30/PMuuv+zgqBLoLGqiVl0PtGXX48qOvoT1xBIEhQnWxibE4vVoMEXVDjYbGdbdSfegIJalpiZHuKOxt/g3uTB3axBP3QoyX/4PYYhn9+//4m0Hwm7i/a+AqHe7S700TD+ZzD2qpN21orLhWvbNly9YhCorwdAjhJYU1zokgPsic9nvyqHVJPENM1B4pxH+guIzoRhF4QF4WQuqVAAuqrCLqy2Q71/D0NXJYhw+6p4KxFDvJ+0CWEPSF+TShmBt2A+tx3N49UqLa9cNZ5xuXEDiv+mJ58l4FnCE803HHf8HqDzuMnnWCHEryRJGgK8SP/k82ogv3fyeTtwLbCVsBXxoBDinU87f41fuWAAACAASURBVGlpqbikyMOpZQpBGWQFtuZl8O+C8zCnpnBP9BvkNy7Fb87APfseLEPmfKp/WAjBy3vfQb7llxTXwc1TrkXStnLL9tdJtIXYNW8UM8achf1Pf4RQCK05SMbUTrTZOXDhK4i4PLZWd/H0R9W8f7AVSZKYMzSZyyZmM7p3f59jkRT7Gm3sbbCxv9HG3oYe7N4gVpzs0fdbChtG/R2l6AyWPLUNgGum51GcYiE3xoDh9pvxbd9O1gvPYxjeP0KvaHMw5+8bOH90Onc5/w+q1wHwu6NTuWhHBVeftoRqQ9iK+oP6aZao3+fddalk9a4lqx3nRVEkcrbrUCR44EyZG5YNdNi3JxpJaAtHf/SYINoFVYkathTlcm5iFSPVtRwKJLG6KpEpezvR9nqDvPNVnKO6G51axtfryzdoVH2jxJVRfyatrhJ7jRFHoxFCCqHkBHQFRlLjD2PSduNTRXE09hT2xszisGEEroCMNxDCEwjh8AbYXtP9aU3m4784KtNRigMfcMbBaqbtH3g/BGX65iraLTKVKdHUpWTTmjoCT+o4DAYTeo0Kw7GXVoValmmxe6nrclHb6aah23OS84bdHyMzYxieHp6TKkq2YDX+j+/R9Ql49u6l64lHcKxejwgJTOkSMRdfQuCc6yhrsPftMbS/MbyGQC1LlKRbGZsTtq69AYU99T1srOigzeEDwhbDseihcblxROnU4GhFPDsf++5mWvenELK7iLl4MQnXXY8q6kvsOVS3NTyhXL6i/5gpMTyYLL0cdOa+w0IIfEeO4tq4AeeGjbjLyiAYRKhltIkBYlMcaJNDbDYOZY+Si04KMEd/gPzg0b4yAmoTjalzqEo9g0brSPwh8AeCGF0NWBxHiXVVEOuqIt5TRYKvFrU40UpXguB3qPHZNDRtiQFAawkQcGtJ//k8ohb9nIpAHFc9t4OqjvBz1h9ZPIp5JSkDyvmmhWEysAHYRzhcFeA3hDv3V4FMwm6iBUKIrt48vwUuB4LADccijyRJKqU/XHUlcO1nhauWlpaKS8YFOXW1D2EKsaFIZuIuCaEWxA1x4cs1kK7uQCv1+6l/q/0VHdZhGGJTSYo2kmLRkxJtYOeyB6l06ig+ZRHtnieZe+dbGISFKyfdSEAd4rrDjzDtaBf70w1UFp/BGWuXoQr4kbUK6ZO6MGUZYMGzkBeOFKrvcvP8llpe3laH3RukJM3KpROzT7qNtBCChtZOMh7tHznMC97DwWAqcKKQXX7gbRYcXcszExfTOPHUARO0OfEmntlUw+sf7aPM/Es0/rBJPNT5AM+/dxc1I9Iov+ghHl1XyYuaO5ioOshLe7IZcejEjcEAFAnk3l/h5Rk6YkIeMqpkBocHSHQbNegDCobezr3NKtNjUpHSHcDsgcqCEBktarR2QfRsNxOMj7D0mkm8VlbPW3ua2PbbWWwsbyFt5WUUu7b2ndcb0LIt+vek7dqEf+dOkCSMJYOwFqgwa8tQKXYwxsPgs2DoedgSSokyaFHJEk5fkMfXV/H4hir8QYULx2ZyzfRBaNUy5S0ODjTZ2HC0g3VH2vvOJ2nbSdCvZU71Tk7bFSDWCR1GI4fiUmmIU5HpaKWozU6cI9zM/SqoSdJzNCmJI3F5HDKNoEFO/fJWzEmINWkZkmrBatD0CY9BowqLkbZfkPTa48VJ7her49Lr1PLXaqUofj+OlSvpeu5ZvAcOIasVLIOCdJ12Pq8lLWJzrZPy1rA7Q6eWGZkZzdicOIalWQkqCjtqu9lwtIPDLY6+MvMTo5g9JInF47JIjTYghCCoCAIhBX8w/Ao62oh7cxFyWxXVHXMJrt2GiI3HceW1OMdMwa+IcNrePMfnDYQUfMEgOZ3rmdDyb7Jc+/rO3alK5B3LAt7Xn4Zb0eAPKaidDnLrDlJYf4AhDQeJ8YTvJY9VS2yKk4QUO1IcrJVGsEPJx4Cf6ardjJb7xSAoZNYrw1gamsw+kUOW1Eq+1ECh3ECBVM8gqQmj5OtL3yDiiceGNhjE51Djs6nx28NC4LOrCThVfLxP0GamYzplOgnXXMOHjV5ueGU3OrXMbfMHc/3Lu7lvRipzogMYx4zpawPf6wVupaWl4rKrRzLjr+EQMo01wM4SQahRx4hqgcuiQjNcTXZqK1ZpYHxzQKhoIp56JZ5hcjWW3s8v99/MAZFKgvFp7nilk8PR2fxm4s9QJInZHW/ws21b8asl3sstYe6RI0QFvCAJkkttWPK8PGP9GWstZ6GSJdSyTCCkDOiAjjF/eCopVj1qWSLO38SPd54DgF9l5LUp72J6cBH6LpnDMYlUWVKpisqlylDMmOZqbi37N2/nTODh4eed9HuRUHhMcz+nyHvQ9Irij/y3UnJkNXMPNvKbhTezz5vMdt3PSJBsPOaYwJQVtZ/5fVcWhDhleDvtepnKFYmkdUHZIIlh1aLPKjieoxkyk8Y00/F2AopfJn1KJ6Vx/8KHlrRoA409Hsp+XkD8qmuhbvMJ+YNC5oDIoU0eSkyPEcv+SkINDUh6PeaxxVhzPBj8m1AJL80ilneU8Ww1TscZV0JGrAmdRubNnY04ezdBu25mPj+ZmotJN3A3mIZuNy9sqePRdZUge9BbtjG5Yy2n73ZQ1AAetYrVGaN4K2cabn2AEZ69lHpqyWhoJqPZg6b32rusKroHJSINKcYyYjKJJTMIqQx4AqGwVeMPWzbH/nf7Q9R0uNhd3zOgg/wmkCT6heRjwqJVy8iyhEoClSyjkkEtn3hMJctEOTop3Po+eVs/QO+yozaHiBnk4p3M8fxNOp9uLF+5rhqVhCRJBELKSYXWipPntX+hSKrjjtbFjN15kDx7E1uTinlk2Dm0mU50/WgJcLZqIz9VryBXauo7Xi+l8rLuPNbrZ6BSacjurKWo7gCDavaT0lyJLAQ+rQ5voobMlDYSUuz4DFpWK6PYrhRiwMcs1U7GSOXI0sDK1isJHBaZxEgOCqR6LFK/9dgqoqkgk1aRQrzDQVHnQYRNwWcPi0HQ/ck7FkkaFbr8QXgPlgNQfPgQQggeWlPB/R8cYUyszF/8e/E//8yAfHmr3kObmRku4/suDDc+fyPrnrmTG49zdwQTA6zL0DG4SiGlG7YmFfFsyVwKLE38S/u3vnTdIooY6eQrI/do9DzRFcfVKwTt+dFsHzaYBpGA3ePjvB2ryWkLsDc1mqwOP1Z/WFRiC50kDrfznHIqT5p+QpRRT1BRCIYE/pByUrfCPHkLj2gfAKBdWBjje5QrVCuYsmYNZpeEIoHJd0I2Xh+ew1FrFhWmQpq1OQipvyFdrVrGrzSvcHtgCder3yBWcnJIyeQy5094/N2HWTMkAW9BMbdoXu7L8862ZHKqBob1eTWwapTEyFqFjJbwSMOvgsZ0hZxaGb9WkLigjXvFYM5f1km069N/r+TSHmIGuXk9NJU3Q5OZLu/mSnW/t7Ax/2KSapahDoQ7yYqU0wl21pDrO4xWChFUJCq6s/G3xaM+0onk8dKpN9OYncrIYS7yVDtRiSAtcjLvMJGXPeM4Ik4eQXLuqDRy402kxxhJjzGQHmMk0ayjst3J8j1NLNvTQJO/jMLgGk4/UM+kA2Hx252YxdKcGWxPLkaRZDSKl0GevQy2H2RodyODWmzE2/utitZ0E/7B2VhGjiFj/BziMgcPGMmGR7HH3odHu25/eLJ7T4ONfQ02Wuwn7vd/Moy9W4C4/SffBO5LIwRDO6uYX/URk5r3IwsFdapCan43mxMGc1foIipF2td2urRoA802DyVpVpKteqwGDRa9hgSzjhiTFq1Kxqg4GbvpKixd+zky8X58e51onn8SCYHq0isxLF6MTqdDF3Rg2PssmrLHkJyt/SdJHAJTbiKQMJmOdRuxb9hIaNsWJLsNIUk4kxPwxfgoSqknPs6JXTLygTKazcpgTHg5VS5jsurAZ16LR22hOyoftzabYCAejc2PuqUVqivwt9gIevq9B5JKoDEFCfllQt7PF7QgqQRp6zbx2m/vZ8K6Nz4xXdKvbyV2yZL+fN9rYRg+RDy47AGuWncDzz3uR98xsGPrSFKoi1JRXAfqkMTS3Cm8XjiNv+z4M4ZgCGNAYLVJKLIgkOsnOstNWpwHjQy7lVxetupI3Gln7g5B6vhurNnhjt0XglVHEhm0R41bB8bjOu6oVC+pE7rZKhfz08AN2IkiPzGKqQUJpFj1pEYb8AVDrNlXz8SK+7hQfh8Ary6ewLV7kFAwPDKK997TEkTFGZPrOJpxHhXubHIfeQkAp17C6BN9Lh6vBmrjdNTEROOwGjndupsq42BuUX7OZtWPSdT2+yrf2pVEepWK7DNbiekd6jaJWO7rnsIVq7YP+P6W3KjisvoSLuZdGl5PpiZL4YgliRGNbSR2neiW2DdUoWeUhwannpgaNXN2nqR9TbdRnPQZCnIcDSIc454udQw4roTA2aTHVmPA2aQHIeGO1mHIDlCQ3YRa3z9QWB8q4fXQNA6JTDxo8QktHrR40RL8HHtJyrom4g1rmV21h9N2hYh3QEuUmbeyprIqaxzOjwU2xAfqGezYQ3FPJYXt7eS1efssqg6zTHmihUNx6RyyFnHUMIKA/L/5ACJd0M/0hp3Mr/qIXHszbo0OTa5CUX4DFcZ07gguZpMylPgoLR3Ok7sij5EVZ8Si14QtJn+Ixp6Tz718Glq1zPpfTu9/YJPPAf9eAPVb4Zx/EYifTMuf/4xz9Rqk7CyiTk0l2bMSdbDfW1CtKWKdYxrOGj+Dag+Q1d0AQLcuipakOGJTnIxOOYpZ76VLRPFeaAy7xCBGShVcqP7wU+snUkYSNBXg98fjc2jxtTjwV1Tgq6kj5OgXd1mtoLUE0VmD6CwBZLUg4FLhs2twtegQyld3+dVPn89HY+fx4qF2Uvy1XLf4XMbkJtHm8DE8PRqdRvU9FoY0rXjn5jxmxqq5a4ed3FUnjzxqiQUUSO4BlT70udXYHqPwfrGK8zaFv6enpp9Ga0wiaVIH6VI7FnslhRu6MX+sjeusATKmdqExhWgWsWwIldAgEmgQ8TSKBNRSkN+pX6BIDjvqe4SJOb67aCGOqw2r+JV4hue355PU7WPW785A2vwIlbtH461s56bJV3MkJpNYtZ94+z5ynRXk2pvI7ukiu8OD+SSDy8riINZkL2lmH6sCw5m2soENoy1clX8YAJsw8o+O6SxYvasvz5IbVZi8eXzYvZaQgCOvpFI92s+8/A4EsPf1VLQfmxvzaqA5XUGb5iUqPsDGpmgmHBbE2k+sUyA5QMGIbnTWIJIEISHxYmgmP1J/0Jdmi1JMvZKAQfKjx4cePwbJTzRO8uT+nVeDXhl7nQFbjQFvlxYkQVSKD2u2m6g0b19498kICFVYLNDiEWGx8KDDixavOPZeg0fo6FLJ7DLb0ba1M3OXn8H14FdLlGdksiN3MI3WxL4yjs8fUBTSPeUU2w5T1NVAYZuNxF6rIqCCqgQd5fHxHIrJ44B5OO3ab2Zn0Y8jSeHnD8cYtZj1ahp7PLTafSS7OjmjehOza7dhDniotySgK1CYkr0frzGOmmE3sdY4i83VPWyu7CR43K50qVY9pxSFdxkYmmZBo5LRyDJqlYRKlthd38P9q46wraaLtGgD18/MZ96wFN7a08Sv3wz7/ItcZZzfsYGlcePZHzVhQJ3vXTAcXzBEl9NPp8uPw2Hj8rpbKfbt5Q7V1Wz2ZnFD88vk7m4k6FYRneciZpCLA+1ZNLUmkN7aij7oIySr6MgchC/NhDGqnlLrQQxyOFrQLgy0iljy5caTfm9CQNAt45Ny8cVMw98NvrpmfBVHUZz9gx5Zo6CzBtBZgmitQXSWsBCo9QruDi3OZj3dR02I0FcXgs0phWzKykAnd5PhaCXd3kNaj5tEm4IMvDCqkLWxp5OgVHPF5Zcxf0zB91gYhg4S2xd2Myk9mXlOF7Ofi0PyhYgK9A/hJVmAWiD8Mm4tGE8ysPFqBXr/5/9xqlNl2q16mkyxdMrRLNqzn6iPuXtUuhAZU7owxIcbmyKkE3yQx2hVJfOidxLtRHOn5knqlQRe25/B5KoW3jx9HjceeJWuw1GkjO1mXurdNBFHCl3MsDQyO7qRwVRi7diNOuSm1a+h1qHHtMbcF1Fz/ASyVwP63vD72nFeEmN8ZASDdHwwMJxt4a/V/K21nVnusOrtfDOVpqIAIzNtHN4dS2pD2Dr7y9RpbLVOZ4RjE7PbN1NU7zipELgSQqhs8km/5+gCJ6Z0P+Z4b18UK8BF/t+wSRmKrPgpdu+k2lCEWxV9Qn4dfkbKFUyV93KKYzfxdd3YaowEPSpkjYIpK0Rslg1DvH/AAlKHOo4V3hJcGEgxKpSmGYjRhJBDXuSgBxFwE/C6CfndEPAiBT2oQx4gyLsmIx/4zeTvVTPlgEAbBFWSn+R8J+bUgddxDJ/QhEUGHY0+LQ02Db4uMLcLUttEn9B2RUFTkobOOBPO6DjcplR8sqlXaI4TL6ElIOsQagNowi9ZY0DWGggJwZFW54CtPz4NSSiMbD/K/KqPGNtyCCFJbE0pRp8f5LykjQhJ4rHQ6fwrOB8334CFIwTDHZu48OgqhteHO9eQBM+VFvNa6pIBrtKPo8fHHt1V6KTeey0IzmY9jR8NnGvwxiXiGjIMJSHIIGk1qerWkxV3fJXCI3mbGr9dg9euwRNKJ9juRnj6R4Mqo4zW7Edn9qGzBHotgSAqvdLX3gJuGVu1kY4D5q/FIvgqdN1+FZMvuul7LAylpaLs33/i4rXXoxWC+zY6aSmL5sHRs7n0wPuYezeksplNJCTb8DTIqDxffl/0L4OrMEja4G6elc5hqmo/E1UHOerSEa8NEKMJ37TNIpYUqWtAvncq4sgp05E4rpu2rTHE5IcX1X2cgFBRLjIYKtcA8FDwLFqqulm8s4LyVC1zJ9VwdeA66txaLvEsxWpzkLNf9YlbRhzjxitVvOxoILp3o7CypamYTmKN/P2shYzRlHOFOrytlSsksXdFKtHuT29bWwslxpUPTCM0CtEZHtpNMi0aFUfM+Xg7A0yuaibaLXimtJhX0n98QlmSNHBNgw4/IzjK3M6tjKirQN/oQwQlNKYg5twAMZl2tOawb0dBZrtUwuv+cbwXKsVOFCMzo4nSqbF7gzi8ARy9f72B8Jcmo6DHjw4fWkM1BuNWJldWMnunQoIdekx6DubkUZWThkorwpYOfvSSv/e9D5McIEGvEKsNYdUE0Qo/NZ0uWlv8BFoFMa0Q1/tzB2VoTRR4E4NY4vzkWd2k6AJ8cuS1FBYKtR40RtDoCakNOEMaOrwyVTalz0LyB1RYa10kV3Zgcnjx6jRU52WRX9hGiS5sUTaIeP4UuJhqkYIHLalxMZTkpDAyLxmL0UiHy0+r3Uer3Utb799Wh5dWu++zhUkojOtZywVH1lDU7KXbKLFsSCGrE07jZ+XPMLHSxvZsM38deg1O9cCtM2QUZstlXKN5iwJ7Lc4WHa5mHe62sDsmIKtwafVEe8NCY0zykTy6B50l9PEq4HeGXTl+mzo8AWwPRwOJUH9/4dFrwSJhtbqItTr7LAG17sRrDPkluo+aaN9vDu+Q+i2iANXJ0JytxTx9MWdeeAMmne57LAxFmaLs1fu4rfoN1nXu5cOqRireSsIbp+OeUfO5Zs1SrL0dVAgJ7VgFTYcHb9XJXU7Vg4Oo7DLJLfIJbpKPUxWdQm5P86cnOg6fBrqsghAq0jvCDck528Y67UTG6BuZpj44IP0H9TGkfRTeRM6Q4CNreudJR6HHYxdGHq4q4ezt9TRHq1g+ZSZ/Nz1zQrraUAJHNmhIb/n08vxqaI8TWO0SUR9zlymEN6jLP7ulz5/vC8Gabclk134+8W3ODLE7WcWwCkjr+uz0VQtLkCdewmvVWtbUBj47Qy+WoJMFzR8yrX438W3hTcsM8eFdXy2ZHlTa/vvg/dAo3gpN5ANlFAUZyaTFGLDo1Zj1Gsw6NeZj74/7a9FraHY18/iOZ2Hb25y2w8vQOoFPpWJN+iiW506hxprKhNw4YkwaGro9NHR7Tnh2sE4tkxZjIKN3QjxZtGKp24jh6B7MlXWkNLjR9bbL7iiJmiQDjXHRdFsTUKISMKklkg0KyUaBRR0k5HOjBDzhhzv53ejwY5T8RGtDRDkDBMoDOI+CCEroY/3EFrgwZ3g+1fX2cYJC7rVgtHiFrv/9AFec9jgXW9g151Y0aDoaGHa4nsy2IJ1miQ+HZrIvcTJ5cVHcUVyL1LidDzoGkfLiVuxmFea7f8+wU87HZrdzaOkDJG94AV2jG2eLri+KR2sJEJXiw5Tsw5jgQ1aHO/6eSiOtuy2IkIxilXGkRmF12tHaAwQc6gGjeI2xt8OPUSPHGTDrW9Gbfai0AqchjYDaRIyjf7GaUMBnU+No1NNx4NsXAoA2K+zLltifDQkJXhYEHAzz+cn2vsiVU3L4vzOGfH+FYXSaVuy40sCzFjP3xsWwobaBwB4THQfM5M5r41ndDEa+e4AoT/91dkaZiXM6EAicBumE+QHTGBtJ2S4OO400dRqgVfOJHd3+NDPNhnhEyESUT1DcXUuM55P3f69PV8hoOLGsoAzdVoHLIghZFLRRQaQWDenV4Ts0/+wWbDoTcVJ/SGOlkjLAzw6wqjaWjM16nHqImd3FIOPJo1mUgMThN5ORjmvALRkhkutVdMcpxHSG61iTpXxmJ989ykNiuptUnZ+PNieRfpLr+zppTVYQBV5K4h3Uq3OoUFKpFilUi2SqRQo1Igkv4R10M2INTMqLJxASLN3dSEgRxHt6mFlfxrz6LSQ6ehAymNJ8xGY7iUrxDRDfzaHBPBM6jZEzF5CdFEdGrIGM/2fvzOPjqurG/Zx7Z5/MTCb7vjXdG7rQ0loolIIgmyAgAiqgCAqI+irwKj/X90UQ8X1VeAEFQUFQBIqy2AJSQJaW0pZSuu9J02ZPJjOT2e/c8/tjkmnSbN3Tpvdp5zOZc885c24yc77nfLeT5RgyF09Ei/D0+r+z5M3Hmbu8gXnrJFYNPskp56XKM2idOptvfnoC500pIK7p7OmMsNsXpr4j9dwjNHb7wul0Kj04VY3pbGKifwPlTTsp291Bbmdq9aspUJtnZWNONhu9VWzImEazpYzeN6RInVlNG/l8/TImN2wioZj4d/FUXq46FbIEPzM9wafUDUSlmd9ol/FvfSq2fXY6PXYeG91lIlXmNiUocylkmjWCXUESkVCvejFsIoGdGFY9zsdNDhLrHeR2CFq8EK2JcEaBD9sgH511AQf+9zLJCkDCpuPOSBBpt4AUKVVhfgxnYYyMghhmZ7JPEFjPyt8f9KD4++uRM4qiWD2JvcZgl4Zi7p4vrG5k8Qxk/hRkRy3q5ldS6qUulUi7hUi7Gd/WjP352B42QlYTEacNlwxj9idRugValw3Wlws+qUg9Iu4kl3eFuCrQhdQ8FIoOfmD6Hi9EZ/HF2eX85LOjWDC4i8fIp782kUzHCm4uyOOJhmZO8ifY9lI+nsowhbP8bAjaCb/h7efyacuKo04KsyThYtInap/8QMKZpPL0dqye1PJM02FryM6KDhezlg2s60yosL3QQqvDTVzzcNaOwVNK9FBflUQtihENmSBowhYQeDsF9n0+vx0uaPOYqM/IZIx7DxnOBDmOBN9Tb+d+2x+oVhp4clc1s5aG0RRInONnxiC+o/Euld3vZRHr3Du5NXqhUo0R85tZdF6S817aey1shWSWhqsxdd91s6MozWZKaw8tB1DGBUGaV9hxthz8CbNhu6T1pDjV+V1U2WNp1UqrkstmLY9avYBmcwmu4glUTZjKjJOmYbfZ+PeWFl5d28iOpR/xqe3LOXP3ajzxEEm7BWu1hZLCndi8iT72iIi08MPEV3lRn4vTbk8Jie6VfWmWg1Kvg9KslNurzawipWRZ4zL+/P4f8L61nHNX6uQFoMXh4pWKebxWPpurzqnha6dV9UsF30NXTGOPr7fACFPbHmbdHn86gZw30cikrtVM7NzOhNYWqlsie3cVTsHmfDe7M3IpaU8yrq2VrFgXbTYP/6z8FIsrZmOy6vyH6XmuUt8khJ3fap9je8VVnFSRz7j8DLIcFjIdFjwOM6oQ6FLiC8fZ1BhkY2OADY0BNjYG+gmxfTEnY5zb8hJXbFpFrl+jNlflxUnTiGdV8WXT20zQNrCpw0GpO0q1M0Zb2XlEYxbMaz9B2+4jUG9PGcu6cYwNkV0YRbHoxINDBIEJicWV0vn3TP5aWKFjSwZaRMVdHiZ/eqCPF1tvtKhCpN1MpN1CtMNMqOnoeZDtyrfiq7Azxh6m0tdGa7MNvdWMkhRoCmwphkn1sK5ccO/lCpoKpUmNi/0aq3yXUzb3Szy1ZBP3B+9nnK+eD86+l9trnXzrrLF875zxo1cw1EybISfd9CCx3a+zvfp5ftzWzueDIRo/9OCvc1B9UTMmm866gIPYG5kDGp6Hwju2i9yaYB9Vw/1eDy8obh5+8PD4ipscGs6CGPbsBPbsOK9XfomuRVuYXlcLQGumJJCvowds5Pq1frr7gAPcvWL31pXZ6Jzo4dMZOygz+QntsaHFFJx5MRIRlR3v5qGQ5JefU7lkqc6E3dBWmCSnceCJXswLIJZloGsKTV6FM89Nuff9fl0Rp687+PuOWMAeB18G+MYkaLeVYauHmob9V8/ty7aTkugFdqQrjzK1gyrRSKbYKyATUqVe5rJbKULLrIKcapb6PLxab6e4uYWz6j9iTtN6zHqSdk8Wpil5TMt+B5ujv17xKe0sHtA+RzPDJD0jFVXtylrGjJYPOH9Vgpq6lJrp7eLpvFQ1jx2Zhy8GQNXjVEXXMSmwgfO2bKa8o79b6OJJhWzKKqfSE+Fm59s4RYw/Jz/N/drnDkuAWm+sWoQLm/7OpRs/Jiuks6XAzIsTT6Ys08SM4FKUlhgZe0zkt6cm8o6iJGMzqqcLzwAAIABJREFUw4SarEQ7zEDKc8JsT2JyJIm0DixEpQKBDCdbXCUE3U4qPM2c7V2d2n0P8NHWNWjb4KJ9kwvNpLJmSjUzy7dQ2tlKtMNCpMNMuM1CMnJ0kiDWjk1izo9RlhmljASRZivBJivBFitKrPv89NyUeshfrKF6NWSHiStfTI1PUyUyR+PZky7gLK+b8SEfkQ1bidXWI7rnectXb+CsjvH88IKJ3HD6mNErGGbOnClXrFjBL1/dSMviz5MdlEztSpDZoJDVrpAzJUDulJRqZ43fQXJJZr/V+P6gTghTUdOJRYUEcE1RPrYGlTv+lnKLzBwbonG9i2Tb4U+93FGR4NQ5rXw29t98IquwJ4Pcpf2a/FgjXSEzBR9ZsQ6yWOuZfAfikat0rvyH0i+T6rCcGsDeaCIygJ2mLVPiL9fIyIyz1GXjc68M/6Wqmx0l2xOjKiNKdrezfzIu2LPLSdcqVx9114GwrUxlRWU177jPJsuUoFI0UaE0USkaqRJNVIimPqkIItJCrSygNpZHtN6Mty5AfrsPHViTW82OsmLOLVvJLOvWfu+1Xi/n99qFfKBPogXv4INSopgzVzAm+Q7nf9LJvLUSmwZrs8t5qep0lhVOIXkgCv4BUPUkcxvXctGO96lp30lUNbM6r4pteU7sdDC+rZmxLZG0Z5rfAVsLnKzPKmWDZwKbHdOIqYeuHnHGg1zSsJDPblqPOypZX2KhsdjOGNmC2mCmsFFJR4wfCELV+xiEdxU7aL7qdsYWxBi39j6yY/VDtn85OYdHzV8ibsmlpHY5N+/+O/ZtA0SQHiESKjTlSRL5GpnZMcZ5wmSRJNRiJdRkJdhsJRlM7aJ9GfBJhWBjOWS74sxpSZDRpKK1WMhuEwyntFVMOs6CGBmFMb6e8x/MPu9i7n9zG/deVsOVp5SPbsGwcuVK1vzlxzQ/9BylvWKgrHkxNL+J6ouaUUwpX/3tAYF9sWfAviJjYpgCKubWoVUb2ydqdGXr/KPUxvwdSc5YLsitCZAzuYtkXOCvs+Pf6Uj50x9G3GVhklkqsWwLY7IaUVR4p9lD9ttOFAnvjPXym4m3cm7iLZKRKOZIlAXh1YxZe+Cqmvcmw2nDB3X2Hd8lrRTbEiSBX2Z52dLs5I6FA2/Pg5k6rs7+H+tOJ3Tm6OjeJE5PnEJXjBxLgpYX8g/4HvZle0EGT4w/j5WZs5BCQaCTj49KpYlKkRIYqUcTZaIFs0gSD6r4ax34ap0kQwq6KmgozmFDeQUz87dy6j4OAz38VTuTD/SJfKBPGmRHoWPK2Eim4x3O3r6Tz6yU5PslbfYMXqmYx6sVs/Fb+0/OxZl25lVn47QIXBaBwwxaIsG63T52bKnj1C0fclbtKrzRLlodHj6Zcgq2T5/B9IlFZNkVnM0ryX3vJ2hagm0hOzuVacR2d5FV20meb6+tYk+uifq8DJoys/C7i9AsXkxKygtI3efRtyyJLR6ioHYz1RujaQeOkDW1QFEOYrqxuLr1/66UKsjUfYZ4MK7iW+ZBINCFJHuWH7uqpwy/sttLTQpk98/xoIlIm+Wwfy8PGLOeUokdhtiFoWjKNLMr30q20gm6oF3Jx2MW+LpimC69mmtu+M4oFwwrVsDPMlnyehEBO0zYJyYl5+ROcsemdC3/k7ic8154f9BV6I5JbmqmtBNP+Hm5OZvPLN3/P14wSydcE6HQFaPSHkUPmvDvdODfaScZP7Lb0aBTUnNBI1/X/pMnLfemy8MtFure7H861pFi2xgdPaKQ3wmeQY7eFSYdqaWEQsvkOHnrU1/UujIdzSGxdyjktot+q8mgHXxTo3gdCVxvuvbttg9bimBcw5BVCLgs1JUV0+VxEnbZkCqYZGqis8oExbRRTjOltCKkJNxqSQl8396JxZ4Tx10exurSkANMSL1fI1OLk6DuQJE6QkoUKelQJRstCp56mLjPYtdWFMfi0RASBBLRE0gmSb9fpN3Sx14EqVV1RmGs71gAdPqOk73jjEdV9PD+p2EQiux7vyPsm2/Ql6A9ZYeQikRXQDebSSqCwpY4H8+r4uo/LBq9gqFiQo3cun4N5v/28varRWwuFuTb44xfaSZuIr1iaZkf4rR8P6qAjc8UDdmnyE0w7ow2kibJwxkeyhc5B51kdmdDu0swtbZ/uubWLElLloXSpjhZgSP/pVGtSRSzxOLUsLiS+Lb1TUP88imCyXWSqqFjekYMa3acWHtq0rV648QC5iO+qjIwOFw0ZCvszM+gw5JBWFjJiCaZ0uijvLN/ckRNgS57yh08r39o0iGzasFEfuS6ltW2m8gUIa6O38nt37iR9o4gxVeey9vnTObmBxYOKhgO3h3kGKHRH+V7z67h8iYP+Z0QsUjaq1KTyZZTLVTvDmLbbiXvbSdv5zlwTeuiZ62p23T0eGrlqql7o4Flq5nNLxRQdW4r38LP2gUR3l2dy7z1kvcnCuZtT6bblbRDSbukwyPJ8qfet/W0MMGQCcVnYtL2BOaDnNyGsg8MRDKmkIwJEl0mQgNM/hd9eGwvAvRegYdaVO0nFFylEWIJhVi7GZE4ukGKvfHZzcRNCkJKvOEEZn3g32vcBLoiU74xktSqX6Z8ZUT3ql1IhtUTHw10AUml+6F2v+5+1rtXnQC5viMjqHVV0jkmQSxPAxUUIVEUUJEoikQRoAgdqSt01nso2KFj3v8wlsNGhwvqCmzUZeeyzlPDCusc4krK1mbVYpzUtoNprVs4vXU9hYFUYE7CplOfD20WhYRJUOiXVDUwbMLJ/aHZo5DvT6nW/vnlK7ngz88QmOLmh+7rycGfdrxYpk/icw8tJS/czhPAJ8PYFY97weAmRNuaV8h+O7U6rmiBim73xyn/jhOetPdL6w4KMl7fq4LILo2wvUzifiuDgAM6FCjqOeNFF+xYnEfhbB81lRGqaxp40F7EBSsl/56sUjO5g8I3HUTaUh4SPUIBIPc9BxOnBHCNj/KGLZsxm/Zuz3eO0bGEBDltIu1SOBCui1upsCaofXbo3U1fju/VdaJXmuGBPEE6GuyoyZGfSL2R/jNSzEw/B4DUblUQsUB9sYJZ1ZBCIhVSN6F0S4nun4XY+yyUlMRoMqtstlq44l293yKhJdvKRzW5SEWgCwUpFKSiMFY0Ms60B1VIVAErxUS2JYuQSsoKIIWKQ4lTqTQzXjQwVm3Eoez9MOpJ9rp/Bkx0ttvRGg/+AKE2t4moyYonoeHqioIUmB0arrIo7tIItqy+bsEA7XGV+pCNYIMN90YLJm1vBRf7l+LjUNEU2JVrwm9zMr0utaxvV4r5Y9FlbPWWoUidsb56prduZVbLRsZ37EKVEqlIutyS3XmCkFngjCpU1UEVAAe/OPM7BNtynWzOLmCLewz1GdWUWSL8tPZx5Efw7cBvqLXnUtrVxBuW2xgjGtBiCiarjuz+1uQlUmetT5xSNuR7HfeqpJlFqlxxQwab/paaQDsyUpb8Md0RvXGVAc8J6ME0J0CrquJe6kQd5Fehu5JETwmRVAV7NriYkPLW5PHPCM7zRShcvn9+zW2ZEn9pMhUynASrX6Wk8fiezI8mcask6tJBAXeLSsSj0zoxjuheUfZ+1hIKtrV2sgfI2XQwBO0QzNOx2FSyFFACEjqB3qs+i0TxgOKREAO9U6AHAQRKho61QsNanqTQtX8nzOmawF9rx7fVScxvJmGVrC8VJBFMqdOxJgTW7DjZY0O4SyMDumQO3X/fILBD9dFP2HXy53dgdiTZ2urEssqBLdRfjIcdkpbJcbK9MVwWjYZOG3qt7YgHRg5Hlw1aC3VEboL8rCjjXWGc3ZOClBCst7FnaS9HAiHTEc66KkmYQEMMmCL/YKgvhK48sHglkzw+KmzRAVOgBHalxlV+Vht1S1L2xGShgqU9QTKu4rzlQk7fM597Lq1Be28xMx/5DRvu+xqXf/a20WtjmOh1y5fn5JDYude3eeFckc6G2nVNOzuDNmr+fhDH/hkcF0gknrIIJoee9nU325OY7EkSVni/0UPRUnsfj5gON4SykgcdpLeq2s6qwvF85DwVZwgq/Q1UBRqp8jdQEWjElhxcz9HgzObZsQt4t7iGKksTF6nLuFD9gGLRTkRa+HeghvatLibW1WFPxFC9grxqH+7yCDEzvJLh4Hmri/JNJs5fpZPvA8WWJKs6hHdMOO2100MyIdKr/zafm0ijBVPw8MTgtBcnKZjRSbUzxuuRGcxq2ERwt41QsxX01M7AXBhnj1lF7LGQGTx2FkINWQqBfB13Tphyb4QXTBeREBYEEoWUCtASi5Pb6iO3uZOClnYs4WHy5BwC28tMtJXZKM8MM8+xG9MQclJKiAdMhNsstHziQo/1/Rx3We0U5nXgzI9huucNah6s5c7zJ2B9/S+c8vxf2P7EnVw055rRKxim2OzyuYqKIetYXBrx4OHRmklXEjGzi51BG5UrrcRV+O+rVaapIc6IRvhjIpvbB3DRjFkl1tix86U4FGLlcT6cqWP7xM6srYf389M7WG+43d7+otpSQiLm6++m2FSpMXNaOwkF1q3zkrv5wF0Zd5XoUBLHlWulw1ZGi55JKGgDv8TWGSPT30W+v4PcyMBWxn8XT+Xv1fOYGdvChbVLyWwKggB7SYIN1RU8mzmf9+VJlIsmTlPW8QX1bSYou/jAZuVpt5vOJisXrNSZtmNvn2anhhZVDzqdc9Kmo0YHnpnqq5Jkj+timicECUFwtw3/LjvhIxgRHLaCJSn7qJQOhhUVLhZVzGFjxnT8pjwAvqC+xT2mP7BUn8TN0W9R1dHE7Ka1nFe7HGvyMB941IvVVSofVE8l1+lksmkPk0Qd1WIPJqETS0JrwowvbiYQS6n1HHVm3C376TV200lM8L0KgPafzZz9/Ue4NL+dM596DpMu2VAKl7+x6cQWDEeDJ85SaK3QKLDFWSqdPPRQ3w+UIzdG4exOzI4k4VYLu946ei6kBvuHKUPDmqGlhIhUiNbaD6qf7TUapSVdTHaF+6z6knFBrNNMnS+X+A4Vi3/w1eeHYyYysaieGVnb+u0AtKiSXi127bGlcgYdJBELhF06jqTEoUsIDSxMtpZLMqvC1GQHafbbiK1wYek8OhHBB0PQJlhb7GFDdgnrPZPJSAb57geLccQlD59yCq/lXYFZD1MS28GpjR/z2a3rcEWO3G4AYE2F4F8zFIpNFk7tDGKNxYhG1ZSjRUTBHBbYwmLAA7D2hy6PlTazjYo2P4HSBFFdIbtRRR3AJPNxpeDqVzeOXsEw2W6Xz5dXjPQw9ht3WQSLO0HbOjdZ47rwVIbZ+VreSA/ruGFXiU5GUpI1SPqOfQnZoMshidnBEgOvXwwaJX6k2D5JY0K1v08up5jfhG+rE992x2HPxLm1FByhgbPV6gLasiQ2oZOhSywx0EIj64MSNacSI5KlkZ/QyQrrRHfb0LX9tzl0OgUfVuSwzVvGFtdk2iylSKGi6DFyYrsojO5hgm87n/1k4IN3jiSN3pQjgifEsKnujyR/ueaLzF3yBiLeTP7CvzAjf8bodVdNWEbaR+XACOyyA6mVqMmRJNodmBTLT2BtTv2surR0SLxBX8oGMFCGrCkBkBXs/8VzRsEZ3Tvxbp+QRHFpWKw6iiKJdJmwNJr32wlAIhEH6P01ZoOJxIZsNg9wzVEawVsaIRlT6NzRN3huf1BMOq6yCO6SKDF3ko1hB6LZhmmQz48iIa9dACoIiTYC6aHb3NBWoOPMiVFiilMShKw9NsJrUnbCQeIihyQzJDlnfSvn0EpcXUXInpK3mcGR92Ir3D9fg8NO9lQ/5llfoumxV9g+diz5mRlYtRjNGYJK08DHDvRw3O8YxhZmy5c8fVfcL8wVXLr0+L6vkWDZBMGnNp2Yv7e4CVpyJCVNBzZRHmisyaGQURzBWRBDNUtifhPhDguR5oETyvUwlK3gaNGUCavHCOL5Gp83d5LfCV2NVnxb9j8fU0OJTiQriWrVWS8qyOwKkRWMUtYSP2xeQMcTXW6djpoY2XlRxlhjdPwzB2tmguK5Pra8UICnIkLByX6Cu23sfi+L0jPaySiM8ckrBSytULng8dco85SN3h2DOaN/aoQFH/ed3FSLTjI+0uuGY58TVShAaqt/oEIBjp5QAOjaY6drz4HZPUZKKLw2XbB8giCWm+SmpiDXbNfpWu4g0p7N0Cnu9uJ3QsQuMcUFBXsUlO7dYgWNdNmgI1NQV66gOQXukCSnRSej88jd00jRXKWhjIlQmhOhTGrsq0RtsVWiWgMkYwrLlankZ+wh3qVCdjWBunJUxzZaS0txJrahRgSdGWA3D/05Ou4Fg83lhXDfw2h6e7KEHRJHOPWBSphUzNqR8zIwMDhRidl13jhT57nJZmJC4dJtMe74WMO20Qa4aT2IPj0hsCQEMTO0Z0oSZtDMEDcLMrqgrElC0+hZzOhC4hufwFUVpsoVwdV9PvzE7utB3c6TybN4NXkKu2RKSyKkhjfYxL2df0bVoCi0kSgeoo02tObtdK3owl0WoVDzk0wIlKSg0ylwDKNKOu4Fg6L1P6Fs0Zk6l7+aEgaWXvplQygYjAQJlYNKL32sk/RqRKaHeb7axirFxkk7Jb+/X8cak6SmlkOfXuzx7l1ZaHS4evcQt+nEx8bJKwxT4o6hmoYWcPEkNEd1xoaWUdqyipyt5gHd30Mv7fV23Pp8IQC1CSuFdKeZIZXB2GYa2rX4uBcMMhIEta86aeZHStoHfiS9AAxOTMLjYoQKNeKaQiKhoMcVZFwg4gIlLtDiCtXDnLV9PKD6TGS86ea6N+G6dJqK0TWBHw5iniSWshjumCS0w46uKeTkR8mrCqAokmREYUukiLXRCrSwjqfDR2FTAHu8/+SVfRDvb50cYpU+lgmROgC6Mkwote8P2eb4FwxJyb5Kt4qWASqqkgZ7NkVd+3HivIHBIWDebiUesKA4kuSakrh0Da3VjOI/dv3+DQ4PUpWY3Bp2p4YlI2Us12MCrUshGVcIu2zYfHECdQ4Cdb3VOUlqGP4o4OH43XkKGVH40lt7hYr9VQ/tC5rTO4aEPQ5PXDhkP6NAMOznliApDKFgcFQwJ6G4SdCjTtEZeZfJYwmLO4HZqxEPqyRaR/jQnMOMSAqSPjNdvoGTDto4fN4KnZk6uqaQ1bW37BuLB54PE2udaCWpxGEhtxsu+x38bP6gfR/3guEoJVoEUsFprtIIuoTGpcOf82tgcKBYXAnsOXE6bArtIQuOVpWMAz169RgnHjATDxx8tlZIpQdv80oUHWxRgeso/45M9iQWl0ZEU5Adh3YvB0vmACcgDsSuMhs7qjMZ3xAmrgrimXlQdcaQbY57waCqEWLTLFg/7mtlf3GO4OIPDnMen1327gA1A4MjQzxoJh40owLHUzy8mh9Ht+kkO00o/iM/rag65LcfeXtGRlmY1nYb9u4ssaEiDYtPgYiKNkBq+JEmbIUX5ippVdKy2U5y9ABnZwXxb8+g06HisAyfUPSw7HCFEI8LIVqEEOt6lWUJIf4lhNja/eztde0HQohtQojNQohze5WfLIRY233tfiH2zdI+0JvDR7kmVlf1rXr62r5CITR0HNAxh3FwmcFIUpsH/5wlqC9Pog3jMQOQbLYg62xHRSgcSRIlcaLFCTRrd3bmXY60UABwNpgwR44dxeCmYvjXLNhQmnrtiPW1L3xqeYixK1Q8uo9Q1EqnU8U5jKsqHD7V55+Az+xT9n1giZRyLLCk+zVCiEnAlcDk7jYPCZHOJP8wcCMwtvuxb5/90GNdnPSOhek7+n54vfucjhSeexiOSzqKDHY2hIHBvuzMhzemCRafLPhozOFZUVS0wAUrJKV16iFnND2eMO+2YNtjxnScZEKesAc+vQImDRE1uHWyTo5ZIxlV6HQKnJajJBiklO8A+1p2Lwae6P75CeCSXuXPSCljUsqdwDbgFCFEIeCWUi6TqTwdT/ZqM8QNSNZfFiI8zI4gOEzqAAOD45XKZjj7Y8l5qyQzthsrCoO9BH59N5+aqqEIUKNJOp3gPlqqpEHIl1I2AnQ/96hMi6FPVPzu7rLi7p/3LR+WMlucX18y9K1UbTi+t7gGBgYGA6EPsLkRBSnvp7v/UYdfsyB1sMdidGZIXNaRFQyDMdAeTQ5R3r8DIW4UQqwUQqwESALqKIwsNTAwMBgOZYBZsmJqKmnUhPAuwljRYgoK0JmhY1WHd6A5koKhuVs9RPdzT9jZbqC0V70SoKG7vGSA8n5IKR+RUs6UUs6USQFB5agmMzMwMDA4VthdKOlcEKT3OtrsTK2Uq0INxDGnPag6XUn8+5Fe5EgKhpeAa7t/vhZ4sVf5lUIIqxCikpSR+cNudVNQCDGn2xvpml5tBiXmN1P8nIdvv2TkvjAwMDjxKGkUZL7porfS5YMdXhRLkpPC25ksakl2Z9ntdArG5w1/euRhUbwLIf4KzAdyhBC7gZ8AvwCeFUJcD+wCPg8gpVwvhHgW2ABowC1Syh5F0E2kPJzswOLux7AExsaItFrJH4Updw2G581pUJRM4ohLyjYbtiQDg6yPbegWnaJQO3YRpzOaUh91ZoDdNLwq6bB8i6SUVw1y6axB6v8c+PkA5SuBKQf6/u6tVtwH2shg1LDgY+iXMMvA4ASmOV9lnD1MsMHG2k4HOVQDbRS3S3KXb6Nz/QtDtj/uT3CbYrPL311YSPY6wx3VwMDAYH+ZtHnT6D3BDaDlpDgvFNu54TXDzmBgcCLic8KH4wQfjhfszhHkd8L07Tqnr5NkB0d6dMcOv75Y4frZ1zHj1GugoGDQeqNCMEgJNbV7dz7NmRj2BgODEwhvCM5dLTl39fGtATmSJAoSLJtk5+ZpJ2HOzx+y7rGT9OMQSAqYs3nvB8IQCgYGBgZ9SdhTc6TVWThs3VEhGPI+NuwLBgYGBkMRc3YvnvcjQ+eoUCXlbxhdh30YGBgYHG4ijpRgyH18AXjKh6w7KnYMBgYGBgZDE+7eMdjcpeAa3PAMo0QwrP5ceKSHYGBgYHBMU2/PAMBx60q47pUh644KwRB1GJ4IBgYGBkPxT9tJmIQNMWC+0r6MChuDcgydqGRgYGBwLPKrF1azqspE/IoEVtvQdtlRIRicPkMwGBgYGAyFpkDMrWB5525IDB31NyoEw5S3DHdVAwMDg6HYkydZtCDK9Ut/PWxdY6ltYGBgcAKQ1SkoX28iKQFv5ZB1DcFgYGBgMArZUNr3tSsK1y7RCSUVOOvHQ7Y1BIOBgYHBKGRSff+yv52uEM6cwDOhk4dsawgGAwMDgxOE5dN1GgNxHvzHkiHrGYLBwMDAYJRSl9v39enRCFOVnfzjsqGPNjMEg4GBgcEopby17+v6ZAkToo+zRM4esp0hGAwMDAxOEBbs2c1TGQ/wmZLEkPVGRRyDgYGBgcHwTH/ZDjRgPX/3kPVGxY6hwzvSIzAwMDA4PliTW8bsJxuGrDMqBEOWb6RHYGBgYHB8EHFFyNbqhqxjqJIMDAwMTiDm7Ghlzo4/MWmIOqNix+BzjfQIDAwMDEYPo0IweIdOFGhgYGBgcACMCsFgYGBgYLD/lM5vH/K6IRgMDAwMTjAalmUOed0QDAYGBgYnENbKCDmTuoasYwgGAwMDgxMIX7sV79jQkHUMwWBgYGBwAuEIKLRu9AxZxxAMBgYGBicY64J5Q14/5gSDEOIzQojNQohtQojvj/R4DAwMDEYbSTUw5PVjSjAIIVTgQeA8YBJwlRBiqAA9AwMDA4MDZErm8WV8PgXYJqXcIaWMA88AF4/wmAwMDAxGFT+c8/shrx9ruZKKgd4nle4G+p0oIYS4EbgRwFZh48r/VLHHoKQNCn0SIaGoXdLmFqg6aCq4IqnnhAplrZIFn8ghBxI3gd8Bfif4HYIuO0TNELUAAi7+QKIp8EmloCEr1bcUqbafW9a/77AV2l3Q7hL4MmDeeolJP8jfkoGBgcFB8typgp9eN43HvzV4nWNNMIgByvrNslLKR4BHAOyVdqkrgpAdNpfC5tKBuujP7y44pHHy9JmDX/vr/OHbP3zhob2/gYGBwcFyaseWIa8fa6qk3UBpr9clwNCJww0MDAwM9puJWRM5q/ysIesca4JhBTBWCFEphLAAVwIvjfCYDAwMDEYN/pifxTsXD1nnmFIlSSk1IcQ3gdcAFXhcSrl+hIdlYGBgMGqIJWNk27KHrHNMCQYAKeUiYNFIj8PAwMBgtHHFuCu4c/adqIo6ZL1jTjAYGBgYGBwZnt3yLM9ueZYce86Q9Y41G4OBgYGBwRHmixO/OOR1QzAYGBgYnGD89qPfDnndEAwGBgYGBn0wbAwGBgYGJwBVnipun3U7DpODaDLKqZw6aF1jx2BgYGAwCll61VJmF+zNKHTLtFs4rfg0ZuTPYG7R3CHbjirBkO/IH+khGBgYGBwTXP/a9SxvWp5+vcO/gy2+LbRF2oZtK6QcOpncsY690i6rf1rNt2d8m6smXMWcv8wZ6SEZGBgYHNM8ff7TTM2bukpKOXOg66Nmx9AeaecnS38y0sMwMDAwOKa5beZtjM8aP2SdUWN8fmrjUyM9BAMDA4OjSoW7gtpALeO847io6iIe+eQRgonggHVfv+x1CjMK96vfUbNjACh3l4/0EAwMDAyOGrWBWgBmF87muinXcd2U6wA4tai/x5HH6tnvfkfNjuH7p3yfL078IjVP1Iz0UAwMDAwAmJY7jTNKzyCcCNOV6KI90k5jqJG6QB2B+NDnLttUG7FkDLnPkTRW1cqFVReycOvCdNmfN/wZkzARS8ZwmBx8/5Tvc9E/Lurbn8m23+MeNYIhokV4d/e7Iz0MAwMDgzQft37Mx60fH1TbaDLa57VJmPj+Kd/n0nGXYlbM/HTuT1ndspprFl8DwB/X/zFd16pasam2Pn0oYv8VRKPGK8nAwMBgtJFly2Js5liqvdVUuCuo8FRQ5ioj256NVbXYg5JjAAAgAElEQVQC8Hb929z65q3YTXYiWmTQvtZeu7bPayHEoF5Jo2bHAFCTU8PatrXDVzQwMDAYhIlZEzmt+DSKM4rpjHXii/roiHbQEevAF/WlX8eSsQHbmxUzCT1xWMbSEe1gedPyPvEIgzGUUADQpb7fu4ZRIxjuPu1uxmeN57KXLhvpoRgYGIwwk7InkWHO4MOmDw+47caOjWz2bSbHlkOuIzf1sOcy1T2VPHseuY5c1rev56GPHwLAZXalPYFumXYLoUSIjmhHWoD4oj58Md+wE/eR5hcf/oI7Z9+5X3VHjWBQhcrmjs2H3M/5lecT1sK8Xf/2oQ/KwMDgiCMQnF5yOmeUnkFntJM/b/gzG9o3DFp/VsEszig5g1OLTmVM5hg0qdEeaac13EpLpCX1HG6hLdJGS6SFhq4G1rSswRfzDdhfj1AY5x1HW6SNPEceVZ6qtEDJc+SRac0kmozu3X1Ee+0+Yh10RDpoj7bz3p73jsjvCMBtcdPY1bhfLqujxsZw3xn34TA5uGXJLSM9JAMDg24sioW4Hh/pYTAlewqXVF/CuRXnkmnLPOD2mq7xp/V/Sqerrsmp4TMVn+G+lfel61RnVtMaacUf8/drb1bM5NpzyXHkpHcdeY68VJk9hwxLBi6zC7Nipj5Yz9ff+DoA473jmV04m/pgPR+1fDRg3weCRbGw9OqlWFXriWFjiGpRbv/37SM9DIMRpsJdQWuklVAi1KfcZXGxoHQB5e5ydvh38Frta4dND2wwOMeCUABY176Ode3ruGv5XQCUZJSQbc8m25ZNlj2LLFvqkS7rfu2xeljftp6fLvspW3xbmJg1ke/O/C5eq5eXtr+U7uuW6bcQ0SJEEhE6Y53UB+upC9SxK7iLUCJEQk/QEGqgIdRwQOPe7NvMZt+ha0IAfn7azyl1laaN1kMxanYMBgYGBgYpvjLlK/xx3R/5wvgvsGTXEk4tOpW7TrurT50TYsdgYGBgMBpwWVxpFVO2PZvFOxenr51Tfk46UC2WjNEWaUvZQsItfYzbf1yXimn42+a/IRBYVMsBjcEQDAajGrNipspTRaYtE7fFjdviZn37ejZ1bBrpofVhvHc8SZkkoSeIJWM0hZpGekgGR5EMcwbjvOMY6x1LgbOAbFs22faUSus7M77DW/Vvcd+K+6gP1vPQ2Q+RY8/p015KyWUvX8ZW31aum3wdwXiQhVsXMtY7lurMas6vPP+AxjPqBMMNNTfw6NpH068FAq/NS0e0A0hFBPb2P7520rUs2bWE3V27gb6uZwbHNudVnMfknMnkO/NxW9x4LJ7U5G91k2HOQFXUdF1/zM+L217kuS3PpfPLHEsMpEc+u+xsFpQtYFL2JMpcZWhS42+b/sb/rPqfERjhsYVAYFJMmBUzZtWMSZgwq2Yg9bceadfQ3nisHnLtuVhVK1bVilk1Y1EsWNTUI6JF6Ih20BJuYVPHJsJaeNC+NnZs5EuLvsTfL/47dpM9XS6EoCanhq2+reQ78pmcPZmFWxdy3+n3MSZzzAGPedTYGEyKCU3XsKk2ijOKqfRU8nb926z40gpMiok73rkjvSUrchaljUCPn/s4L257kRe3vziSt3HQZFoz6Yx1jvQwjjrfPfm7fGXKVwa9LqWkPdrOXzb+pc9C4WjjUl3cUHYDpfZSBGLExmFw7KIIBVWoqIqKKlSEEKT/idRnRpd6+gGp733PtR6C8SDBeBCn2YmqqARiAQqcBTjsDkpKSjCbzX3qD2VjGDWCYbx3fHrV9dYVb7FoxyLuW3kfz1/0PH/e8Oc+E//M/JmsbF55yO9dnVnNhKwJvLLjlUPuq4ffnvlbfv7Bz6nKrOLayddy0xs3Hba+jwdm5M2gI9qxX6t6kzBxdvnZZFoz2ezbzIb2DYNGow7F58d9ns5YJ/+q+9dBjHhovlv5XaaWTMXisvT7IhsMjc1kw6JaMAlTOmJXdv9L/ZfoUieejBPVov2SzR0MWfYsLIoFs2LGpJgwKSZUoRJNRqn11x5y/weLSUntiMzKAA/VjCrUdOyFw+zAYXLQHm1ngncCHR0dBINBKisr+/R5QgiGHuYUzuHRcx7l3d3vcvOSm/upjg6UkoyStJoJ4I5Zd9CV6GLhloU0h5v3q49rJl1DniOPX6381UGP40hz09SbWNaw7KATfh0qk7InsadrD1EtyrdnfJvffvTbQ/q7HSv8etKvKagoMITCIaAqKkk9OeA1RShplZJJMaEqakqt1GtiNykpwZLUk2i6RkJP0BZp66NusqgWdKmj6dqw48m0Zqb77RFOsWSMqBYlnjw491whRHq3kNST6Z3BgbQfaC4vd5ejCpWdW3cyadKkfducGIJhcvZk1rev587Zd7K2dS0v73h5hEdncKJhU214rB7sJjt2k51bi28lqyxrpId1XOOyuLCZbJiEqc9k3zPhHwgxLUZDqIFwIozdbKfIWdQnHbWUEk1qaPreR2uklUQyFfNiN9lT5VIbcCLuEVSKUNKqn/0RNvviMDtQhYoilLSqSREKEklST5KUKSHX+3moubxpZxM/2vYjCp2FFDgLKHIW8cNP/fDEcFdd374egLuX392n/LKxl6Hp2nFrR4DUTuiK8Vcwv2Q+Qgim/3n6IfWXa8/lf+f/L19e/OXDNMIThy9P+jLVmdWUukppCjXx7p53eX/P+wTigdTfJm86C8oWpFZ9x6H5Z6DVp91kx6yYhz1D4EAxq2Y8Vg8Ok4N4Mj6g4bhHd+61efGavdhU2wHvwHSp0xpupT3ajoJCYUYhXqu3Xz9CCMwipaKBVOCspms4zU7K3eXp+lLK9KTcswtJCxOZet1T52AIJwY2QAshsKpWLKoFu8meMmArFsxqKmI6qvVN1Z3vzCepJwmYA5ycfzKd0U7qAnWsb1s/5PuPmh3D9LzpTMqexNMbnwZS3kZPbHhihEc3NFm2LAqcBewK7KIr0TVovfml87ly/JXEk3HWtK7hsXWPpa99dsxncVlc6fseacrd5dQF6o7qexY4CxjvHc/4rPHkO/LZ3rmdDxo/YId/x2HpXxFKWgjsq94yCRN5jjyiyWja8603v5n0GwoqCw7LOEYzJsWE0+xMP1ShEtbCtEZaiST6exjZTDbyHHk4zc5hdw1d8S4aQg0kkgk8Vg8FzgJMyvBr4qSeZId/B7rUGZM5Zr/a7IuUKVXTQIKj965E07UDVh8NhNPsJK7HSSQTeG1eijKKANi4cSMTJ07sU/eEUSUd6+x7cMbhQBUqDpMDu8lOS6TlsPZ9NCl1ldLQ1TDsCuup85/iW29+i5n5M/mf+f9DVIuyeOdinlj/BNv924dse3rJ6VS4KxAINvs280HjB4PWvXTspZxfeT6TsyeTYckAUl9yf8zPRy0f8cDqB9jWuW3Y+zqSgiHHnoPb6k6voDVdS6Vl0CIE48F+q8fjhUd+/Qhf/+7X8Vg8OM1OvnPTd1j0z0Vk5WSx8J2FA7bJd+bjsXq44as3cOGFF3L55ZeTSCZoCjcRiAWwqBYKnYXpv+VwSCnZ3bWbQCxAhacCp9l5OG+xz/v07DxiyRgRLUJUixLRIgctKJxmJ6FEKJ2PCQ5cMBySKkkI8Xngp8BE4BQp5cpe134AXA8kgW9JKV/rLj8Z+BNgBxYB35ZSSiGEFXgSOBloB74gpazd37GcV3Eep5Wchlkxc8c7d/DVKV9FFSqPrn2U/5z1n+Q6crnt37cdyu0eMgMJBbvJTpWnKq0GG4gqT1Wf1e8zFz7DE+uf4O36t1l+9XKEELxR9wb/8fZ/DDuGfEc+zeFmvj3j23yt5msAPPLJIzyw+oGDuKPDR32wftBrN029iYfXPAzAkl1L6Ih28Hrd64Me4+q1etOZME2KiYUXLaTcXc5HLR9x74f3DhgzUOoqZXredD5p/YTaQC0vbH2BF7a+cBju7MjRE/Xag81kS68+D4RkMomqqsNXPEo8+ptHufE/bqQz1klnrJMzP3cmF3zpAn546w8pcZVgVa1EtAhNoab05NkcaqY51ExntJP2SDsNXQ34Y34kklxHKor4QOwRvqiPQCyQ3pUcDFLKPmqmhJ7o83PP80CLc5NiwqJa0p5H+xrYBaLfTqTns2BRLYQSoUPagRyqjWEdcCnw+96FQohJwJXAZKAIeEMIMU5KmQQeBm4EPiAlGD4DLCYlRHxSymohxJXAvcAXhhtASUYJALdMv4VydzkAL21/iVd2vMI3p30TgGpvNTe8fkO6zb4T7cHgMrv4xtRv0Bpp5U/r/9Tv+jjvOMKJcB+Pph7+dfm/eGbTMzy27jF+cMoP+PHSHwMplcjzFz3P79b8jmc2PcPJBSezvHE5O/w7MCtmBIK4Huee5fdQnFFMRIvw3Jbn+L/V/zdoSuB96fGk2unfCcDv1/ye//v4/3CYHEMG1hwNxnnHYVEsrGtf16e8RyjA3lD/fTEJE2eWnUlCT/RJme40O7n4xYsHfc+e+64P1g8pnA4Wi2oh15GL0+zkvsU7WdfQ2e0dc3gS+FXlWbhxQTZAnx1Ctj0bh8mBSTFx5eVXsmf3HqLRKLd+61au/eq15Hpz+dotX+OtN97itp/dRlewi/t+fB+ZWZlMPGkiu+t289BfHuLBXz6Iw+ngK7ekYkYumXcJDz79IAA3XXkTp512Gis/XMn4yeM5/4rzefDeB+lo6+De391LzYwawqEwd//gbrZu3EpSS3LzHTez4LwF/OOv/+Ct194iGo5SX1vPWRecxW0/vY0H7nqAWDTGZfMvo3pCNff+7l5mzp3Jnl170KXO7uDe75PT7MRr8yIQ+GI+uuIpdWw4EcYX9bF+zXru+9F9JKIJ8nLzeOJPT1BYWMj8+fOZPXs2b731Fp2dnTz22GPMmzcv3W8kEaEp3ESGJaNfhHEPPR5OQ034AwloIfYG5tlNdlyKq8/Eb1bMqIp6wEb1pJ6kLdJGvjMfkzDhw3fQHlJwiIJBSrkRGMgQdDHwjJQyBuwUQmwDThFC1AJuKeWy7nZPApeQEgwXk9p9ADwP/J8QQshhdF09vsuq2LviuaT6Em77923pSbC3UACGFQrnVZ7HhVUXDpjCe1L2JH51xq+wm+w8+PGDPL/l+QH72N65nam5U5maN5V/7vgnAGeVncWSXUt4dvOzXF9zPY+teywtFC6supC7T7sbIQRXT7yapzY+xfLG1KlNufZc/nrBX9nh38E9H97DmtY1rGldA8B/f/DfQ97LYLy0/aV0dkhgxIUCwBbfloNuq0ltwDiE4dIUH4n7rnBXcMX4K5iRP4NEYwKLaiGcCBOIB4gdJfVOe6SddtoB+MlvfkJ1UTV6XGfep+Zx+WWXEwqFmFIzhe/c+R06gh2cP/t8nnjpCUrKS7j9xv3LUly3o45f/eFX3PaL27jqnKtwvuzkw2Uf8uwLz/L4/Y/zmz/9hkd+/Qiz583mrvvvIuAPcNU5VzHn9DkAbF63mefefA6LxcKFn7qQq792Nd/8f9/kiUeeYOHbC7Gb7VgVK5oceAcUSoT6ZdHtIZFIcPcP7uaBJx8gKyeLxX9fzM3fu5nf/+H3qZW8pvHhhx+yaNEifvazn/HGG28AqfTatYFapJR4LB58MV//VX8yMeBqXBFKOtbAarL2m/B7YiKOhOtyjwq2J1AODi2z7ZHySiomtSPoYXd3WaL7533Le9rUA0gpNSGEH8gG2tgHIcSNpHYd5JXnYcfeRzCcWXomAA9+/GC67NPln+aj5o9Sh2Fc+R6nPXMaAD+a8yPeqHsDr83Lop2LgNQReQMJhfvOuI8zSs7g4Y8f7nPwdg9FziJOKz6NuUVzOaXwFPwxP9e/dn36+uklp5NpzeTRtY/yt81/S5efWnwq98y7B4BAPMAf1v6hT7+tkVbOWXgOutQRCDxWT78Jz2v18ot5v0AIwY3/urHf2Hre5/097/crn5k/k29M/QYz8mcgGNjj6Zen/5JfrfwVLeGh7RjT86Zz+8zb2eHfwcKtC1ndsnrI+qOR2kAtv1zxSyBlYzAHUx4u18/3AJ5+9a0mKw6TI61f7o1JMTEmc0zaGNsZ7SQQD6BLHatqJcOSgdPsREqZzrPki/bdPT728GMsWbQEgIZdDby+8nVUVeWUT59CKBFi59adlJaXUlKe2n1fdNlFvPDUC2TZh3azLS4rZtykcQBUja9iypwpbPFtIacqh6b6JsZljWPluyt55/V3+NNDfwIJsViMxj2NAMyeNxuX2wXAmHFjaKxvpLB47yEykUSECHsNz4pQ8Nq8KELBF/UNqSqp3VbLto3buPHzN6ZiDZI6Ofk5tIZbCWthpi2Yxvq29eSOzWXbjm3s9O9MT/o97Ona0+fvYFZSqSycJme/Cb9HxTNS9BYMPTuV3vdyoAwrGIQQbwADWc/+n5RyMP/PgUSiHKJ8qDb9C6V8BHgEYMyUMRJI/1ESeoInNzzZp/5nx3yWn5/2c3635nc8+PGDOEyO9LWx3rGUukr7TKb7nt6mCIWHz36Ye5bfM+CZD1+d8lUuHXspZa6y9GqgPljP9a9dTygR4pkLn+Ge5ffwwOoHePIzT7Jw68I+bn8NXQ1ousY7u9/hrg/uoj3azsn5J7OqeVWf95iVP4ua3BpcFhcPrH6ARz55JH39+prrmVM0h7fq3wLgrlPv4ofv/7DPOAcSCg6Tg49aPuKVHa9Q7i7nqQ1P9bnekzvqjnfu4IXPvsD1r12PWTEPauhe3bKaqxddPeC1Q8UkTIOuHo9HFKFQnFGcjlw1KSYEglAihD/mpzPWiaZrbO7YjFkxk+/Mp8BZQIGzAH/cn9and0Q7cFlcZFozybJlUZRRhJSSiBbh5ddf5oN/f8DTi57G7rBz3cXXEYvFsFgtabvCvpvypEySSCboindht9ixCEvahTUW3euVZbFa+tyLxZJ6LYQgEo+wuWMzcS3OE399glk1s+hKdBGIBQgmgqxdtTZdH0BRFbSkhtvqHnRFrUsdX9SH2+qmOrMaXeppr6F9kVJSPaGapxcP7K3XM/aYHiOhJfq4h5pVMwWOgvTkfzCqnaNNTwCgqqjEEqm/kS51knryoATWsIJBSnn2Afea2gmU9npdAjR0l5cMUN67zW4hhInU0qq//98gKEJhdctq/mvZf7GtcxsFzoJ0hspdgV1ASu8K0B5tT7db27q2z85iIHSp8/V/fb1f+X/N/S8+N/Zz/crrA/V85bWvEE1Geezcx5iQNYHbZ93OlxZ9ifP/3jfLYU+Ub88qfZx3HA8seIDJOZPxRX2saV3DrW/eyvS86cwtngvAe3ve4/G1jwPwv/P/l4VbFvKrlb/i3d3vMj0/1c++QmEgfjb3ZywoXcCjax/lr5v+yj+2/aNfnbPKz0qXX/rSpcP2ORCFzkL8Mf8hq21GUijYTXbOrzyfqblTybZnowqVukAdGzs28nb92wPmq6pwV/QJntoXXeoD2jV6Vp8OsyM9YSX0RFq/3rNyLsooQpc6gXiAzlgngVj/GIOWjha8Xi9lOWXs2raLT1Z90q9O5dhK6uvq2bNrD5PHTeatl9/CrJqxmWwUlxaz5LUlfFF+kQ1rNrBn155+7Ydi7plzuf/++7nzF3cihGDnhp2cMecMvDYvFtWSDgTrIRALYDKZUKVKljMLRSj97isQCwx4r33uqbqSjrYOPl7xMdNmTSORSFC3vY7qCcN7MCaSCcJamGxbdjox37FOnx1Dr+9JWAvjsrgOuL8jpUp6CfiLEOJ/SRmfxwIfSimTQoigEGIOsBy4BnigV5trgWXA5cCbw9kXYK+N4Zcf/pLFtYspcBZw/5n3M790Ppe+dCnbOrel8+5k2VJb497+5r2P5ttfPlX4KR4+++EBJXFdoI6vvvZV4sk4j53zGOOzxqNLnY+aP+pT7xfzfsF9K+5LHxUIqcM1bp1+azq4xmvzMrdoLhnmDN6oe4PTS05n6Z6lfPvNb1PtreYP5/wBj9XD3KK5fO/t7/F+w/ssb1o+6Lh7C0uArb6tXDr2Um6fdTvT86YP6NU0kLA4UBpDjYfcx9FkbtFc5pfOZ3bhbCrdlQghaAm3sLJpJauaV7GqeVXaNdam2piaO5WT80/m5PyTOSn3pLR30Ku1r6L5Ul9Sq2olx5GDx+JBIoklYwTjQboSXf389IfzLNKlnrIhRNoHrdPDGWefwQtPvsC8WfOoGFPBSSefhIKCEIIyd1laJfmjX/6Ib3zhG2RmZVIzo4ZYMoZZMfOVq7/Cqwtf5Ytnf5GTZ57M2LGptNCD6fb35Rvf+wb3/vBeLj3jUqSUFJUWUfmXSnzRlHG053fVm8uvuZzzTz2fSSdN4t7f3cvtN97OivdX8P/ZO+/wKqq1i//m9JbeE0oS0iChJRiqSAcpEkEv+NmRIooFRbFcFb2KYsGC14qgcMUuQRGlqIiCUkW6lBAgIaT3nH7m+2OYISc9FPviOU/CnJk9+0yS/e63rVVWUsbgLoO55d5bGH/N+Abvp1PrCDWF0jm8Mys+XcFtt99GWXkZDqeDa6Zd0yLDAHg9X6PWSLgpHKPG+IelNpGfoVolhZJkUtGzNQzn1McgCMLlSAt7CFKP505RFIeffu9BYBLgAu4URfHL08d7cKZc9UvgttPlqgZgKdAdyVOYKIpis6VDMSkxouUeC2pBzTUdr+GWbrdg0kqhonf2vqPwE22YsIFjFce49streXXIq2dNTrd6/GqlaaQussuzuWn1TbhEF28Oe5OEgARKbaU8+MODfJ/7vXJelCWKxcMXM/GLiV5GakrnKdyeenu9cWdvmM2mk5t48uInufPbO2nv2555F89jZ+FOvjn+DT/l/dSoTGVtJlmAdj7tOF4peVAaQcPyscvZmr+Vx3587Kyex7mi7o7xQiHUGErnkM5YtBYOlh7kQMkBRESMGiNpYWn0DO9JekQ6iQGJqAQVuVW5bM/fzrZ8yRjIO3uz1ky30G70COtBj7AeJAcle+0qnR4nX2R9wZu73uR45XH+m/JfuqZ0xVfXeIgEpNCHzLdT46rB6rJid9uVMI/8h94SNMabUxcqQaVwC1VXV6PSqxBFkcdnP0772PZcd/N1XmOGm8Px1fl6NXo5PU5F1N7lcaESVPjqfDFoDNjddmqcNReE8yrIGISAoITb6sKkNWHRWvDR+cj6xsozrnHVUOOsodpZfVZ0FRGWCPz1/n+o8FJBTQGFNYV0DOqoNJh6RA9qQU20X/Tfr8EtpVuKOOqlUdyYciNJgUle7xVZixj4oZSIXnLpEoINwYxcPpJuId2aJIszaoz12vKf6PcEl3W4rNFrssqzmLx6Mm7RzVvD3iIuII4d+Tu4d8O9SnWUQW0gMTBRqSgyaox0Ce6i7PJ1Kh1fjPuCcLN3Sqduj0K0bzTHKo4hIhJliWJg24G09WnLW3veqpccrqtPMaTdENYdX9fo5/g7YWj7oVzW4TISAxKxuqxsL5C8gW2ntik/Mz+9H6mhqaSFpdEjvAeJAYkNdsA63U5WHFnBwt0Lya3KpWNgR6Z1mUZETQSdOnaqd35L4BE9WJ1WimxFSilmQzBrzbhFt5chaQo6tQ6LVmr0cosS784bL7/Bp+99isPhoGPnjsyZPwejydjMSK2DXDEjJ8rPFVqVlmBTMFqVFqvLSrWzukEqCY1Kg4/OBx+dj1entCiK5FXnKcl6nVrX6hJPs9as5Il+T+RV51FmK6NjUEcOlR5SuKXK7GUkBSZx4MCBv5dh6NGjh7htW+MU2hmZGRwpP8LDvR+mnU87Jq+Z3Krxe0X04pUhryjhnYaQVZbFpNWTAHhr+FvE+MWwaM8iXv5Z6g+odFZiUBu4N/1ePvz1Q0U97MtxX9LGpw1L9y1VqljkRHltbMjZ4FUl1TGwIwPbDWRQ20EkBCTwfe733PPdPQpD5Lnw2YQYQwgzhRFqCiXEFML2/O1Kh+9vKWI0tP3QZmmwA/QBdA/tTpeQLiQHJyMgsLtoN5vzNvNzwc/Y3XZUgopQUyjBhmCCTcH46nzJqcxhR8GOJsfuG9WXCQkTuLjNxU1SIdjddj499CmL9iziVPUpOgd35uauN3Nx1MUIgtDgTq0pyLvaKmcVVY4qalw1iKKIIAiYtWaMGqkCr8RW0qJFTBAEZUH0iB4q7BVYXVbluL/eH4vWgiAICuGb0+PE5rIpHsz5Er3Rq/WK5oD8VaPS4HA76lVSNYfH732cn7d4V7xdM/Uarrzmyma9AIvOIgk5CWpyq3Lx0/sRZYlCEAQlv1DtrKbGVYPd1TpvR5bjPBv6jHNBTmUONa4aEgIS2F+8H3+DPyaNiZzKHGL9Y8k+lP2PYaiNNdlruPu7u89q7FXjVtHWp22T5xwpO8Kk1ZNQCSreGv4W/np/HvjhATbmbqRnRE9yKnPIr8knPTyd7fnb0al1xPjFsKtwF88PeJ4h7YcgiiJzN8/l/V/fB+DD0R/SMUj6IW49tZVbv74Vq8vKlM5TGBY9DKfbyeZTm9l0chNbT209q89WF7F+sfy7178pt5crHbXy62T1SQ6VHmr1mA/1eogwUxglthKlX6Mubul2CwH6AIptxbz2y2tNjtc1pCtdQrqwI38He4v3svTSpewp2sPmvM1sy9+m8E3FB8RLoaHwdHqE98CoMXKg5MCZHEHBdiod3gbOoDbgb/D36iCVj8f4xRDrH0sHvw7E+scS6xdLiDGE5YeXs3jPYgqthXQP7c7NXW6md2Rvr5BRSwyD2+OWDMFpYyAvbHI5qkVrwaQ1eYUu5Hk2lGdoLjynVWtbXMooCEK9zlu3x02Nq6ZRwyTzHqlVakqs9etH5A1Mc4yg54LWhChVgoogYxB+Oj+0am2951zjrFGMRWtpRsLMYZg1ZvQa/QUNPR2rOIbL4yLaN5oDJQcINYXir/fnYOlBws3hFGQX/GMYasPpdpL6v9RWjdlYtVFdHCo9xOQ1k1ELat4a/hYlthLu/e5eyuxl3Nz1ZlZnr6QfTekAACAASURBVPaiXxjcbjAP9nyQAEMAV35+JXa3ncyxmYoLO2b5GCUfcF/6fXx88OMW8fE0hbON4asEFYGGQGUHJEsTrji8osV8T7F+sURYItiat7VVzTbTukxj8Z7FyjXvjXqPxIBE8qrz2Hxqc718SFuftvSM6EnP8J70CO+Br86XPUV7lBzBzoKdSkVUe9/2UlgorAdpYWkN5ovK7eUcLT/KkbIjHCk/QlZZFlnlWY0m0XuE9WBC0gTi/OJo79veK6zQkGEQRRGby0als9Ir/KESVIohsGgt9cIToihS5ayizFZGpbMSURTr0WDIIi3VruoGyedaAj+9H4GGQHRqXbMNWS6Pi2pnNSW2kkYZQQMNgbhEicfJ6XaiUWkINAQqXctyOKsunbScBzhXtEZrQYZGpcGoMXrJh2pVUlmx0+NUjIXVZW2xcVOr1Aolu0ljktgMzlMyO6ssC7VKTYQ5gkOlh4i0RBJgCOBgyUGMWiNVOVX/GIa6SFua1qKFKT08nVeHvIpOrWv23IOlB5m8ejJalZaFwxey7tg6Xt75Mm192vJwr4eZu3muUrli1Bi5KeUmuoZ2paCmgIKaAjIPZypJonMRExIQuDHlRoqtxRTZihrsVWgOd6TewRdZX3C47DBmrZllI5dJAh+N1D9/d+I7Znwzo8XjhxpDmyT4G9R2EL0je/PE5id4fejr9Insw68lv3LF51cAMLbDWLac2lJvYb6l2y2M7TAWf70/u4p2KRVDuwp3Kc8zzj/OyxCEmEJaPO/aqHJU8daet7yaD320Pvjp/cityvXqwG/r05YO/h2I9Yuln7YfHTt2lBrUnDWKZyDXnRs0Biw6Cz5an3pVL/JiVu2s9tIEqI3GEs2CIGBQG7z4deT+hLreUkMQBAF/vT/+ev8WV+PIvROVzkqKaur1pTZ6j0BDYJNlvSA9i2pntVSqerrBr/Y4v/U6plaplWfbVDd0c2PIuh3y62xDUAdLD2LSmAg0BHK0/CjtfNvho/PhROUJrE4r7nz3P4ZBRl5VHk9ueVJp+moKn2d8TrRfdIvu+WvJr0xeMxmdSsf9Pe/nsR8fU7iKxsSOOe8CQYGGQPRqPWX2sgbjvRpBQ5AxCJfH5dWjcX/6/QQaArlnwz2Mix/HhpwN+Op80al1Sp4jJSiF90a/B8BXR7/igR8eIMoSxatDXqWNT5t695Lx+E+Pe3VvtxR1k+F18XT/p9mev91rbD+9H+nh6aSHp9Mzoidb8rbw+ObHGdR2EMW2YvYW7cUlShUxiQGJ9AiXjEBaaBr+Bv9Wz7E2yu3lLNu/jKX7l1LpqKR/m/5M7TKVriFdlXOsLivZ5dle3sWvJb+SU5XTKLuqUWuUfhYqnUKGVpt2oalEslallSQva4V35K/ljnJKrCWoVWoizZH46n0b/Wwuj4sSWwmFNYXNPgd/gz+hptAmc20NjV/lqKLcUd5k8hzO0GjL+Y6mIIoi1c5qKh2VVDgqcHlcCAiYdWZ8tD7oNXpsLhuF1sJGld9k+Op9UQkqymx/DOEMWWdBfhk0hhaFoPYX78df749Za+ZE5Qli/WMxaowUW4s5VX0KMV8kJTnF65q/nWFwepws27+M/+78L6IoEh8Qz+6i3Q1e3zeqL68OfrXeL6PdbaeguoD8mnwKas583ZCzQSn3/C0QaY6krW9bgo3BZJVlsb9kPwC3dL2Foe2HKtTLAgJdlnRRrvvlul8UOcNuS7txa7dbOVZxjB9P/si6K9fx3Lbn+N9+qcv5kd6PcEWCtDvfnr+d27+5HY1KwyuDXyE5ONlrPqeqT7H+xHo+P/I5u4rqN0s1hIy4DDIPZzKrxyw6B3fm+q+uB2BC4oRmjcv4+PHcnno7Pxf8rOQI5GcAUt5B9ga6hXY7q5rthlBmK2PJviW8d+A9qpxVDGo7iKldp5IclNzoNblVufyQ8wMrs1YqVW/ng3bbrDUTbAzGoDG0iGvH5rIpMqn+en/CzeHNdr+KokiNq4Zia3GzHoVeoyfEGKKI97TWmyixljS5u/bV+xJhjmjR7lket8JRQaWjUsl7mLQmfHQ+SnltpaPSi4CvIWhVWgIMAWhVWsnwOCubNSzyz8TpcZ4TaV1z95Cp9WVxnrqe5f7i/YSYQtAIGvKq80gITFCqtbLKsrDn2Unt7B1Sv2C0239E/FL4C4/9+BgHSw8SaAhEq9I2ahRkvPrLq8riLxuA5sjXzgUaQUOn4E6EGEP4+rjEYXNtp2sxqA28uftNr5r1KJ8oXh/yOssPL2f10dV08OvAy4Nf9trNi6LIYz+dibsPaTdE2WXUFlHvHtqdlVkryavKY3b6bBICEnh408M8+uOj/JT3Ew/1eoi0sDSWXrqU6eumc+PqG3m6/9MEGYJYn7OedcfWNUpAKNN5NwS5SS7IGOQViqlrFBpieP3k0Cd8ckji4Ner9XQJ6ULn4M7sLtrNm8PepFdEr2aedutQbC3mnX3v8P6B97G5bAxtP5SpXaaSGJiI0+3kZNVJ5ffkeMVxVmWtalYHAvDi1lGr1IpWsNsjlZk2Fv82a83o1XocHgeCW1Lv0ghN/9kaNFLCvLCmkCJrEdXOaiItkU1qEchVTzLvUo2rhgp7BeWO8nqLo91l91pkfXQ+XjvchhZ0QRCk/IfWRJgpDKfHSbWjWlnQa+PZp55l6kyJosZWbOPuaXeTn5+PSqVi6tSp3HHHHY2Oe9311zFg+AAGjBqgUHEbNAZ8dD6oBem5R5gjqHJW1fsbd3qc9cq9Zfprl8fV4MJvc9mk8t/T4UC5h0rOl8i5E5fowul2YnPbmvWeGrpHY0lvk1YyGAAOtwM7UghV5o4zqCWPo7VG6y/jMZTby3lxx4t8fPBjRER0Kl2rEp4CgqKrKnOjqAQVAsJZlX+mBKWQHpFOUmASwcZg5VXXVS62FjN6+WiMGiM2lw0/vR+LRyymoKaAq1dd7TVm36i+PNP/Ga9dsSiKPL/9eS9Sv7olr53f6cz0rtMZ0n4I4z8b79WT8cnBT5jz4xxAKrV7pPcjpIenszJrZZPMrdG+0cT6xfLNiW8AWHfFOoZ83Dr2lCmdp/BL4S9sObUFkMRxNudt9iIvi7JEMT5+PGlhaaQEp6BT69h6aiuTVk9i4bCF9Izo2ap7Nobs8mzmbZ3HD7k/KMd6hPXAorOQXy1tFmqH6RrDoLaDSI9IJ9wUTqgpFKFAILlTcr1dtUJlYStTEqxmrRmT1oRerZfCSS47drf0qr3DVqvU6NX6ei+NSlPvPjXOGnKrcnG4HQQaAgkzh9ULTTSlx1DbSMhhm+bQ2nCIfI8qh7RYd2vbja3HpGq7wlOFFOYX0qlrJ7ROLSP7j2T58uV0TmlYi+OGG25QhHocbgcVDmnetRPxQcYgpQmv2llNmb2MSkfleclTqAQVZq1ZMRQt6W9wup1S/qQBI3kukMuCnR4nRceK6J/a3+v9v7zH8PmRz3l227OU2cto69OW45XHERHx1/s3yGHTEEQkEXBEoIU5pNqCMCDFxy+NubRVcw8yBtE3qi+rs1cD8MllnyhEaf3b9GdDzgbl3JcHvey1GxNFkfnb5yt6EH0i+7C3eK8XSSCgiHrE+cfho/VhR/4OxTCMTxjPwdKDLDuwjCJrEbd9c1ujc72649X0COtB99DuBBmDKLeX8837kmGQE8UANybf2CD7bG3E+sWSV52nGAWAtcfWkhaWxpB2Q3hn3ztcGnMpT/d/ut61erUeoEUJe5l4TQkJVud7hQd3Fe5qlMPpcNlhTBqTV+d4bYztMJZLYy4lLSyt0eTp/qL9Z3SCv5yNJ+8XRd5RK0LoaX5+jUqDioYXT/H0P4/oUaQiPUhC87bgeI5dfCcgLUp6jR6D2oBOrVO+zrphFkePH6XGWsP1067n7hl3ExoQyl133cXq1at57rnnqKio4K677iI4OJjU1FSysrJYuXIljz76KBaLhVmzZhEuhpOckszbH75NpbOSKVdOoXvP7uzavovE5EQyrsrgv/P+S2lxKc+89gyduneiprqGJ+9/ksMHDuNxe7j/3/cz/vLxvLf0PT7//HNqamo4cuQIl19+OU8//TTP/+d57DY7EwdPJDYxlrmvzCUkXCoYcGqdtItrx08HfsLc1qxUbzWWHN+9czd33XUXFZUVmPxMPLHgCaLbRnPZsMvonNaZrT9spbqimlfeeIXBAwZT4aiQOL1OV1cZNUZEpGa85kJKMjyiR9GoziNPKi443YHd2Dy1ai3+an8lHyaXyJbYShqsytKoNFh0FnQqKaRUYi3B6XESZAxSypdDTCGK16L1aDGom07u17tHq87+A+JYxTEe+OEBQNrFyrxITo+zxUahIfjp/UgJTqHGWeNFHR3jF8P96ffz0cGPvBqw5g+Yz9D2Q1t9n/3F+/nuxHeA5JLLUnwnq06y7dSZ3ImAwPc53zOwndTJLYoiz217jnf2vYNWpcXpcTIpZRLT101X3FkZcsmqSlDRNbQrOwt24hE9fHv8W+Zvn99oziQ+IJ47ut/BF0e/4MujX1JqK6V/m/5K1VbtX/Laz7o5owBSp3jdn89TFz9F/zb9FSN5bcdrG7xWNgxVjipyq3IbXPDlYwXWgnq7XLWgblBCdEa3GaSGpVJsK+ZgyUG2529XutQtWgu9InrRJ6oPfSP7NkqL0hCcHifl9nI09nK0LhsIUjhRo9YoXmlTEE7/UwkqLw5iERGDPgC9b3vFs7C77VQ4KrwWsvueu4+w4DCqqqsYP2Q8g0YNorq6mk7JnXjsscew2WzEx8ezYcMGYmJiuOqqqxqehyDNIdQcSogYwvGjx1n4v4VEdIjgisFX8MUnX7D0i6V8+9W3vPHCGyz9cClvPf0WgwcPZv6r88kvzmfC0AkkpCeQV53Hth3bWLdpHX5mP9K7pDNjxgyeeuopXn75ZXb/IoV/5Wqk3KpcjmcfZ//u/XRJ6yJRcjutFFJYr4kPJD2G2267jY8+/YhKbSVrVqzhnefeYfHixRi1RoyCkZXrV7Jq1SrmPDqH9t3a46P1IdgYjM6so9xRTrm9HIfbgSBIVPd+ej+lubCloWY5DFRkLUKtUitGwqw1N5pD0ag0+Op9lcIBuc9FDt+5PC4lWa5Wqb0q3ORQnryOyLDqWle6/Kc3DHJTk4/OB5WgIj08HZWgUvR8r+10Lf2i+hFsDMZf78/gjwZ7Xd/G0kYqLTzdwNTBvwMxfjGYtWZ2Fuzk2i/PLE5jYsfQOaQzs76b5RVeevaSZ8/KKBwoOcCUtVMIMAQwIXECL+x4gc+OfEasfyy3f3M7akFNYkAiv5b+ikalYfb3s1k8YjGdAjvx7LZnWbJvCRMTJ7Lp5CYsOgupoak4Pc76HoMgICKSXZ5Ndnk2OVU5dF3StZFZwQsDXmDBzws4VHqIb098y8O9HiYhIIEXd7zI3uK9XJV0FfuK9zVa7TUyZiRrstc0yYbaLaQbLw9+mSEfDWFk7Ei2ntrKSzteol9UP4VwUK/R8+PJH70X+poCtuZLYYbZ38+uN65RY1Q6t1PDUpXvw8xhhJnClE7lVVmrEASBcfHjyIjL4Gj5UTae3MiyA8sU/qpOQZ2YlDKJvlF96RLSpVUVOU6Pkw05GzDYDBwskQSIjAPvxV/vj5/O77xw9wuAGrAAFrzzB7KGsN1tZ9H8Raz6bBUiIqdyT3Es6xhqtZpOAzqxt2gvOb/m0Da6LUGRQdhddiZOnMibbzZeOQbS71RMTAyDeg5CFEW6du5K34F90aq1xHeM58SxExRbi1mzZg3OlU5ef+l1qRjC6cZT6sGkMdH7kt649C6KnEW0i2vH93u+52L/ixERqXRUKuWbPjof2ujacPWUq3n62aex+Hh/VlEUFcbVCnsFeVV5/PDzD+zZs4chQ4cgIqJBQ2RE5OnnJnDVv66inW87LrvkMp5+8GksWovCUiv3k4SaQlELaiUcVW4vR6PS4Kf3I9Y/FoPagFt0U24vb1EnutsjnSsblYb4nBqC3P/gp5e0PDyix4sCpNojeRW5lWdCsCW2Esxas+JVtBZ/esOQEJDAlmu2KLtIGblVuUSYI+rFNi/rcJmiXDYhcQL/7tUwPXVdo3BL11v4pfAX5m6eS1JgEtoaLaX2UuZdPI/h0cNbPe9fS35lypopGNQG3hr+Fm0sbaRF+HSHcFuftrw84mWCDEGMWj6KUFMoVY4qZnw9g+6h3Vl7bC1Xd7yatLA03v/1fZ655BklJGLSmnB73BwqO8T2/O24PC4W7l5YTwCoU1An7uh+B+kR6WhUGvYW7+X6L6/nf/v/x7JRy3hj1xu8tectPjn0iSKbeqziGE9teQqAflH9vGLyMmTBo6aws3CnIpaUV5XHqepTOD1OL4M1/jNvBk1/vT9hpjCiLFFKR+f0rtO9Fn8frU+DfwhZ5Vm8uetNVh1dhQoV8QHxxAfEs6twl5IEDzQE0juyN30j+9Inso9C094aHCo9RObhTFZmraTEVsKC5AUEGYMI0Aeg1+ibH+A8QQ5Pbd24lc0bNrN9y3ZMJhOXDLiEQE0geoNeyStU2itxup0KUeCJyhNUO6s5UXkCm2hD5VApSVab7UwSVK+XPo8gCOg0OsL8wkgISMDt5waPNAdRFHlu0XPExMWgUWmk3giDP/t37ifEJ4SkwCTsLjsmnQkdUqOnKIoKVb5OrUMjarhpwk1cOfFKrp5wNSpBhd1tp9ha3CCVhryjjk2MVfQY5FJYOY8gz12n1eFxe2jj0waP6FGU9iockpGRk/KhxlAQJC+1xFZCsbUYvUavGHr5d0VetEttpc2rBzolMr+CmgK0Kq2Ul6jD59QQ5DyGrEVdWFNIQU0BwaZgpX8kr0rq+dGqtLTzbdfkPBrCn94waFXaekYBpKRlQ7g++XrFMDTmwsvJTZBCCCNjRirhkZlpM/k+53sO2g/yZL8nGREzotVzPlh6kClrpqBT61g8fDFtfdriET0KsRnAspHLlJjjzV1uZt7WedyddjfPbX+OtcfWkhGXweyLZnP1qqtpY2nDgDYDFIGhp7c+zas7X63Ha/Rw74dJC00jxi+mwcUzOSiZey+6l//89B96LuvpRUooN+N1Ce6ilKluydtSbwwZ13S8RimHbQ5bTm0hyBjkVRFi1BiZ03uOsuCHmkKVn3OprZT+H/TnhuQbGBfftEbEodJDvLHrDb7K/ko55sHD/pL9HCw9SNeQrtzW/Tb6RvWlY2DHs6ItKLeX89XRr1h+eDl7i/eiUWkY0GYAGXEZhFSG1CNF/C1RXl5OQEAAJpOJAwcOsPmnzRg0BgQEEgOlbvKY+BhyjuXgLnbTrn07vvn8G1SCCqvLin+4P9+t+Y4jZUfY98s+jh49Sm5lLjq1Drfoxuqyev39yVVCGpWGhIAERo4YySeLP2H23Nm4PC6+3/w9Hbt0pLCmUOEhMmqNaNVaQkwhxAXEodfpiTJG4RScWF1Wbp9yO1GxUYy5cQz7i/dj0BiUxLafnx9Wl5USW4lXA2BdPYbc8lyOHTlGYqdEKdxmr6jXMKh0nussRIgR1LhqpF4Je4VSSSSXDouiSLWrWql8MmvN+Ov9lYXdrDXTxqcNoijicDuoclaRX5PfaIK7NkstnOFz8tH5NNtw6xbdCIJAkCGIohpJ99mitVDtrFb4wlqLP71haC0SAhKU7xtaHL86+hX3bJBU2qIsUfjqfPnw4If0iezD7ItmM3fLXHYU7OCJfk8wMnZkveubw+HSw0xZMwWtSsui4Yto69sWm8vGvzf+m40npa5ltaD2op2YkDiBZQeW8dz255RjxyqO8eKOF5VS3H7v9/NKxspGIT4gXuE5+vHkj2zO2yxVXp2uwHJ6nOwp2tOgYIzcBFcbtXsXmqr6aolRmNZlGu182xFqCkUjaNh0cpPS/Da963Ri/WOVUruTVSeVSjH5DzqnModia7FyvHZV2e7C3UxfN70efUe4OZy+kX3pF9WPnhE9z7rvwe1xs/nUZjIPZfL18a9xeBwkBCRw70X3Mip2lKL9sX///mZGurAYMWIEr732Gl26dCExMZFevc6U92pUGtpY2uCj8+Ghpx8iY3QGoSGh9O7ZmwJNAQkBCdx2/W2s+3QdEwdPpGtqV2LiYnB4HApldVaZVL5c4aigsKaQU9WnqLBXKEnyx+Y8xp133smVA67E7XET1S6Kl999GYdbGuPXkl/x0/t58SZNnTqV3j16k5qayvTp01nx4QpSOqdw1eCr8Ige7n7obnoN6qUsoipBpRg7GVqdlucXPc+8B+dRUVGBy+Xi2mnXEpcUh8vjotBayMHSg1SVVeEW3VQ6KjFpTEqIr3b5bpgpDJvbJlUN2SuVhkCjxoi/wV/xEnKrclEJKoWc0Kw1IwgCeo0evUaveBVy49/J6pONGooqh8SbJeun+On9CDAEYNQY61eViW4vSU+tSqvkG84Wf5ly1dag8ztSqVtqaCrvXPqOcvylHS8pC5OPzge7y45BY+Dei+5lePRwbv/mdn7K+4kn+j3BmA5jWj1XmXBPLahZNHwR0X7RFNYUcse3d7CnaA8z02YyPHo4Y5aPYXj0cOZePBeQYqgXvXtRo1U4Hfw60DuyN52COvHBrx9IVUh48HgkojK5IayDXwccHkeDRuDvAvkPq7YhqWdYGjmuElTkVed5aWjICDQEkhKcUu/8cb7jaBfXTlq0BG8vte4x5avQ9P8bPKelYzV0ngBlFWVUIO2i586eS9eOXZl518wGx5LhcDuk2nm3HYfn9NfToSAZWpVWWhhrldXq1DolSV5hP1MCK4dm/PX+zTa3iaKIw+PA6rIqL5vL1uhCG2IKQS2oqXJWUe2sbpRGxKQxKeWmBrWhwc2j3WVXSktlJgK5XNgtunG4HXhEj5KP8Nf7N7lIuz1uim3FLepAl+Fv8CfEGIJOreN4xXEcHgfhpnCOVRwj2i9aCTPJaK0ew9/OYwCJtnp/yX6FetnlcXHjVzd6aTRUOioZ2n4oD/R8AB+dj2IU/tP3P2dlFLLKs7hp9U2oBBULhy8k2k9iQZzx9QwqHBW8OPBFpeLouuTrWLh7If4Gf2wuGx8d/KjB+QPckHwDd/c4wx7b0NxkQ9jGpw3b8ltnREEqy70q6Sra+rbForWwbP8yfsz7UanuCTIE8cllnyiMmR5RKqVc8POCZvMNi4ZLEqVu0Y3H4yG3OpeDJQfpHdkbURSV8WqP6xE9PLzpYQQE0iPS2ZzXsGpdrF8sl7S5BI1Ko1xXe5y6YzZ2rypnVaP36BTUCY0gjV9YU1jveqdFonFGPKM2qHyttTg1dOy3xJLXlrDi/RU4nU46du7I4AmDz4pRty6cHidOh5Mqmm/qsrvs5Luk0AxIRlw2Yk0axdMMsFqdtlHJz5YsujLVRrWzul5Y06KzKMUHAgJatZYgYxBOj6SNLYdtasPlcXkpwckJZFnbW/kMAopBFBCwuW0UW4ubJBAss5XVo/GQC3Gaa4BsCf6WhiHaL1pZWHMqc7j0U+/egyBDEP/u9W+GtB+Cw+3gjm/vYNPJTTzW5zHGxo1t9f2Olh/lptU3AfDWsLekxrDj33Df9/fhq/NlyaVLMKgNfHLwE3YU7FB6F5buW+o1zl1pdzF/+3wGtB3A+6PfZ3PeZnqEN2jwG8R3Od81+b6vzpeRMSMZFj2MLiFdOFp+lGtXXUuMXwyTO09WmnUGtB3glYcJMARg1prr7YoujblUMQxPXvwk939/PyDlH7QqLYv3LuZQ6SH+r+P/tWj+HtHDgZIDbDq5CZAW07oL9r8S/sVdPe6qt2NqLURRZGfhTjIPZ/LjyR8BSf0uIy6DMR3GtDhvsH//fq/wZUvvDfWNhZdhOW0/6h5r1vg0cs6D9zzIA/dIZd8Ot8NrYQw1hSoCO7Wva81cRUTFu2gpy6m8G5d5oZSxRJFHZj3Cjs07vOZy9ZSrufz/JFZk2eM4H9TeskdyrqhdkXQhIBugMnsZwargc6p8+1sahiDDmWqTukYhIy6DWT1m4af3w+F2MHP9TH7I/YE5vee0iIq7LmS5T4/oYdHwRcT4xbBw90JF6zkpMIlpa6cp4YlAQyA9wnqQVZ6l0E/ckHwDd6XdhSAI7C3ey9t73+aKhCvoHdm7RXOQKTZ8dD5KZ6WP1ofUsFSFeTQpKKleOWZSYBKP9X2Mezfcy7yt87wquC4Kv4ie4T3ZfGozh8sOc+XnV/JEvyfoEnKGr6k2r9ComFF8+OuH/FzwM1qVlttTb2df8T7Wn1jfpGEosZWw6eQmNuVuYuPJjQ2Gcfz0fkzpPIUrE66s18PRWhTUFPDZkc9YcXgF2RXZGDVGhkcPJyMug9TQ1N9E87de6Oh3kBkONgZTbCtWOr4jzZH4Ghon5DtbyGpuDrcDm9umfLW7znR7O9wOXB6X1LynkZr2Xn3lVfRqvcLVZHfZySrPwqAx0N63fYMJV5lXKb8mv1GK8NZA1p2waC3o1XovIyXnLer2lNSF3CMhl5g3amBP52wqnZXNigcVWYsothVj0piUDuxWf7ZWX/EXgFwPXBtGjZEXBrxAn6g+gNSmfvf6u9mQs4GHez/M+ISGxcebwrGKY9y0+iasLisz02ayJnsNr/zyitc5+dX59InsQ1pYGqlhqYr4vMvj4q71d5EUmMT0rtOVxeKO1Dv4+vjX/Hfnf3m0z6MtmkdSQBInq08qgvVpYWnE+8e3aEdxacyl7C/ez+K9i+kY2FF5DiW2Erbnb+eG5BvoE9mHRzY9wrVfXsuNyTdyS7db0Kl1XhTXgiBwXafr+LngZz48+CF39biLN4a90aD7vbtoNz/k/sDG3I3sK96ndLH3iexDv6h+9I7szZ3f3kledR6TUiYxPn78OSXaHG4H60+sJ/NwJhtPbsQjekgNTWVSyiSGRw8/Z2PzZ4QgCAqFS25VLicqT+Dn8CPCHHFeejBq30en1kl8Q7V6MURR9OrFaKx5+p9+hAAAIABJREFUTyWo0Kq1ymLpp/fD5XE1SO4nV0zF+MXgcDsosZVQaitVmj9NWkkjwea2NZmvkOHyuBQvoLaRMOvMmFQSiV8kkWcow0/nJWrPXxRFiRZFVa3kI5oqaw4jDEApra10VNbbLPnr/RVhoWpnNfnkU1RTRObmTK5KuqpFLNJ/u+TzqepTDP3YuxltVOwoHu71sLIAON1O7v7ubr498S3/7vlvJiRNaNWcapw1zXINze03lx5hPYiwRLRqbIBntj7D0n1L+WjMRyQGJjZ7vvwzPtvdrtvj5pavb2Hrqa0sGr6IbqHdeHf/uzy15Sk+vexT4gPiqXJU8ey2Z/nk0CfE+cfxeL/HSQ5KVvIbu6/fzcbcjdy87mbAW6XuVPUpNuZuZOPJjfx08icqnZVSl3ZIV/pG9lVKSWsvSE63E+E0ncTZ4kDJAaXnoNxeTqgplLEdxjI2bqzSt3GuaK205x8RHtFDkbWIwppCNCoNUZaoJgn5LjS8DIbL3qAXKQhCg3xSdZlJ3R435Y5yiq3FONwONCoNAYYAAvQBiriQ/GqNzKdeo1coO2qr74mi6NUr0VBYzaAxSP0Rp/MRTcHtcXOg5AB+ej/FwPrrpTJ3p8eJ1WmlxlXDoV8Pcfue27ks7jJlQ/m3o91uDBtyNvDgDw96UTEsuXQJ3UO7K/93epzc8909fH38ax7o+QBXJTVMD1AbpbZSdhTsYEf+Drbnb2dv8V7lPY1KQ6+IXkoj2LyL551VmWttlNvLGfnpSDoHd+a1oU3LYZ4vlNvLmbhyIna3nfdHv8/t39yOR/Tw4ZgPvc77Pud75vw4h2JrMZM7T+b1Xa8DsOmqTaw9tpZHNj0CQOfgznQP7c7G3I0KO2mYKYx+Uf3oG9WXnhE98dWd/9BFma2ML45+QebhTA6UHECr0jKo3SAy4jLoHdH7vO6G4a9hGGRYnVZyqnJwuB0EGAIIM4Wd9+fVWpTaSjlZdZIQUwhBhqB6HobdZcfpOdOvIHsoDRkMWYmuylGlhHiCDEGKN+r2uLG5bYqhaCzRXRe1S1/lsJMsLmR1WZWQU93OaQEBi86Cn95PYXaoC4fb4aXY1hj2799PbEKsVyf0374qyelxsuDnBSze483hc03Ha+oZhdkbZvP18a+5L/2+Ro3CqepTilrYjvwdysKmU+m8umXfHvE2DreDu9ffTaAhkJcGveQl8HK28NP7Ma3LNJ7Z9gwbczfSN6rvOY/Zknu+OOhFrll1DVPWTCGrPIt7L7q33nkXt7mY5WOXM2/LPMUoAOwr3kd+dT4CAg/0fIAnNj/BgZID9AjrweXxl9M3si8d/DtckBi+2+Nm08lNLD+8nPUn1uP0OOkY2JEHej7AyJiRDYYW/0F9GLVGOvh3IL8mnxKrRPAWZYn63UJtNpeNvOo8zFozIcYQKVSkMtWbj9vjVhLf8svmstVb2GWD4av3pcpRpVT+mLVmAg2BXs1rAPhIa4bNZaPKWdWgvjWclmQ93ZeQT75Egnc65GTRWpQGTjlUVumolEJZp6lBKh2SBy1XNZk0JuXvRA5LyTTbTaGhRuDG8Jc3DHlVedy74V6lFLVjYEdu7nozd3x7h1dHocvj4r4N97H22Fruveheru4oUV6Lokh2RbZiBHYU7FBooc1aM91CuzG6w2hSQ1MJNAQybe00fHQ+LBy2kN2Fu3lyy5PE+sfy8qCXW0W81hwmJk3kvQPv8dz25+gV0es32bklBCTwn77/YdZ3s1AL6kaZZH11vjzR7wmGth/Kc9ueI7simz1Fe8ivySfIGMSExAl0CelCtG/0BV1UssuzyTycyedHPqfAWoC/3p8JiRPIiMtoUQjuH9SHSlARYY7AV+dLbmUuR8uPEmwMJsQUct7E7ufOncsDDzyg/H/SpEmsXLmS0NBQ9uzZA0gL4oyZM/jmq28wG83EdYhj8eLF+PvXV+xTq9Rs3rCZZ599lpUrVyrHPaLHy7OQv6+7c5dj9SCFecJMYRg1RkXeU6vT8smyT9i2bRsLFizgv6/+F4/Ww+DLB5N1KIt7ptyDIAjMXzSfDWs38MHbH9CpSyfmvTZPGdOitShd1aGmUIUyvNJRSY2zRmEJLrWVSmysp0NNMhnkuYRUG8Jf2jB8d+I7Htz4IOX2cnQqHbd0u4Xrk69X4npy1YfL4+L+7+9nzbE13JV2Fz3CevC/ff9jR4EUGqpdMZQWlsY1Ha8hNSyVxIBEZUHOq8rjxtU3Uums5LUhr7Hi8AqWHVjGJW0uYV7/eedcPlkXOrWOO9PuZNZ3s/jsyGdnVTF1NhgePVxxt4ONwU2eO6DtAAa0HcCln1zK3uK91DhrCDOFIQgCnYI6XZD5VTurWZ29mszDmfxc8DMqQUW/qH7cH3c/l7S5pEX8+BcK87bMa7Cb/FyQFJjE7PT6ZIKtQVN6DI3BrDXTwb8Dp2pOUWQtotJZSZQlShGNORfUNQw33HADM2bM4LrrrgOkzVpedR7p/dN57unn8DP6MXv2bJ588knmzZvX4vuoBJVCrUGtzbRH9Hh7GKcb2kDyUmR6GJCoK/RqvdIJ7hE9zLjljB765ws/58pxVzJj9gyKrEV8sPgDXn3/Vdq0PyO0VZuBVU6CW7RSNVGQIQiX6FI8h2pHNU63k8KawlY1xLUWf0nD4PQ4eWnHS4pOQWpoKo/2eVTJxmtUGjLiMkgPT8flcfHADw/wVfZXaFVa3tj1BvO3zwckSoy+kX2Vss5o3+gGQx2nqk8xafUkKuwVzB84n1d+eYWNuRu5vtP1zEybecF288PaS/0GC35e8JtWz7Qk71IbKcEp7CrchUlrop1P6wm9moMoimzL30bm4UzWHluL1WUlxi+GmWkzGRM7xqs66u+IjIwMTpw4gc1m44477mDq1KlYLJYW6THMmTNH0WMASElJUXbdI0aMoF+/fmz6cRMdOnUg46oMXn/mdUqLSnn33XdJT0+nurqa2267jd27d+NyuZgzZw5jx47l7bff5rPPPqunx3DfffdhtVrp1q0bycnJvPvuu/Tv35/s7Gzl85TaJYK6y0ddjp9RCgP26tWLjz/+uEXPo7VzkiGKIuWOcvKq8vCIHpYvW87CFxcSEhZC+w7t0ekkLfVXn3kVXx9fOnXsxPMvPI9areb7778nKTGJnGM53H393Vx57ZVccdMV9ebmET1K2AnOaC9YtBaF/63KUUWFo4IqZ5VSWHK0/KhCxWHRWc7Ze/vLGYaTVSe5Z8M90kKkMTEzbSb/SvxXvQf1n75SxdA3x7/hy6NfAlIDk2wE0sLSWtTEJBuFMnsZj/R+hHlb5pFdnu2lo3yhIAgC9/S4h2u/vJZ39r3D9K7TL+j9zhbJQcmK4b0o/KLzNu6p6lOsOLyCFUdWcKLyBGatmZExI8mIy6BrSNffpOegNTjXnf3ZYtGiRQQGBmK1WrnooosYP3481dXVpKSktEqPoS4OHz7MRx99xBtvvEGPi3qwZvkaFn22iI1rN/L4E4/z2YrPeOKJJxg0aBCLFi2irKyM9PR0hgyRlP527tzJzz//jF6vJzExkdtuu03RY9i5c2eD97S6rJyqPoVFZ/HyWBctWsSECS2rHmztnNq2bQtIf29yh/LxnOO89sxrfPj1h5gsJiZdPonOXTsTYgpBp9IhiiJpA9IYf914TGYTN956I2qVmpWrVvL+yveJCItQaDRkuc+Gmt9kpli5y1kOOwUZg4iyRHG04ih2l0SUJ3sVakGNr94Xf71/o+JAzeEvZRi+Pf4t/974byocFfSN6ssjvR5pthy0T2QfFg5bSEJAQpNZ/YaQX53P5DWTKbGVML3rdOZunotbdPP60NdJj0g/l4/SYnQL7cbQ9kNZvGcxV8Rf8YfcHScHS41uTo+TMFPYOY1ld9v55vg3SkeyiEh6eDrTu05ncLvBf8ueg+bw0ksvsXz5cgBOnDjBoUOHUKvVjB8v9aQcOHCA2NhYYmJiALjqqqt44403mh03JiaGzp2lcuSU5BSGDx9OW9+2xCbGcjDroKLH8Nlnn/Hss88CYLPZOH5cotQePHgwfn7Sjr9Tp04cO3ZMWYQbw4nKE6gFNVGWKGXBe+KJJ9BoNFx99dVNXivjfMxpx7YdDBo4iF7xvSi3lzNq3CiOHDxCia0ElaDCX+9PUmCSVNWkNxBmDlNyFxWOCoTqM4u1rLwnE/I53U6cHmeDpax1w04e0YNaUJMQmKCUwVY6KpV8hE6tU3o7WoO/hGFwup08v+N5lu5bip/ej7n95jI6dnSLLKVBYzgr3eDCmkImr5lMYU0ho2NH8+KOF4myRLFg0IIWNZCcT9yZeiffnviW/+78L3P6zPlN790SdArqhIAkFhRmbr1hEEWRfcX7WH54OauOrqLSUUmEOYJpXacxtsNY2vi0aX6QvynWr1/PunXr+PHHHzGZTAwYMACbzYbBYFDyCk2VrGs0GjyeM1q3DekxAKhUKvR6PX56P6L9oxHdIqeqT2F32Xnvw/fo3Mlbo3nz5s1e16vValyuxhcvuUPa5XYR7RetJFvfeecdVq5cyddff93inbEoinzyySckJnoXILR2TrKiXYAhgGBDMAX6AkwaEzWuGoqsReRW5eIRPeg1esW70ag0xAfE4x/gX6+0tm7zW2OQGYQ1ggary6po1MuU4XIZrNwrIes13LT6Jp4f+HyLysDPTxnB74z3f32fpfuWMjx6OJljMxnTYcwFDSMUWYuYtHoS+TX5dArqxIcHPyQ1NJX/jfzfb24UANr5tmNi4kSWH15+XojPzjfMWjMxftJutDUeQ4mthCV7lzDus3FM/GIimYczuTjqYt4c9iZfjf+KW7vd+o9RaAZ19Rh++umneuckJSWRlZWlxPE/+OAD5b3o6Gh27JDIJnfs2MHRo0ebvadWrUWr0hJhiaD3wN48Nf8pSqwliKLIzz//3Pz1Wi1Op7dWQpm9DI/oIdQcqniFX331FfPmzeOzzz7DZGq5pzh8+HAWLFigGMSWzKkuevbsyfr16ykuLsbpdPLxxx8rojhBhiCMWqO0c7eXUmwrptxerlB8CIJEwmfRSSGhSEskMX4xJAUmkRiYSLRfNBGWCAINgQ1KgMpehczf5HA7qLCf6QiXO7zDzeHE+8cT6x+Lj84Hk8bkZeSbwl/CYxgVO4quIV29eHouFGSjkF2RTaAhkG3527gi4Qoe6PlAq6QfzzemdZnGiiMrmL99Pq8OefV3m0djSAlOIas8i3BT03kbp8fJDzk/kHk4kw05G3CJLjoHd+ahXg8xImbEBWl6+yujKT0GGUajkVdeeYURI0YQHBxMevqZMOj48eNZsmQJ3bp146KLLiIhoeWEgIGGQJ75zzNMv206vdJ6ISAQFxPHF1980eR1U6dOpUuXLqSmpvLuu+9y5YQrWb9+PWUlZXSL78ajjz7KTTfdxIwZM7Db7QwdKjEZ9OrVi9dea77h86GHHuLOO++kS5cuiKJIdHS0VxlrSxAREcGcOXPo3bs3ERERpKam4naf7ilQqbHoLCQEJEiqcR6RnMocheW3qbCOrLxXt4rR7XE32bx3ovIEgiDQ3re917WCIGDUGPHR+bBg8IIWf75z6nwWBOEZYAzgAI4AN4qiWHb6vfuBmwA3cLsoiqtPH08D3gaMwCrgDlEURUEQ9MASIA0oBiaIopjd3BzORo/hbFFsLeam1TcpDW0qQcWsHrO4puM1f4hE5zt73+HZbc/y+tDX6RPZ5/eejhfWZK/hpZ9fYvllyxssGT1SdkTpOSi2FRNoCOSyDpcxtsNY4gLifocZnx/8WTqfq6qqsFikMMStt95KfHw8M2fOPC9ji6KoEPKpBJVEyKdvmYFXxIAEiUb9fNfr/xYQRZEqZ5VCpS0nsQMNgefE8QUSrYtG0BBsDMbhcRCgD2jw7+u31mNYC9wviqJLEIR5wP3AbEEQOgETgWQgElgnCEKCKIpu4FVgKvATkmEYAXyJZERKRVGMEwRhIjAPaB1J0QVEia2EyWsmK0bBpDHxzCXP0L9N/995ZmdwVdJVUtPbtufoObrn705XUBvDoocxLHqY17FKRyVfHv2SFYdXsKtoFxpBQ/82/cmIy6Bfm36/qwf2d8Obb77JO++8g8PhoHv37kybNu28jd0YIV+4ObzJhV4URXKrcnGJLmJ8Yv6URgGkz++j88FH54PNZaPEVkKZvYxSWylmrZkgYxAWreWsNpeiKGLWmxUZ4POFc3rSoiiuqfXfnwC5PnMs8L4oinbgqCAIh4F0QRCyAV9RFH8EEARhCZCBZBjGAnNOX/8x8LIgCIL4ByBzKrWVMnnNZA6XHQYg0hzJgsELWs2zf6GhU+u4M/VO7tlwD59nfU5GXMbvPaV68IgetpzaQubhTNYdW4fdbSfOP45ZPWYxOna0F6XIP/jtMHPmzPPmITQGg8ZAjF+MQsgnU2o0RshXZC2iylFFuDkco7ZljXOrV69m9mzvsuCYmBilKuts0LNnT+x2bwK9pUuXKhVZrYFBYyDSEkmoKZRSWyklthKOVxxHp9YRaAjEX+/f4g2dLAZ1PoR56uJ8jjgJkLNWUUiGQkbO6WPO09/XPS5fcwLgtAdSDgQBRXVvJAjCVCSvg3btzn/DVG2U2cqYvGayktTtGtKVFwa+0GzX7++F4dHDWbpvKQt2SE1v56MT9XwgtypX6jk4vIKT1Sfx0fqQEZdBRlwGyUHJf4hQ3D+48FAJKkJNofhofcityuVYxbEGCflkFTVfva+in90SDB8+nOHDh5/XOW/e3LB637lAo9JIxH/GICodlRRbizlVfYqCmgICDAEEGgK9KHsaQmt4klo9v+ZOEARhHdBQxvBBURRXnD7nQcAFvCtf1sD5YhPHm7qm/kFRfAN4A6QcQ6OTP0eU28uZsnYKB0sPAjAyZiSP9X2sVWRUvzUEQeDuHndz/VfXs2TvEqZ1PX8hgdbC6rKy7tg6Mg9nsuXUFgQEekX04o7UOxjUbtA5x1f/wZ8XRq2RWP9YSQjIWkyVs4ooSxRmrRmXx0VOZQ46tY5Ic+RfetNQmxyvxllDsa1YkQP11fkSaAz0Is2rDZkn6UKEjJs1DKIoDmnqfUEQrgdGA4NrhX1ygNpdIW2Ak6ePt2ngeO1rcgRB0AB+QMN0hb8Byu3lTFkzReG2mdFtBlO7TP1T/JKmhqUypN0Q3trzFuMTxv+m3o0oiuwq2sXyQ8tZnb2aKmcVbSxtuLXbrYztMPas9Cf+wV8TKkFFuDkcH53kPWSXZxNkDMLmsuEW3bT3bf+HypNdaJi0EjOs0+RURIQqHBUYNAaCDEH46n29GBwUw/B7eAxNQRCEEcBs4BJRFGtr5X0GLBMEYT5S8jke2CKKolsQhEpBEHoBm4HrgAW1rrke+BEpV/HN75VfqHBUMHXtVPaX7Eev1vN4v8cZET3i95jKWePOtDtZf2I9r+x8hYd7P3zB71dYU8jnWZ+TeTiTo+VHMWqMDG0/lIy4DNLC0s4b8+Y/+OvBrDXTwU+i85Z1iyMtkX9bj1Kr1hJmDiPEFEKZvYwSawm5Vbnk1+RLIkKGALQq7ZlQ0u/hMTSDl5F4Cdee3kn/JIrizaIo7hUE4UNgH1KI6dbTFUkA0zlTrvrl6RfAW8DS04nqEqSqpt8cFY4Kpq2Zxr7ifQQbg1kwaAEpwSm/x1TOCe192zMhaQLvHXiPqzteTQf/Duf9Hk63k+9yviPzcCY/5P6AW3TTPbQ7j/Z5lOHRw887o+w/+OtCrVITaYnEV+eLw+1QVMj+zlAJKgINgQToA6h2VlNsK6awppAiaxF+Oj/FIFyI5PM5beNEUYwTRbGtKIrdTr9urvXeE6IodhBFMVEUxS9rHd8mimLK6fdmyF6BKIo2URSvPD1muiiKWecyt7NBpaOS6Wuns6d4D0mBSbw36r0/pVGQMa3LNMwas8IWe77wa8mvzNsyj8EfDWbm+pnsK97HDck38FnGZyy5dAnj4sf9YxT+wVnBorPw2vOveYVsJ02aRGhoKCkp3n+L99xzD0lJSXTp0oXLL7+csrKyusMpWL9+PaNHj75g83777beZMUOi237ttddYsmQJIPFQdevWje7du3PkyBFeeuklOnbs2GJeJ5Dyhh8v+5hnHniGOP84AvQBVDgqFO/qj+gx/GVQ5aji5nU3s6toF4PaDuLJi5/80xOyBRgCmNJlCvO3z+envJ/oFVG/67WlKLeXs+roKjIPZ7KveB8alYaBbQeSEZdBn8g+f9oa898Sp+bOxb7//Oox6DsmEV5Lu+BscDZ6DBcSzekxyBg6dChPPvkkGo3mrPQYLhRuvlnZH5OZmcnYsWN59FFJZ/mVV17hyy+/VAgLWwu9Rk+EJUIqd7WX4hE9FyRM+0/gF6ke+Javb2FX4S4mpUzi+YHP/+mNgoz/6/h/RJojeW7bcwpXS0vh9rjZmLuRe767h4EfDmTu5rl4RA/3pd/HN1d+w/wB8+nfpv8/RuEPjoyMDNLS0khOTlZYUy0WCw8//DA9e/bkxx9/ZNWqVSQlJdGvXz9uv/12ZXc9Z84chYUUJD2G7OxssrOzSUpKYvLkyaSkpHD11Vezbt06+vbtS3x8PFu2bAEk7YNJkyZx0UUX0b17d1asWAFIO+xx48YxYsQI4uPjufdeSSa2th6DvKvu378/gYH1S1aHDRuGRiP97vXq1YucnJx65zSE1s6pMSxevJiEhAQuueQSNm7cqByXn9mqVat44YUXWLhwIQMHDuTmm28mKyuLyy67jOeff77BMbds2UKfPn3o3r07ffr04ddff1XeO3HiBCNGjCAxMZHH//M4wcZgzKKZUaNG0bVrV1JSUrx4rs4Joij+qV9paWniuaLCXiH+6/N/iZ8e/PScx/oj4osjX4gpb6eIKw6vaNH5x8qPiS9uf1Ec/OFgMeXtFLHve33FuT/NFfcV7bvAM/3rYd++3/+ZFRcXi6IoijU1NWJycrJYVFQkAuIHH3wgiqIoWq1WsU2bNmJWVpYoiqI4ceJEcdSoUaIoiuIjjzwiPvPMM8pYycnJ4tGjR8WjR4+KarVa3LVrl+h2u8XU1FTxxhtvFD0ej5iZmSmOHTtWFEVRvP/++8WlS5eKoiiKpaWlYnx8vFhVVSUuXrxYjImJEcvKykSr1Sq2a9dOPH78uCiKomg2m+t9hqNHj4rJycmNfsbRo0cr92kI3377rfKZzmZOdXHy5Emxbdu2YkFBgWi328U+ffqIt956a71nVvf5tW/fXiwsLGx0nuXl5aLT6RRFURTXrl0rjhs3ThRFUVy8eLEYHh4uFhUVKT/HrVu3ih9//LE4efJk5fqysrIGx23o9xDYJjayrv6z1QN8dD58MPo8Wdo/IEbEjGDpvqW8tOMlhrYf2mDTW42zhjXH1rD80HJ2FOxAJajoE9mHey66h4FtBzbbbPMP/rj4LfQYkpOTGTx4MIIg0LlzZ4Wp9XzrMTSE30OPYfPmzQwYMICQEEn/ZMKECRw8eLDVc6+L8vJyrr/+eg4dOoQgCF4ss0OHDiUoSGIGGDduHD/88AMjR45k1qxZzJ49m9GjR3PxxRef8xzgnxzD3wIqQcXdPe7mxtU38r99/2NKlymA5C3uKNhB5uFMVmevxuqy0t63PXek3sGY2DFnpZ3wD/5Y+K31GOTvZR0D8TxpHzSG31uP4XzjoYceYuDAgSxfvpzs7GwGDBjQ6P0EQSAhIYHt27ezatUq7r//foYNG8bDD597efo/OYa/CXqE92BQ20Es3L2QfcX7eHPXm4zJHMMNX93Amuw1XBpzKUsuXcLnGZ8zufPkf4zCXwS/hx5DbZyN9kFDegwN4Y+kx/DRRx+1eoyGUF5eTlSUxBL09ttve723du1aSkpKsFqtZGZm0rdvX06ePInJZOKaa65h1qxZys/qXPGPYfgbYWbaTBxuBxNWTuCln18ixPj/7d1diFR1GMfx74OaU5qppbI5kgqiiC3jJuK6S5QvZRFGroSCZhd1E0IvF4tL7oWgF0VEVmJBYtGLWWYvCFGhUheBYvSy1u6mYemm5baCmVdaTxfnvzpHzqw7urMzs/P7wGHOPOec4X+end1n53/O/P9jWF+3nr0P7mXd3HXMHDuzLL7ZLb23aNEizp8/T3V1Nc3NzZedj6G+vp5x48Zd6E5paGjg1KlTZDIZNm/enNd8DBD9B3zu3Dmqq6uZMWMGzc3Nlz2mez6G7q6h5cuXU1tbS3t7O+l0mi1btgCwevVqzpw5w8KFC8lkMrG7gfq6TZfKno9hwYIF1NTU5P0aSRobG2lqaqKuru7C/A7d6uvrWblyJZlMhoaGBmbNmkVLSwuzZ88mk8mwYcMG1q5d2yftuKr5GEpBf87HMBDsPLSTE2dPsHjyYiaMyL8/V/Kj+RikFPT3fAxSZpZMWVLsJkgJKuR8DFJ+VBhEpF/mY+gPpT4fQ7etW7eycePGWKyuro5NmzZd8Wv2JXUliRRQa2sr06ZN07UbKRp3p62tLa+uJF18FimgVCpFV1dXj7eEihSKu9PV1UUqld9ItepKEimgdDpNR0cHnZ2dxW6KVKhUKkU6nb78jllUGEQKaMiQIVc8YJpIsagrSUREYlQYREQkRoVBRERiyv52VTPrBH4rdjtK0E3AX8VuRAlSXnJTbpIN1Lzc4u5jkjaUfWGQZGZ2INc9ypVMeclNuUlWiXlRV5KIiMSoMIiISIwKw8B1+Sm4KpPykptyk6zi8qJrDCIiEqNPDCIiEqPCICIiMSoMJczMJpjZXjNrNbMfzezxEB9tZl+Y2aHwOCrrmCYzO2xm7WZ2d1b8NjNrCdtetDAOtJkNNbPtIb7PzCb293leKTMbZGbfmtmu8Lzi82JmI81sh5m1hfdNrfISMbMnw+/RQTPbZmYp5SYHd9dSogtQBdSE9euBn4HpwLPAmhBfAzwT1qcD3wNDgUnAL8CgsG0/UAvDqEw1AAADOklEQVQY8ClwT4g/BrwS1pcB24t93nnk5yngHWBXeF7xeQHeAB4J69cAI5UXBxgPHAGuDc/fAx5WbnLkq9gN0JLHDws+BhYC7UBViFUB7WG9CWjK2v+z8AauAtqy4suBV7P3CeuDib7hacU+117kIg3sBuZlFYaKzgswIvzxs0viFZ2X0NbxwDFgdGj3LuAu5SZ5UVdSmQgfS2cC+4Bx7n4CIDyODbt1v/m7dYTY+LB+aTx2jLufB04DNxbiHPrYC0Aj8F9WrNLzMhnoBLaGLrbXzGwYygvu/jvwHHAUOAGcdvfPUW4SqTCUATMbDnwAPOHuf/e0a0LMe4j3dEzJMrP7gJPu/k1vD0mIDbi8EP2XWgNsdveZwFmi7pFcKiUvhGsH9xN1C90MDDOzFT0dkhAbkLlJosJQ4sxsCFFReNvdd4bwn2ZWFbZXASdDvAOYkHV4Gjge4umEeOwYMxsM3ACc6vsz6VN1wGIz+xV4F5hnZm+hvHQAHe6+LzzfQVQoKj0vAAuAI+7e6e7ngJ3AXJSbRCoMJSzc7bAFaHX357M2fQKsCuuriK49dMeXhbsjJgFTgP3hI/IZM5sTXvOhS47pfq2lwB4PnaSlyt2b3D3t7hOJLvLtcfcVKC9/AMfMbGoIzQd+osLzEhwF5pjZdeGc5gOtKDfJin2RQ0vuBagn+ij6A/BdWO4l6rfcDRwKj6Ozjnma6A6KdsLdEiE+CzgYtr3MxW+9p4D3gcNEd1tMLvZ555mjO7h48bni8wJkgAPhPfMRMEp5uXBO64C2cF5vEt1xpNwkLBoSQ0REYtSVJCIiMSoMIiISo8IgIiIxKgwiIhKjwiAiIjEqDCJ9yMy+zhF/3cyW9nd7RK6ECoNIH3L3ucVug8jVGlzsBogMJGb2j7sPD9+KfYlo9NcjJI+jI1KS9IlBpDAeAKYCtwKPEo3LI1IWVBhECuN2YJu7/+vux4E9xW6QSG+pMIgUjsabkbKkwiBSGF8Rjc45KAznfGexGyTSW7r4LFIYHxJdeG4hmqv7y+I2R6T3NLqqiIjEqCtJRERiVBhERCRGhUFERGJUGEREJEaFQUREYlQYREQkRoVBRERi/gdOX02wFiL/5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "FPFN_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
