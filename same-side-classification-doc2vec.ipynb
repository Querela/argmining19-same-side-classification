{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:35:02.420986Z",
     "start_time": "2019-06-26T12:35:02.413592Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "# from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:18:50.407998Z",
     "start_time": "2019-06-26T12:18:50.405562Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:18:52.558618Z",
     "start_time": "2019-06-26T12:18:52.300804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:00:33.332063Z",
     "start_time": "2019-06-26T11:00:33.330171Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:00:33.361391Z",
     "start_time": "2019-06-26T11:00:33.356244Z"
    },
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:00:34.345752Z",
     "start_time": "2019-06-26T11:00:34.342067Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:00:39.324202Z",
     "start_time": "2019-06-26T11:00:37.370142Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:00.930528\n",
      "Time for [read within]: 0:00:01.014369\n"
     ]
    }
   ],
   "source": [
    "# escapechar to detect quoting escapes, else it fails\n",
    "\n",
    "# na_filter=False, because pandas automatic \"nan\" detection fails with the topic column, too\n",
    "# cross_test_df['topic'].astype(str)[9270]\n",
    "\n",
    "with Timer(\"read cross\"):\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    within_traindev_df = pd.read_csv(data_within_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:30.366812Z",
     "start_time": "2019-06-26T11:00:40.007171Z"
    },
    "code_folding": [
     1,
     12,
     14,
     17,
     19
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag cross traindev]: 0:00:35.189107\n",
      "Time for [tag cross test]: 0:00:19.834640\n",
      "Time for [tag within traindev]: 0:00:37.309147\n",
      "Time for [tag within test]: 0:00:18.014437\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross traindev\"):\n",
    "    cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "with Timer(\"tag cross test\"):\n",
    "    cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within traindev\"):\n",
    "    within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "with Timer(\"tag within test\"):\n",
    "    within_test_df = within_test_df.apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:30.562851Z",
     "start_time": "2019-06-26T11:02:30.554538Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_overview(df, task='same-side', class_name='is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task)\n",
    "    print('=' * 40, '\\n')\n",
    "\n",
    "    print('Total instances: ', total)\n",
    "    print('\\n')\n",
    "\n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t', is_same_side, ': ', len(side_df), ' instances')\n",
    "    print('\\n')\n",
    "\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "        print('\\n')\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))), '\\n')\n",
    "\n",
    "    print('-' * 40, '\\n')\n",
    "\n",
    "    arguments_length_lst = [\n",
    "        len(word_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_length_lst.extend(\n",
    "        [len(word_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Words:')\n",
    "    print('\\tshortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('\\tlongest argument:', max(arguments_length_lst), ' words')\n",
    "    print('\\targument average length:', np.mean(arguments_length_lst),\n",
    "          ' words')\n",
    "\n",
    "    arguments_sent_length_lst = [\n",
    "        len(sent_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_sent_length_lst.extend(\n",
    "        [len(sent_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Sentences:')\n",
    "    print('\\tshortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\tlongest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\targument average length:', np.mean(arguments_sent_length_lst),\n",
    "          ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:30.732372Z",
     "start_time": "2019-06-26T11:02:30.730309Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# with Timer(\"overview cross\"):\n",
    "#     get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:30.900880Z",
     "start_time": "2019-06-26T11:02:30.899095Z"
    }
   },
   "outputs": [],
   "source": [
    "# with Timer(\"overview within\"):\n",
    "#     get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to only tagged input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_traindev_df = within_traindev_df[(within_traindev_df['tag'] == 'gay marriage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_traindev_df = cross_traindev_df[(cross_traindev_df['tag'] == 'gay marriage') | (cross_traindev_df['tag'] == 'abortion')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.072476Z",
     "start_time": "2019-06-26T11:02:31.069500Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.244617Z",
     "start_time": "2019-06-26T11:02:31.238033Z"
    },
    "code_folding": [
     0,
     15,
     22,
     40
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v)\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # As default pos in lemmatization is Noun\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "def lemmatize_stemming(token, pos_tag):\n",
    "    '''lemmatize words (with POS information) and then stem'''\n",
    "    stemmer = SnowballStemmer(\n",
    "        \"english\")  # pOrter, M. \"An algorithm for suffix stripping.\"\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(token, pos=pos_tag))\n",
    "\n",
    "\n",
    "def do_segmentation(text):\n",
    "    '''do sentence segmentation, tokenization (with lemmatization&stemming)'''\n",
    "    lemma = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('\\n', ' ').strip()\n",
    "        tokens = [token for token in word_tokenize(sentence)]\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "        for idx in range(0, len(tokens)):\n",
    "            token = tokens[idx].lower()\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(\n",
    "                    token) > 3:\n",
    "                wordnet_pos = get_wordnet_pos(pos_tags[idx][1])\n",
    "                l_ = lemmatize_stemming(token, wordnet_pos)\n",
    "                lemma.append(l_)\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    '''concat lemmatized words together again'''\n",
    "    lemma = do_segmentation(text)\n",
    "    return ' '.join(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting n grams lemma for argument1 and argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.417931Z",
     "start_time": "2019-06-26T11:02:31.410882Z"
    },
    "code_folding": [
     0,
     38
    ]
   },
   "outputs": [],
   "source": [
    "def extract_ngrams(X_train, X_dev, col, idx='id'):\n",
    "    vectorizer = CountVectorizer(min_df=600,\n",
    "                                 max_df=0.7,\n",
    "                                 ngram_range=(3, 3),\n",
    "                                 max_features=5000)\n",
    "\n",
    "    vectorizer.fit(X_train[col])\n",
    "    features = vectorizer.transform(X_train[col])\n",
    "    features_dev = vectorizer.transform(X_dev[col])\n",
    "\n",
    "    train_df = pd.DataFrame(features.todense(),\n",
    "                            columns=vectorizer.get_feature_names())\n",
    "    train_df = train_df.add_prefix(col)\n",
    "\n",
    "    aid_df = X_train[[idx]]\n",
    "\n",
    "    train_df = train_df.merge(aid_df,\n",
    "                              left_index=True,\n",
    "                              right_index=True,\n",
    "                              suffixes=(False, False),\n",
    "                              how='inner')\n",
    "    train_df.set_index(idx, inplace=True)\n",
    "\n",
    "    dev_df = pd.DataFrame(features_dev.todense(),\n",
    "                          columns=vectorizer.get_feature_names())\n",
    "    dev_df = dev_df.add_prefix(col)\n",
    "\n",
    "    aid_dev_df = X_dev[[idx]]\n",
    "\n",
    "    dev_df = dev_df.merge(aid_dev_df,\n",
    "                          left_index=True,\n",
    "                          right_index=True,\n",
    "                          suffixes=(False, False),\n",
    "                          how='inner')\n",
    "    dev_df.set_index(idx, inplace=True)\n",
    "    return train_df, dev_df\n",
    "\n",
    "\n",
    "def extract_n_grams_features(X_train, X_dev, columns, idx='id'):\n",
    "    X_train = X_train.reset_index()\n",
    "    result_train_df = X_train[[idx]]\n",
    "    result_train_df.set_index(idx, inplace=True)\n",
    "\n",
    "    X_dev = X_dev.reset_index()\n",
    "    result_dev_df = X_dev[[idx]]\n",
    "    result_dev_df.set_index(idx, inplace=True)\n",
    "\n",
    "    for col in columns:\n",
    "        result_train_df_, result_dev_df_ = extract_ngrams(X_train, X_dev, col)\n",
    "        result_train_df = result_train_df.join(result_train_df_)\n",
    "        result_dev_df = result_dev_df.join(result_dev_df_)\n",
    "    return result_train_df, result_dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Doc2Vec model and vectorize argument1 and argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.593837Z",
     "start_time": "2019-06-26T11:02:31.585675Z"
    },
    "code_folding": [
     0,
     15,
     34,
     56
    ]
   },
   "outputs": [],
   "source": [
    "def make_d2v_docs(row):\n",
    "    words1 = do_segmentation(row['argument1'])\n",
    "    words2 = do_segmentation(row['argument2'])\n",
    "\n",
    "    row['argument1_doc'] = TaggedDocument(words=words1,\n",
    "                                          tags=[row['argument1_id']])\n",
    "    row['argument2_doc'] = TaggedDocument(words=words2,\n",
    "                                          tags=[row['argument2_id']])\n",
    "\n",
    "    row['argument1_lemmas'] = ' '.join(words1)\n",
    "    row['argument2_lemmas'] = ' '.join(words2)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "class DatasetIter:\n",
    "    def __init__(self, ds, shuffle=True):\n",
    "        self.ds = ds\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def _make_taggeddocs(self, row):\n",
    "        yield row['argument1_doc']\n",
    "        yield row['argument2_doc']\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.ds = self.ds.sample(frac=1)\n",
    "\n",
    "        for _, row in self.ds.iterrows():\n",
    "            for doc in self._make_taggeddocs(row):\n",
    "                yield doc\n",
    "\n",
    "\n",
    "# https://github.com/RaRe-Technologies/gensim/blob/2024be9053094fbb2e765b9a06b9dc580f55c505/gensim/test/test_doc2vec.py#L501\n",
    "class ConcatenatedDoc2Vec(object):\n",
    "    \"\"\"\n",
    "    Concatenation of multiple models for reproducing the Paragraph Vectors paper.\n",
    "    Models must have exactly-matching vocabulary and document IDs. (Models should\n",
    "    be trained separately; this wrapper just returns concatenated results.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        if hasattr(models[0], 'docvecs'):\n",
    "            self.docvecs = ConcatenatedDocvecs([model.docvecs for model in models])\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return np.concatenate([model[token] for model in self.models])\n",
    "\n",
    "    def infer_vector(self, document, alpha=0.1, min_alpha=0.0001, steps=5):\n",
    "        return np.concatenate([model.infer_vector(document, alpha, min_alpha, steps) for model in self.models])\n",
    "\n",
    "    def train(self, *ignore_args, **ignore_kwargs):\n",
    "        pass  # train subcomponents individually\n",
    "\n",
    "\n",
    "class ConcatenatedDocvecs(object):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return np.concatenate([model[token] for model in self.models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:46:41.508871Z",
     "start_time": "2019-06-26T11:46:41.497868Z"
    },
    "code_folding": [
     0,
     6,
     19
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, X_dev, workers=2, epochs=30):\n",
    "    with Timer(\"doc2vec dbow\"):\n",
    "        # columns=['argument1_lemmas', 'argument2_lemmas']\n",
    "        # pd.concat([X_train[columns], X_dev[columns]])\n",
    "        alpha = 0.025  # https://radimrehurek.com/gensim/models/base_any2vec.html#gensim.models.base_any2vec.BaseWordEmbeddingsModel\n",
    "        # %%time\n",
    "        model_dbow = Doc2Vec(DatasetIter(X_train, shuffle=True),\n",
    "                             dm=0,\n",
    "                             vector_size=300,\n",
    "                             negative=5,\n",
    "                             hs=0,\n",
    "                             min_count=2,\n",
    "                             sample=0,\n",
    "                             workers=workers,\n",
    "                             epochs=epochs,\n",
    "                             alpha=alpha,\n",
    "                             min_alpha=alpha - (epochs * 0.002))\n",
    "        \n",
    "    with Timer(\"doc2vec dmm\"):\n",
    "        model_dmm = Doc2Vec(DatasetIter(X_train, shuffle=True),\n",
    "                            dm=1,\n",
    "                            dm_mean=1,\n",
    "                            vector_size=300,\n",
    "                            window=10,\n",
    "                            negative=5,\n",
    "                            min_count=1,\n",
    "                            workers=workers,\n",
    "                            epochs=epochs,\n",
    "                            alpha=0.065,\n",
    "                            min_alpha=0.065 - (epochs * 0.002))\n",
    "        \n",
    "    return model_dbow, model_dmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.935090Z",
     "start_time": "2019-06-26T11:02:31.932250Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# unused\n",
    "def vec_for_learning(model, df):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:32.106479Z",
     "start_time": "2019-06-26T11:02:32.103067Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_vectors(X_train, X_dev, model):\n",
    "    def make_d2v_vecs(row):\n",
    "        vec1 = model.infer_vector(row['argument1_doc'].words, steps=20)\n",
    "        vec2 = model.infer_vector(row['argument2_doc'].words, steps=20)\n",
    "\n",
    "        row['argument1_vec'] = vec1\n",
    "        row['argument2_vec'] = vec2\n",
    "        \n",
    "        return row\n",
    "\n",
    "    X_train = X_train.progress_apply(make_d2v_vecs, axis=1)\n",
    "    X_dev = X_dev.progress_apply(make_d2v_vecs, axis=1)\n",
    "    \n",
    "    return X_train, X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:51:24.766258Z",
     "start_time": "2019-06-26T11:51:24.753098Z"
    },
    "code_folding": [
     0,
     10,
     20
    ]
   },
   "outputs": [],
   "source": [
    "def make_vector_comparison_diff(X_train, X_dev):\n",
    "    def ret_vec_diff(row):\n",
    "        return row['argument1_vec'] - row['argument2_vec']\n",
    "\n",
    "    X_train_diff = X_train.progress_apply(ret_vec_diff, axis=1)\n",
    "    X_dev_diff = X_dev.progress_apply(ret_vec_diff, axis=1)\n",
    "\n",
    "    return X_train_diff, X_dev_diff\n",
    "\n",
    "\n",
    "def make_vector_comparison_concat(X_train, X_dev):\n",
    "    def ret_vec_concat(row):\n",
    "        return np.concatenate((row['argument1_vec'], row['argument2_vec']))\n",
    "\n",
    "    X_train_concat = X_train.progress_apply(ret_vec_concat, axis=1)\n",
    "    X_dev_concat = X_dev.progress_apply(ret_vec_concat, axis=1)\n",
    "\n",
    "    return X_train_concat, X_dev_concat\n",
    "\n",
    "\n",
    "def make_vector_comparison(X_train, X_dev, mode=\"diff\"):\n",
    "    if mode == \"concat\":\n",
    "        X_train, X_dev = make_vector_comparison_concat(X_train, X_dev)\n",
    "    else:\n",
    "        X_train, X_dev = make_vector_comparison_diff(X_train, X_dev)\n",
    "\n",
    "    # array of array to 2d array\n",
    "    X_train = np.array(list(X_train.values))\n",
    "    X_dev = np.array(list(X_dev.values))\n",
    "\n",
    "    return X_train, X_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:52:15.777378Z",
     "start_time": "2019-06-26T12:52:15.768729Z"
    },
    "code_folding": [
     22,
     33,
     44,
     56
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_test_svm(X_train, y_train, X_test):\n",
    "    with Timer(\"StandardScaler fit\"):\n",
    "        scaler = StandardScaler(copy=True, with_mean=False)\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "    with Timer(\"StandardScaler transform\"):\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # ------------------\n",
    "\n",
    "    with Timer(\"SVC (linear) fit\"):\n",
    "        # svclassifier = SVC(kernel='linear')\n",
    "        svclassifier = LinearSVC()        \n",
    "        svclassifier.fit(X_train, y_train)\n",
    "\n",
    "    with Timer(\"SVC predict\"):\n",
    "        y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def train_test_logreg(X_train, y_train, X_test):\n",
    "    with Timer(\"LogisticRegression fit\"):\n",
    "        logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "        logreg.fit(X_train, y_train)\n",
    "    \n",
    "    with Timer(\"LogisticRegression predict\"):\n",
    "        y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def train_test_sgd(X_train, y_train, X_test):\n",
    "    with Timer(\"SGDClassifier fit\"):\n",
    "        sgdcla = SGDClassifier()\n",
    "        sgdcla.fit(X_train, y_train)\n",
    "    \n",
    "    with Timer(\"SGDClassifier predict\"):\n",
    "        y_pred = sgdcla.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def heatconmat(y_test, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(y_test.unique()))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, name=None, heatmap=True):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    if heatmap:\n",
    "        heatconmat(y_test['is_same_side'], y_pred)\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2), '\\n')  #\n",
    "\n",
    "    print('Report{}:'.format(\"\" if not name else \" for [{}]\".format(name)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    f1_dic = {}\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:19:28.820114Z",
     "start_time": "2019-06-26T13:19:28.763482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train]: 0:00:00.051779\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:40:01.100088Z",
     "start_time": "2019-06-26T13:19:32.816435Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44732/44732 [14:23<00:00, 51.79it/s]\n",
      "100%|██████████| 19171/19171 [06:04<00:00, 52.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2 - tokenize]: 0:20:28.278134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. tokenize (make doc2vec docs + lemma string)\n",
    "# tqdm.pandas()\n",
    "with Timer(\"2 - tokenize\"):\n",
    "    X_train = X_train.progress_apply(make_d2v_docs, axis=1)\n",
    "    X_dev = X_dev.progress_apply(make_d2v_docs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:32:34.812979Z",
     "start_time": "2019-06-26T14:32:28.131449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2a - pickle]: 0:00:06.676402\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"2a - pickle\"):\n",
    "    X_train.to_pickle(\"data/X_train.cross_td.p\")\n",
    "    X_dev.to_pickle(\"data/X_dev.cross_td.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:08:32.385935Z",
     "start_time": "2019-06-26T13:08:29.231234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2b - unpickle]: 0:00:03.149843\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"2b - unpickle\"):\n",
    "    X_train = pd.read_pickle(\"data/X_train.cross_td.p\")\n",
    "    X_dev = pd.read_pickle(\"data/X_dev.cross_td.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:59:14.335912Z",
     "start_time": "2019-06-26T13:40:06.211724Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:40:06,213 : INFO : collecting all words and their counts\n",
      "2019-06-26 15:40:06,228 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-06-26 15:40:06,728 : INFO : PROGRESS: at example #10000, processed 747850 words (1499229/s), 23869 word types, 2334 tags\n",
      "2019-06-26 15:40:07,240 : INFO : PROGRESS: at example #20000, processed 1480421 words (1435534/s), 33053 word types, 3864 tags\n",
      "2019-06-26 15:40:07,757 : INFO : PROGRESS: at example #30000, processed 2241461 words (1472511/s), 38835 word types, 5098 tags\n",
      "2019-06-26 15:40:08,269 : INFO : PROGRESS: at example #40000, processed 2982076 words (1450841/s), 42821 word types, 6096 tags\n",
      "2019-06-26 15:40:08,789 : INFO : PROGRESS: at example #50000, processed 3729338 words (1439301/s), 45834 word types, 6958 tags\n",
      "2019-06-26 15:40:09,312 : INFO : PROGRESS: at example #60000, processed 4501107 words (1478209/s), 47780 word types, 7722 tags\n",
      "2019-06-26 15:40:09,828 : INFO : PROGRESS: at example #70000, processed 5247281 words (1446187/s), 48880 word types, 8350 tags\n",
      "2019-06-26 15:40:10,350 : INFO : PROGRESS: at example #80000, processed 5996116 words (1438510/s), 49866 word types, 8903 tags\n",
      "2019-06-26 15:40:10,849 : INFO : collected 50325 word types and 9303 unique tags from a corpus of 89464 examples and 6707530 words\n",
      "2019-06-26 15:40:10,849 : INFO : Loading a fresh vocabulary\n",
      "2019-06-26 15:40:10,920 : INFO : effective_min_count=2 retains 45414 unique words (90% of original 50325, drops 4911)\n",
      "2019-06-26 15:40:10,921 : INFO : effective_min_count=2 leaves 6702619 word corpus (99% of original 6707530, drops 4911)\n",
      "2019-06-26 15:40:11,020 : INFO : deleting the raw counts dictionary of 50325 items\n",
      "2019-06-26 15:40:11,023 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-06-26 15:40:11,023 : INFO : downsampling leaves estimated 6702619 word corpus (100.0% of prior 6702619)\n",
      "2019-06-26 15:40:11,173 : INFO : estimated required memory for 45414 words and 300 dimensions: 144724800 bytes\n",
      "2019-06-26 15:40:11,174 : INFO : resetting layer weights\n",
      "2019-06-26 15:40:11,653 : INFO : training model with 3 workers on 45414 vocabulary and 300 features, using sg=1 hs=0 sample=0 negative=5 window=5\n",
      "2019-06-26 15:40:12,666 : INFO : EPOCH 1 - PROGRESS: at 5.25% examples, 374074 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:13,686 : INFO : EPOCH 1 - PROGRESS: at 10.41% examples, 362844 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:14,694 : INFO : EPOCH 1 - PROGRESS: at 16.62% examples, 380446 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:15,700 : INFO : EPOCH 1 - PROGRESS: at 25.05% examples, 431396 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:16,711 : INFO : EPOCH 1 - PROGRESS: at 34.01% examples, 465429 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:17,739 : INFO : EPOCH 1 - PROGRESS: at 42.11% examples, 475497 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:18,747 : INFO : EPOCH 1 - PROGRESS: at 47.12% examples, 455873 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:19,765 : INFO : EPOCH 1 - PROGRESS: at 53.86% examples, 452832 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:20,777 : INFO : EPOCH 1 - PROGRESS: at 59.24% examples, 443114 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:21,783 : INFO : EPOCH 1 - PROGRESS: at 67.09% examples, 451328 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:22,793 : INFO : EPOCH 1 - PROGRESS: at 75.87% examples, 464266 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:23,815 : INFO : EPOCH 1 - PROGRESS: at 84.95% examples, 474579 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:24,815 : INFO : EPOCH 1 - PROGRESS: at 92.57% examples, 478003 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:25,831 : INFO : EPOCH 1 - PROGRESS: at 98.01% examples, 469741 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:26,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:40:26,034 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:40:26,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:40:26,037 : INFO : EPOCH - 1 : training on 6707530 raw words (6792083 effective words) took 14.4s, 472333 effective words/s\n",
      "2019-06-26 15:40:27,064 : INFO : EPOCH 2 - PROGRESS: at 5.91% examples, 389619 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:28,064 : INFO : EPOCH 2 - PROGRESS: at 14.52% examples, 477426 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:29,075 : INFO : EPOCH 2 - PROGRESS: at 22.94% examples, 515444 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:30,081 : INFO : EPOCH 2 - PROGRESS: at 31.58% examples, 532345 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:31,083 : INFO : EPOCH 2 - PROGRESS: at 40.30% examples, 547668 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:32,086 : INFO : EPOCH 2 - PROGRESS: at 49.09% examples, 555918 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:33,105 : INFO : EPOCH 2 - PROGRESS: at 57.04% examples, 550629 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:34,125 : INFO : EPOCH 2 - PROGRESS: at 63.12% examples, 530509 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:35,170 : INFO : EPOCH 2 - PROGRESS: at 69.12% examples, 514874 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:36,213 : INFO : EPOCH 2 - PROGRESS: at 74.61% examples, 498462 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:37,243 : INFO : EPOCH 2 - PROGRESS: at 79.68% examples, 483842 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:38,256 : INFO : EPOCH 2 - PROGRESS: at 86.47% examples, 481096 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:39,257 : INFO : EPOCH 2 - PROGRESS: at 92.50% examples, 476440 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:40,271 : INFO : EPOCH 2 - PROGRESS: at 98.24% examples, 469194 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:40,437 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:40:40,452 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:40:40,464 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:40:40,465 : INFO : EPOCH - 2 : training on 6707530 raw words (6792083 effective words) took 14.4s, 470897 effective words/s\n",
      "2019-06-26 15:40:41,477 : INFO : EPOCH 3 - PROGRESS: at 5.13% examples, 336755 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:42,489 : INFO : EPOCH 3 - PROGRESS: at 10.55% examples, 354469 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:43,511 : INFO : EPOCH 3 - PROGRESS: at 16.58% examples, 373064 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:44,551 : INFO : EPOCH 3 - PROGRESS: at 21.91% examples, 365999 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:45,568 : INFO : EPOCH 3 - PROGRESS: at 29.42% examples, 392961 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:46,578 : INFO : EPOCH 3 - PROGRESS: at 38.63% examples, 430877 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:47,592 : INFO : EPOCH 3 - PROGRESS: at 47.41% examples, 455071 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:48,626 : INFO : EPOCH 3 - PROGRESS: at 55.12% examples, 459963 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:49,649 : INFO : EPOCH 3 - PROGRESS: at 63.13% examples, 469386 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:50,658 : INFO : EPOCH 3 - PROGRESS: at 67.97% examples, 454090 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:51,665 : INFO : EPOCH 3 - PROGRESS: at 72.38% examples, 440039 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:52,666 : INFO : EPOCH 3 - PROGRESS: at 77.36% examples, 431786 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:53,698 : INFO : EPOCH 3 - PROGRESS: at 82.30% examples, 422946 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:54,750 : INFO : EPOCH 3 - PROGRESS: at 87.36% examples, 415584 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:55,767 : INFO : EPOCH 3 - PROGRESS: at 93.13% examples, 412769 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:40:56,806 : INFO : EPOCH 3 - PROGRESS: at 98.25% examples, 407834 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:56,976 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:40:56,995 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:40:57,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:40:57,005 : INFO : EPOCH - 3 : training on 6707530 raw words (6792083 effective words) took 16.5s, 410709 effective words/s\n",
      "2019-06-26 15:40:58,009 : INFO : EPOCH 4 - PROGRESS: at 4.71% examples, 310519 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:40:59,027 : INFO : EPOCH 4 - PROGRESS: at 9.95% examples, 336670 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:00,041 : INFO : EPOCH 4 - PROGRESS: at 14.68% examples, 329044 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:01,046 : INFO : EPOCH 4 - PROGRESS: at 20.45% examples, 341099 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:02,074 : INFO : EPOCH 4 - PROGRESS: at 27.72% examples, 366705 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:03,101 : INFO : EPOCH 4 - PROGRESS: at 34.00% examples, 377049 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:04,123 : INFO : EPOCH 4 - PROGRESS: at 40.41% examples, 383270 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:05,172 : INFO : EPOCH 4 - PROGRESS: at 44.95% examples, 374197 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:06,222 : INFO : EPOCH 4 - PROGRESS: at 51.54% examples, 378212 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:07,259 : INFO : EPOCH 4 - PROGRESS: at 56.71% examples, 374032 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:08,272 : INFO : EPOCH 4 - PROGRESS: at 61.23% examples, 367749 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:09,281 : INFO : EPOCH 4 - PROGRESS: at 65.90% examples, 363584 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:10,309 : INFO : EPOCH 4 - PROGRESS: at 71.24% examples, 364023 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:11,328 : INFO : EPOCH 4 - PROGRESS: at 76.28% examples, 360484 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:12,356 : INFO : EPOCH 4 - PROGRESS: at 81.21% examples, 357808 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:13,382 : INFO : EPOCH 4 - PROGRESS: at 87.86% examples, 362779 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:14,386 : INFO : EPOCH 4 - PROGRESS: at 92.63% examples, 360782 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:15,445 : INFO : EPOCH 4 - PROGRESS: at 97.30% examples, 357981 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:15,825 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:41:15,835 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:41:15,838 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:41:15,839 : INFO : EPOCH - 4 : training on 6707530 raw words (6792083 effective words) took 18.8s, 360699 effective words/s\n",
      "2019-06-26 15:41:16,845 : INFO : EPOCH 5 - PROGRESS: at 4.73% examples, 308697 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:17,862 : INFO : EPOCH 5 - PROGRESS: at 11.51% examples, 385794 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:18,875 : INFO : EPOCH 5 - PROGRESS: at 16.27% examples, 362303 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:19,877 : INFO : EPOCH 5 - PROGRESS: at 20.99% examples, 349140 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:20,878 : INFO : EPOCH 5 - PROGRESS: at 25.88% examples, 345191 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:21,912 : INFO : EPOCH 5 - PROGRESS: at 30.64% examples, 338859 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:22,950 : INFO : EPOCH 5 - PROGRESS: at 36.31% examples, 342673 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:23,956 : INFO : EPOCH 5 - PROGRESS: at 41.95% examples, 347088 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:24,963 : INFO : EPOCH 5 - PROGRESS: at 46.72% examples, 344796 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:25,976 : INFO : EPOCH 5 - PROGRESS: at 51.46% examples, 342672 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:27,014 : INFO : EPOCH 5 - PROGRESS: at 57.18% examples, 345732 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:28,035 : INFO : EPOCH 5 - PROGRESS: at 63.41% examples, 351096 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:29,041 : INFO : EPOCH 5 - PROGRESS: at 68.25% examples, 350679 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:30,056 : INFO : EPOCH 5 - PROGRESS: at 72.79% examples, 347424 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:31,067 : INFO : EPOCH 5 - PROGRESS: at 77.54% examples, 345976 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:32,075 : INFO : EPOCH 5 - PROGRESS: at 83.55% examples, 348380 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:33,101 : INFO : EPOCH 5 - PROGRESS: at 88.88% examples, 347945 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:34,120 : INFO : EPOCH 5 - PROGRESS: at 93.69% examples, 347033 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:34,957 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:41:34,978 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:41:34,979 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:41:34,979 : INFO : EPOCH - 5 : training on 6707530 raw words (6792083 effective words) took 19.1s, 354892 effective words/s\n",
      "2019-06-26 15:41:35,984 : INFO : EPOCH 6 - PROGRESS: at 4.46% examples, 318806 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:37,004 : INFO : EPOCH 6 - PROGRESS: at 9.16% examples, 316515 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:38,068 : INFO : EPOCH 6 - PROGRESS: at 14.08% examples, 317325 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:41:39,077 : INFO : EPOCH 6 - PROGRESS: at 19.03% examples, 319488 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:40,095 : INFO : EPOCH 6 - PROGRESS: at 23.34% examples, 316129 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:41,102 : INFO : EPOCH 6 - PROGRESS: at 28.84% examples, 321348 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:42,106 : INFO : EPOCH 6 - PROGRESS: at 33.77% examples, 325077 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:43,119 : INFO : EPOCH 6 - PROGRESS: at 38.20% examples, 321367 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:44,147 : INFO : EPOCH 6 - PROGRESS: at 42.91% examples, 320125 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:45,168 : INFO : EPOCH 6 - PROGRESS: at 47.77% examples, 320370 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:46,193 : INFO : EPOCH 6 - PROGRESS: at 52.71% examples, 322348 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:47,196 : INFO : EPOCH 6 - PROGRESS: at 57.89% examples, 326032 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:48,203 : INFO : EPOCH 6 - PROGRESS: at 64.53% examples, 335183 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:49,230 : INFO : EPOCH 6 - PROGRESS: at 69.83% examples, 334828 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:50,240 : INFO : EPOCH 6 - PROGRESS: at 75.66% examples, 338015 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:51,273 : INFO : EPOCH 6 - PROGRESS: at 82.99% examples, 346014 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:41:52,312 : INFO : EPOCH 6 - PROGRESS: at 87.82% examples, 343705 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:53,313 : INFO : EPOCH 6 - PROGRESS: at 92.82% examples, 343958 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:41:54,317 : INFO : EPOCH 6 - PROGRESS: at 98.94% examples, 347741 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:54,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:41:54,373 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:41:54,375 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:41:54,376 : INFO : EPOCH - 6 : training on 6707530 raw words (6792083 effective words) took 19.4s, 350211 effective words/s\n",
      "2019-06-26 15:41:55,394 : INFO : EPOCH 7 - PROGRESS: at 4.68% examples, 342616 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:56,417 : INFO : EPOCH 7 - PROGRESS: at 11.65% examples, 396039 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:57,419 : INFO : EPOCH 7 - PROGRESS: at 19.16% examples, 432832 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:58,434 : INFO : EPOCH 7 - PROGRESS: at 24.38% examples, 412644 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:41:59,462 : INFO : EPOCH 7 - PROGRESS: at 29.21% examples, 392211 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:00,472 : INFO : EPOCH 7 - PROGRESS: at 36.03% examples, 402495 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:42:01,489 : INFO : EPOCH 7 - PROGRESS: at 41.92% examples, 400816 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:02,513 : INFO : EPOCH 7 - PROGRESS: at 46.81% examples, 388372 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:03,540 : INFO : EPOCH 7 - PROGRESS: at 51.78% examples, 381966 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:04,558 : INFO : EPOCH 7 - PROGRESS: at 56.30% examples, 375018 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:05,558 : INFO : EPOCH 7 - PROGRESS: at 62.35% examples, 378837 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:06,567 : INFO : EPOCH 7 - PROGRESS: at 66.82% examples, 372924 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:07,584 : INFO : EPOCH 7 - PROGRESS: at 74.48% examples, 383573 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:08,611 : INFO : EPOCH 7 - PROGRESS: at 81.21% examples, 388176 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:09,641 : INFO : EPOCH 7 - PROGRESS: at 86.27% examples, 384870 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:10,657 : INFO : EPOCH 7 - PROGRESS: at 91.84% examples, 383589 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:11,599 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:42:11,607 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:42:11,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:42:11,623 : INFO : EPOCH - 7 : training on 6707530 raw words (6792083 effective words) took 17.2s, 393883 effective words/s\n",
      "2019-06-26 15:42:12,655 : INFO : EPOCH 8 - PROGRESS: at 4.91% examples, 330216 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:13,656 : INFO : EPOCH 8 - PROGRESS: at 11.23% examples, 374553 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:14,667 : INFO : EPOCH 8 - PROGRESS: at 16.86% examples, 371508 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:15,673 : INFO : EPOCH 8 - PROGRESS: at 21.87% examples, 367788 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:16,709 : INFO : EPOCH 8 - PROGRESS: at 26.89% examples, 357772 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:17,740 : INFO : EPOCH 8 - PROGRESS: at 31.87% examples, 353142 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:18,757 : INFO : EPOCH 8 - PROGRESS: at 39.27% examples, 375505 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:19,783 : INFO : EPOCH 8 - PROGRESS: at 43.90% examples, 366368 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:20,800 : INFO : EPOCH 8 - PROGRESS: at 51.50% examples, 382194 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:21,808 : INFO : EPOCH 8 - PROGRESS: at 59.06% examples, 395353 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:22,816 : INFO : EPOCH 8 - PROGRESS: at 64.57% examples, 393709 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:23,840 : INFO : EPOCH 8 - PROGRESS: at 69.42% examples, 387638 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:24,842 : INFO : EPOCH 8 - PROGRESS: at 74.00% examples, 381642 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:25,876 : INFO : EPOCH 8 - PROGRESS: at 78.88% examples, 377027 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:26,901 : INFO : EPOCH 8 - PROGRESS: at 84.48% examples, 375869 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:27,920 : INFO : EPOCH 8 - PROGRESS: at 90.19% examples, 376195 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:28,968 : INFO : EPOCH 8 - PROGRESS: at 97.74% examples, 382362 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:42:29,249 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:42:29,266 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:42:29,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:42:29,271 : INFO : EPOCH - 8 : training on 6707530 raw words (6792083 effective words) took 17.6s, 384937 effective words/s\n",
      "2019-06-26 15:42:30,304 : INFO : EPOCH 9 - PROGRESS: at 4.57% examples, 299879 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:31,326 : INFO : EPOCH 9 - PROGRESS: at 9.62% examples, 311808 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:32,359 : INFO : EPOCH 9 - PROGRESS: at 14.56% examples, 314130 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:33,389 : INFO : EPOCH 9 - PROGRESS: at 19.23% examples, 315652 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:34,392 : INFO : EPOCH 9 - PROGRESS: at 26.20% examples, 347298 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:35,404 : INFO : EPOCH 9 - PROGRESS: at 32.86% examples, 364670 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:36,409 : INFO : EPOCH 9 - PROGRESS: at 38.02% examples, 361047 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:42:37,422 : INFO : EPOCH 9 - PROGRESS: at 45.70% examples, 378666 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:38,428 : INFO : EPOCH 9 - PROGRESS: at 53.31% examples, 395790 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:39,435 : INFO : EPOCH 9 - PROGRESS: at 60.86% examples, 406556 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:40,435 : INFO : EPOCH 9 - PROGRESS: at 68.65% examples, 417592 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:41,459 : INFO : EPOCH 9 - PROGRESS: at 75.12% examples, 420097 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:42,474 : INFO : EPOCH 9 - PROGRESS: at 82.66% examples, 426261 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:43,474 : INFO : EPOCH 9 - PROGRESS: at 89.79% examples, 430715 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:44,519 : INFO : EPOCH 9 - PROGRESS: at 94.53% examples, 422752 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:45,283 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:42:45,296 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:42:45,306 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:42:45,307 : INFO : EPOCH - 9 : training on 6707530 raw words (6792083 effective words) took 16.0s, 423596 effective words/s\n",
      "2019-06-26 15:42:46,314 : INFO : EPOCH 10 - PROGRESS: at 4.96% examples, 326937 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:47,320 : INFO : EPOCH 10 - PROGRESS: at 9.49% examples, 322432 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:48,330 : INFO : EPOCH 10 - PROGRESS: at 14.27% examples, 326598 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:49,356 : INFO : EPOCH 10 - PROGRESS: at 19.21% examples, 322751 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:50,394 : INFO : EPOCH 10 - PROGRESS: at 24.45% examples, 327430 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:51,407 : INFO : EPOCH 10 - PROGRESS: at 30.15% examples, 335260 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:52,414 : INFO : EPOCH 10 - PROGRESS: at 35.57% examples, 336947 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:53,415 : INFO : EPOCH 10 - PROGRESS: at 40.74% examples, 339643 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:54,421 : INFO : EPOCH 10 - PROGRESS: at 45.65% examples, 339546 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:55,428 : INFO : EPOCH 10 - PROGRESS: at 50.35% examples, 338215 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:56,450 : INFO : EPOCH 10 - PROGRESS: at 55.37% examples, 337745 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:57,476 : INFO : EPOCH 10 - PROGRESS: at 60.36% examples, 337924 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:42:58,494 : INFO : EPOCH 10 - PROGRESS: at 65.37% examples, 337633 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:42:59,517 : INFO : EPOCH 10 - PROGRESS: at 72.26% examples, 346358 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:00,528 : INFO : EPOCH 10 - PROGRESS: at 77.05% examples, 343634 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:01,529 : INFO : EPOCH 10 - PROGRESS: at 81.87% examples, 342105 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:02,530 : INFO : EPOCH 10 - PROGRESS: at 86.63% examples, 340696 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:03,538 : INFO : EPOCH 10 - PROGRESS: at 91.74% examples, 340471 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:04,553 : INFO : EPOCH 10 - PROGRESS: at 98.10% examples, 345824 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:04,776 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:43:04,779 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:43:04,781 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:43:04,782 : INFO : EPOCH - 10 : training on 6707530 raw words (6792083 effective words) took 19.5s, 348800 effective words/s\n",
      "2019-06-26 15:43:05,825 : INFO : EPOCH 11 - PROGRESS: at 5.04% examples, 325294 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:06,829 : INFO : EPOCH 11 - PROGRESS: at 9.72% examples, 322029 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:07,849 : INFO : EPOCH 11 - PROGRESS: at 15.10% examples, 335194 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:08,855 : INFO : EPOCH 11 - PROGRESS: at 20.38% examples, 343168 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:09,856 : INFO : EPOCH 11 - PROGRESS: at 25.44% examples, 342527 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:10,873 : INFO : EPOCH 11 - PROGRESS: at 31.31% examples, 349360 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:11,909 : INFO : EPOCH 11 - PROGRESS: at 38.55% examples, 367042 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:12,928 : INFO : EPOCH 11 - PROGRESS: at 46.34% examples, 388496 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:13,953 : INFO : EPOCH 11 - PROGRESS: at 52.25% examples, 390631 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:14,955 : INFO : EPOCH 11 - PROGRESS: at 57.37% examples, 384706 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:15,960 : INFO : EPOCH 11 - PROGRESS: at 62.15% examples, 379520 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:16,977 : INFO : EPOCH 11 - PROGRESS: at 67.33% examples, 375718 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:18,021 : INFO : EPOCH 11 - PROGRESS: at 72.55% examples, 372558 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:19,066 : INFO : EPOCH 11 - PROGRESS: at 77.62% examples, 369083 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:20,067 : INFO : EPOCH 11 - PROGRESS: at 82.27% examples, 366422 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:21,079 : INFO : EPOCH 11 - PROGRESS: at 87.03% examples, 362763 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:22,094 : INFO : EPOCH 11 - PROGRESS: at 91.73% examples, 359948 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:23,095 : INFO : EPOCH 11 - PROGRESS: at 96.63% examples, 358800 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:23,575 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:43:23,577 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:43:23,584 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:43:23,585 : INFO : EPOCH - 11 : training on 6707530 raw words (6792083 effective words) took 18.8s, 361275 effective words/s\n",
      "2019-06-26 15:43:24,605 : INFO : EPOCH 12 - PROGRESS: at 4.89% examples, 322508 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:25,608 : INFO : EPOCH 12 - PROGRESS: at 9.94% examples, 335917 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:26,614 : INFO : EPOCH 12 - PROGRESS: at 14.73% examples, 336570 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:27,658 : INFO : EPOCH 12 - PROGRESS: at 20.01% examples, 341155 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:28,666 : INFO : EPOCH 12 - PROGRESS: at 26.53% examples, 361787 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:29,707 : INFO : EPOCH 12 - PROGRESS: at 32.08% examples, 362024 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:30,724 : INFO : EPOCH 12 - PROGRESS: at 36.67% examples, 355156 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:31,759 : INFO : EPOCH 12 - PROGRESS: at 41.71% examples, 351789 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:32,773 : INFO : EPOCH 12 - PROGRESS: at 47.84% examples, 357515 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:33,797 : INFO : EPOCH 12 - PROGRESS: at 52.66% examples, 354820 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:34,804 : INFO : EPOCH 12 - PROGRESS: at 59.30% examples, 362905 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:35,821 : INFO : EPOCH 12 - PROGRESS: at 64.59% examples, 362797 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:36,830 : INFO : EPOCH 12 - PROGRESS: at 69.71% examples, 360828 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:37,843 : INFO : EPOCH 12 - PROGRESS: at 74.89% examples, 359717 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:38,862 : INFO : EPOCH 12 - PROGRESS: at 80.01% examples, 357392 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:39,864 : INFO : EPOCH 12 - PROGRESS: at 85.01% examples, 356246 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:40,883 : INFO : EPOCH 12 - PROGRESS: at 90.33% examples, 355922 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:41,889 : INFO : EPOCH 12 - PROGRESS: at 95.31% examples, 354840 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:42,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:43:42,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:43:42,667 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:43:42,668 : INFO : EPOCH - 12 : training on 6707530 raw words (6792083 effective words) took 19.1s, 355960 effective words/s\n",
      "2019-06-26 15:43:43,677 : INFO : EPOCH 13 - PROGRESS: at 4.98% examples, 327725 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:44,711 : INFO : EPOCH 13 - PROGRESS: at 10.06% examples, 332955 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:45,739 : INFO : EPOCH 13 - PROGRESS: at 16.33% examples, 357881 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:46,758 : INFO : EPOCH 13 - PROGRESS: at 21.29% examples, 346905 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:47,776 : INFO : EPOCH 13 - PROGRESS: at 26.14% examples, 342331 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:48,795 : INFO : EPOCH 13 - PROGRESS: at 31.06% examples, 340791 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:49,810 : INFO : EPOCH 13 - PROGRESS: at 37.91% examples, 357979 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:50,832 : INFO : EPOCH 13 - PROGRESS: at 42.62% examples, 352343 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:51,874 : INFO : EPOCH 13 - PROGRESS: at 47.71% examples, 348275 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:52,876 : INFO : EPOCH 13 - PROGRESS: at 52.69% examples, 347202 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:53,911 : INFO : EPOCH 13 - PROGRESS: at 57.59% examples, 345546 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:54,940 : INFO : EPOCH 13 - PROGRESS: at 62.78% examples, 345129 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:43:55,949 : INFO : EPOCH 13 - PROGRESS: at 67.59% examples, 343704 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:56,961 : INFO : EPOCH 13 - PROGRESS: at 72.73% examples, 344505 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:57,964 : INFO : EPOCH 13 - PROGRESS: at 77.31% examples, 342807 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:43:58,985 : INFO : EPOCH 13 - PROGRESS: at 82.14% examples, 340998 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:00,020 : INFO : EPOCH 13 - PROGRESS: at 87.10% examples, 340251 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:01,026 : INFO : EPOCH 13 - PROGRESS: at 91.72% examples, 339052 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:02,055 : INFO : EPOCH 13 - PROGRESS: at 96.55% examples, 338031 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:02,549 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:44:02,565 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:44:02,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:44:02,572 : INFO : EPOCH - 13 : training on 6707530 raw words (6792083 effective words) took 19.9s, 341302 effective words/s\n",
      "2019-06-26 15:44:03,599 : INFO : EPOCH 14 - PROGRESS: at 4.56% examples, 310366 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:04,606 : INFO : EPOCH 14 - PROGRESS: at 9.48% examples, 318506 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:05,632 : INFO : EPOCH 14 - PROGRESS: at 14.73% examples, 322644 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:06,670 : INFO : EPOCH 14 - PROGRESS: at 19.78% examples, 323615 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:44:07,686 : INFO : EPOCH 14 - PROGRESS: at 24.58% examples, 321662 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:08,704 : INFO : EPOCH 14 - PROGRESS: at 30.00% examples, 327063 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:09,729 : INFO : EPOCH 14 - PROGRESS: at 35.19% examples, 330346 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:10,729 : INFO : EPOCH 14 - PROGRESS: at 40.54% examples, 332585 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:11,774 : INFO : EPOCH 14 - PROGRESS: at 45.53% examples, 331875 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:12,786 : INFO : EPOCH 14 - PROGRESS: at 50.48% examples, 333107 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:13,789 : INFO : EPOCH 14 - PROGRESS: at 56.62% examples, 341579 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:14,816 : INFO : EPOCH 14 - PROGRESS: at 61.75% examples, 341374 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:15,830 : INFO : EPOCH 14 - PROGRESS: at 66.57% examples, 340892 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:16,838 : INFO : EPOCH 14 - PROGRESS: at 71.76% examples, 341371 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:17,857 : INFO : EPOCH 14 - PROGRESS: at 76.78% examples, 340134 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:18,895 : INFO : EPOCH 14 - PROGRESS: at 83.45% examples, 347283 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:19,900 : INFO : EPOCH 14 - PROGRESS: at 88.29% examples, 346110 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:20,911 : INFO : EPOCH 14 - PROGRESS: at 94.10% examples, 348251 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:21,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:44:21,832 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:44:21,841 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:44:21,842 : INFO : EPOCH - 14 : training on 6707530 raw words (6792083 effective words) took 19.3s, 352515 effective words/s\n",
      "2019-06-26 15:44:22,862 : INFO : EPOCH 15 - PROGRESS: at 5.02% examples, 334330 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:23,884 : INFO : EPOCH 15 - PROGRESS: at 12.40% examples, 416862 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:24,891 : INFO : EPOCH 15 - PROGRESS: at 18.03% examples, 403808 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:25,901 : INFO : EPOCH 15 - PROGRESS: at 22.99% examples, 386924 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:26,909 : INFO : EPOCH 15 - PROGRESS: at 28.09% examples, 375153 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:27,925 : INFO : EPOCH 15 - PROGRESS: at 33.09% examples, 369884 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:28,941 : INFO : EPOCH 15 - PROGRESS: at 39.13% examples, 374380 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:29,945 : INFO : EPOCH 15 - PROGRESS: at 43.93% examples, 367566 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:30,948 : INFO : EPOCH 15 - PROGRESS: at 49.39% examples, 366532 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:31,962 : INFO : EPOCH 15 - PROGRESS: at 54.29% examples, 363400 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:32,962 : INFO : EPOCH 15 - PROGRESS: at 59.30% examples, 362086 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:33,984 : INFO : EPOCH 15 - PROGRESS: at 65.63% examples, 367008 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:35,020 : INFO : EPOCH 15 - PROGRESS: at 71.63% examples, 370681 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:36,031 : INFO : EPOCH 15 - PROGRESS: at 76.72% examples, 367497 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:37,050 : INFO : EPOCH 15 - PROGRESS: at 81.54% examples, 364606 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:38,056 : INFO : EPOCH 15 - PROGRESS: at 86.68% examples, 363439 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:39,059 : INFO : EPOCH 15 - PROGRESS: at 91.58% examples, 360842 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:40,060 : INFO : EPOCH 15 - PROGRESS: at 96.62% examples, 360096 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:40,570 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:44:40,579 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:44:40,582 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:44:40,583 : INFO : EPOCH - 15 : training on 6707530 raw words (6792083 effective words) took 18.7s, 362481 effective words/s\n",
      "2019-06-26 15:44:41,595 : INFO : EPOCH 16 - PROGRESS: at 4.58% examples, 316132 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:42,602 : INFO : EPOCH 16 - PROGRESS: at 9.36% examples, 316603 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:43,619 : INFO : EPOCH 16 - PROGRESS: at 14.56% examples, 325451 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:44,626 : INFO : EPOCH 16 - PROGRESS: at 20.90% examples, 346121 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:45,626 : INFO : EPOCH 16 - PROGRESS: at 25.65% examples, 342960 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:46,658 : INFO : EPOCH 16 - PROGRESS: at 30.67% examples, 340570 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:47,660 : INFO : EPOCH 16 - PROGRESS: at 35.73% examples, 343091 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:48,663 : INFO : EPOCH 16 - PROGRESS: at 41.38% examples, 346405 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:49,677 : INFO : EPOCH 16 - PROGRESS: at 46.53% examples, 345028 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:50,689 : INFO : EPOCH 16 - PROGRESS: at 51.25% examples, 343070 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:51,702 : INFO : EPOCH 16 - PROGRESS: at 56.05% examples, 342330 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:52,704 : INFO : EPOCH 16 - PROGRESS: at 61.88% examples, 346732 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:53,727 : INFO : EPOCH 16 - PROGRESS: at 67.75% examples, 349385 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:54,733 : INFO : EPOCH 16 - PROGRESS: at 73.15% examples, 349201 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:55,763 : INFO : EPOCH 16 - PROGRESS: at 78.87% examples, 351131 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:44:56,770 : INFO : EPOCH 16 - PROGRESS: at 83.88% examples, 350293 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:57,771 : INFO : EPOCH 16 - PROGRESS: at 88.40% examples, 347270 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:58,789 : INFO : EPOCH 16 - PROGRESS: at 93.38% examples, 347039 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:44:59,791 : INFO : EPOCH 16 - PROGRESS: at 99.71% examples, 352593 words/s, in_qsize 2, out_qsize 1\n",
      "2019-06-26 15:44:59,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:44:59,802 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:44:59,804 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:44:59,805 : INFO : EPOCH - 16 : training on 6707530 raw words (6792083 effective words) took 19.2s, 353384 effective words/s\n",
      "2019-06-26 15:45:00,830 : INFO : EPOCH 17 - PROGRESS: at 5.07% examples, 333027 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:01,851 : INFO : EPOCH 17 - PROGRESS: at 10.20% examples, 337476 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:02,866 : INFO : EPOCH 17 - PROGRESS: at 15.09% examples, 336534 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:03,868 : INFO : EPOCH 17 - PROGRESS: at 20.17% examples, 336818 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:04,897 : INFO : EPOCH 17 - PROGRESS: at 25.21% examples, 335454 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:05,905 : INFO : EPOCH 17 - PROGRESS: at 29.95% examples, 333821 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:06,912 : INFO : EPOCH 17 - PROGRESS: at 35.75% examples, 342773 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:07,947 : INFO : EPOCH 17 - PROGRESS: at 41.40% examples, 348280 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:08,964 : INFO : EPOCH 17 - PROGRESS: at 46.79% examples, 348772 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:09,970 : INFO : EPOCH 17 - PROGRESS: at 51.73% examples, 346457 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:10,986 : INFO : EPOCH 17 - PROGRESS: at 56.52% examples, 345195 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:45:12,005 : INFO : EPOCH 17 - PROGRESS: at 62.09% examples, 348277 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:13,037 : INFO : EPOCH 17 - PROGRESS: at 67.42% examples, 349097 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:14,042 : INFO : EPOCH 17 - PROGRESS: at 72.52% examples, 347630 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:15,066 : INFO : EPOCH 17 - PROGRESS: at 77.95% examples, 347879 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:16,077 : INFO : EPOCH 17 - PROGRESS: at 83.16% examples, 347130 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:17,097 : INFO : EPOCH 17 - PROGRESS: at 88.58% examples, 349124 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:18,103 : INFO : EPOCH 17 - PROGRESS: at 94.24% examples, 351151 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:18,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:45:18,954 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:45:18,959 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:45:18,960 : INFO : EPOCH - 17 : training on 6707530 raw words (6792083 effective words) took 19.2s, 354625 effective words/s\n",
      "2019-06-26 15:45:19,979 : INFO : EPOCH 18 - PROGRESS: at 4.76% examples, 313375 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:21,007 : INFO : EPOCH 18 - PROGRESS: at 10.48% examples, 336469 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:22,011 : INFO : EPOCH 18 - PROGRESS: at 16.12% examples, 356370 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:23,024 : INFO : EPOCH 18 - PROGRESS: at 21.53% examples, 353914 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:24,033 : INFO : EPOCH 18 - PROGRESS: at 26.61% examples, 350531 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:25,043 : INFO : EPOCH 18 - PROGRESS: at 31.37% examples, 348200 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:26,056 : INFO : EPOCH 18 - PROGRESS: at 37.86% examples, 358817 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:27,069 : INFO : EPOCH 18 - PROGRESS: at 43.19% examples, 358348 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:28,100 : INFO : EPOCH 18 - PROGRESS: at 48.02% examples, 354081 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:29,113 : INFO : EPOCH 18 - PROGRESS: at 53.42% examples, 353250 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:30,120 : INFO : EPOCH 18 - PROGRESS: at 58.14% examples, 351046 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:31,121 : INFO : EPOCH 18 - PROGRESS: at 63.03% examples, 350095 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:32,125 : INFO : EPOCH 18 - PROGRESS: at 67.78% examples, 348390 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:33,140 : INFO : EPOCH 18 - PROGRESS: at 73.64% examples, 352973 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:34,158 : INFO : EPOCH 18 - PROGRESS: at 80.94% examples, 360785 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:35,168 : INFO : EPOCH 18 - PROGRESS: at 86.79% examples, 362841 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:36,182 : INFO : EPOCH 18 - PROGRESS: at 92.42% examples, 364099 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:37,192 : INFO : EPOCH 18 - PROGRESS: at 98.78% examples, 367990 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:37,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:45:37,261 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:45:37,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:45:37,264 : INFO : EPOCH - 18 : training on 6707530 raw words (6792083 effective words) took 18.3s, 371134 effective words/s\n",
      "2019-06-26 15:45:38,271 : INFO : EPOCH 19 - PROGRESS: at 4.82% examples, 337497 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:39,281 : INFO : EPOCH 19 - PROGRESS: at 9.65% examples, 330989 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:40,299 : INFO : EPOCH 19 - PROGRESS: at 14.62% examples, 334934 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:41,301 : INFO : EPOCH 19 - PROGRESS: at 20.72% examples, 353079 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:42,303 : INFO : EPOCH 19 - PROGRESS: at 26.88% examples, 364177 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:43,337 : INFO : EPOCH 19 - PROGRESS: at 32.14% examples, 358301 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:44,357 : INFO : EPOCH 19 - PROGRESS: at 37.20% examples, 356086 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:45,373 : INFO : EPOCH 19 - PROGRESS: at 42.52% examples, 356907 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:46,377 : INFO : EPOCH 19 - PROGRESS: at 49.56% examples, 370299 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:47,390 : INFO : EPOCH 19 - PROGRESS: at 55.23% examples, 371590 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:48,428 : INFO : EPOCH 19 - PROGRESS: at 60.77% examples, 370863 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:49,435 : INFO : EPOCH 19 - PROGRESS: at 65.93% examples, 368155 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:50,446 : INFO : EPOCH 19 - PROGRESS: at 71.42% examples, 366435 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:51,468 : INFO : EPOCH 19 - PROGRESS: at 77.46% examples, 369619 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:45:52,484 : INFO : EPOCH 19 - PROGRESS: at 82.67% examples, 368549 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:53,494 : INFO : EPOCH 19 - PROGRESS: at 88.32% examples, 368365 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:54,495 : INFO : EPOCH 19 - PROGRESS: at 94.61% examples, 372454 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:55,230 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:45:55,243 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:45:55,244 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:45:55,245 : INFO : EPOCH - 19 : training on 6707530 raw words (6792083 effective words) took 18.0s, 377783 effective words/s\n",
      "2019-06-26 15:45:56,257 : INFO : EPOCH 20 - PROGRESS: at 4.67% examples, 325381 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:57,283 : INFO : EPOCH 20 - PROGRESS: at 10.17% examples, 342419 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:58,305 : INFO : EPOCH 20 - PROGRESS: at 15.33% examples, 339414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:45:59,316 : INFO : EPOCH 20 - PROGRESS: at 20.25% examples, 341065 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:00,319 : INFO : EPOCH 20 - PROGRESS: at 25.26% examples, 344433 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:01,338 : INFO : EPOCH 20 - PROGRESS: at 31.65% examples, 356002 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:02,346 : INFO : EPOCH 20 - PROGRESS: at 37.26% examples, 357763 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:03,348 : INFO : EPOCH 20 - PROGRESS: at 42.64% examples, 358051 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:04,384 : INFO : EPOCH 20 - PROGRESS: at 47.82% examples, 354437 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:05,397 : INFO : EPOCH 20 - PROGRESS: at 53.02% examples, 353471 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:06,410 : INFO : EPOCH 20 - PROGRESS: at 58.47% examples, 353616 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:07,420 : INFO : EPOCH 20 - PROGRESS: at 65.13% examples, 361239 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:08,460 : INFO : EPOCH 20 - PROGRESS: at 70.87% examples, 363098 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:09,485 : INFO : EPOCH 20 - PROGRESS: at 76.20% examples, 362265 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:10,511 : INFO : EPOCH 20 - PROGRESS: at 81.29% examples, 360231 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:11,531 : INFO : EPOCH 20 - PROGRESS: at 86.77% examples, 360939 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:12,562 : INFO : EPOCH 20 - PROGRESS: at 92.83% examples, 363065 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:46:13,569 : INFO : EPOCH 20 - PROGRESS: at 98.63% examples, 364890 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:13,670 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:46:13,671 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:46:13,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:46:13,683 : INFO : EPOCH - 20 : training on 6707530 raw words (6792083 effective words) took 18.4s, 368446 effective words/s\n",
      "2019-06-26 15:46:14,686 : INFO : EPOCH 21 - PROGRESS: at 5.55% examples, 398039 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:15,708 : INFO : EPOCH 21 - PROGRESS: at 11.10% examples, 393902 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:16,710 : INFO : EPOCH 21 - PROGRESS: at 17.54% examples, 411638 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:17,745 : INFO : EPOCH 21 - PROGRESS: at 23.13% examples, 395184 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:18,756 : INFO : EPOCH 21 - PROGRESS: at 28.23% examples, 379186 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:19,761 : INFO : EPOCH 21 - PROGRESS: at 34.26% examples, 382222 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:20,789 : INFO : EPOCH 21 - PROGRESS: at 40.04% examples, 382927 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:21,794 : INFO : EPOCH 21 - PROGRESS: at 45.13% examples, 377242 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:22,831 : INFO : EPOCH 21 - PROGRESS: at 50.89% examples, 373906 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:23,833 : INFO : EPOCH 21 - PROGRESS: at 57.01% examples, 379126 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:24,835 : INFO : EPOCH 21 - PROGRESS: at 62.14% examples, 376482 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:25,836 : INFO : EPOCH 21 - PROGRESS: at 68.17% examples, 379061 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:26,844 : INFO : EPOCH 21 - PROGRESS: at 74.27% examples, 381078 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:27,868 : INFO : EPOCH 21 - PROGRESS: at 79.18% examples, 378224 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:28,873 : INFO : EPOCH 21 - PROGRESS: at 84.86% examples, 378802 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:29,905 : INFO : EPOCH 21 - PROGRESS: at 90.02% examples, 376245 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:30,923 : INFO : EPOCH 21 - PROGRESS: at 95.40% examples, 374959 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:31,694 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:46:31,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:46:31,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:46:31,717 : INFO : EPOCH - 21 : training on 6707530 raw words (6792083 effective words) took 18.0s, 376659 effective words/s\n",
      "2019-06-26 15:46:32,729 : INFO : EPOCH 22 - PROGRESS: at 4.92% examples, 326870 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:33,732 : INFO : EPOCH 22 - PROGRESS: at 11.27% examples, 377157 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:34,751 : INFO : EPOCH 22 - PROGRESS: at 16.75% examples, 372432 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:35,772 : INFO : EPOCH 22 - PROGRESS: at 22.16% examples, 367686 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:36,781 : INFO : EPOCH 22 - PROGRESS: at 29.40% examples, 389061 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:37,797 : INFO : EPOCH 22 - PROGRESS: at 35.13% examples, 388015 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:38,836 : INFO : EPOCH 22 - PROGRESS: at 40.06% examples, 379034 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:39,839 : INFO : EPOCH 22 - PROGRESS: at 44.89% examples, 372672 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:40,844 : INFO : EPOCH 22 - PROGRESS: at 50.06% examples, 370916 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:41,845 : INFO : EPOCH 22 - PROGRESS: at 55.31% examples, 368701 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:42,851 : INFO : EPOCH 22 - PROGRESS: at 61.84% examples, 376497 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:43,860 : INFO : EPOCH 22 - PROGRESS: at 67.40% examples, 377457 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:44,882 : INFO : EPOCH 22 - PROGRESS: at 73.77% examples, 382067 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:45,888 : INFO : EPOCH 22 - PROGRESS: at 79.19% examples, 380273 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:46,895 : INFO : EPOCH 22 - PROGRESS: at 85.72% examples, 385206 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:47,924 : INFO : EPOCH 22 - PROGRESS: at 91.24% examples, 384715 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:48,939 : INFO : EPOCH 22 - PROGRESS: at 98.50% examples, 389351 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:49,013 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:46:49,028 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:46:49,040 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:46:49,041 : INFO : EPOCH - 22 : training on 6707530 raw words (6792083 effective words) took 17.3s, 392128 effective words/s\n",
      "2019-06-26 15:46:50,062 : INFO : EPOCH 23 - PROGRESS: at 5.28% examples, 333873 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:51,068 : INFO : EPOCH 23 - PROGRESS: at 10.08% examples, 339589 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:52,079 : INFO : EPOCH 23 - PROGRESS: at 16.30% examples, 364471 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:53,104 : INFO : EPOCH 23 - PROGRESS: at 21.00% examples, 351200 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:54,104 : INFO : EPOCH 23 - PROGRESS: at 26.53% examples, 350801 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:55,131 : INFO : EPOCH 23 - PROGRESS: at 31.30% examples, 344067 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:46:56,154 : INFO : EPOCH 23 - PROGRESS: at 36.11% examples, 342340 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:57,161 : INFO : EPOCH 23 - PROGRESS: at 41.49% examples, 345207 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:46:58,161 : INFO : EPOCH 23 - PROGRESS: at 47.49% examples, 353418 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:46:59,179 : INFO : EPOCH 23 - PROGRESS: at 53.66% examples, 360220 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:00,197 : INFO : EPOCH 23 - PROGRESS: at 58.87% examples, 359603 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:01,208 : INFO : EPOCH 23 - PROGRESS: at 64.39% examples, 360202 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:02,239 : INFO : EPOCH 23 - PROGRESS: at 69.63% examples, 360014 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:03,241 : INFO : EPOCH 23 - PROGRESS: at 74.34% examples, 358442 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:04,262 : INFO : EPOCH 23 - PROGRESS: at 79.09% examples, 355507 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:05,278 : INFO : EPOCH 23 - PROGRESS: at 86.60% examples, 363931 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:06,315 : INFO : EPOCH 23 - PROGRESS: at 91.85% examples, 361727 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:07,350 : INFO : EPOCH 23 - PROGRESS: at 97.75% examples, 362583 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:07,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:47:07,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:47:07,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:47:07,599 : INFO : EPOCH - 23 : training on 6707530 raw words (6792083 effective words) took 18.6s, 366036 effective words/s\n",
      "2019-06-26 15:47:08,624 : INFO : EPOCH 24 - PROGRESS: at 5.31% examples, 342058 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:09,625 : INFO : EPOCH 24 - PROGRESS: at 11.60% examples, 385309 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:10,658 : INFO : EPOCH 24 - PROGRESS: at 16.71% examples, 372053 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:11,680 : INFO : EPOCH 24 - PROGRESS: at 22.87% examples, 381903 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:12,686 : INFO : EPOCH 24 - PROGRESS: at 28.52% examples, 381090 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:13,694 : INFO : EPOCH 24 - PROGRESS: at 34.88% examples, 390106 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:14,712 : INFO : EPOCH 24 - PROGRESS: at 40.89% examples, 390615 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:15,713 : INFO : EPOCH 24 - PROGRESS: at 47.01% examples, 393953 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:47:16,736 : INFO : EPOCH 24 - PROGRESS: at 52.97% examples, 393531 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:17,756 : INFO : EPOCH 24 - PROGRESS: at 59.23% examples, 395312 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:18,768 : INFO : EPOCH 24 - PROGRESS: at 63.97% examples, 389082 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:19,775 : INFO : EPOCH 24 - PROGRESS: at 69.83% examples, 388871 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:20,797 : INFO : EPOCH 24 - PROGRESS: at 75.99% examples, 390544 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:21,801 : INFO : EPOCH 24 - PROGRESS: at 81.20% examples, 386857 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:22,845 : INFO : EPOCH 24 - PROGRESS: at 87.24% examples, 387229 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:23,862 : INFO : EPOCH 24 - PROGRESS: at 92.75% examples, 386388 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:24,875 : INFO : EPOCH 24 - PROGRESS: at 97.52% examples, 382813 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:25,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:47:25,194 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:47:25,205 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:47:25,206 : INFO : EPOCH - 24 : training on 6707530 raw words (6792083 effective words) took 17.6s, 385824 effective words/s\n",
      "2019-06-26 15:47:26,213 : INFO : EPOCH 25 - PROGRESS: at 4.93% examples, 327014 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:27,234 : INFO : EPOCH 25 - PROGRESS: at 10.51% examples, 358962 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:28,240 : INFO : EPOCH 25 - PROGRESS: at 15.71% examples, 361701 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:29,273 : INFO : EPOCH 25 - PROGRESS: at 21.20% examples, 360634 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:30,288 : INFO : EPOCH 25 - PROGRESS: at 26.61% examples, 361266 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:31,314 : INFO : EPOCH 25 - PROGRESS: at 31.63% examples, 357667 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:32,339 : INFO : EPOCH 25 - PROGRESS: at 36.63% examples, 353817 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:33,350 : INFO : EPOCH 25 - PROGRESS: at 41.69% examples, 352807 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:34,366 : INFO : EPOCH 25 - PROGRESS: at 47.57% examples, 357225 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:35,382 : INFO : EPOCH 25 - PROGRESS: at 53.30% examples, 359035 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:36,390 : INFO : EPOCH 25 - PROGRESS: at 58.18% examples, 357078 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:37,393 : INFO : EPOCH 25 - PROGRESS: at 63.24% examples, 355587 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:38,405 : INFO : EPOCH 25 - PROGRESS: at 68.23% examples, 353390 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:39,409 : INFO : EPOCH 25 - PROGRESS: at 73.41% examples, 352320 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:40,442 : INFO : EPOCH 25 - PROGRESS: at 78.56% examples, 352057 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:41,451 : INFO : EPOCH 25 - PROGRESS: at 83.77% examples, 351657 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:42,453 : INFO : EPOCH 25 - PROGRESS: at 89.28% examples, 351566 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:43,459 : INFO : EPOCH 25 - PROGRESS: at 94.59% examples, 351840 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:47:44,106 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:47:44,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:47:44,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:47:44,122 : INFO : EPOCH - 25 : training on 6707530 raw words (6792083 effective words) took 18.9s, 359101 effective words/s\n",
      "2019-06-26 15:47:45,134 : INFO : EPOCH 26 - PROGRESS: at 5.31% examples, 345414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:46,146 : INFO : EPOCH 26 - PROGRESS: at 10.97% examples, 355524 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:47,184 : INFO : EPOCH 26 - PROGRESS: at 17.14% examples, 375227 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:48,193 : INFO : EPOCH 26 - PROGRESS: at 23.43% examples, 389947 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:49,194 : INFO : EPOCH 26 - PROGRESS: at 30.14% examples, 403119 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:50,209 : INFO : EPOCH 26 - PROGRESS: at 35.27% examples, 393230 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:51,210 : INFO : EPOCH 26 - PROGRESS: at 41.89% examples, 399759 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:52,227 : INFO : EPOCH 26 - PROGRESS: at 47.27% examples, 393921 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:53,254 : INFO : EPOCH 26 - PROGRESS: at 52.39% examples, 388946 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:54,275 : INFO : EPOCH 26 - PROGRESS: at 57.99% examples, 388217 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:55,297 : INFO : EPOCH 26 - PROGRESS: at 63.18% examples, 383860 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:56,315 : INFO : EPOCH 26 - PROGRESS: at 70.31% examples, 391234 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:47:57,340 : INFO : EPOCH 26 - PROGRESS: at 76.02% examples, 390229 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:58,346 : INFO : EPOCH 26 - PROGRESS: at 81.07% examples, 385850 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:47:59,355 : INFO : EPOCH 26 - PROGRESS: at 86.04% examples, 383178 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:00,377 : INFO : EPOCH 26 - PROGRESS: at 91.26% examples, 381732 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:01,396 : INFO : EPOCH 26 - PROGRESS: at 96.18% examples, 378865 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:01,827 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:48:01,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:48:01,845 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:48:01,846 : INFO : EPOCH - 26 : training on 6707530 raw words (6792083 effective words) took 17.7s, 383276 effective words/s\n",
      "2019-06-26 15:48:02,881 : INFO : EPOCH 27 - PROGRESS: at 5.22% examples, 337976 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:03,906 : INFO : EPOCH 27 - PROGRESS: at 9.98% examples, 334619 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:04,912 : INFO : EPOCH 27 - PROGRESS: at 15.34% examples, 345380 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:05,941 : INFO : EPOCH 27 - PROGRESS: at 20.79% examples, 343905 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:06,965 : INFO : EPOCH 27 - PROGRESS: at 25.86% examples, 343278 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:07,968 : INFO : EPOCH 27 - PROGRESS: at 31.20% examples, 345807 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:08,970 : INFO : EPOCH 27 - PROGRESS: at 36.52% examples, 346270 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:09,972 : INFO : EPOCH 27 - PROGRESS: at 41.90% examples, 347858 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:10,973 : INFO : EPOCH 27 - PROGRESS: at 47.53% examples, 352387 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:12,002 : INFO : EPOCH 27 - PROGRESS: at 52.96% examples, 353061 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:13,031 : INFO : EPOCH 27 - PROGRESS: at 58.98% examples, 357267 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:14,067 : INFO : EPOCH 27 - PROGRESS: at 63.98% examples, 355493 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:15,085 : INFO : EPOCH 27 - PROGRESS: at 69.85% examples, 358287 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:16,098 : INFO : EPOCH 27 - PROGRESS: at 76.16% examples, 361591 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:17,108 : INFO : EPOCH 27 - PROGRESS: at 83.76% examples, 371102 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:18,141 : INFO : EPOCH 27 - PROGRESS: at 89.02% examples, 370264 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:19,142 : INFO : EPOCH 27 - PROGRESS: at 94.34% examples, 369549 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:20,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:48:20,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:48:20,086 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:48:20,087 : INFO : EPOCH - 27 : training on 6707530 raw words (6792083 effective words) took 18.2s, 372402 effective words/s\n",
      "2019-06-26 15:48:21,112 : INFO : EPOCH 28 - PROGRESS: at 5.02% examples, 332303 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:22,134 : INFO : EPOCH 28 - PROGRESS: at 9.92% examples, 332069 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:23,149 : INFO : EPOCH 28 - PROGRESS: at 16.35% examples, 362252 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:24,158 : INFO : EPOCH 28 - PROGRESS: at 21.41% examples, 360660 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:25,166 : INFO : EPOCH 28 - PROGRESS: at 27.16% examples, 365647 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:26,181 : INFO : EPOCH 28 - PROGRESS: at 32.16% examples, 360349 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:27,188 : INFO : EPOCH 28 - PROGRESS: at 37.09% examples, 358636 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:28,203 : INFO : EPOCH 28 - PROGRESS: at 42.20% examples, 354397 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:29,230 : INFO : EPOCH 28 - PROGRESS: at 48.14% examples, 357249 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:30,244 : INFO : EPOCH 28 - PROGRESS: at 53.90% examples, 359989 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:31,252 : INFO : EPOCH 28 - PROGRESS: at 60.17% examples, 367640 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:32,262 : INFO : EPOCH 28 - PROGRESS: at 65.24% examples, 365933 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:33,293 : INFO : EPOCH 28 - PROGRESS: at 69.92% examples, 361575 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:34,300 : INFO : EPOCH 28 - PROGRESS: at 77.15% examples, 369765 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:35,332 : INFO : EPOCH 28 - PROGRESS: at 82.86% examples, 370333 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:36,344 : INFO : EPOCH 28 - PROGRESS: at 88.69% examples, 371095 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:37,352 : INFO : EPOCH 28 - PROGRESS: at 95.33% examples, 374859 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:38,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:48:38,125 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:48:38,130 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:48:38,132 : INFO : EPOCH - 28 : training on 6707530 raw words (6792083 effective words) took 18.0s, 376483 effective words/s\n",
      "2019-06-26 15:48:39,145 : INFO : EPOCH 29 - PROGRESS: at 4.62% examples, 324865 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:40,179 : INFO : EPOCH 29 - PROGRESS: at 9.92% examples, 340877 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:41,183 : INFO : EPOCH 29 - PROGRESS: at 15.10% examples, 340009 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:42,197 : INFO : EPOCH 29 - PROGRESS: at 20.14% examples, 338433 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:43,227 : INFO : EPOCH 29 - PROGRESS: at 25.37% examples, 340694 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:44,252 : INFO : EPOCH 29 - PROGRESS: at 30.67% examples, 340935 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:45,260 : INFO : EPOCH 29 - PROGRESS: at 35.90% examples, 341500 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:46,266 : INFO : EPOCH 29 - PROGRESS: at 42.08% examples, 350873 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:47,305 : INFO : EPOCH 29 - PROGRESS: at 47.73% examples, 353726 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:48,311 : INFO : EPOCH 29 - PROGRESS: at 52.56% examples, 351160 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:49,312 : INFO : EPOCH 29 - PROGRESS: at 57.39% examples, 349096 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:50,323 : INFO : EPOCH 29 - PROGRESS: at 62.67% examples, 349633 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:51,363 : INFO : EPOCH 29 - PROGRESS: at 68.39% examples, 352970 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:52,371 : INFO : EPOCH 29 - PROGRESS: at 73.51% examples, 353259 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:53,387 : INFO : EPOCH 29 - PROGRESS: at 78.17% examples, 351322 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:48:54,395 : INFO : EPOCH 29 - PROGRESS: at 83.57% examples, 351072 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:55,417 : INFO : EPOCH 29 - PROGRESS: at 89.08% examples, 350550 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:56,430 : INFO : EPOCH 29 - PROGRESS: at 94.93% examples, 352999 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:48:57,064 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:48:57,071 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:48:57,079 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:48:57,080 : INFO : EPOCH - 29 : training on 6707530 raw words (6792083 effective words) took 18.9s, 358521 effective words/s\n",
      "2019-06-26 15:48:58,092 : INFO : EPOCH 30 - PROGRESS: at 4.75% examples, 334994 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 15:48:59,105 : INFO : EPOCH 30 - PROGRESS: at 10.22% examples, 349417 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:00,132 : INFO : EPOCH 30 - PROGRESS: at 16.28% examples, 366115 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:01,164 : INFO : EPOCH 30 - PROGRESS: at 21.59% examples, 363617 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:02,174 : INFO : EPOCH 30 - PROGRESS: at 26.99% examples, 360361 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:03,180 : INFO : EPOCH 30 - PROGRESS: at 31.79% examples, 356379 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:04,218 : INFO : EPOCH 30 - PROGRESS: at 37.92% examples, 359281 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:05,221 : INFO : EPOCH 30 - PROGRESS: at 43.42% examples, 360529 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:06,237 : INFO : EPOCH 30 - PROGRESS: at 48.08% examples, 356451 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:07,266 : INFO : EPOCH 30 - PROGRESS: at 53.32% examples, 355738 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:08,295 : INFO : EPOCH 30 - PROGRESS: at 58.27% examples, 354105 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:09,314 : INFO : EPOCH 30 - PROGRESS: at 62.97% examples, 351586 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:10,334 : INFO : EPOCH 30 - PROGRESS: at 68.99% examples, 354682 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:11,368 : INFO : EPOCH 30 - PROGRESS: at 74.34% examples, 354245 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:12,378 : INFO : EPOCH 30 - PROGRESS: at 79.69% examples, 353142 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:13,391 : INFO : EPOCH 30 - PROGRESS: at 85.84% examples, 356324 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:14,395 : INFO : EPOCH 30 - PROGRESS: at 91.19% examples, 356365 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:15,405 : INFO : EPOCH 30 - PROGRESS: at 97.07% examples, 359527 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:15,704 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:49:15,706 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:49:15,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:49:15,714 : INFO : EPOCH - 30 : training on 6707530 raw words (6792083 effective words) took 18.6s, 364529 effective words/s\n",
      "2019-06-26 15:49:15,714 : INFO : training on a 201225900 raw words (203762490 effective words) took 544.1s, 374522 effective words/s\n",
      "2019-06-26 15:49:15,724 : INFO : collecting all words and their counts\n",
      "2019-06-26 15:49:15,745 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [doc2vec dbow]: 0:09:09.510699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:49:16,332 : INFO : PROGRESS: at example #10000, processed 750805 words (1281682/s), 23121 word types, 2327 tags\n",
      "2019-06-26 15:49:16,915 : INFO : PROGRESS: at example #20000, processed 1505007 words (1296575/s), 32711 word types, 3860 tags\n",
      "2019-06-26 15:49:17,507 : INFO : PROGRESS: at example #30000, processed 2246842 words (1256074/s), 38845 word types, 5112 tags\n",
      "2019-06-26 15:49:18,097 : INFO : PROGRESS: at example #40000, processed 2992234 words (1265215/s), 43071 word types, 6158 tags\n",
      "2019-06-26 15:49:18,689 : INFO : PROGRESS: at example #50000, processed 3746641 words (1276491/s), 45750 word types, 7015 tags\n",
      "2019-06-26 15:49:19,284 : INFO : PROGRESS: at example #60000, processed 4508593 words (1283865/s), 47529 word types, 7713 tags\n",
      "2019-06-26 15:49:19,879 : INFO : PROGRESS: at example #70000, processed 5271518 words (1283565/s), 48798 word types, 8325 tags\n",
      "2019-06-26 15:49:20,466 : INFO : PROGRESS: at example #80000, processed 6016632 words (1270783/s), 49725 word types, 8881 tags\n",
      "2019-06-26 15:49:21,038 : INFO : collected 50325 word types and 9303 unique tags from a corpus of 89464 examples and 6707530 words\n",
      "2019-06-26 15:49:21,040 : INFO : Loading a fresh vocabulary\n",
      "2019-06-26 15:49:22,493 : INFO : effective_min_count=1 retains 50325 unique words (100% of original 50325, drops 0)\n",
      "2019-06-26 15:49:22,494 : INFO : effective_min_count=1 leaves 6707530 word corpus (100% of original 6707530, drops 0)\n",
      "2019-06-26 15:49:22,622 : INFO : deleting the raw counts dictionary of 50325 items\n",
      "2019-06-26 15:49:22,625 : INFO : sample=0.001 downsamples 47 most-common words\n",
      "2019-06-26 15:49:22,626 : INFO : downsampling leaves estimated 5880283 word corpus (87.7% of prior 6707530)\n",
      "2019-06-26 15:49:22,810 : INFO : estimated required memory for 50325 words and 300 dimensions: 158966700 bytes\n",
      "2019-06-26 15:49:22,811 : INFO : resetting layer weights\n",
      "2019-06-26 15:49:23,334 : INFO : training model with 3 workers on 50325 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-06-26 15:49:24,353 : INFO : EPOCH 1 - PROGRESS: at 5.26% examples, 312005 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 15:49:25,377 : INFO : EPOCH 1 - PROGRESS: at 9.58% examples, 283992 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:26,396 : INFO : EPOCH 1 - PROGRESS: at 15.62% examples, 309937 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:27,407 : INFO : EPOCH 1 - PROGRESS: at 21.42% examples, 321300 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:28,424 : INFO : EPOCH 1 - PROGRESS: at 27.76% examples, 332623 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:49:29,432 : INFO : EPOCH 1 - PROGRESS: at 33.31% examples, 332466 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:30,449 : INFO : EPOCH 1 - PROGRESS: at 37.43% examples, 319549 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:31,451 : INFO : EPOCH 1 - PROGRESS: at 42.10% examples, 314882 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:32,457 : INFO : EPOCH 1 - PROGRESS: at 48.39% examples, 321673 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:33,473 : INFO : EPOCH 1 - PROGRESS: at 52.37% examples, 312828 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:34,476 : INFO : EPOCH 1 - PROGRESS: at 56.97% examples, 308986 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:35,488 : INFO : EPOCH 1 - PROGRESS: at 61.38% examples, 304941 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:36,519 : INFO : EPOCH 1 - PROGRESS: at 67.50% examples, 308338 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:37,545 : INFO : EPOCH 1 - PROGRESS: at 71.82% examples, 303353 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:38,547 : INFO : EPOCH 1 - PROGRESS: at 76.74% examples, 302481 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:39,562 : INFO : EPOCH 1 - PROGRESS: at 80.96% examples, 298142 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:40,576 : INFO : EPOCH 1 - PROGRESS: at 86.69% examples, 299371 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:41,588 : INFO : EPOCH 1 - PROGRESS: at 92.74% examples, 302885 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:42,592 : INFO : EPOCH 1 - PROGRESS: at 98.65% examples, 305767 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:42,704 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:49:42,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:49:42,724 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:49:42,725 : INFO : EPOCH - 1 : training on 6707530 raw words (5969595 effective words) took 19.4s, 307933 effective words/s\n",
      "2019-06-26 15:49:43,758 : INFO : EPOCH 2 - PROGRESS: at 4.20% examples, 231507 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:44,759 : INFO : EPOCH 2 - PROGRESS: at 8.64% examples, 250940 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:45,778 : INFO : EPOCH 2 - PROGRESS: at 15.72% examples, 299362 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:46,817 : INFO : EPOCH 2 - PROGRESS: at 20.74% examples, 296405 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:47,819 : INFO : EPOCH 2 - PROGRESS: at 26.94% examples, 310481 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:48,838 : INFO : EPOCH 2 - PROGRESS: at 32.45% examples, 313050 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:49,866 : INFO : EPOCH 2 - PROGRESS: at 36.55% examples, 304796 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:50,875 : INFO : EPOCH 2 - PROGRESS: at 40.65% examples, 296103 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:51,885 : INFO : EPOCH 2 - PROGRESS: at 44.77% examples, 291273 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:52,927 : INFO : EPOCH 2 - PROGRESS: at 50.83% examples, 296821 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:53,941 : INFO : EPOCH 2 - PROGRESS: at 55.17% examples, 293530 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:54,955 : INFO : EPOCH 2 - PROGRESS: at 59.49% examples, 290016 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:55,977 : INFO : EPOCH 2 - PROGRESS: at 63.58% examples, 286174 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:49:57,017 : INFO : EPOCH 2 - PROGRESS: at 68.20% examples, 284465 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:58,028 : INFO : EPOCH 2 - PROGRESS: at 72.43% examples, 281773 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:49:59,029 : INFO : EPOCH 2 - PROGRESS: at 78.25% examples, 287537 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:00,035 : INFO : EPOCH 2 - PROGRESS: at 82.24% examples, 284487 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:01,036 : INFO : EPOCH 2 - PROGRESS: at 86.65% examples, 282375 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:02,048 : INFO : EPOCH 2 - PROGRESS: at 93.00% examples, 287558 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:03,090 : INFO : EPOCH 2 - PROGRESS: at 97.53% examples, 285757 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:03,510 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:50:03,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:50:03,523 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:50:03,523 : INFO : EPOCH - 2 : training on 6707530 raw words (5969496 effective words) took 20.8s, 287060 effective words/s\n",
      "2019-06-26 15:50:04,529 : INFO : EPOCH 3 - PROGRESS: at 4.02% examples, 244096 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:05,547 : INFO : EPOCH 3 - PROGRESS: at 10.01% examples, 303346 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:06,556 : INFO : EPOCH 3 - PROGRESS: at 15.21% examples, 312654 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:07,588 : INFO : EPOCH 3 - PROGRESS: at 22.10% examples, 330532 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:08,598 : INFO : EPOCH 3 - PROGRESS: at 27.49% examples, 328805 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:09,618 : INFO : EPOCH 3 - PROGRESS: at 31.52% examples, 314108 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:10,620 : INFO : EPOCH 3 - PROGRESS: at 35.37% examples, 304288 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:11,636 : INFO : EPOCH 3 - PROGRESS: at 39.79% examples, 299636 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:12,651 : INFO : EPOCH 3 - PROGRESS: at 43.87% examples, 294257 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:50:13,661 : INFO : EPOCH 3 - PROGRESS: at 49.21% examples, 295209 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:14,679 : INFO : EPOCH 3 - PROGRESS: at 53.58% examples, 291889 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:15,734 : INFO : EPOCH 3 - PROGRESS: at 57.94% examples, 288195 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:16,739 : INFO : EPOCH 3 - PROGRESS: at 62.90% examples, 287408 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:17,743 : INFO : EPOCH 3 - PROGRESS: at 69.57% examples, 293716 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:18,752 : INFO : EPOCH 3 - PROGRESS: at 75.64% examples, 297818 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:19,768 : INFO : EPOCH 3 - PROGRESS: at 80.58% examples, 295919 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:20,784 : INFO : EPOCH 3 - PROGRESS: at 86.14% examples, 297212 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:21,798 : INFO : EPOCH 3 - PROGRESS: at 90.12% examples, 294649 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:22,802 : INFO : EPOCH 3 - PROGRESS: at 94.30% examples, 292003 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:23,806 : INFO : EPOCH 3 - PROGRESS: at 98.33% examples, 289249 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:24,016 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:50:24,020 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:50:24,025 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:50:24,026 : INFO : EPOCH - 3 : training on 6707530 raw words (5968915 effective words) took 20.5s, 291140 effective words/s\n",
      "2019-06-26 15:50:25,062 : INFO : EPOCH 4 - PROGRESS: at 4.28% examples, 254255 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:26,092 : INFO : EPOCH 4 - PROGRESS: at 8.53% examples, 254346 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:27,130 : INFO : EPOCH 4 - PROGRESS: at 13.07% examples, 253931 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:28,168 : INFO : EPOCH 4 - PROGRESS: at 17.40% examples, 251865 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:29,174 : INFO : EPOCH 4 - PROGRESS: at 21.59% examples, 250538 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:30,187 : INFO : EPOCH 4 - PROGRESS: at 25.59% examples, 247788 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:31,231 : INFO : EPOCH 4 - PROGRESS: at 29.75% examples, 245879 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:32,258 : INFO : EPOCH 4 - PROGRESS: at 35.31% examples, 255807 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:33,266 : INFO : EPOCH 4 - PROGRESS: at 39.75% examples, 256435 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:34,308 : INFO : EPOCH 4 - PROGRESS: at 44.36% examples, 258696 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:35,332 : INFO : EPOCH 4 - PROGRESS: at 48.58% examples, 257701 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:36,339 : INFO : EPOCH 4 - PROGRESS: at 54.57% examples, 265201 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:37,362 : INFO : EPOCH 4 - PROGRESS: at 59.67% examples, 267091 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:38,394 : INFO : EPOCH 4 - PROGRESS: at 63.86% examples, 266854 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:39,394 : INFO : EPOCH 4 - PROGRESS: at 67.71% examples, 264240 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:40,397 : INFO : EPOCH 4 - PROGRESS: at 72.21% examples, 263592 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:41,442 : INFO : EPOCH 4 - PROGRESS: at 77.19% examples, 264354 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:42,467 : INFO : EPOCH 4 - PROGRESS: at 81.49% examples, 263914 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:43,506 : INFO : EPOCH 4 - PROGRESS: at 85.74% examples, 262442 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:44,545 : INFO : EPOCH 4 - PROGRESS: at 90.12% examples, 261912 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:45,568 : INFO : EPOCH 4 - PROGRESS: at 94.20% examples, 260815 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:46,577 : INFO : EPOCH 4 - PROGRESS: at 98.64% examples, 260811 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:46,741 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:50:46,743 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:50:46,752 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:50:46,753 : INFO : EPOCH - 4 : training on 6707530 raw words (5969910 effective words) took 22.7s, 262716 effective words/s\n",
      "2019-06-26 15:50:47,770 : INFO : EPOCH 5 - PROGRESS: at 5.14% examples, 320521 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:48,778 : INFO : EPOCH 5 - PROGRESS: at 9.27% examples, 277912 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:49,794 : INFO : EPOCH 5 - PROGRESS: at 15.55% examples, 311981 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:50,810 : INFO : EPOCH 5 - PROGRESS: at 22.76% examples, 333179 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:51,817 : INFO : EPOCH 5 - PROGRESS: at 28.46% examples, 332856 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:52,859 : INFO : EPOCH 5 - PROGRESS: at 34.86% examples, 339106 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:53,870 : INFO : EPOCH 5 - PROGRESS: at 39.12% examples, 327889 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:54,883 : INFO : EPOCH 5 - PROGRESS: at 43.41% examples, 317213 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:55,901 : INFO : EPOCH 5 - PROGRESS: at 48.59% examples, 315432 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:56,947 : INFO : EPOCH 5 - PROGRESS: at 53.00% examples, 308966 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:50:57,977 : INFO : EPOCH 5 - PROGRESS: at 57.36% examples, 304147 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:50:58,984 : INFO : EPOCH 5 - PROGRESS: at 62.66% examples, 304226 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:00,023 : INFO : EPOCH 5 - PROGRESS: at 69.41% examples, 310799 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:01,047 : INFO : EPOCH 5 - PROGRESS: at 76.51% examples, 319157 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:02,060 : INFO : EPOCH 5 - PROGRESS: at 82.60% examples, 322059 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:03,090 : INFO : EPOCH 5 - PROGRESS: at 88.95% examples, 324844 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:04,094 : INFO : EPOCH 5 - PROGRESS: at 93.70% examples, 322692 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:05,094 : INFO : EPOCH 5 - PROGRESS: at 97.98% examples, 319358 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:05,342 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:51:05,356 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:51:05,374 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:51:05,375 : INFO : EPOCH - 5 : training on 6707530 raw words (5969598 effective words) took 18.6s, 320609 effective words/s\n",
      "2019-06-26 15:51:06,398 : INFO : EPOCH 6 - PROGRESS: at 4.01% examples, 233169 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:07,428 : INFO : EPOCH 6 - PROGRESS: at 8.32% examples, 239643 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:08,454 : INFO : EPOCH 6 - PROGRESS: at 12.52% examples, 239897 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:09,483 : INFO : EPOCH 6 - PROGRESS: at 16.82% examples, 243836 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:10,487 : INFO : EPOCH 6 - PROGRESS: at 21.18% examples, 247420 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:11,516 : INFO : EPOCH 6 - PROGRESS: at 26.71% examples, 260205 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:12,556 : INFO : EPOCH 6 - PROGRESS: at 31.09% examples, 258830 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:13,594 : INFO : EPOCH 6 - PROGRESS: at 35.36% examples, 258075 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:14,604 : INFO : EPOCH 6 - PROGRESS: at 39.67% examples, 256510 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:15,625 : INFO : EPOCH 6 - PROGRESS: at 43.92% examples, 255748 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:16,653 : INFO : EPOCH 6 - PROGRESS: at 48.31% examples, 255040 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:51:17,672 : INFO : EPOCH 6 - PROGRESS: at 52.55% examples, 255149 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:18,678 : INFO : EPOCH 6 - PROGRESS: at 57.30% examples, 257535 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:19,719 : INFO : EPOCH 6 - PROGRESS: at 61.25% examples, 255424 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:20,734 : INFO : EPOCH 6 - PROGRESS: at 65.88% examples, 256249 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:21,750 : INFO : EPOCH 6 - PROGRESS: at 71.49% examples, 261225 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:22,751 : INFO : EPOCH 6 - PROGRESS: at 77.86% examples, 267868 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:23,763 : INFO : EPOCH 6 - PROGRESS: at 82.09% examples, 266945 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:24,782 : INFO : EPOCH 6 - PROGRESS: at 86.55% examples, 266431 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:25,805 : INFO : EPOCH 6 - PROGRESS: at 92.43% examples, 270697 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:26,814 : INFO : EPOCH 6 - PROGRESS: at 97.33% examples, 271080 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:27,261 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:51:27,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:51:27,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:51:27,272 : INFO : EPOCH - 6 : training on 6707530 raw words (5969617 effective words) took 21.9s, 272671 effective words/s\n",
      "2019-06-26 15:51:28,291 : INFO : EPOCH 7 - PROGRESS: at 4.00% examples, 241276 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:29,294 : INFO : EPOCH 7 - PROGRESS: at 8.45% examples, 251665 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:30,313 : INFO : EPOCH 7 - PROGRESS: at 12.73% examples, 248016 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:31,333 : INFO : EPOCH 7 - PROGRESS: at 18.82% examples, 280498 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:32,337 : INFO : EPOCH 7 - PROGRESS: at 25.34% examples, 299313 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:33,377 : INFO : EPOCH 7 - PROGRESS: at 30.41% examples, 297334 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:34,432 : INFO : EPOCH 7 - PROGRESS: at 35.92% examples, 298438 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:35,435 : INFO : EPOCH 7 - PROGRESS: at 40.12% examples, 292857 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:36,437 : INFO : EPOCH 7 - PROGRESS: at 44.63% examples, 292328 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:37,499 : INFO : EPOCH 7 - PROGRESS: at 49.51% examples, 290253 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:38,509 : INFO : EPOCH 7 - PROGRESS: at 53.99% examples, 286808 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:39,517 : INFO : EPOCH 7 - PROGRESS: at 58.36% examples, 283983 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:40,532 : INFO : EPOCH 7 - PROGRESS: at 62.58% examples, 280181 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:41,549 : INFO : EPOCH 7 - PROGRESS: at 69.01% examples, 287183 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:42,566 : INFO : EPOCH 7 - PROGRESS: at 74.14% examples, 288102 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:43,582 : INFO : EPOCH 7 - PROGRESS: at 78.80% examples, 287453 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:44,612 : INFO : EPOCH 7 - PROGRESS: at 83.22% examples, 285565 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:45,626 : INFO : EPOCH 7 - PROGRESS: at 88.02% examples, 286054 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:46,674 : INFO : EPOCH 7 - PROGRESS: at 92.93% examples, 285514 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:47,681 : INFO : EPOCH 7 - PROGRESS: at 98.72% examples, 288162 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:47,820 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:51:47,822 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:51:47,824 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:51:47,825 : INFO : EPOCH - 7 : training on 6707530 raw words (5968804 effective words) took 20.5s, 290461 effective words/s\n",
      "2019-06-26 15:51:48,841 : INFO : EPOCH 8 - PROGRESS: at 6.56% examples, 373327 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:49,857 : INFO : EPOCH 8 - PROGRESS: at 12.95% examples, 371823 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:50,883 : INFO : EPOCH 8 - PROGRESS: at 19.28% examples, 370537 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:51,908 : INFO : EPOCH 8 - PROGRESS: at 25.19% examples, 367841 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:52,922 : INFO : EPOCH 8 - PROGRESS: at 30.92% examples, 363410 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:53,924 : INFO : EPOCH 8 - PROGRESS: at 36.85% examples, 362835 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:51:54,930 : INFO : EPOCH 8 - PROGRESS: at 41.71% examples, 353519 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:55,932 : INFO : EPOCH 8 - PROGRESS: at 46.30% examples, 343292 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:56,970 : INFO : EPOCH 8 - PROGRESS: at 50.52% examples, 331184 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:57,972 : INFO : EPOCH 8 - PROGRESS: at 54.53% examples, 321915 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:58,980 : INFO : EPOCH 8 - PROGRESS: at 58.75% examples, 315549 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:51:59,982 : INFO : EPOCH 8 - PROGRESS: at 63.86% examples, 314056 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:00,997 : INFO : EPOCH 8 - PROGRESS: at 68.79% examples, 310514 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:02,003 : INFO : EPOCH 8 - PROGRESS: at 72.79% examples, 305194 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:03,005 : INFO : EPOCH 8 - PROGRESS: at 77.40% examples, 304046 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:04,007 : INFO : EPOCH 8 - PROGRESS: at 81.75% examples, 301425 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:05,008 : INFO : EPOCH 8 - PROGRESS: at 85.75% examples, 297571 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:06,016 : INFO : EPOCH 8 - PROGRESS: at 90.00% examples, 294593 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:07,022 : INFO : EPOCH 8 - PROGRESS: at 94.41% examples, 292807 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:07,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:52:07,801 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:52:07,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:52:07,805 : INFO : EPOCH - 8 : training on 6707530 raw words (5970190 effective words) took 20.0s, 298833 effective words/s\n",
      "2019-06-26 15:52:08,850 : INFO : EPOCH 9 - PROGRESS: at 3.72% examples, 219001 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:09,868 : INFO : EPOCH 9 - PROGRESS: at 7.97% examples, 234323 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:10,875 : INFO : EPOCH 9 - PROGRESS: at 13.77% examples, 274397 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:11,895 : INFO : EPOCH 9 - PROGRESS: at 20.06% examples, 298581 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:12,906 : INFO : EPOCH 9 - PROGRESS: at 24.63% examples, 291132 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:13,927 : INFO : EPOCH 9 - PROGRESS: at 29.09% examples, 287177 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:14,941 : INFO : EPOCH 9 - PROGRESS: at 33.43% examples, 283163 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:15,946 : INFO : EPOCH 9 - PROGRESS: at 38.02% examples, 281692 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:16,947 : INFO : EPOCH 9 - PROGRESS: at 42.10% examples, 277589 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:17,967 : INFO : EPOCH 9 - PROGRESS: at 47.32% examples, 279792 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:19,015 : INFO : EPOCH 9 - PROGRESS: at 52.24% examples, 278645 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:20,025 : INFO : EPOCH 9 - PROGRESS: at 56.51% examples, 276374 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:21,034 : INFO : EPOCH 9 - PROGRESS: at 60.32% examples, 273880 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:52:22,037 : INFO : EPOCH 9 - PROGRESS: at 64.97% examples, 273685 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:23,048 : INFO : EPOCH 9 - PROGRESS: at 69.71% examples, 273852 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:24,054 : INFO : EPOCH 9 - PROGRESS: at 74.43% examples, 274675 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:25,093 : INFO : EPOCH 9 - PROGRESS: at 79.69% examples, 276415 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:26,111 : INFO : EPOCH 9 - PROGRESS: at 86.03% examples, 281647 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:27,116 : INFO : EPOCH 9 - PROGRESS: at 90.28% examples, 280210 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:28,129 : INFO : EPOCH 9 - PROGRESS: at 94.75% examples, 278356 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:29,136 : INFO : EPOCH 9 - PROGRESS: at 99.44% examples, 278354 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-26 15:52:29,152 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:52:29,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:52:29,179 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:52:29,180 : INFO : EPOCH - 9 : training on 6707530 raw words (5968930 effective words) took 21.4s, 279275 effective words/s\n",
      "2019-06-26 15:52:30,187 : INFO : EPOCH 10 - PROGRESS: at 4.11% examples, 245719 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:31,215 : INFO : EPOCH 10 - PROGRESS: at 8.07% examples, 237503 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:32,249 : INFO : EPOCH 10 - PROGRESS: at 12.65% examples, 243002 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:33,278 : INFO : EPOCH 10 - PROGRESS: at 16.59% examples, 239664 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:34,309 : INFO : EPOCH 10 - PROGRESS: at 21.67% examples, 251418 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:35,319 : INFO : EPOCH 10 - PROGRESS: at 28.12% examples, 275786 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:36,362 : INFO : EPOCH 10 - PROGRESS: at 33.26% examples, 278509 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:37,383 : INFO : EPOCH 10 - PROGRESS: at 37.34% examples, 272516 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:38,418 : INFO : EPOCH 10 - PROGRESS: at 41.60% examples, 268617 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:39,478 : INFO : EPOCH 10 - PROGRESS: at 45.77% examples, 265579 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:40,499 : INFO : EPOCH 10 - PROGRESS: at 50.45% examples, 264779 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:41,546 : INFO : EPOCH 10 - PROGRESS: at 55.34% examples, 265930 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:42,569 : INFO : EPOCH 10 - PROGRESS: at 60.28% examples, 267823 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:43,578 : INFO : EPOCH 10 - PROGRESS: at 65.58% examples, 272078 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:44,584 : INFO : EPOCH 10 - PROGRESS: at 69.60% examples, 270819 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:45,613 : INFO : EPOCH 10 - PROGRESS: at 73.77% examples, 268850 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:46,616 : INFO : EPOCH 10 - PROGRESS: at 77.82% examples, 267467 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:47,641 : INFO : EPOCH 10 - PROGRESS: at 81.96% examples, 266483 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:48,665 : INFO : EPOCH 10 - PROGRESS: at 86.18% examples, 265019 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:49,720 : INFO : EPOCH 10 - PROGRESS: at 90.53% examples, 263780 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:50,728 : INFO : EPOCH 10 - PROGRESS: at 94.81% examples, 263230 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:51,695 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:52:51,696 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:52:51,721 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:52:51,723 : INFO : EPOCH - 10 : training on 6707530 raw words (5969297 effective words) took 22.5s, 264845 effective words/s\n",
      "2019-06-26 15:52:52,744 : INFO : EPOCH 11 - PROGRESS: at 5.30% examples, 336506 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:53,763 : INFO : EPOCH 11 - PROGRESS: at 10.66% examples, 323617 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:54,773 : INFO : EPOCH 11 - PROGRESS: at 15.07% examples, 305909 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:55,780 : INFO : EPOCH 11 - PROGRESS: at 19.76% examples, 296925 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:52:56,827 : INFO : EPOCH 11 - PROGRESS: at 24.00% examples, 285945 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:57,841 : INFO : EPOCH 11 - PROGRESS: at 28.18% examples, 275705 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:58,853 : INFO : EPOCH 11 - PROGRESS: at 32.46% examples, 273396 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:52:59,859 : INFO : EPOCH 11 - PROGRESS: at 36.75% examples, 270761 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:00,899 : INFO : EPOCH 11 - PROGRESS: at 41.33% examples, 269563 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:01,910 : INFO : EPOCH 11 - PROGRESS: at 46.19% examples, 271173 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:02,915 : INFO : EPOCH 11 - PROGRESS: at 50.67% examples, 269556 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:03,948 : INFO : EPOCH 11 - PROGRESS: at 57.47% examples, 280463 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:04,957 : INFO : EPOCH 11 - PROGRESS: at 61.84% examples, 277026 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:05,973 : INFO : EPOCH 11 - PROGRESS: at 67.16% examples, 280090 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:06,998 : INFO : EPOCH 11 - PROGRESS: at 71.54% examples, 279173 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:08,018 : INFO : EPOCH 11 - PROGRESS: at 75.83% examples, 278380 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:09,029 : INFO : EPOCH 11 - PROGRESS: at 81.38% examples, 280930 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:10,054 : INFO : EPOCH 11 - PROGRESS: at 85.62% examples, 278193 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:11,057 : INFO : EPOCH 11 - PROGRESS: at 89.85% examples, 276516 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:12,095 : INFO : EPOCH 11 - PROGRESS: at 94.41% examples, 275734 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:13,080 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:53:13,090 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:53:13,099 : INFO : EPOCH 11 - PROGRESS: at 100.00% examples, 279282 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-26 15:53:13,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:53:13,101 : INFO : EPOCH - 11 : training on 6707530 raw words (5969178 effective words) took 21.4s, 279264 effective words/s\n",
      "2019-06-26 15:53:14,112 : INFO : EPOCH 12 - PROGRESS: at 4.50% examples, 260900 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:15,112 : INFO : EPOCH 12 - PROGRESS: at 10.81% examples, 314943 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:16,127 : INFO : EPOCH 12 - PROGRESS: at 14.92% examples, 290073 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:17,145 : INFO : EPOCH 12 - PROGRESS: at 19.70% examples, 290573 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:18,152 : INFO : EPOCH 12 - PROGRESS: at 26.08% examples, 308919 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:19,176 : INFO : EPOCH 12 - PROGRESS: at 31.88% examples, 314475 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:20,229 : INFO : EPOCH 12 - PROGRESS: at 36.80% examples, 308570 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:21,230 : INFO : EPOCH 12 - PROGRESS: at 41.67% examples, 308460 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:22,261 : INFO : EPOCH 12 - PROGRESS: at 46.60% examples, 304473 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 15:53:23,269 : INFO : EPOCH 12 - PROGRESS: at 50.95% examples, 300181 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:24,284 : INFO : EPOCH 12 - PROGRESS: at 56.52% examples, 302639 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:25,290 : INFO : EPOCH 12 - PROGRESS: at 62.59% examples, 309232 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:53:26,297 : INFO : EPOCH 12 - PROGRESS: at 68.34% examples, 311450 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:27,334 : INFO : EPOCH 12 - PROGRESS: at 72.29% examples, 304833 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:28,355 : INFO : EPOCH 12 - PROGRESS: at 77.25% examples, 304547 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:29,394 : INFO : EPOCH 12 - PROGRESS: at 82.93% examples, 305122 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:30,427 : INFO : EPOCH 12 - PROGRESS: at 87.66% examples, 302657 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:31,432 : INFO : EPOCH 12 - PROGRESS: at 93.22% examples, 304220 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:32,449 : INFO : EPOCH 12 - PROGRESS: at 97.92% examples, 302725 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:32,689 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:53:32,702 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:53:32,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:53:32,720 : INFO : EPOCH - 12 : training on 6707530 raw words (5968671 effective words) took 19.6s, 304266 effective words/s\n",
      "2019-06-26 15:53:33,728 : INFO : EPOCH 13 - PROGRESS: at 3.88% examples, 227710 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:34,730 : INFO : EPOCH 13 - PROGRESS: at 8.29% examples, 249609 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:35,756 : INFO : EPOCH 13 - PROGRESS: at 12.79% examples, 254618 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:36,811 : INFO : EPOCH 13 - PROGRESS: at 16.41% examples, 246806 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:37,814 : INFO : EPOCH 13 - PROGRESS: at 20.37% examples, 246315 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:38,827 : INFO : EPOCH 13 - PROGRESS: at 24.85% examples, 249964 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:39,837 : INFO : EPOCH 13 - PROGRESS: at 28.68% examples, 245113 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:40,851 : INFO : EPOCH 13 - PROGRESS: at 33.82% examples, 250115 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:41,862 : INFO : EPOCH 13 - PROGRESS: at 39.34% examples, 257966 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:42,865 : INFO : EPOCH 13 - PROGRESS: at 43.67% examples, 257286 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 15:53:43,894 : INFO : EPOCH 13 - PROGRESS: at 49.38% examples, 265009 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:44,902 : INFO : EPOCH 13 - PROGRESS: at 53.20% examples, 262537 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:45,969 : INFO : EPOCH 13 - PROGRESS: at 58.88% examples, 267120 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:46,999 : INFO : EPOCH 13 - PROGRESS: at 63.41% examples, 266897 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:48,000 : INFO : EPOCH 13 - PROGRESS: at 67.68% examples, 266070 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:49,016 : INFO : EPOCH 13 - PROGRESS: at 71.96% examples, 265040 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:50,030 : INFO : EPOCH 13 - PROGRESS: at 76.05% examples, 263723 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:51,055 : INFO : EPOCH 13 - PROGRESS: at 79.96% examples, 261899 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:52,074 : INFO : EPOCH 13 - PROGRESS: at 83.77% examples, 259862 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:53,098 : INFO : EPOCH 13 - PROGRESS: at 88.81% examples, 260976 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:54,116 : INFO : EPOCH 13 - PROGRESS: at 94.71% examples, 264625 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:53:54,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:53:54,868 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:53:54,883 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:53:54,884 : INFO : EPOCH - 13 : training on 6707530 raw words (5969453 effective words) took 22.2s, 269372 effective words/s\n",
      "2019-06-26 15:53:55,901 : INFO : EPOCH 14 - PROGRESS: at 3.97% examples, 224771 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:56,912 : INFO : EPOCH 14 - PROGRESS: at 7.66% examples, 220574 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:57,921 : INFO : EPOCH 14 - PROGRESS: at 13.49% examples, 263163 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:58,969 : INFO : EPOCH 14 - PROGRESS: at 18.11% examples, 260063 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:53:59,985 : INFO : EPOCH 14 - PROGRESS: at 23.23% examples, 268245 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:01,002 : INFO : EPOCH 14 - PROGRESS: at 27.46% examples, 265241 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:02,022 : INFO : EPOCH 14 - PROGRESS: at 32.80% examples, 270401 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:03,036 : INFO : EPOCH 14 - PROGRESS: at 37.40% examples, 271071 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:04,043 : INFO : EPOCH 14 - PROGRESS: at 42.50% examples, 273955 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:05,055 : INFO : EPOCH 14 - PROGRESS: at 49.01% examples, 286276 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:06,064 : INFO : EPOCH 14 - PROGRESS: at 54.74% examples, 291046 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:07,124 : INFO : EPOCH 14 - PROGRESS: at 58.65% examples, 285837 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:08,147 : INFO : EPOCH 14 - PROGRESS: at 63.45% examples, 283675 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:09,171 : INFO : EPOCH 14 - PROGRESS: at 69.01% examples, 287173 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:10,184 : INFO : EPOCH 14 - PROGRESS: at 73.21% examples, 285422 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:11,222 : INFO : EPOCH 14 - PROGRESS: at 78.31% examples, 286091 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:12,245 : INFO : EPOCH 14 - PROGRESS: at 82.90% examples, 284917 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:13,248 : INFO : EPOCH 14 - PROGRESS: at 86.87% examples, 282239 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:14,274 : INFO : EPOCH 14 - PROGRESS: at 92.02% examples, 283567 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:15,290 : INFO : EPOCH 14 - PROGRESS: at 96.09% examples, 281455 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:16,025 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:54:16,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:54:16,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:54:16,049 : INFO : EPOCH - 14 : training on 6707530 raw words (5969803 effective words) took 21.2s, 282079 effective words/s\n",
      "2019-06-26 15:54:17,099 : INFO : EPOCH 15 - PROGRESS: at 4.08% examples, 234877 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:18,134 : INFO : EPOCH 15 - PROGRESS: at 9.60% examples, 272705 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:19,149 : INFO : EPOCH 15 - PROGRESS: at 14.48% examples, 279611 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:20,157 : INFO : EPOCH 15 - PROGRESS: at 19.23% examples, 277034 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:21,210 : INFO : EPOCH 15 - PROGRESS: at 24.55% examples, 281681 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:22,225 : INFO : EPOCH 15 - PROGRESS: at 30.41% examples, 290806 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:23,226 : INFO : EPOCH 15 - PROGRESS: at 35.61% examples, 295732 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:24,237 : INFO : EPOCH 15 - PROGRESS: at 40.18% examples, 293352 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:25,253 : INFO : EPOCH 15 - PROGRESS: at 46.69% examples, 301023 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:26,258 : INFO : EPOCH 15 - PROGRESS: at 52.84% examples, 306729 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:27,287 : INFO : EPOCH 15 - PROGRESS: at 57.15% examples, 301214 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:28,306 : INFO : EPOCH 15 - PROGRESS: at 60.73% examples, 295517 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:29,342 : INFO : EPOCH 15 - PROGRESS: at 65.14% examples, 292260 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:30,348 : INFO : EPOCH 15 - PROGRESS: at 69.01% examples, 287583 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:54:31,363 : INFO : EPOCH 15 - PROGRESS: at 73.18% examples, 284589 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:32,388 : INFO : EPOCH 15 - PROGRESS: at 77.60% examples, 282884 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:33,418 : INFO : EPOCH 15 - PROGRESS: at 82.25% examples, 281850 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:34,420 : INFO : EPOCH 15 - PROGRESS: at 87.44% examples, 283270 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:35,421 : INFO : EPOCH 15 - PROGRESS: at 92.21% examples, 283533 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:36,450 : INFO : EPOCH 15 - PROGRESS: at 96.92% examples, 283414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:36,897 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:54:36,908 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:54:36,922 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:54:36,923 : INFO : EPOCH - 15 : training on 6707530 raw words (5969234 effective words) took 20.9s, 286002 effective words/s\n",
      "2019-06-26 15:54:37,946 : INFO : EPOCH 16 - PROGRESS: at 3.68% examples, 214345 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:38,960 : INFO : EPOCH 16 - PROGRESS: at 7.76% examples, 227770 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:39,999 : INFO : EPOCH 16 - PROGRESS: at 11.75% examples, 225034 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:41,022 : INFO : EPOCH 16 - PROGRESS: at 15.55% examples, 224494 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:42,041 : INFO : EPOCH 16 - PROGRESS: at 19.94% examples, 229609 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:43,046 : INFO : EPOCH 16 - PROGRESS: at 24.65% examples, 239366 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:44,047 : INFO : EPOCH 16 - PROGRESS: at 29.35% examples, 247526 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:45,059 : INFO : EPOCH 16 - PROGRESS: at 35.89% examples, 266197 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:46,082 : INFO : EPOCH 16 - PROGRESS: at 39.75% examples, 262233 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:47,106 : INFO : EPOCH 16 - PROGRESS: at 44.18% examples, 260077 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:48,117 : INFO : EPOCH 16 - PROGRESS: at 48.81% examples, 260064 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:49,121 : INFO : EPOCH 16 - PROGRESS: at 54.86% examples, 268028 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:50,134 : INFO : EPOCH 16 - PROGRESS: at 59.80% examples, 268149 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:51,144 : INFO : EPOCH 16 - PROGRESS: at 65.04% examples, 271266 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:52,145 : INFO : EPOCH 16 - PROGRESS: at 69.36% examples, 270168 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:53,158 : INFO : EPOCH 16 - PROGRESS: at 74.90% examples, 272756 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:54,159 : INFO : EPOCH 16 - PROGRESS: at 80.99% examples, 278307 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:55,162 : INFO : EPOCH 16 - PROGRESS: at 85.04% examples, 276470 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:56,177 : INFO : EPOCH 16 - PROGRESS: at 89.04% examples, 274178 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:57,192 : INFO : EPOCH 16 - PROGRESS: at 94.16% examples, 276426 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:54:58,193 : INFO : EPOCH 16 - PROGRESS: at 98.59% examples, 276544 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:54:58,305 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:54:58,327 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:54:58,330 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:54:58,331 : INFO : EPOCH - 16 : training on 6707530 raw words (5970228 effective words) took 21.4s, 278915 effective words/s\n",
      "2019-06-26 15:54:59,347 : INFO : EPOCH 17 - PROGRESS: at 3.84% examples, 225007 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:00,403 : INFO : EPOCH 17 - PROGRESS: at 8.31% examples, 233385 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:01,407 : INFO : EPOCH 17 - PROGRESS: at 14.66% examples, 284921 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:02,437 : INFO : EPOCH 17 - PROGRESS: at 20.66% examples, 303374 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:03,460 : INFO : EPOCH 17 - PROGRESS: at 27.45% examples, 323075 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:04,464 : INFO : EPOCH 17 - PROGRESS: at 33.16% examples, 325987 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:05,480 : INFO : EPOCH 17 - PROGRESS: at 37.14% examples, 311481 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:06,525 : INFO : EPOCH 17 - PROGRESS: at 41.70% examples, 306072 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:07,550 : INFO : EPOCH 17 - PROGRESS: at 46.24% examples, 300524 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:08,570 : INFO : EPOCH 17 - PROGRESS: at 50.39% examples, 294534 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:09,612 : INFO : EPOCH 17 - PROGRESS: at 54.48% examples, 289025 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:10,648 : INFO : EPOCH 17 - PROGRESS: at 59.59% examples, 288283 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:11,712 : INFO : EPOCH 17 - PROGRESS: at 63.80% examples, 285019 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:12,723 : INFO : EPOCH 17 - PROGRESS: at 67.75% examples, 281461 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:13,742 : INFO : EPOCH 17 - PROGRESS: at 72.48% examples, 281088 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:14,745 : INFO : EPOCH 17 - PROGRESS: at 76.97% examples, 280497 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:15,762 : INFO : EPOCH 17 - PROGRESS: at 81.40% examples, 278707 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:16,786 : INFO : EPOCH 17 - PROGRESS: at 85.58% examples, 276559 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:17,815 : INFO : EPOCH 17 - PROGRESS: at 90.21% examples, 276895 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:18,831 : INFO : EPOCH 17 - PROGRESS: at 94.36% examples, 275562 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:19,861 : INFO : EPOCH 17 - PROGRESS: at 98.53% examples, 273385 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:19,999 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:55:20,014 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:55:20,019 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:55:20,020 : INFO : EPOCH - 17 : training on 6707530 raw words (5968679 effective words) took 21.7s, 275223 effective words/s\n",
      "2019-06-26 15:55:21,023 : INFO : EPOCH 18 - PROGRESS: at 5.29% examples, 331746 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:22,024 : INFO : EPOCH 18 - PROGRESS: at 11.92% examples, 362974 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:23,033 : INFO : EPOCH 18 - PROGRESS: at 18.45% examples, 372129 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:24,049 : INFO : EPOCH 18 - PROGRESS: at 24.24% examples, 369426 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:25,074 : INFO : EPOCH 18 - PROGRESS: at 28.83% examples, 348536 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:26,093 : INFO : EPOCH 18 - PROGRESS: at 33.36% examples, 332017 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:27,098 : INFO : EPOCH 18 - PROGRESS: at 37.71% examples, 321783 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:28,132 : INFO : EPOCH 18 - PROGRESS: at 42.70% examples, 317528 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:29,134 : INFO : EPOCH 18 - PROGRESS: at 47.82% examples, 316260 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:30,181 : INFO : EPOCH 18 - PROGRESS: at 53.03% examples, 313029 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:31,204 : INFO : EPOCH 18 - PROGRESS: at 59.04% examples, 317231 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:32,218 : INFO : EPOCH 18 - PROGRESS: at 66.88% examples, 329731 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:33,229 : INFO : EPOCH 18 - PROGRESS: at 72.49% examples, 330349 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:34,253 : INFO : EPOCH 18 - PROGRESS: at 78.62% examples, 331874 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:55:35,271 : INFO : EPOCH 18 - PROGRESS: at 85.88% examples, 337898 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:36,277 : INFO : EPOCH 18 - PROGRESS: at 90.97% examples, 334856 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:37,278 : INFO : EPOCH 18 - PROGRESS: at 95.82% examples, 331653 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:37,977 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:55:37,985 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:55:37,998 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:55:37,999 : INFO : EPOCH - 18 : training on 6707530 raw words (5969451 effective words) took 18.0s, 332050 effective words/s\n",
      "2019-06-26 15:55:39,014 : INFO : EPOCH 19 - PROGRESS: at 5.07% examples, 303711 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:40,021 : INFO : EPOCH 19 - PROGRESS: at 9.91% examples, 286957 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:41,026 : INFO : EPOCH 19 - PROGRESS: at 14.81% examples, 289924 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:42,048 : INFO : EPOCH 19 - PROGRESS: at 19.52% examples, 286077 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:43,064 : INFO : EPOCH 19 - PROGRESS: at 24.02% examples, 282395 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:44,101 : INFO : EPOCH 19 - PROGRESS: at 29.55% examples, 286367 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:45,131 : INFO : EPOCH 19 - PROGRESS: at 34.85% examples, 289367 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:46,143 : INFO : EPOCH 19 - PROGRESS: at 40.20% examples, 295103 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:47,155 : INFO : EPOCH 19 - PROGRESS: at 45.57% examples, 297904 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:48,179 : INFO : EPOCH 19 - PROGRESS: at 52.22% examples, 307700 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:49,182 : INFO : EPOCH 19 - PROGRESS: at 57.69% examples, 308932 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:50,193 : INFO : EPOCH 19 - PROGRESS: at 63.51% examples, 311428 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:51,197 : INFO : EPOCH 19 - PROGRESS: at 71.26% examples, 322258 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:52,202 : INFO : EPOCH 19 - PROGRESS: at 79.00% examples, 331042 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:55:53,209 : INFO : EPOCH 19 - PROGRESS: at 83.90% examples, 329273 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:54,213 : INFO : EPOCH 19 - PROGRESS: at 88.27% examples, 325176 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:55,234 : INFO : EPOCH 19 - PROGRESS: at 93.47% examples, 324195 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:56,256 : INFO : EPOCH 19 - PROGRESS: at 98.68% examples, 322881 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:56,338 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:55:56,343 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:55:56,355 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:55:56,356 : INFO : EPOCH - 19 : training on 6707530 raw words (5969187 effective words) took 18.4s, 325208 effective words/s\n",
      "2019-06-26 15:55:57,364 : INFO : EPOCH 20 - PROGRESS: at 4.53% examples, 253349 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:58,398 : INFO : EPOCH 20 - PROGRESS: at 9.11% examples, 257922 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:55:59,415 : INFO : EPOCH 20 - PROGRESS: at 13.36% examples, 258610 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:00,450 : INFO : EPOCH 20 - PROGRESS: at 18.13% examples, 259487 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:01,469 : INFO : EPOCH 20 - PROGRESS: at 22.66% examples, 262527 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:02,503 : INFO : EPOCH 20 - PROGRESS: at 27.48% examples, 265293 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:03,519 : INFO : EPOCH 20 - PROGRESS: at 32.65% examples, 271648 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:04,521 : INFO : EPOCH 20 - PROGRESS: at 37.77% examples, 274886 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:05,537 : INFO : EPOCH 20 - PROGRESS: at 42.31% examples, 274106 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:06,546 : INFO : EPOCH 20 - PROGRESS: at 49.13% examples, 286614 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:07,563 : INFO : EPOCH 20 - PROGRESS: at 56.98% examples, 301276 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:08,565 : INFO : EPOCH 20 - PROGRESS: at 64.48% examples, 314688 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:09,586 : INFO : EPOCH 20 - PROGRESS: at 72.20% examples, 325564 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:10,597 : INFO : EPOCH 20 - PROGRESS: at 76.58% examples, 321537 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:11,633 : INFO : EPOCH 20 - PROGRESS: at 81.33% examples, 316909 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:12,657 : INFO : EPOCH 20 - PROGRESS: at 85.87% examples, 314209 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:13,658 : INFO : EPOCH 20 - PROGRESS: at 90.20% examples, 311699 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:14,673 : INFO : EPOCH 20 - PROGRESS: at 95.10% examples, 310711 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:15,504 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:56:15,508 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:56:15,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:56:15,531 : INFO : EPOCH - 20 : training on 6707530 raw words (5970373 effective words) took 19.2s, 311390 effective words/s\n",
      "2019-06-26 15:56:16,535 : INFO : EPOCH 21 - PROGRESS: at 4.86% examples, 280693 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:17,554 : INFO : EPOCH 21 - PROGRESS: at 10.43% examples, 304254 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:18,574 : INFO : EPOCH 21 - PROGRESS: at 16.00% examples, 314859 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:19,590 : INFO : EPOCH 21 - PROGRESS: at 23.51% examples, 345903 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:20,600 : INFO : EPOCH 21 - PROGRESS: at 29.62% examples, 346317 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:21,603 : INFO : EPOCH 21 - PROGRESS: at 35.98% examples, 349676 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:22,631 : INFO : EPOCH 21 - PROGRESS: at 40.25% examples, 335964 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:23,649 : INFO : EPOCH 21 - PROGRESS: at 45.70% examples, 333881 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:24,667 : INFO : EPOCH 21 - PROGRESS: at 50.62% examples, 329282 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:25,697 : INFO : EPOCH 21 - PROGRESS: at 55.30% examples, 324345 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:26,702 : INFO : EPOCH 21 - PROGRESS: at 61.47% examples, 329607 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:27,709 : INFO : EPOCH 21 - PROGRESS: at 69.21% examples, 338936 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:28,727 : INFO : EPOCH 21 - PROGRESS: at 76.33% examples, 345430 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:29,754 : INFO : EPOCH 21 - PROGRESS: at 84.10% examples, 351952 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:30,772 : INFO : EPOCH 21 - PROGRESS: at 89.64% examples, 350368 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:31,775 : INFO : EPOCH 21 - PROGRESS: at 94.33% examples, 346557 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:32,762 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:56:32,766 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:56:32,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:56:32,773 : INFO : EPOCH - 21 : training on 6707530 raw words (5970044 effective words) took 17.2s, 346309 effective words/s\n",
      "2019-06-26 15:56:33,822 : INFO : EPOCH 22 - PROGRESS: at 4.56% examples, 258801 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:34,848 : INFO : EPOCH 22 - PROGRESS: at 9.34% examples, 270432 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:35,851 : INFO : EPOCH 22 - PROGRESS: at 14.43% examples, 276218 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:56:36,868 : INFO : EPOCH 22 - PROGRESS: at 19.73% examples, 282227 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:37,901 : INFO : EPOCH 22 - PROGRESS: at 26.44% examples, 300710 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:38,918 : INFO : EPOCH 22 - PROGRESS: at 30.97% examples, 295011 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:39,943 : INFO : EPOCH 22 - PROGRESS: at 35.86% examples, 293238 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:40,951 : INFO : EPOCH 22 - PROGRESS: at 40.48% examples, 292326 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:41,951 : INFO : EPOCH 22 - PROGRESS: at 45.53% examples, 293645 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:42,959 : INFO : EPOCH 22 - PROGRESS: at 53.24% examples, 310279 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:43,977 : INFO : EPOCH 22 - PROGRESS: at 61.27% examples, 324525 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:44,991 : INFO : EPOCH 22 - PROGRESS: at 68.96% examples, 336301 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:45,996 : INFO : EPOCH 22 - PROGRESS: at 76.45% examples, 345979 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:46,998 : INFO : EPOCH 22 - PROGRESS: at 84.34% examples, 354492 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:48,012 : INFO : EPOCH 22 - PROGRESS: at 91.76% examples, 360825 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:49,020 : INFO : EPOCH 22 - PROGRESS: at 96.44% examples, 354628 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:49,581 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:56:49,593 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:56:49,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:56:49,606 : INFO : EPOCH - 22 : training on 6707530 raw words (5970330 effective words) took 16.8s, 354723 effective words/s\n",
      "2019-06-26 15:56:50,630 : INFO : EPOCH 23 - PROGRESS: at 4.97% examples, 300243 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 15:56:51,632 : INFO : EPOCH 23 - PROGRESS: at 12.35% examples, 365392 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:52,637 : INFO : EPOCH 23 - PROGRESS: at 18.37% examples, 362366 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:53,661 : INFO : EPOCH 23 - PROGRESS: at 26.28% examples, 385614 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:54,674 : INFO : EPOCH 23 - PROGRESS: at 31.29% examples, 367394 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:55,693 : INFO : EPOCH 23 - PROGRESS: at 36.29% examples, 356471 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:56,702 : INFO : EPOCH 23 - PROGRESS: at 44.37% examples, 375174 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:56:57,702 : INFO : EPOCH 23 - PROGRESS: at 52.37% examples, 386148 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:58,718 : INFO : EPOCH 23 - PROGRESS: at 58.95% examples, 387418 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:56:59,719 : INFO : EPOCH 23 - PROGRESS: at 63.96% examples, 377690 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:00,734 : INFO : EPOCH 23 - PROGRESS: at 69.15% examples, 371598 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:01,755 : INFO : EPOCH 23 - PROGRESS: at 73.78% examples, 362758 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:02,778 : INFO : EPOCH 23 - PROGRESS: at 79.05% examples, 357843 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:03,826 : INFO : EPOCH 23 - PROGRESS: at 84.59% examples, 354936 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:04,877 : INFO : EPOCH 23 - PROGRESS: at 89.53% examples, 350054 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:05,880 : INFO : EPOCH 23 - PROGRESS: at 94.27% examples, 346817 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:06,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:57:06,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:57:06,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:57:06,649 : INFO : EPOCH - 23 : training on 6707530 raw words (5969969 effective words) took 17.0s, 350356 effective words/s\n",
      "2019-06-26 15:57:07,666 : INFO : EPOCH 24 - PROGRESS: at 4.58% examples, 267094 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:08,678 : INFO : EPOCH 24 - PROGRESS: at 8.95% examples, 259662 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:09,715 : INFO : EPOCH 24 - PROGRESS: at 14.32% examples, 277975 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:10,723 : INFO : EPOCH 24 - PROGRESS: at 19.47% examples, 286907 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:11,726 : INFO : EPOCH 24 - PROGRESS: at 25.13% examples, 297193 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:12,749 : INFO : EPOCH 24 - PROGRESS: at 32.47% examples, 319266 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:13,758 : INFO : EPOCH 24 - PROGRESS: at 40.30% examples, 338263 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:14,784 : INFO : EPOCH 24 - PROGRESS: at 48.17% examples, 351662 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:15,801 : INFO : EPOCH 24 - PROGRESS: at 56.27% examples, 366095 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:16,815 : INFO : EPOCH 24 - PROGRESS: at 63.93% examples, 374525 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:17,845 : INFO : EPOCH 24 - PROGRESS: at 71.84% examples, 380866 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:18,860 : INFO : EPOCH 24 - PROGRESS: at 79.65% examples, 387372 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:19,873 : INFO : EPOCH 24 - PROGRESS: at 87.35% examples, 393506 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:20,889 : INFO : EPOCH 24 - PROGRESS: at 92.87% examples, 388902 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:21,893 : INFO : EPOCH 24 - PROGRESS: at 97.31% examples, 381752 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:22,171 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:57:22,173 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:57:22,186 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:57:22,187 : INFO : EPOCH - 24 : training on 6707530 raw words (5969924 effective words) took 15.5s, 384276 effective words/s\n",
      "2019-06-26 15:57:23,196 : INFO : EPOCH 25 - PROGRESS: at 4.93% examples, 278071 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:24,220 : INFO : EPOCH 25 - PROGRESS: at 9.54% examples, 272301 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:25,244 : INFO : EPOCH 25 - PROGRESS: at 14.22% examples, 275112 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:26,251 : INFO : EPOCH 25 - PROGRESS: at 19.09% examples, 278316 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:27,265 : INFO : EPOCH 25 - PROGRESS: at 26.68% examples, 314512 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:28,289 : INFO : EPOCH 25 - PROGRESS: at 34.57% examples, 337834 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:29,302 : INFO : EPOCH 25 - PROGRESS: at 41.74% examples, 353742 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:30,309 : INFO : EPOCH 25 - PROGRESS: at 49.40% examples, 366088 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:31,350 : INFO : EPOCH 25 - PROGRESS: at 55.41% examples, 364774 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:32,378 : INFO : EPOCH 25 - PROGRESS: at 60.04% examples, 354755 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:33,378 : INFO : EPOCH 25 - PROGRESS: at 64.88% examples, 348897 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:34,378 : INFO : EPOCH 25 - PROGRESS: at 69.87% examples, 343999 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:35,407 : INFO : EPOCH 25 - PROGRESS: at 75.29% examples, 341660 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:36,429 : INFO : EPOCH 25 - PROGRESS: at 82.51% examples, 346655 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:37,435 : INFO : EPOCH 25 - PROGRESS: at 87.07% examples, 341100 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:38,468 : INFO : EPOCH 25 - PROGRESS: at 92.78% examples, 339829 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:39,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:57:39,326 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:57:39,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:57:39,327 : INFO : EPOCH - 25 : training on 6707530 raw words (5970182 effective words) took 17.1s, 348350 effective words/s\n",
      "2019-06-26 15:57:40,352 : INFO : EPOCH 26 - PROGRESS: at 4.58% examples, 258088 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:41,363 : INFO : EPOCH 26 - PROGRESS: at 9.04% examples, 262946 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:42,375 : INFO : EPOCH 26 - PROGRESS: at 13.57% examples, 265231 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:43,385 : INFO : EPOCH 26 - PROGRESS: at 17.95% examples, 266320 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:44,411 : INFO : EPOCH 26 - PROGRESS: at 23.17% examples, 273096 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:45,423 : INFO : EPOCH 26 - PROGRESS: at 28.14% examples, 276702 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:46,432 : INFO : EPOCH 26 - PROGRESS: at 35.55% examples, 301544 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:47,455 : INFO : EPOCH 26 - PROGRESS: at 42.64% examples, 314358 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:48,489 : INFO : EPOCH 26 - PROGRESS: at 47.55% examples, 310448 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:49,495 : INFO : EPOCH 26 - PROGRESS: at 52.09% examples, 306412 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:50,499 : INFO : EPOCH 26 - PROGRESS: at 59.50% examples, 318159 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:51,517 : INFO : EPOCH 26 - PROGRESS: at 66.01% examples, 323237 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:52,524 : INFO : EPOCH 26 - PROGRESS: at 70.61% examples, 318484 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:53,557 : INFO : EPOCH 26 - PROGRESS: at 75.50% examples, 316350 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:54,569 : INFO : EPOCH 26 - PROGRESS: at 80.29% examples, 314399 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:57:55,581 : INFO : EPOCH 26 - PROGRESS: at 85.80% examples, 314213 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:56,601 : INFO : EPOCH 26 - PROGRESS: at 93.44% examples, 322632 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:57,496 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:57:57,502 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:57:57,508 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:57:57,509 : INFO : EPOCH - 26 : training on 6707530 raw words (5969657 effective words) took 18.2s, 328367 effective words/s\n",
      "2019-06-26 15:57:58,521 : INFO : EPOCH 27 - PROGRESS: at 4.83% examples, 276902 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:57:59,531 : INFO : EPOCH 27 - PROGRESS: at 9.86% examples, 290490 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:00,537 : INFO : EPOCH 27 - PROGRESS: at 14.85% examples, 295647 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:01,547 : INFO : EPOCH 27 - PROGRESS: at 19.36% examples, 289182 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:02,557 : INFO : EPOCH 27 - PROGRESS: at 24.30% examples, 285097 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:03,581 : INFO : EPOCH 27 - PROGRESS: at 28.66% examples, 278918 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:04,587 : INFO : EPOCH 27 - PROGRESS: at 33.27% examples, 276482 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:05,608 : INFO : EPOCH 27 - PROGRESS: at 37.67% examples, 274073 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:06,620 : INFO : EPOCH 27 - PROGRESS: at 43.68% examples, 282145 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:07,643 : INFO : EPOCH 27 - PROGRESS: at 48.50% examples, 282315 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:08,645 : INFO : EPOCH 27 - PROGRESS: at 54.18% examples, 286804 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:09,675 : INFO : EPOCH 27 - PROGRESS: at 59.51% examples, 289884 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:10,701 : INFO : EPOCH 27 - PROGRESS: at 65.06% examples, 292518 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:11,707 : INFO : EPOCH 27 - PROGRESS: at 70.66% examples, 295278 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:12,718 : INFO : EPOCH 27 - PROGRESS: at 76.13% examples, 297517 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:13,732 : INFO : EPOCH 27 - PROGRESS: at 80.47% examples, 295684 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:14,741 : INFO : EPOCH 27 - PROGRESS: at 84.89% examples, 294172 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:15,754 : INFO : EPOCH 27 - PROGRESS: at 89.35% examples, 292299 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:16,754 : INFO : EPOCH 27 - PROGRESS: at 93.88% examples, 291677 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:17,765 : INFO : EPOCH 27 - PROGRESS: at 98.48% examples, 290568 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:17,879 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:58:17,880 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:58:17,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:58:17,883 : INFO : EPOCH - 27 : training on 6707530 raw words (5969641 effective words) took 20.4s, 293041 effective words/s\n",
      "2019-06-26 15:58:18,889 : INFO : EPOCH 28 - PROGRESS: at 4.43% examples, 253094 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:19,911 : INFO : EPOCH 28 - PROGRESS: at 9.34% examples, 268051 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:20,919 : INFO : EPOCH 28 - PROGRESS: at 14.17% examples, 274247 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:21,920 : INFO : EPOCH 28 - PROGRESS: at 18.88% examples, 275640 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:22,923 : INFO : EPOCH 28 - PROGRESS: at 23.02% examples, 271311 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:23,942 : INFO : EPOCH 28 - PROGRESS: at 27.38% examples, 269133 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:24,946 : INFO : EPOCH 28 - PROGRESS: at 31.90% examples, 268093 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:25,972 : INFO : EPOCH 28 - PROGRESS: at 36.59% examples, 267804 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:27,002 : INFO : EPOCH 28 - PROGRESS: at 41.19% examples, 269457 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:28,005 : INFO : EPOCH 28 - PROGRESS: at 47.45% examples, 277269 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:29,038 : INFO : EPOCH 28 - PROGRESS: at 52.07% examples, 276734 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:30,044 : INFO : EPOCH 28 - PROGRESS: at 59.60% examples, 292877 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:31,058 : INFO : EPOCH 28 - PROGRESS: at 67.13% examples, 304831 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:32,080 : INFO : EPOCH 28 - PROGRESS: at 75.27% examples, 316971 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:33,114 : INFO : EPOCH 28 - PROGRESS: at 80.17% examples, 313447 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:34,154 : INFO : EPOCH 28 - PROGRESS: at 84.57% examples, 309083 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:35,179 : INFO : EPOCH 28 - PROGRESS: at 89.18% examples, 307005 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:36,219 : INFO : EPOCH 28 - PROGRESS: at 93.95% examples, 304846 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:37,143 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:58:37,148 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:58:37,155 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:58:37,156 : INFO : EPOCH - 28 : training on 6707530 raw words (5969498 effective words) took 19.3s, 309742 effective words/s\n",
      "2019-06-26 15:58:38,162 : INFO : EPOCH 29 - PROGRESS: at 6.54% examples, 393518 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:39,166 : INFO : EPOCH 29 - PROGRESS: at 14.46% examples, 423290 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:40,178 : INFO : EPOCH 29 - PROGRESS: at 21.73% examples, 423955 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:41,213 : INFO : EPOCH 29 - PROGRESS: at 25.99% examples, 380738 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:42,222 : INFO : EPOCH 29 - PROGRESS: at 30.64% examples, 356877 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 15:58:43,235 : INFO : EPOCH 29 - PROGRESS: at 37.50% examples, 366945 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:44,235 : INFO : EPOCH 29 - PROGRESS: at 44.48% examples, 374410 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:45,272 : INFO : EPOCH 29 - PROGRESS: at 51.56% examples, 379515 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:46,302 : INFO : EPOCH 29 - PROGRESS: at 56.89% examples, 373071 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:47,336 : INFO : EPOCH 29 - PROGRESS: at 61.99% examples, 364518 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:48,343 : INFO : EPOCH 29 - PROGRESS: at 69.35% examples, 372317 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:49,348 : INFO : EPOCH 29 - PROGRESS: at 77.08% examples, 379151 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:50,349 : INFO : EPOCH 29 - PROGRESS: at 84.65% examples, 384276 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:51,382 : INFO : EPOCH 29 - PROGRESS: at 91.21% examples, 382879 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:52,403 : INFO : EPOCH 29 - PROGRESS: at 96.01% examples, 376250 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:53,099 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:58:53,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:58:53,115 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:58:53,115 : INFO : EPOCH - 29 : training on 6707530 raw words (5969553 effective words) took 16.0s, 374127 effective words/s\n",
      "2019-06-26 15:58:54,118 : INFO : EPOCH 30 - PROGRESS: at 3.97% examples, 235337 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:55,131 : INFO : EPOCH 30 - PROGRESS: at 8.56% examples, 251839 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:58:56,142 : INFO : EPOCH 30 - PROGRESS: at 14.04% examples, 271625 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:57,195 : INFO : EPOCH 30 - PROGRESS: at 18.90% examples, 272596 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:58,197 : INFO : EPOCH 30 - PROGRESS: at 24.11% examples, 279199 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:58:59,204 : INFO : EPOCH 30 - PROGRESS: at 28.66% examples, 279190 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:00,210 : INFO : EPOCH 30 - PROGRESS: at 32.96% examples, 275270 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:59:01,231 : INFO : EPOCH 30 - PROGRESS: at 37.53% examples, 274235 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:59:02,235 : INFO : EPOCH 30 - PROGRESS: at 42.09% examples, 272984 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:03,249 : INFO : EPOCH 30 - PROGRESS: at 46.48% examples, 273342 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:04,271 : INFO : EPOCH 30 - PROGRESS: at 51.27% examples, 275067 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:05,281 : INFO : EPOCH 30 - PROGRESS: at 56.01% examples, 276682 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:06,301 : INFO : EPOCH 30 - PROGRESS: at 60.95% examples, 277188 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:07,311 : INFO : EPOCH 30 - PROGRESS: at 65.61% examples, 277249 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 15:59:08,329 : INFO : EPOCH 30 - PROGRESS: at 70.26% examples, 277086 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:09,359 : INFO : EPOCH 30 - PROGRESS: at 75.31% examples, 277951 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:10,384 : INFO : EPOCH 30 - PROGRESS: at 80.02% examples, 278682 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:11,388 : INFO : EPOCH 30 - PROGRESS: at 85.04% examples, 278710 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:12,414 : INFO : EPOCH 30 - PROGRESS: at 89.97% examples, 278891 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:13,449 : INFO : EPOCH 30 - PROGRESS: at 95.03% examples, 279322 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 15:59:14,257 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 15:59:14,269 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 15:59:14,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 15:59:14,289 : INFO : EPOCH - 30 : training on 6707530 raw words (5969263 effective words) took 21.2s, 281940 effective words/s\n",
      "2019-06-26 15:59:14,290 : INFO : training on a 201225900 raw words (179086670 effective words) took 591.0s, 303046 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [doc2vec dmm]: 0:09:58.574804\n",
      "Time for [3 - doc2vec model]: 0:19:08.120081\n"
     ]
    }
   ],
   "source": [
    "# 3. train doc2vec model\n",
    "with Timer(\"3 - doc2vec model\"):\n",
    "    model_dbow, model_dmm = train_model(X_train, X_dev, workers=3, epochs=30)\n",
    "\n",
    "    model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "    model_concat = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:13:17.972831Z",
     "start_time": "2019-06-26T13:59:14.925065Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44732/44732 [09:53<00:00, 75.39it/s] \n",
      "100%|██████████| 19171/19171 [04:09<00:00, 76.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [4 - vectorize arguments]: 0:14:03.043704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. vectorize arguments\n",
    "with Timer(\"4 - vectorize arguments\"):\n",
    "    # X_train, X_dev = make_vectors(X_train, X_dev, model_dbow)\n",
    "    # X_train, X_dev = make_vectors(X_train, X_dev, model_dmm)\n",
    "    X_train, X_dev = make_vectors(X_train, X_dev, model_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:13:24.057978Z",
     "start_time": "2019-06-26T14:13:18.951698Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44732/44732 [00:03<00:00, 13138.50it/s]\n",
      "100%|██████████| 19171/19171 [00:01<00:00, 12915.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [5 - vector comparison of arguments]: 0:00:05.090890\n"
     ]
    }
   ],
   "source": [
    "# 5. combine two argument vectors into a single one\n",
    "# - diff / concat / ...\n",
    "with Timer(\"5 - vector comparison of arguments\"):\n",
    "    X_train_diff, X_dev_diff = make_vector_comparison(X_train, X_dev, mode=\"concat\")\n",
    "\n",
    "X_train_ = X_train_diff\n",
    "X_dev_ = X_dev_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:17:49.342039Z",
     "start_time": "2019-06-26T14:13:25.005024Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [StandardScaler fit]: 0:00:00.747875\n",
      "Time for [StandardScaler transform]: 0:00:00.295211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [SVC (linear) fit]: 0:04:22.565508\n",
      "Time for [SVC predict]: 0:00:00.049544\n",
      "Time for [6 - SVM (train -> predict)]: 0:04:23.723510\n",
      "Confusion Matrix:\n",
      "[[3011 5822]\n",
      " [2589 7749]]\n",
      "\n",
      "Accuracy:  0.56 \n",
      "\n",
      "Report for [SVM]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.34      0.42      8833\n",
      "        True       0.57      0.75      0.65     10338\n",
      "\n",
      "    accuracy                           0.56     19171\n",
      "   macro avg       0.55      0.55      0.53     19171\n",
      "weighted avg       0.56      0.56      0.54     19171\n",
      "\n",
      "{'macro': 0.53, 'micro': 0.56}\n",
      "Time for [7 - report]: 0:00:00.609881\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - SVM (train -> predict)\"):\n",
    "    y_pred_svm = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_svm, name=\"SVM\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:18:53.080062Z",
     "start_time": "2019-06-26T14:17:50.287973Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [LogisticRegression fit]: 0:01:02.070384\n",
      "Time for [LogisticRegression predict]: 0:00:00.049328\n",
      "Time for [6 - LogReg (train -> predict)]: 0:01:02.166525\n",
      "Confusion Matrix:\n",
      "[[4568 4265]\n",
      " [3819 6519]]\n",
      "\n",
      "Accuracy:  0.58 \n",
      "\n",
      "Report for [LogisticRegression]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.52      0.53      8833\n",
      "        True       0.60      0.63      0.62     10338\n",
      "\n",
      "    accuracy                           0.58     19171\n",
      "   macro avg       0.57      0.57      0.57     19171\n",
      "weighted avg       0.58      0.58      0.58     19171\n",
      "\n",
      "{'macro': 0.57, 'micro': 0.58}\n",
      "Time for [7 - report]: 0:00:00.621420\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - LogReg (train -> predict)\"):\n",
    "    y_pred_logreg = train_test_logreg(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_logreg, name=\"LogisticRegression\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:19:35.491827Z",
     "start_time": "2019-06-26T14:18:54.023735Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [SGDClassifier fit]: 0:00:41.005865\n",
      "Time for [SGDClassifier predict]: 0:00:00.098403\n",
      "Time for [6 - SGDClassifier (train -> predict)]: 0:00:41.104528\n",
      "Confusion Matrix:\n",
      "[[4920 3913    0]\n",
      " [4009 6328    1]\n",
      " [   0    0    0]]\n",
      "\n",
      "Accuracy:  0.59 \n",
      "\n",
      "Report for [SGDClassifier]:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.55      0.56      0.55      8833\n",
      "        True       0.62      0.61      0.61     10338\n",
      "gay marriage       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.59     19171\n",
      "   macro avg       0.39      0.39      0.39     19171\n",
      "weighted avg       0.59      0.59      0.59     19171\n",
      "\n",
      "{'macro': 0.39, 'micro': 0.59}\n",
      "Time for [7 - report]: 0:00:00.360067\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - SGDClassifier (train -> predict)\"):\n",
    "    y_pred_sgdcla = train_test_sgd(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_sgdcla, name=\"SGDClassifier\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:45:45.813418Z",
     "start_time": "2019-06-26T11:45:45.808878Z"
    },
    "code_folding": [
     0,
     6,
     11,
     16,
     20
    ]
   },
   "outputs": [],
   "source": [
    "# old\n",
    "return\n",
    "\n",
    "asdf\n",
    "\n",
    "# 2. Lemmatizing argument1 and argument2\n",
    "with Timer(\"2 - lemmatize\"):\n",
    "    X_train = X_train.apply(get_lemma, axis=1)\n",
    "    X_dev = X_dev.apply(get_lemma, axis=1)\n",
    "\n",
    "# 3. Extracting features - 1-3 grams lemma\n",
    "with Timer(\"3 - n-grams\"):\n",
    "    X_train_, X_dev_ = extract_n_grams_features(\n",
    "        X_train, X_dev, columns=['argument1_lemmas', 'argument2_lemmas'])\n",
    "\n",
    "# 4. train\n",
    "with Timer(\"4 - SVM (train -> predict)\"):\n",
    "    y_pred = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 5. Evaluate\n",
    "with Timer(\"5 - report\"):\n",
    "    report_training_results(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
