{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:35:02.420986Z",
     "start_time": "2019-06-26T12:35:02.413592Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "# from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:18:50.407998Z",
     "start_time": "2019-06-26T12:18:50.405562Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:18:52.558618Z",
     "start_time": "2019-06-26T12:18:52.300804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:00:33.332063Z",
     "start_time": "2019-06-26T11:00:33.330171Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:00:33.361391Z",
     "start_time": "2019-06-26T11:00:33.356244Z"
    },
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:00:34.345752Z",
     "start_time": "2019-06-26T11:00:34.342067Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:00:39.324202Z",
     "start_time": "2019-06-26T11:00:37.370142Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:00.930528\n",
      "Time for [read within]: 0:00:01.014369\n"
     ]
    }
   ],
   "source": [
    "# escapechar to detect quoting escapes, else it fails\n",
    "\n",
    "# na_filter=False, because pandas automatic \"nan\" detection fails with the topic column, too\n",
    "# cross_test_df['topic'].astype(str)[9270]\n",
    "\n",
    "with Timer(\"read cross\"):\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    within_traindev_df = pd.read_csv(data_within_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:30.366812Z",
     "start_time": "2019-06-26T11:00:40.007171Z"
    },
    "code_folding": [
     1,
     12,
     14,
     17,
     19
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag cross traindev]: 0:00:35.189107\n",
      "Time for [tag cross test]: 0:00:19.834640\n",
      "Time for [tag within traindev]: 0:00:37.309147\n",
      "Time for [tag within test]: 0:00:18.014437\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross traindev\"):\n",
    "    cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "with Timer(\"tag cross test\"):\n",
    "    cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within traindev\"):\n",
    "    within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "with Timer(\"tag within test\"):\n",
    "    within_test_df = within_test_df.apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:30.562851Z",
     "start_time": "2019-06-26T11:02:30.554538Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_overview(df, task='same-side', class_name='is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task)\n",
    "    print('=' * 40, '\\n')\n",
    "\n",
    "    print('Total instances: ', total)\n",
    "    print('\\n')\n",
    "\n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t', is_same_side, ': ', len(side_df), ' instances')\n",
    "    print('\\n')\n",
    "\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "        print('\\n')\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))), '\\n')\n",
    "\n",
    "    print('-' * 40, '\\n')\n",
    "\n",
    "    arguments_length_lst = [\n",
    "        len(word_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_length_lst.extend(\n",
    "        [len(word_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Words:')\n",
    "    print('\\tshortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('\\tlongest argument:', max(arguments_length_lst), ' words')\n",
    "    print('\\targument average length:', np.mean(arguments_length_lst),\n",
    "          ' words')\n",
    "\n",
    "    arguments_sent_length_lst = [\n",
    "        len(sent_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_sent_length_lst.extend(\n",
    "        [len(sent_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Sentences:')\n",
    "    print('\\tshortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\tlongest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\targument average length:', np.mean(arguments_sent_length_lst),\n",
    "          ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:30.732372Z",
     "start_time": "2019-06-26T11:02:30.730309Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# with Timer(\"overview cross\"):\n",
    "#     get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:30.900880Z",
     "start_time": "2019-06-26T11:02:30.899095Z"
    }
   },
   "outputs": [],
   "source": [
    "# with Timer(\"overview within\"):\n",
    "#     get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.072476Z",
     "start_time": "2019-06-26T11:02:31.069500Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.244617Z",
     "start_time": "2019-06-26T11:02:31.238033Z"
    },
    "code_folding": [
     0,
     15,
     22,
     40
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v)\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # As default pos in lemmatization is Noun\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "def lemmatize_stemming(token, pos_tag):\n",
    "    '''lemmatize words (with POS information) and then stem'''\n",
    "    stemmer = SnowballStemmer(\n",
    "        \"english\")  # pOrter, M. \"An algorithm for suffix stripping.\"\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(token, pos=pos_tag))\n",
    "\n",
    "\n",
    "def do_segmentation(text):\n",
    "    '''do sentence segmentation, tokenization (with lemmatization&stemming)'''\n",
    "    lemma = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('\\n', ' ').strip()\n",
    "        tokens = [token for token in word_tokenize(sentence)]\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "        for idx in range(0, len(tokens)):\n",
    "            token = tokens[idx].lower()\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(\n",
    "                    token) > 3:\n",
    "                wordnet_pos = get_wordnet_pos(pos_tags[idx][1])\n",
    "                l_ = lemmatize_stemming(token, wordnet_pos)\n",
    "                lemma.append(l_)\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    '''concat lemmatized words together again'''\n",
    "    lemma = do_segmentation(text)\n",
    "    return ' '.join(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting n grams lemma for argument1 and argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.417931Z",
     "start_time": "2019-06-26T11:02:31.410882Z"
    },
    "code_folding": [
     0,
     38
    ]
   },
   "outputs": [],
   "source": [
    "def extract_ngrams(X_train, X_dev, col, idx='id'):\n",
    "    vectorizer = CountVectorizer(min_df=600,\n",
    "                                 max_df=0.7,\n",
    "                                 ngram_range=(3, 3),\n",
    "                                 max_features=5000)\n",
    "\n",
    "    vectorizer.fit(X_train[col])\n",
    "    features = vectorizer.transform(X_train[col])\n",
    "    features_dev = vectorizer.transform(X_dev[col])\n",
    "\n",
    "    train_df = pd.DataFrame(features.todense(),\n",
    "                            columns=vectorizer.get_feature_names())\n",
    "    train_df = train_df.add_prefix(col)\n",
    "\n",
    "    aid_df = X_train[[idx]]\n",
    "\n",
    "    train_df = train_df.merge(aid_df,\n",
    "                              left_index=True,\n",
    "                              right_index=True,\n",
    "                              suffixes=(False, False),\n",
    "                              how='inner')\n",
    "    train_df.set_index(idx, inplace=True)\n",
    "\n",
    "    dev_df = pd.DataFrame(features_dev.todense(),\n",
    "                          columns=vectorizer.get_feature_names())\n",
    "    dev_df = dev_df.add_prefix(col)\n",
    "\n",
    "    aid_dev_df = X_dev[[idx]]\n",
    "\n",
    "    dev_df = dev_df.merge(aid_dev_df,\n",
    "                          left_index=True,\n",
    "                          right_index=True,\n",
    "                          suffixes=(False, False),\n",
    "                          how='inner')\n",
    "    dev_df.set_index(idx, inplace=True)\n",
    "    return train_df, dev_df\n",
    "\n",
    "\n",
    "def extract_n_grams_features(X_train, X_dev, columns, idx='id'):\n",
    "    X_train = X_train.reset_index()\n",
    "    result_train_df = X_train[[idx]]\n",
    "    result_train_df.set_index(idx, inplace=True)\n",
    "\n",
    "    X_dev = X_dev.reset_index()\n",
    "    result_dev_df = X_dev[[idx]]\n",
    "    result_dev_df.set_index(idx, inplace=True)\n",
    "\n",
    "    for col in columns:\n",
    "        result_train_df_, result_dev_df_ = extract_ngrams(X_train, X_dev, col)\n",
    "        result_train_df = result_train_df.join(result_train_df_)\n",
    "        result_dev_df = result_dev_df.join(result_dev_df_)\n",
    "    return result_train_df, result_dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Doc2Vec model and vectorize argument1 and argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.593837Z",
     "start_time": "2019-06-26T11:02:31.585675Z"
    },
    "code_folding": [
     0,
     15,
     34,
     56
    ]
   },
   "outputs": [],
   "source": [
    "def make_d2v_docs(row):\n",
    "    words1 = do_segmentation(row['argument1'])\n",
    "    words2 = do_segmentation(row['argument2'])\n",
    "\n",
    "    row['argument1_doc'] = TaggedDocument(words=words1,\n",
    "                                          tags=[row['argument1_id']])\n",
    "    row['argument2_doc'] = TaggedDocument(words=words2,\n",
    "                                          tags=[row['argument2_id']])\n",
    "\n",
    "    row['argument1_lemmas'] = ' '.join(words1)\n",
    "    row['argument2_lemmas'] = ' '.join(words2)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "class DatasetIter:\n",
    "    def __init__(self, ds, shuffle=True):\n",
    "        self.ds = ds\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def _make_taggeddocs(self, row):\n",
    "        yield row['argument1_doc']\n",
    "        yield row['argument2_doc']\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.ds = self.ds.sample(frac=1)\n",
    "\n",
    "        for _, row in self.ds.iterrows():\n",
    "            for doc in self._make_taggeddocs(row):\n",
    "                yield doc\n",
    "\n",
    "\n",
    "# https://github.com/RaRe-Technologies/gensim/blob/2024be9053094fbb2e765b9a06b9dc580f55c505/gensim/test/test_doc2vec.py#L501\n",
    "class ConcatenatedDoc2Vec(object):\n",
    "    \"\"\"\n",
    "    Concatenation of multiple models for reproducing the Paragraph Vectors paper.\n",
    "    Models must have exactly-matching vocabulary and document IDs. (Models should\n",
    "    be trained separately; this wrapper just returns concatenated results.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        if hasattr(models[0], 'docvecs'):\n",
    "            self.docvecs = ConcatenatedDocvecs([model.docvecs for model in models])\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return np.concatenate([model[token] for model in self.models])\n",
    "\n",
    "    def infer_vector(self, document, alpha=0.1, min_alpha=0.0001, steps=5):\n",
    "        return np.concatenate([model.infer_vector(document, alpha, min_alpha, steps) for model in self.models])\n",
    "\n",
    "    def train(self, *ignore_args, **ignore_kwargs):\n",
    "        pass  # train subcomponents individually\n",
    "\n",
    "\n",
    "class ConcatenatedDocvecs(object):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return np.concatenate([model[token] for model in self.models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:46:41.508871Z",
     "start_time": "2019-06-26T11:46:41.497868Z"
    },
    "code_folding": [
     0,
     6,
     19
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, X_dev, workers=2, epochs=30):\n",
    "    with Timer(\"doc2vec dbow\"):\n",
    "        # columns=['argument1_lemmas', 'argument2_lemmas']\n",
    "        # pd.concat([X_train[columns], X_dev[columns]])\n",
    "        alpha = 0.025  # https://radimrehurek.com/gensim/models/base_any2vec.html#gensim.models.base_any2vec.BaseWordEmbeddingsModel\n",
    "        # %%time\n",
    "        model_dbow = Doc2Vec(DatasetIter(X_train, shuffle=True),\n",
    "                             dm=0,\n",
    "                             vector_size=300,\n",
    "                             negative=5,\n",
    "                             hs=0,\n",
    "                             min_count=2,\n",
    "                             sample=0,\n",
    "                             workers=workers,\n",
    "                             epochs=epochs,\n",
    "                             alpha=alpha,\n",
    "                             min_alpha=alpha - (epochs * 0.002))\n",
    "        \n",
    "    with Timer(\"doc2vec dmm\"):\n",
    "        model_dmm = Doc2Vec(DatasetIter(X_train, shuffle=True),\n",
    "                            dm=1,\n",
    "                            dm_mean=1,\n",
    "                            vector_size=300,\n",
    "                            window=10,\n",
    "                            negative=5,\n",
    "                            min_count=1,\n",
    "                            workers=workers,\n",
    "                            epochs=epochs,\n",
    "                            alpha=0.065,\n",
    "                            min_alpha=0.065 - (epochs * 0.002))\n",
    "        \n",
    "    return model_dbow, model_dmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:31.935090Z",
     "start_time": "2019-06-26T11:02:31.932250Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# unused\n",
    "def vec_for_learning(model, df):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:32.106479Z",
     "start_time": "2019-06-26T11:02:32.103067Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_vectors(X_train, X_dev, model):\n",
    "    def make_d2v_vecs(row):\n",
    "        vec1 = model.infer_vector(row['argument1_doc'].words, steps=20)\n",
    "        vec2 = model.infer_vector(row['argument2_doc'].words, steps=20)\n",
    "\n",
    "        row['argument1_vec'] = vec1\n",
    "        row['argument2_vec'] = vec2\n",
    "        \n",
    "        return row\n",
    "\n",
    "    X_train = X_train.progress_apply(make_d2v_vecs, axis=1)\n",
    "    X_dev = X_dev.progress_apply(make_d2v_vecs, axis=1)\n",
    "    \n",
    "    return X_train, X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:51:24.766258Z",
     "start_time": "2019-06-26T11:51:24.753098Z"
    },
    "code_folding": [
     0,
     10,
     20
    ]
   },
   "outputs": [],
   "source": [
    "def make_vector_comparison_diff(X_train, X_dev):\n",
    "    def ret_vec_diff(row):\n",
    "        return row['argument1_vec'] - row['argument2_vec']\n",
    "\n",
    "    X_train_diff = X_train.progress_apply(ret_vec_diff, axis=1)\n",
    "    X_dev_diff = X_dev.progress_apply(ret_vec_diff, axis=1)\n",
    "\n",
    "    return X_train_diff, X_dev_diff\n",
    "\n",
    "\n",
    "def make_vector_comparison_concat(X_train, X_dev):\n",
    "    def ret_vec_concat(row):\n",
    "        return np.concatenate((row['argument1_vec'], row['argument2_vec']))\n",
    "\n",
    "    X_train_concat = X_train.progress_apply(ret_vec_concat, axis=1)\n",
    "    X_dev_concat = X_dev.progress_apply(ret_vec_concat, axis=1)\n",
    "\n",
    "    return X_train_concat, X_dev_concat\n",
    "\n",
    "\n",
    "def make_vector_comparison(X_train, X_dev, mode=\"diff\"):\n",
    "    if mode == \"concat\":\n",
    "        X_train, X_dev = make_vector_comparison_concat(X_train, X_dev)\n",
    "    else:\n",
    "        X_train, X_dev = make_vector_comparison_diff(X_train, X_dev)\n",
    "\n",
    "    # array of array to 2d array\n",
    "    X_train = np.array(list(X_train.values))\n",
    "    X_dev = np.array(list(X_dev.values))\n",
    "\n",
    "    return X_train, X_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:52:15.777378Z",
     "start_time": "2019-06-26T12:52:15.768729Z"
    },
    "code_folding": [
     22,
     33,
     44,
     56
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_test_svm(X_train, y_train, X_test):\n",
    "    with Timer(\"StandardScaler fit\"):\n",
    "        scaler = StandardScaler(copy=True, with_mean=False)\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "    with Timer(\"StandardScaler transform\"):\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # ------------------\n",
    "\n",
    "    with Timer(\"SVC (linear) fit\"):\n",
    "        # svclassifier = SVC(kernel='linear')\n",
    "        svclassifier = LinearSVC()        \n",
    "        svclassifier.fit(X_train, y_train)\n",
    "\n",
    "    with Timer(\"SVC predict\"):\n",
    "        y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def train_test_logreg(X_train, y_train, X_test):\n",
    "    with Timer(\"LogisticRegression fit\"):\n",
    "        logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "        logreg.fit(X_train, y_train)\n",
    "    \n",
    "    with Timer(\"LogisticRegression predict\"):\n",
    "        y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def train_test_sgd(X_train, y_train, X_test):\n",
    "    with Timer(\"SGDClassifier fit\"):\n",
    "        sgdcla = SGDClassifier()\n",
    "        sgdcla.fit(X_train, y_train)\n",
    "    \n",
    "    with Timer(\"SGDClassifier predict\"):\n",
    "        y_pred = sgdcla.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def heatconmat(y_test, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(y_test.unique()))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, name=None, heatmap=True):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    if heatmap:\n",
    "        heatconmat(y_test['is_same_side'], y_pred)\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2), '\\n')  #\n",
    "\n",
    "    print('Report{}:'.format(\"\" if not name else \" for [{}]\".format(name)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    f1_dic = {}\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:02:32.640713Z",
     "start_time": "2019-06-26T11:02:32.624572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train]: 0:00:00.013205\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:22:57.491220Z",
     "start_time": "2019-06-26T11:02:32.887970Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42733/42733 [14:09<00:00, 50.30it/s]\n",
      "100%|██████████| 18315/18315 [06:15<00:00, 48.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2 - tokenize]: 0:20:24.600272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. tokenize (make doc2vec docs + lemma string)\n",
    "# tqdm.pandas()\n",
    "with Timer(\"2 - tokenize\"):\n",
    "    X_train = X_train.progress_apply(make_d2v_docs, axis=1)\n",
    "    X_dev = X_dev.progress_apply(make_d2v_docs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:08:27.027714Z",
     "start_time": "2019-06-26T13:08:22.268721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2a - pickle]: 0:00:04.754327\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"2a - pickle\"):\n",
    "    X_train.to_pickle(\"X_train.cross_td.p\")\n",
    "    X_dev.to_pickle(\"X_dev.cross_td.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:08:32.385935Z",
     "start_time": "2019-06-26T13:08:29.231234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2b - unpickle]: 0:00:03.149843\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"2b - unpickle\"):\n",
    "    X_train = pd.read_pickle(\"X_train.cross_td.p\")\n",
    "    X_dev = pd.read_pickle(\"X_dev.cross_td.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T12:52:14.777029Z",
     "start_time": "2019-06-26T12:35:39.465346Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:35:39,467 : INFO : collecting all words and their counts\n",
      "2019-06-26 14:35:39,555 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-06-26 14:35:40,328 : INFO : PROGRESS: at example #10000, processed 756855 words (980205/s), 21416 word types, 2136 tags\n",
      "2019-06-26 14:35:41,071 : INFO : PROGRESS: at example #20000, processed 1517256 words (1027139/s), 28668 word types, 3475 tags\n",
      "2019-06-26 14:35:41,810 : INFO : PROGRESS: at example #30000, processed 2300874 words (1063249/s), 32981 word types, 4535 tags\n",
      "2019-06-26 14:35:42,538 : INFO : PROGRESS: at example #40000, processed 3055071 words (1039104/s), 35228 word types, 5294 tags\n",
      "2019-06-26 14:35:43,312 : INFO : PROGRESS: at example #50000, processed 3831527 words (1005748/s), 36541 word types, 5933 tags\n",
      "2019-06-26 14:35:44,236 : INFO : PROGRESS: at example #60000, processed 4602568 words (848394/s), 37180 word types, 6380 tags\n",
      "2019-06-26 14:35:45,127 : INFO : PROGRESS: at example #70000, processed 5352588 words (842704/s), 37647 word types, 6756 tags\n",
      "2019-06-26 14:35:46,118 : INFO : PROGRESS: at example #80000, processed 6145933 words (801515/s), 37953 word types, 7081 tags\n",
      "2019-06-26 14:35:46,517 : INFO : collected 38071 word types and 7236 unique tags from a corpus of 85466 examples and 6557240 words\n",
      "2019-06-26 14:35:46,518 : INFO : Loading a fresh vocabulary\n",
      "2019-06-26 14:35:46,584 : INFO : effective_min_count=2 retains 36901 unique words (96% of original 38071, drops 1170)\n",
      "2019-06-26 14:35:46,585 : INFO : effective_min_count=2 leaves 6556070 word corpus (99% of original 6557240, drops 1170)\n",
      "2019-06-26 14:35:46,689 : INFO : deleting the raw counts dictionary of 38071 items\n",
      "2019-06-26 14:35:46,692 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-06-26 14:35:46,693 : INFO : downsampling leaves estimated 6556070 word corpus (100.0% of prior 6556070)\n",
      "2019-06-26 14:35:46,825 : INFO : estimated required memory for 36901 words and 300 dimensions: 117143300 bytes\n",
      "2019-06-26 14:35:46,826 : INFO : resetting layer weights\n",
      "2019-06-26 14:35:47,379 : INFO : training model with 3 workers on 36901 vocabulary and 300 features, using sg=1 hs=0 sample=0 negative=5 window=5\n",
      "2019-06-26 14:35:48,409 : INFO : EPOCH 1 - PROGRESS: at 4.82% examples, 294300 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:35:49,410 : INFO : EPOCH 1 - PROGRESS: at 11.22% examples, 350285 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:35:50,416 : INFO : EPOCH 1 - PROGRESS: at 16.97% examples, 359085 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:35:51,423 : INFO : EPOCH 1 - PROGRESS: at 22.92% examples, 370341 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:35:52,438 : INFO : EPOCH 1 - PROGRESS: at 29.08% examples, 378760 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:35:53,438 : INFO : EPOCH 1 - PROGRESS: at 34.83% examples, 383419 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:35:54,464 : INFO : EPOCH 1 - PROGRESS: at 41.06% examples, 385766 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:35:55,471 : INFO : EPOCH 1 - PROGRESS: at 47.18% examples, 388344 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:35:56,502 : INFO : EPOCH 1 - PROGRESS: at 53.44% examples, 390491 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:35:57,543 : INFO : EPOCH 1 - PROGRESS: at 59.56% examples, 389840 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:35:58,555 : INFO : EPOCH 1 - PROGRESS: at 65.77% examples, 392108 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:35:59,576 : INFO : EPOCH 1 - PROGRESS: at 71.97% examples, 392975 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:00,621 : INFO : EPOCH 1 - PROGRESS: at 78.06% examples, 392102 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:01,639 : INFO : EPOCH 1 - PROGRESS: at 84.08% examples, 392816 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:02,661 : INFO : EPOCH 1 - PROGRESS: at 90.54% examples, 394124 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:03,665 : INFO : EPOCH 1 - PROGRESS: at 96.09% examples, 392430 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:04,286 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:36:04,291 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:36:04,292 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:36:04,293 : INFO : EPOCH - 1 : training on 6557240 raw words (6641536 effective words) took 16.9s, 392919 effective words/s\n",
      "2019-06-26 14:36:05,312 : INFO : EPOCH 2 - PROGRESS: at 5.38% examples, 359764 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:06,331 : INFO : EPOCH 2 - PROGRESS: at 11.66% examples, 385633 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:07,331 : INFO : EPOCH 2 - PROGRESS: at 17.92% examples, 389818 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:08,341 : INFO : EPOCH 2 - PROGRESS: at 24.40% examples, 398852 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:09,352 : INFO : EPOCH 2 - PROGRESS: at 31.18% examples, 405975 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:10,362 : INFO : EPOCH 2 - PROGRESS: at 37.54% examples, 407347 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:11,365 : INFO : EPOCH 2 - PROGRESS: at 43.79% examples, 410345 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:12,370 : INFO : EPOCH 2 - PROGRESS: at 49.64% examples, 407589 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:13,375 : INFO : EPOCH 2 - PROGRESS: at 55.48% examples, 408610 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:14,390 : INFO : EPOCH 2 - PROGRESS: at 61.23% examples, 405070 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:15,426 : INFO : EPOCH 2 - PROGRESS: at 67.35% examples, 403195 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:16,430 : INFO : EPOCH 2 - PROGRESS: at 73.25% examples, 402762 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:17,447 : INFO : EPOCH 2 - PROGRESS: at 79.74% examples, 404215 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:18,459 : INFO : EPOCH 2 - PROGRESS: at 86.11% examples, 404957 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:19,467 : INFO : EPOCH 2 - PROGRESS: at 91.75% examples, 402439 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:20,493 : INFO : EPOCH 2 - PROGRESS: at 98.15% examples, 402690 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:20,722 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:36:20,735 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:36:20,756 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:36:20,756 : INFO : EPOCH - 2 : training on 6557240 raw words (6641536 effective words) took 16.4s, 403877 effective words/s\n",
      "2019-06-26 14:36:21,782 : INFO : EPOCH 3 - PROGRESS: at 5.34% examples, 366659 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:22,789 : INFO : EPOCH 3 - PROGRESS: at 11.38% examples, 377014 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:23,820 : INFO : EPOCH 3 - PROGRESS: at 17.73% examples, 381041 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:24,821 : INFO : EPOCH 3 - PROGRESS: at 23.91% examples, 387765 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:25,853 : INFO : EPOCH 3 - PROGRESS: at 30.69% examples, 393377 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:26,862 : INFO : EPOCH 3 - PROGRESS: at 36.58% examples, 393757 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:27,892 : INFO : EPOCH 3 - PROGRESS: at 42.56% examples, 391401 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:28,914 : INFO : EPOCH 3 - PROGRESS: at 48.61% examples, 392432 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:29,937 : INFO : EPOCH 3 - PROGRESS: at 54.90% examples, 393290 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:30,937 : INFO : EPOCH 3 - PROGRESS: at 61.08% examples, 396978 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:31,960 : INFO : EPOCH 3 - PROGRESS: at 67.12% examples, 396448 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:32,993 : INFO : EPOCH 3 - PROGRESS: at 73.54% examples, 397321 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:34,002 : INFO : EPOCH 3 - PROGRESS: at 79.15% examples, 395713 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:35,017 : INFO : EPOCH 3 - PROGRESS: at 85.22% examples, 396970 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:36:36,055 : INFO : EPOCH 3 - PROGRESS: at 91.87% examples, 399432 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:37,055 : INFO : EPOCH 3 - PROGRESS: at 97.90% examples, 399396 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:37,287 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:36:37,315 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:36:37,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:36:37,324 : INFO : EPOCH - 3 : training on 6557240 raw words (6641536 effective words) took 16.5s, 401304 effective words/s\n",
      "2019-06-26 14:36:38,358 : INFO : EPOCH 4 - PROGRESS: at 5.54% examples, 351959 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:39,360 : INFO : EPOCH 4 - PROGRESS: at 11.50% examples, 380331 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:40,366 : INFO : EPOCH 4 - PROGRESS: at 18.02% examples, 395881 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:41,367 : INFO : EPOCH 4 - PROGRESS: at 24.28% examples, 401290 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:42,393 : INFO : EPOCH 4 - PROGRESS: at 30.90% examples, 408846 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:43,396 : INFO : EPOCH 4 - PROGRESS: at 37.01% examples, 408742 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:44,403 : INFO : EPOCH 4 - PROGRESS: at 42.39% examples, 402720 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:45,420 : INFO : EPOCH 4 - PROGRESS: at 48.85% examples, 404060 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:46,421 : INFO : EPOCH 4 - PROGRESS: at 54.81% examples, 403475 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:47,424 : INFO : EPOCH 4 - PROGRESS: at 60.79% examples, 401950 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:48,444 : INFO : EPOCH 4 - PROGRESS: at 66.99% examples, 402838 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:49,454 : INFO : EPOCH 4 - PROGRESS: at 74.02% examples, 405321 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:50,477 : INFO : EPOCH 4 - PROGRESS: at 79.77% examples, 404120 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:51,512 : INFO : EPOCH 4 - PROGRESS: at 86.52% examples, 406396 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:52,532 : INFO : EPOCH 4 - PROGRESS: at 92.89% examples, 406770 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:53,539 : INFO : EPOCH 4 - PROGRESS: at 98.64% examples, 404349 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:53,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:36:53,670 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:36:53,672 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:36:53,673 : INFO : EPOCH - 4 : training on 6557240 raw words (6641536 effective words) took 16.3s, 406611 effective words/s\n",
      "2019-06-26 14:36:54,722 : INFO : EPOCH 5 - PROGRESS: at 5.37% examples, 342693 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:55,723 : INFO : EPOCH 5 - PROGRESS: at 11.43% examples, 375624 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:56,728 : INFO : EPOCH 5 - PROGRESS: at 18.04% examples, 393191 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:57,752 : INFO : EPOCH 5 - PROGRESS: at 24.61% examples, 397648 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:36:58,772 : INFO : EPOCH 5 - PROGRESS: at 30.92% examples, 400060 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:36:59,805 : INFO : EPOCH 5 - PROGRESS: at 37.16% examples, 401134 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:00,809 : INFO : EPOCH 5 - PROGRESS: at 42.58% examples, 397733 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:01,851 : INFO : EPOCH 5 - PROGRESS: at 48.70% examples, 395697 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:02,852 : INFO : EPOCH 5 - PROGRESS: at 54.70% examples, 394013 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:03,861 : INFO : EPOCH 5 - PROGRESS: at 61.16% examples, 398052 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:04,863 : INFO : EPOCH 5 - PROGRESS: at 67.44% examples, 398111 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:05,895 : INFO : EPOCH 5 - PROGRESS: at 74.02% examples, 401261 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:06,907 : INFO : EPOCH 5 - PROGRESS: at 80.33% examples, 403610 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:07,919 : INFO : EPOCH 5 - PROGRESS: at 87.12% examples, 406393 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:08,922 : INFO : EPOCH 5 - PROGRESS: at 93.66% examples, 407880 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:09,856 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:37:09,869 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:37:09,875 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:37:09,877 : INFO : EPOCH - 5 : training on 6557240 raw words (6641536 effective words) took 16.2s, 410600 effective words/s\n",
      "2019-06-26 14:37:10,893 : INFO : EPOCH 6 - PROGRESS: at 5.42% examples, 358552 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:11,899 : INFO : EPOCH 6 - PROGRESS: at 11.51% examples, 382727 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:12,914 : INFO : EPOCH 6 - PROGRESS: at 17.95% examples, 389901 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:13,943 : INFO : EPOCH 6 - PROGRESS: at 23.67% examples, 384035 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:14,951 : INFO : EPOCH 6 - PROGRESS: at 30.02% examples, 392307 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:15,975 : INFO : EPOCH 6 - PROGRESS: at 36.24% examples, 395066 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:16,987 : INFO : EPOCH 6 - PROGRESS: at 42.83% examples, 397715 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:18,035 : INFO : EPOCH 6 - PROGRESS: at 49.15% examples, 398010 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:19,047 : INFO : EPOCH 6 - PROGRESS: at 55.27% examples, 399655 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:20,065 : INFO : EPOCH 6 - PROGRESS: at 61.76% examples, 400871 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:21,090 : INFO : EPOCH 6 - PROGRESS: at 68.00% examples, 402325 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:22,109 : INFO : EPOCH 6 - PROGRESS: at 74.28% examples, 402261 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:23,114 : INFO : EPOCH 6 - PROGRESS: at 80.39% examples, 403298 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:24,120 : INFO : EPOCH 6 - PROGRESS: at 86.87% examples, 405518 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:25,147 : INFO : EPOCH 6 - PROGRESS: at 93.74% examples, 407018 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:26,134 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:37:26,137 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:37:26,170 : INFO : EPOCH 6 - PROGRESS: at 100.00% examples, 408007 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-26 14:37:26,172 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:37:26,173 : INFO : EPOCH - 6 : training on 6557240 raw words (6641536 effective words) took 16.3s, 407915 effective words/s\n",
      "2019-06-26 14:37:27,218 : INFO : EPOCH 7 - PROGRESS: at 5.38% examples, 350255 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:28,259 : INFO : EPOCH 7 - PROGRESS: at 12.19% examples, 386362 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:29,264 : INFO : EPOCH 7 - PROGRESS: at 18.36% examples, 397040 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:30,268 : INFO : EPOCH 7 - PROGRESS: at 24.71% examples, 402459 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:31,277 : INFO : EPOCH 7 - PROGRESS: at 30.80% examples, 405033 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:32,298 : INFO : EPOCH 7 - PROGRESS: at 37.02% examples, 405877 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:33,321 : INFO : EPOCH 7 - PROGRESS: at 43.27% examples, 404854 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:34,326 : INFO : EPOCH 7 - PROGRESS: at 49.29% examples, 406333 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:35,332 : INFO : EPOCH 7 - PROGRESS: at 55.65% examples, 406317 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:37:36,348 : INFO : EPOCH 7 - PROGRESS: at 61.99% examples, 406966 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:37,356 : INFO : EPOCH 7 - PROGRESS: at 68.03% examples, 406923 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:38,358 : INFO : EPOCH 7 - PROGRESS: at 74.13% examples, 407846 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:39,380 : INFO : EPOCH 7 - PROGRESS: at 80.38% examples, 407260 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:40,410 : INFO : EPOCH 7 - PROGRESS: at 86.67% examples, 405930 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:41,411 : INFO : EPOCH 7 - PROGRESS: at 92.90% examples, 406130 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:42,417 : INFO : EPOCH 7 - PROGRESS: at 99.27% examples, 406217 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:42,476 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:37:42,478 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:37:42,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:37:42,487 : INFO : EPOCH - 7 : training on 6557240 raw words (6641536 effective words) took 16.3s, 407562 effective words/s\n",
      "2019-06-26 14:37:43,565 : INFO : EPOCH 8 - PROGRESS: at 5.65% examples, 353920 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:44,576 : INFO : EPOCH 8 - PROGRESS: at 12.09% examples, 383827 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:45,592 : INFO : EPOCH 8 - PROGRESS: at 18.59% examples, 396435 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:46,600 : INFO : EPOCH 8 - PROGRESS: at 24.52% examples, 401150 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:47,616 : INFO : EPOCH 8 - PROGRESS: at 30.16% examples, 397919 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:48,641 : INFO : EPOCH 8 - PROGRESS: at 35.98% examples, 396607 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 14:37:49,696 : INFO : EPOCH 8 - PROGRESS: at 42.81% examples, 399497 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:50,738 : INFO : EPOCH 8 - PROGRESS: at 49.17% examples, 397433 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:51,759 : INFO : EPOCH 8 - PROGRESS: at 55.40% examples, 399825 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:52,778 : INFO : EPOCH 8 - PROGRESS: at 62.31% examples, 403123 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:53,783 : INFO : EPOCH 8 - PROGRESS: at 68.73% examples, 404497 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:54,794 : INFO : EPOCH 8 - PROGRESS: at 75.58% examples, 406150 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:55,799 : INFO : EPOCH 8 - PROGRESS: at 81.82% examples, 406975 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:37:56,819 : INFO : EPOCH 8 - PROGRESS: at 87.85% examples, 406468 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:57,864 : INFO : EPOCH 8 - PROGRESS: at 94.36% examples, 407408 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:37:58,765 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:37:58,800 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:37:58,807 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:37:58,808 : INFO : EPOCH - 8 : training on 6557240 raw words (6641536 effective words) took 16.3s, 407694 effective words/s\n",
      "2019-06-26 14:37:59,826 : INFO : EPOCH 9 - PROGRESS: at 5.10% examples, 347128 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:00,835 : INFO : EPOCH 9 - PROGRESS: at 11.49% examples, 385661 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:01,841 : INFO : EPOCH 9 - PROGRESS: at 16.95% examples, 379385 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:02,865 : INFO : EPOCH 9 - PROGRESS: at 23.05% examples, 382563 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:03,884 : INFO : EPOCH 9 - PROGRESS: at 29.15% examples, 382478 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:04,924 : INFO : EPOCH 9 - PROGRESS: at 36.02% examples, 392723 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:05,930 : INFO : EPOCH 9 - PROGRESS: at 42.29% examples, 395900 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:06,933 : INFO : EPOCH 9 - PROGRESS: at 48.20% examples, 396166 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:07,957 : INFO : EPOCH 9 - PROGRESS: at 54.41% examples, 396556 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:08,958 : INFO : EPOCH 9 - PROGRESS: at 60.97% examples, 398719 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:09,970 : INFO : EPOCH 9 - PROGRESS: at 67.53% examples, 401050 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:10,986 : INFO : EPOCH 9 - PROGRESS: at 74.04% examples, 402833 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:11,991 : INFO : EPOCH 9 - PROGRESS: at 79.91% examples, 402388 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:13,015 : INFO : EPOCH 9 - PROGRESS: at 86.27% examples, 403564 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:14,037 : INFO : EPOCH 9 - PROGRESS: at 92.24% examples, 402123 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:15,067 : INFO : EPOCH 9 - PROGRESS: at 98.73% examples, 403677 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:15,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:38:15,179 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:38:15,183 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:38:15,184 : INFO : EPOCH - 9 : training on 6557240 raw words (6641536 effective words) took 16.4s, 405791 effective words/s\n",
      "2019-06-26 14:38:16,205 : INFO : EPOCH 10 - PROGRESS: at 5.89% examples, 393198 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:17,230 : INFO : EPOCH 10 - PROGRESS: at 12.52% examples, 405671 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:18,233 : INFO : EPOCH 10 - PROGRESS: at 18.30% examples, 399906 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:19,284 : INFO : EPOCH 10 - PROGRESS: at 24.87% examples, 404804 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:20,321 : INFO : EPOCH 10 - PROGRESS: at 31.08% examples, 402882 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:21,324 : INFO : EPOCH 10 - PROGRESS: at 37.47% examples, 406912 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:22,336 : INFO : EPOCH 10 - PROGRESS: at 43.76% examples, 408040 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:23,348 : INFO : EPOCH 10 - PROGRESS: at 50.24% examples, 409809 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:24,354 : INFO : EPOCH 10 - PROGRESS: at 56.73% examples, 411707 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:25,364 : INFO : EPOCH 10 - PROGRESS: at 62.80% examples, 409085 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:26,374 : INFO : EPOCH 10 - PROGRESS: at 68.86% examples, 406848 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:27,385 : INFO : EPOCH 10 - PROGRESS: at 75.06% examples, 406664 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:28,402 : INFO : EPOCH 10 - PROGRESS: at 81.84% examples, 410059 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:29,409 : INFO : EPOCH 10 - PROGRESS: at 87.89% examples, 409125 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:30,415 : INFO : EPOCH 10 - PROGRESS: at 94.26% examples, 410857 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:31,209 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:38:31,218 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:38:31,229 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:38:31,230 : INFO : EPOCH - 10 : training on 6557240 raw words (6641536 effective words) took 16.0s, 413986 effective words/s\n",
      "2019-06-26 14:38:32,252 : INFO : EPOCH 11 - PROGRESS: at 5.65% examples, 364398 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:33,259 : INFO : EPOCH 11 - PROGRESS: at 11.65% examples, 384980 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:34,260 : INFO : EPOCH 11 - PROGRESS: at 17.61% examples, 388876 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:35,271 : INFO : EPOCH 11 - PROGRESS: at 23.74% examples, 390370 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:36,307 : INFO : EPOCH 11 - PROGRESS: at 30.32% examples, 395514 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:38:37,325 : INFO : EPOCH 11 - PROGRESS: at 36.32% examples, 398256 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:38,339 : INFO : EPOCH 11 - PROGRESS: at 42.96% examples, 401966 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:39,343 : INFO : EPOCH 11 - PROGRESS: at 49.31% examples, 403883 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:40,374 : INFO : EPOCH 11 - PROGRESS: at 55.60% examples, 404273 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:41,406 : INFO : EPOCH 11 - PROGRESS: at 62.03% examples, 405293 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:42,411 : INFO : EPOCH 11 - PROGRESS: at 68.31% examples, 406414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:43,423 : INFO : EPOCH 11 - PROGRESS: at 74.68% examples, 406974 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:44,435 : INFO : EPOCH 11 - PROGRESS: at 81.37% examples, 409801 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:45,449 : INFO : EPOCH 11 - PROGRESS: at 87.31% examples, 408763 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:46,454 : INFO : EPOCH 11 - PROGRESS: at 93.12% examples, 408001 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:47,345 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:38:47,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:38:47,378 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:38:47,379 : INFO : EPOCH - 11 : training on 6557240 raw words (6641536 effective words) took 16.1s, 411507 effective words/s\n",
      "2019-06-26 14:38:48,417 : INFO : EPOCH 12 - PROGRESS: at 5.41% examples, 353622 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:49,418 : INFO : EPOCH 12 - PROGRESS: at 11.50% examples, 376221 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:50,432 : INFO : EPOCH 12 - PROGRESS: at 17.29% examples, 375559 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:51,441 : INFO : EPOCH 12 - PROGRESS: at 23.38% examples, 382805 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:52,479 : INFO : EPOCH 12 - PROGRESS: at 29.86% examples, 391230 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:53,488 : INFO : EPOCH 12 - PROGRESS: at 36.46% examples, 396707 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:54,493 : INFO : EPOCH 12 - PROGRESS: at 43.06% examples, 402587 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:38:55,505 : INFO : EPOCH 12 - PROGRESS: at 49.70% examples, 406395 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:56,508 : INFO : EPOCH 12 - PROGRESS: at 56.02% examples, 406621 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:57,534 : INFO : EPOCH 12 - PROGRESS: at 62.27% examples, 406719 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:58,549 : INFO : EPOCH 12 - PROGRESS: at 68.70% examples, 407377 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:38:59,565 : INFO : EPOCH 12 - PROGRESS: at 74.90% examples, 406932 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:00,603 : INFO : EPOCH 12 - PROGRESS: at 81.17% examples, 407472 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 14:39:01,623 : INFO : EPOCH 12 - PROGRESS: at 87.43% examples, 407710 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:02,653 : INFO : EPOCH 12 - PROGRESS: at 93.89% examples, 408923 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:03,453 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:39:03,456 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:39:03,463 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:39:03,464 : INFO : EPOCH - 12 : training on 6557240 raw words (6641536 effective words) took 16.1s, 413382 effective words/s\n",
      "2019-06-26 14:39:04,503 : INFO : EPOCH 13 - PROGRESS: at 5.56% examples, 354747 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:05,516 : INFO : EPOCH 13 - PROGRESS: at 11.97% examples, 379773 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:06,517 : INFO : EPOCH 13 - PROGRESS: at 18.36% examples, 395380 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:07,546 : INFO : EPOCH 13 - PROGRESS: at 24.91% examples, 398104 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:08,557 : INFO : EPOCH 13 - PROGRESS: at 31.07% examples, 401368 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:09,580 : INFO : EPOCH 13 - PROGRESS: at 37.64% examples, 405701 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:10,603 : INFO : EPOCH 13 - PROGRESS: at 44.15% examples, 409185 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:11,620 : INFO : EPOCH 13 - PROGRESS: at 50.29% examples, 408421 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:12,633 : INFO : EPOCH 13 - PROGRESS: at 56.26% examples, 406802 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:13,635 : INFO : EPOCH 13 - PROGRESS: at 62.94% examples, 409066 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:14,642 : INFO : EPOCH 13 - PROGRESS: at 69.57% examples, 412501 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:15,676 : INFO : EPOCH 13 - PROGRESS: at 76.31% examples, 415043 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:16,688 : INFO : EPOCH 13 - PROGRESS: at 83.01% examples, 415752 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:17,698 : INFO : EPOCH 13 - PROGRESS: at 89.60% examples, 417818 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:18,717 : INFO : EPOCH 13 - PROGRESS: at 96.05% examples, 418804 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:19,210 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:39:19,215 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:39:19,215 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:39:19,218 : INFO : EPOCH - 13 : training on 6557240 raw words (6641536 effective words) took 15.7s, 422201 effective words/s\n",
      "2019-06-26 14:39:20,271 : INFO : EPOCH 14 - PROGRESS: at 5.77% examples, 368602 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:21,284 : INFO : EPOCH 14 - PROGRESS: at 12.88% examples, 410789 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:22,285 : INFO : EPOCH 14 - PROGRESS: at 19.61% examples, 423307 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:23,299 : INFO : EPOCH 14 - PROGRESS: at 26.01% examples, 423517 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:24,322 : INFO : EPOCH 14 - PROGRESS: at 33.25% examples, 430883 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:25,363 : INFO : EPOCH 14 - PROGRESS: at 40.99% examples, 439417 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:26,388 : INFO : EPOCH 14 - PROGRESS: at 47.38% examples, 439110 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:27,399 : INFO : EPOCH 14 - PROGRESS: at 54.61% examples, 447031 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:28,415 : INFO : EPOCH 14 - PROGRESS: at 61.58% examples, 449639 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:29,424 : INFO : EPOCH 14 - PROGRESS: at 68.54% examples, 448095 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:30,452 : INFO : EPOCH 14 - PROGRESS: at 75.95% examples, 449693 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:31,488 : INFO : EPOCH 14 - PROGRESS: at 83.44% examples, 450685 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:32,496 : INFO : EPOCH 14 - PROGRESS: at 90.01% examples, 450994 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:33,501 : INFO : EPOCH 14 - PROGRESS: at 97.40% examples, 454217 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:33,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:39:33,754 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:39:33,758 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:39:33,759 : INFO : EPOCH - 14 : training on 6557240 raw words (6641536 effective words) took 14.5s, 457429 effective words/s\n",
      "2019-06-26 14:39:34,792 : INFO : EPOCH 15 - PROGRESS: at 6.41% examples, 421710 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:35,812 : INFO : EPOCH 15 - PROGRESS: at 13.61% examples, 431688 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:36,830 : INFO : EPOCH 15 - PROGRESS: at 20.36% examples, 434424 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:37,883 : INFO : EPOCH 15 - PROGRESS: at 27.74% examples, 444430 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:39:38,899 : INFO : EPOCH 15 - PROGRESS: at 35.04% examples, 445963 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:39,902 : INFO : EPOCH 15 - PROGRESS: at 42.07% examples, 449360 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:40,916 : INFO : EPOCH 15 - PROGRESS: at 49.56% examples, 455342 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:41,929 : INFO : EPOCH 15 - PROGRESS: at 57.01% examples, 458740 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:42,934 : INFO : EPOCH 15 - PROGRESS: at 64.37% examples, 461818 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:43,945 : INFO : EPOCH 15 - PROGRESS: at 71.68% examples, 464972 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:44,949 : INFO : EPOCH 15 - PROGRESS: at 78.84% examples, 465340 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:45,957 : INFO : EPOCH 15 - PROGRESS: at 86.23% examples, 467631 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:46,966 : INFO : EPOCH 15 - PROGRESS: at 93.18% examples, 468870 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:47,811 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:39:47,816 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:39:47,818 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:39:47,819 : INFO : EPOCH - 15 : training on 6557240 raw words (6641536 effective words) took 14.0s, 473035 effective words/s\n",
      "2019-06-26 14:39:48,856 : INFO : EPOCH 16 - PROGRESS: at 5.91% examples, 402368 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:49,867 : INFO : EPOCH 16 - PROGRESS: at 13.09% examples, 442622 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:50,893 : INFO : EPOCH 16 - PROGRESS: at 20.15% examples, 456958 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:51,899 : INFO : EPOCH 16 - PROGRESS: at 26.77% examples, 452061 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:52,908 : INFO : EPOCH 16 - PROGRESS: at 33.53% examples, 451008 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:53,924 : INFO : EPOCH 16 - PROGRESS: at 40.77% examples, 454584 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:39:54,941 : INFO : EPOCH 16 - PROGRESS: at 48.23% examples, 457010 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-26 14:39:55,943 : INFO : EPOCH 16 - PROGRESS: at 54.99% examples, 455830 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:56,965 : INFO : EPOCH 16 - PROGRESS: at 62.53% examples, 460571 words/s, in_qsize 3, out_qsize 0\n",
      "2019-06-26 14:39:57,970 : INFO : EPOCH 16 - PROGRESS: at 69.43% examples, 459273 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:39:58,987 : INFO : EPOCH 16 - PROGRESS: at 76.82% examples, 461207 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:00,022 : INFO : EPOCH 16 - PROGRESS: at 84.34% examples, 461393 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:01,028 : INFO : EPOCH 16 - PROGRESS: at 91.92% examples, 463387 words/s, in_qsize 3, out_qsize 0\n",
      "2019-06-26 14:40:02,045 : INFO : EPOCH 16 - PROGRESS: at 99.57% examples, 465358 words/s, in_qsize 3, out_qsize 0\n",
      "2019-06-26 14:40:02,058 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:40:02,065 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:40:02,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:40:02,075 : INFO : EPOCH - 16 : training on 6557240 raw words (6641536 effective words) took 14.2s, 466427 effective words/s\n",
      "2019-06-26 14:40:03,111 : INFO : EPOCH 17 - PROGRESS: at 6.46% examples, 424974 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:04,111 : INFO : EPOCH 17 - PROGRESS: at 13.44% examples, 452307 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:05,129 : INFO : EPOCH 17 - PROGRESS: at 20.39% examples, 458165 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:06,129 : INFO : EPOCH 17 - PROGRESS: at 27.38% examples, 455777 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:07,148 : INFO : EPOCH 17 - PROGRESS: at 34.61% examples, 459151 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:08,192 : INFO : EPOCH 17 - PROGRESS: at 41.87% examples, 459509 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:09,218 : INFO : EPOCH 17 - PROGRESS: at 49.23% examples, 462171 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:10,232 : INFO : EPOCH 17 - PROGRESS: at 56.50% examples, 462082 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:11,242 : INFO : EPOCH 17 - PROGRESS: at 64.12% examples, 463422 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:12,260 : INFO : EPOCH 17 - PROGRESS: at 71.79% examples, 468039 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:13,265 : INFO : EPOCH 17 - PROGRESS: at 79.17% examples, 471528 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 14:40:14,278 : INFO : EPOCH 17 - PROGRESS: at 86.61% examples, 473327 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:15,291 : INFO : EPOCH 17 - PROGRESS: at 93.30% examples, 469537 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:16,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:40:16,197 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:40:16,200 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:40:16,201 : INFO : EPOCH - 17 : training on 6557240 raw words (6641536 effective words) took 14.1s, 470988 effective words/s\n",
      "2019-06-26 14:40:17,261 : INFO : EPOCH 18 - PROGRESS: at 6.10% examples, 407694 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:18,277 : INFO : EPOCH 18 - PROGRESS: at 13.67% examples, 458129 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:19,278 : INFO : EPOCH 18 - PROGRESS: at 20.86% examples, 464924 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:20,314 : INFO : EPOCH 18 - PROGRESS: at 27.97% examples, 469472 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:21,338 : INFO : EPOCH 18 - PROGRESS: at 35.54% examples, 472818 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:22,338 : INFO : EPOCH 18 - PROGRESS: at 43.08% examples, 472382 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:23,338 : INFO : EPOCH 18 - PROGRESS: at 50.47% examples, 473161 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:24,356 : INFO : EPOCH 18 - PROGRESS: at 57.85% examples, 474067 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:25,363 : INFO : EPOCH 18 - PROGRESS: at 65.13% examples, 473294 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:26,402 : INFO : EPOCH 18 - PROGRESS: at 72.42% examples, 471131 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:27,430 : INFO : EPOCH 18 - PROGRESS: at 79.43% examples, 469942 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:28,436 : INFO : EPOCH 18 - PROGRESS: at 86.90% examples, 471394 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:29,441 : INFO : EPOCH 18 - PROGRESS: at 93.95% examples, 471862 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:30,204 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:40:30,206 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:40:30,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:40:30,208 : INFO : EPOCH - 18 : training on 6557240 raw words (6641536 effective words) took 14.0s, 475250 effective words/s\n",
      "2019-06-26 14:40:31,218 : INFO : EPOCH 19 - PROGRESS: at 6.66% examples, 437259 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-26 14:40:32,220 : INFO : EPOCH 19 - PROGRESS: at 13.95% examples, 453237 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:33,233 : INFO : EPOCH 19 - PROGRESS: at 21.08% examples, 459560 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:34,259 : INFO : EPOCH 19 - PROGRESS: at 28.36% examples, 463845 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:35,283 : INFO : EPOCH 19 - PROGRESS: at 35.91% examples, 468422 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:36,300 : INFO : EPOCH 19 - PROGRESS: at 43.14% examples, 470858 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:37,311 : INFO : EPOCH 19 - PROGRESS: at 50.17% examples, 468520 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:38,314 : INFO : EPOCH 19 - PROGRESS: at 57.68% examples, 470911 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:39,320 : INFO : EPOCH 19 - PROGRESS: at 64.68% examples, 471638 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:40:40,321 : INFO : EPOCH 19 - PROGRESS: at 71.44% examples, 470219 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-26 14:40:41,326 : INFO : EPOCH 19 - PROGRESS: at 77.86% examples, 465310 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:42,338 : INFO : EPOCH 19 - PROGRESS: at 85.00% examples, 465239 words/s, in_qsize 4, out_qsize 0\n",
      "2019-06-26 14:40:43,350 : INFO : EPOCH 19 - PROGRESS: at 92.21% examples, 465653 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:44,385 : INFO : EPOCH 19 - PROGRESS: at 98.84% examples, 463371 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:44,501 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:40:44,520 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:40:44,528 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:40:44,530 : INFO : EPOCH - 19 : training on 6557240 raw words (6641536 effective words) took 14.3s, 463822 effective words/s\n",
      "2019-06-26 14:40:45,556 : INFO : EPOCH 20 - PROGRESS: at 6.18% examples, 414397 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:46,566 : INFO : EPOCH 20 - PROGRESS: at 13.38% examples, 444661 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:47,567 : INFO : EPOCH 20 - PROGRESS: at 19.96% examples, 445897 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:48,584 : INFO : EPOCH 20 - PROGRESS: at 26.79% examples, 447371 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:49,590 : INFO : EPOCH 20 - PROGRESS: at 34.37% examples, 453172 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:50,594 : INFO : EPOCH 20 - PROGRESS: at 41.03% examples, 450630 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:51,620 : INFO : EPOCH 20 - PROGRESS: at 47.97% examples, 450137 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:52,642 : INFO : EPOCH 20 - PROGRESS: at 54.64% examples, 446415 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:40:53,645 : INFO : EPOCH 20 - PROGRESS: at 61.18% examples, 446659 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:54,674 : INFO : EPOCH 20 - PROGRESS: at 68.55% examples, 450411 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:55,677 : INFO : EPOCH 20 - PROGRESS: at 75.98% examples, 454798 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:56,704 : INFO : EPOCH 20 - PROGRESS: at 83.19% examples, 456635 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:57,709 : INFO : EPOCH 20 - PROGRESS: at 90.22% examples, 456568 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:58,726 : INFO : EPOCH 20 - PROGRESS: at 97.55% examples, 456960 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:40:58,972 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:40:58,974 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:40:58,977 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:40:58,978 : INFO : EPOCH - 20 : training on 6557240 raw words (6641536 effective words) took 14.4s, 460204 effective words/s\n",
      "2019-06-26 14:40:59,997 : INFO : EPOCH 21 - PROGRESS: at 6.27% examples, 417498 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:01,013 : INFO : EPOCH 21 - PROGRESS: at 12.43% examples, 410163 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:02,014 : INFO : EPOCH 21 - PROGRESS: at 20.10% examples, 436150 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:03,040 : INFO : EPOCH 21 - PROGRESS: at 26.94% examples, 439194 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:04,046 : INFO : EPOCH 21 - PROGRESS: at 34.68% examples, 452364 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:05,059 : INFO : EPOCH 21 - PROGRESS: at 41.49% examples, 449396 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:06,069 : INFO : EPOCH 21 - PROGRESS: at 48.77% examples, 454548 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:07,080 : INFO : EPOCH 21 - PROGRESS: at 56.18% examples, 459540 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:08,092 : INFO : EPOCH 21 - PROGRESS: at 61.99% examples, 450228 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:09,092 : INFO : EPOCH 21 - PROGRESS: at 68.72% examples, 451062 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:10,119 : INFO : EPOCH 21 - PROGRESS: at 76.98% examples, 458028 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:11,121 : INFO : EPOCH 21 - PROGRESS: at 83.55% examples, 456387 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:12,136 : INFO : EPOCH 21 - PROGRESS: at 89.65% examples, 452984 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:13,141 : INFO : EPOCH 21 - PROGRESS: at 96.41% examples, 452681 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:13,539 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:41:13,543 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:41:13,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:41:13,545 : INFO : EPOCH - 21 : training on 6557240 raw words (6641536 effective words) took 14.6s, 456329 effective words/s\n",
      "2019-06-26 14:41:14,561 : INFO : EPOCH 22 - PROGRESS: at 5.47% examples, 364643 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:15,569 : INFO : EPOCH 22 - PROGRESS: at 11.37% examples, 375591 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:16,575 : INFO : EPOCH 22 - PROGRESS: at 17.40% examples, 389573 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:17,583 : INFO : EPOCH 22 - PROGRESS: at 24.55% examples, 410855 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:18,583 : INFO : EPOCH 22 - PROGRESS: at 32.23% examples, 428468 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:19,603 : INFO : EPOCH 22 - PROGRESS: at 38.79% examples, 427212 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:20,635 : INFO : EPOCH 22 - PROGRESS: at 45.53% examples, 429891 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:21,642 : INFO : EPOCH 22 - PROGRESS: at 51.33% examples, 422046 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:22,648 : INFO : EPOCH 22 - PROGRESS: at 59.16% examples, 431481 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:23,652 : INFO : EPOCH 22 - PROGRESS: at 66.36% examples, 435687 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:24,658 : INFO : EPOCH 22 - PROGRESS: at 75.62% examples, 451884 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:25,667 : INFO : EPOCH 22 - PROGRESS: at 83.52% examples, 456306 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:26,680 : INFO : EPOCH 22 - PROGRESS: at 89.44% examples, 452868 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:27,680 : INFO : EPOCH 22 - PROGRESS: at 95.72% examples, 449783 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:28,189 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:41:28,201 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:41:28,202 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:41:28,203 : INFO : EPOCH - 22 : training on 6557240 raw words (6641536 effective words) took 14.7s, 453178 effective words/s\n",
      "2019-06-26 14:41:29,219 : INFO : EPOCH 23 - PROGRESS: at 6.36% examples, 413338 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:30,232 : INFO : EPOCH 23 - PROGRESS: at 12.61% examples, 408394 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:31,236 : INFO : EPOCH 23 - PROGRESS: at 20.89% examples, 454802 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:32,265 : INFO : EPOCH 23 - PROGRESS: at 26.74% examples, 437704 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:33,278 : INFO : EPOCH 23 - PROGRESS: at 32.93% examples, 434896 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:34,300 : INFO : EPOCH 23 - PROGRESS: at 39.48% examples, 430691 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:35,309 : INFO : EPOCH 23 - PROGRESS: at 46.96% examples, 437238 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:36,321 : INFO : EPOCH 23 - PROGRESS: at 54.63% examples, 443123 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:37,336 : INFO : EPOCH 23 - PROGRESS: at 61.00% examples, 439804 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:38,348 : INFO : EPOCH 23 - PROGRESS: at 70.01% examples, 456960 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:39,355 : INFO : EPOCH 23 - PROGRESS: at 78.81% examples, 469303 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:41:40,359 : INFO : EPOCH 23 - PROGRESS: at 87.88% examples, 479819 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:41,367 : INFO : EPOCH 23 - PROGRESS: at 97.06% examples, 490124 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:41,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:41:41,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:41:41,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:41:41,599 : INFO : EPOCH - 23 : training on 6557240 raw words (6641536 effective words) took 13.4s, 495878 effective words/s\n",
      "2019-06-26 14:41:42,616 : INFO : EPOCH 24 - PROGRESS: at 6.14% examples, 392365 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:43,628 : INFO : EPOCH 24 - PROGRESS: at 13.11% examples, 427050 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:44,628 : INFO : EPOCH 24 - PROGRESS: at 21.97% examples, 477742 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:45,638 : INFO : EPOCH 24 - PROGRESS: at 29.94% examples, 487043 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:46,670 : INFO : EPOCH 24 - PROGRESS: at 38.05% examples, 495990 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:47,702 : INFO : EPOCH 24 - PROGRESS: at 45.44% examples, 492166 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:48,712 : INFO : EPOCH 24 - PROGRESS: at 52.10% examples, 486672 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:49,718 : INFO : EPOCH 24 - PROGRESS: at 57.73% examples, 471858 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:50,739 : INFO : EPOCH 24 - PROGRESS: at 65.69% examples, 476954 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:51,751 : INFO : EPOCH 24 - PROGRESS: at 72.19% examples, 473677 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:52,773 : INFO : EPOCH 24 - PROGRESS: at 80.15% examples, 476047 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:53,779 : INFO : EPOCH 24 - PROGRESS: at 87.86% examples, 477638 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:54,796 : INFO : EPOCH 24 - PROGRESS: at 94.56% examples, 475675 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:55,570 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:41:55,579 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:41:55,583 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:41:55,584 : INFO : EPOCH - 24 : training on 6557240 raw words (6641536 effective words) took 14.0s, 474985 effective words/s\n",
      "2019-06-26 14:41:56,604 : INFO : EPOCH 25 - PROGRESS: at 5.40% examples, 362572 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:57,617 : INFO : EPOCH 25 - PROGRESS: at 12.42% examples, 403638 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:41:58,638 : INFO : EPOCH 25 - PROGRESS: at 19.73% examples, 431654 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:41:59,639 : INFO : EPOCH 25 - PROGRESS: at 26.26% examples, 428732 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:00,643 : INFO : EPOCH 25 - PROGRESS: at 32.62% examples, 428347 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:01,658 : INFO : EPOCH 25 - PROGRESS: at 39.57% examples, 432623 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:02,669 : INFO : EPOCH 25 - PROGRESS: at 45.55% examples, 427119 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:03,682 : INFO : EPOCH 25 - PROGRESS: at 52.61% examples, 432822 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:04,687 : INFO : EPOCH 25 - PROGRESS: at 61.14% examples, 448591 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:05,709 : INFO : EPOCH 25 - PROGRESS: at 67.98% examples, 447701 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:06,732 : INFO : EPOCH 25 - PROGRESS: at 74.95% examples, 446088 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:07,748 : INFO : EPOCH 25 - PROGRESS: at 82.33% examples, 448967 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:08,776 : INFO : EPOCH 25 - PROGRESS: at 89.23% examples, 448904 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:09,776 : INFO : EPOCH 25 - PROGRESS: at 95.26% examples, 446062 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:10,343 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:42:10,350 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:42:10,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:42:10,361 : INFO : EPOCH - 25 : training on 6557240 raw words (6641536 effective words) took 14.8s, 449513 effective words/s\n",
      "2019-06-26 14:42:11,371 : INFO : EPOCH 26 - PROGRESS: at 5.96% examples, 386582 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:12,373 : INFO : EPOCH 26 - PROGRESS: at 12.61% examples, 412744 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:13,374 : INFO : EPOCH 26 - PROGRESS: at 18.39% examples, 395310 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:14,378 : INFO : EPOCH 26 - PROGRESS: at 23.76% examples, 388372 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 14:42:15,391 : INFO : EPOCH 26 - PROGRESS: at 30.26% examples, 395282 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:16,399 : INFO : EPOCH 26 - PROGRESS: at 38.08% examples, 415501 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:17,431 : INFO : EPOCH 26 - PROGRESS: at 44.87% examples, 418428 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:18,436 : INFO : EPOCH 26 - PROGRESS: at 50.93% examples, 413400 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:19,444 : INFO : EPOCH 26 - PROGRESS: at 59.59% examples, 429098 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 14:42:20,447 : INFO : EPOCH 26 - PROGRESS: at 66.82% examples, 434836 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:21,456 : INFO : EPOCH 26 - PROGRESS: at 73.16% examples, 433112 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:22,471 : INFO : EPOCH 26 - PROGRESS: at 81.38% examples, 443092 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:23,472 : INFO : EPOCH 26 - PROGRESS: at 89.70% examples, 454875 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:24,486 : INFO : EPOCH 26 - PROGRESS: at 96.80% examples, 456045 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:24,843 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:42:24,861 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:42:24,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:42:24,872 : INFO : EPOCH - 26 : training on 6557240 raw words (6641536 effective words) took 14.5s, 457774 effective words/s\n",
      "2019-06-26 14:42:25,888 : INFO : EPOCH 27 - PROGRESS: at 5.91% examples, 384826 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:26,900 : INFO : EPOCH 27 - PROGRESS: at 12.31% examples, 403973 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:27,906 : INFO : EPOCH 27 - PROGRESS: at 18.32% examples, 404871 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:28,926 : INFO : EPOCH 27 - PROGRESS: at 24.47% examples, 404190 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:29,936 : INFO : EPOCH 27 - PROGRESS: at 30.73% examples, 406414 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:30,947 : INFO : EPOCH 27 - PROGRESS: at 38.93% examples, 427401 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:31,948 : INFO : EPOCH 27 - PROGRESS: at 44.86% examples, 423304 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:32,952 : INFO : EPOCH 27 - PROGRESS: at 50.45% examples, 417615 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:33,967 : INFO : EPOCH 27 - PROGRESS: at 56.40% examples, 413879 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:34,972 : INFO : EPOCH 27 - PROGRESS: at 65.37% examples, 431032 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:36,005 : INFO : EPOCH 27 - PROGRESS: at 72.08% examples, 430510 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:37,018 : INFO : EPOCH 27 - PROGRESS: at 79.24% examples, 434050 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:38,031 : INFO : EPOCH 27 - PROGRESS: at 85.21% examples, 430211 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:39,042 : INFO : EPOCH 27 - PROGRESS: at 91.88% examples, 429932 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:40,043 : INFO : EPOCH 27 - PROGRESS: at 98.09% examples, 429274 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:42:40,177 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:42:40,178 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:42:40,193 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:42:40,194 : INFO : EPOCH - 27 : training on 6557240 raw words (6641536 effective words) took 15.3s, 433553 effective words/s\n",
      "2019-06-26 14:42:41,204 : INFO : EPOCH 28 - PROGRESS: at 6.68% examples, 447221 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:42,216 : INFO : EPOCH 28 - PROGRESS: at 14.18% examples, 465550 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:43,228 : INFO : EPOCH 28 - PROGRESS: at 20.71% examples, 461668 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:44,231 : INFO : EPOCH 28 - PROGRESS: at 29.47% examples, 485994 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:45,249 : INFO : EPOCH 28 - PROGRESS: at 38.32% examples, 504144 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:46,268 : INFO : EPOCH 28 - PROGRESS: at 44.69% examples, 488547 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:47,291 : INFO : EPOCH 28 - PROGRESS: at 51.06% examples, 474664 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:48,297 : INFO : EPOCH 28 - PROGRESS: at 56.60% examples, 463775 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:49,308 : INFO : EPOCH 28 - PROGRESS: at 64.71% examples, 470330 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:50,319 : INFO : EPOCH 28 - PROGRESS: at 72.00% examples, 468819 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:51,350 : INFO : EPOCH 28 - PROGRESS: at 77.71% examples, 460364 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:52,378 : INFO : EPOCH 28 - PROGRESS: at 83.57% examples, 454301 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:53,398 : INFO : EPOCH 28 - PROGRESS: at 89.84% examples, 452292 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:54,406 : INFO : EPOCH 28 - PROGRESS: at 95.89% examples, 448374 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:54,855 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:42:54,871 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:42:54,876 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:42:54,877 : INFO : EPOCH - 28 : training on 6557240 raw words (6641536 effective words) took 14.7s, 452377 effective words/s\n",
      "2019-06-26 14:42:55,884 : INFO : EPOCH 29 - PROGRESS: at 6.23% examples, 416401 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:56,913 : INFO : EPOCH 29 - PROGRESS: at 12.52% examples, 401821 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:42:57,941 : INFO : EPOCH 29 - PROGRESS: at 18.71% examples, 397579 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:58,957 : INFO : EPOCH 29 - PROGRESS: at 24.64% examples, 394463 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:42:59,962 : INFO : EPOCH 29 - PROGRESS: at 31.26% examples, 400950 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:00,972 : INFO : EPOCH 29 - PROGRESS: at 37.78% examples, 408156 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:01,978 : INFO : EPOCH 29 - PROGRESS: at 43.92% examples, 409358 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:02,991 : INFO : EPOCH 29 - PROGRESS: at 50.65% examples, 412517 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:03,993 : INFO : EPOCH 29 - PROGRESS: at 56.92% examples, 414200 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:05,006 : INFO : EPOCH 29 - PROGRESS: at 65.31% examples, 425969 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 14:43:06,011 : INFO : EPOCH 29 - PROGRESS: at 71.46% examples, 423481 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:07,028 : INFO : EPOCH 29 - PROGRESS: at 78.91% examples, 428283 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:08,040 : INFO : EPOCH 29 - PROGRESS: at 84.58% examples, 424925 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:09,071 : INFO : EPOCH 29 - PROGRESS: at 90.46% examples, 422758 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:10,081 : INFO : EPOCH 29 - PROGRESS: at 97.17% examples, 424119 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:10,404 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:43:10,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:43:10,406 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:43:10,406 : INFO : EPOCH - 29 : training on 6557240 raw words (6641536 effective words) took 15.5s, 427743 effective words/s\n",
      "2019-06-26 14:43:11,431 : INFO : EPOCH 30 - PROGRESS: at 5.38% examples, 352386 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:12,452 : INFO : EPOCH 30 - PROGRESS: at 12.38% examples, 396480 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:13,461 : INFO : EPOCH 30 - PROGRESS: at 19.15% examples, 409094 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:14,472 : INFO : EPOCH 30 - PROGRESS: at 25.58% examples, 412841 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:15,489 : INFO : EPOCH 30 - PROGRESS: at 32.17% examples, 416541 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:16,520 : INFO : EPOCH 30 - PROGRESS: at 38.44% examples, 416819 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:17,528 : INFO : EPOCH 30 - PROGRESS: at 47.79% examples, 444608 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:18,541 : INFO : EPOCH 30 - PROGRESS: at 55.57% examples, 454459 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:19,546 : INFO : EPOCH 30 - PROGRESS: at 61.65% examples, 447122 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:20,577 : INFO : EPOCH 30 - PROGRESS: at 68.14% examples, 443900 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:21,578 : INFO : EPOCH 30 - PROGRESS: at 74.46% examples, 441608 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:22,590 : INFO : EPOCH 30 - PROGRESS: at 81.28% examples, 442537 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:23,590 : INFO : EPOCH 30 - PROGRESS: at 89.34% examples, 448347 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:24,595 : INFO : EPOCH 30 - PROGRESS: at 96.72% examples, 452464 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:24,955 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:43:24,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:43:24,965 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:43:24,966 : INFO : EPOCH - 30 : training on 6557240 raw words (6641536 effective words) took 14.6s, 456220 effective words/s\n",
      "2019-06-26 14:43:24,966 : INFO : training on a 196717200 raw words (199246080 effective words) took 457.6s, 435429 effective words/s\n",
      "2019-06-26 14:43:24,974 : INFO : collecting all words and their counts\n",
      "2019-06-26 14:43:24,991 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [doc2vec dbow]: 0:07:45.506598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:43:25,483 : INFO : PROGRESS: at example #10000, processed 759945 words (1547362/s), 21470 word types, 2066 tags\n",
      "2019-06-26 14:43:25,972 : INFO : PROGRESS: at example #20000, processed 1500326 words (1515917/s), 29003 word types, 3435 tags\n",
      "2019-06-26 14:43:26,474 : INFO : PROGRESS: at example #30000, processed 2257564 words (1511528/s), 32859 word types, 4469 tags\n",
      "2019-06-26 14:43:26,966 : INFO : PROGRESS: at example #40000, processed 3004745 words (1521948/s), 35021 word types, 5248 tags\n",
      "2019-06-26 14:43:27,463 : INFO : PROGRESS: at example #50000, processed 3783673 words (1570509/s), 36349 word types, 5880 tags\n",
      "2019-06-26 14:43:27,959 : INFO : PROGRESS: at example #60000, processed 4562615 words (1571187/s), 37227 word types, 6352 tags\n",
      "2019-06-26 14:43:28,456 : INFO : PROGRESS: at example #70000, processed 5347161 words (1580365/s), 37658 word types, 6727 tags\n",
      "2019-06-26 14:43:28,955 : INFO : PROGRESS: at example #80000, processed 6128916 words (1570304/s), 37983 word types, 7057 tags\n",
      "2019-06-26 14:43:29,231 : INFO : collected 38071 word types and 7236 unique tags from a corpus of 85466 examples and 6557240 words\n",
      "2019-06-26 14:43:29,231 : INFO : Loading a fresh vocabulary\n",
      "2019-06-26 14:43:29,276 : INFO : effective_min_count=1 retains 38071 unique words (100% of original 38071, drops 0)\n",
      "2019-06-26 14:43:29,276 : INFO : effective_min_count=1 leaves 6557240 word corpus (100% of original 6557240, drops 0)\n",
      "2019-06-26 14:43:29,361 : INFO : deleting the raw counts dictionary of 38071 items\n",
      "2019-06-26 14:43:29,363 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2019-06-26 14:43:29,364 : INFO : downsampling leaves estimated 5593924 word corpus (85.3% of prior 6557240)\n",
      "2019-06-26 14:43:29,462 : INFO : estimated required memory for 38071 words and 300 dimensions: 120536300 bytes\n",
      "2019-06-26 14:43:29,463 : INFO : resetting layer weights\n",
      "2019-06-26 14:43:29,855 : INFO : training model with 3 workers on 38071 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-06-26 14:43:30,901 : INFO : EPOCH 1 - PROGRESS: at 4.22% examples, 237178 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:31,903 : INFO : EPOCH 1 - PROGRESS: at 8.95% examples, 250347 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:32,907 : INFO : EPOCH 1 - PROGRESS: at 14.74% examples, 274434 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:33,927 : INFO : EPOCH 1 - PROGRESS: at 19.31% examples, 268326 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:34,953 : INFO : EPOCH 1 - PROGRESS: at 23.98% examples, 269493 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:35,971 : INFO : EPOCH 1 - PROGRESS: at 28.57% examples, 267840 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:36,994 : INFO : EPOCH 1 - PROGRESS: at 34.57% examples, 279477 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:37,997 : INFO : EPOCH 1 - PROGRESS: at 39.64% examples, 281700 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:39,009 : INFO : EPOCH 1 - PROGRESS: at 45.13% examples, 284959 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:40,016 : INFO : EPOCH 1 - PROGRESS: at 50.67% examples, 287025 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:41,020 : INFO : EPOCH 1 - PROGRESS: at 59.03% examples, 302461 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:42,036 : INFO : EPOCH 1 - PROGRESS: at 66.90% examples, 314485 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:43,048 : INFO : EPOCH 1 - PROGRESS: at 74.86% examples, 323285 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:44,097 : INFO : EPOCH 1 - PROGRESS: at 81.56% examples, 325237 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:45,119 : INFO : EPOCH 1 - PROGRESS: at 86.67% examples, 322947 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:46,147 : INFO : EPOCH 1 - PROGRESS: at 91.23% examples, 318819 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:47,163 : INFO : EPOCH 1 - PROGRESS: at 99.19% examples, 325652 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:47,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:43:47,211 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:43:47,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:43:47,212 : INFO : EPOCH - 1 : training on 6557240 raw words (5679510 effective words) took 17.4s, 327267 effective words/s\n",
      "2019-06-26 14:43:48,216 : INFO : EPOCH 2 - PROGRESS: at 4.72% examples, 264494 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:49,236 : INFO : EPOCH 2 - PROGRESS: at 9.92% examples, 282184 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:50,242 : INFO : EPOCH 2 - PROGRESS: at 14.42% examples, 270106 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:51,254 : INFO : EPOCH 2 - PROGRESS: at 19.26% examples, 270369 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:52,276 : INFO : EPOCH 2 - PROGRESS: at 24.08% examples, 268086 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:53,290 : INFO : EPOCH 2 - PROGRESS: at 28.83% examples, 265651 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:54,303 : INFO : EPOCH 2 - PROGRESS: at 33.93% examples, 268526 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:55,329 : INFO : EPOCH 2 - PROGRESS: at 39.23% examples, 272557 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:43:56,341 : INFO : EPOCH 2 - PROGRESS: at 44.51% examples, 273973 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:57,343 : INFO : EPOCH 2 - PROGRESS: at 49.07% examples, 270544 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:58,352 : INFO : EPOCH 2 - PROGRESS: at 54.60% examples, 275958 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:43:59,357 : INFO : EPOCH 2 - PROGRESS: at 59.31% examples, 275710 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:00,363 : INFO : EPOCH 2 - PROGRESS: at 64.65% examples, 277302 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:01,367 : INFO : EPOCH 2 - PROGRESS: at 69.98% examples, 281121 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:02,390 : INFO : EPOCH 2 - PROGRESS: at 75.05% examples, 281287 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:03,414 : INFO : EPOCH 2 - PROGRESS: at 79.95% examples, 281434 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:04,428 : INFO : EPOCH 2 - PROGRESS: at 85.50% examples, 282143 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:05,444 : INFO : EPOCH 2 - PROGRESS: at 90.13% examples, 281409 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:06,446 : INFO : EPOCH 2 - PROGRESS: at 98.49% examples, 291086 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:06,540 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:44:06,549 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:44:06,551 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:44:06,552 : INFO : EPOCH - 2 : training on 6557240 raw words (5680446 effective words) took 19.3s, 293754 effective words/s\n",
      "2019-06-26 14:44:07,580 : INFO : EPOCH 3 - PROGRESS: at 4.57% examples, 256619 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:08,589 : INFO : EPOCH 3 - PROGRESS: at 9.50% examples, 259131 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:09,631 : INFO : EPOCH 3 - PROGRESS: at 15.32% examples, 277130 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:10,636 : INFO : EPOCH 3 - PROGRESS: at 22.43% examples, 301055 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:11,654 : INFO : EPOCH 3 - PROGRESS: at 28.06% examples, 303096 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:12,717 : INFO : EPOCH 3 - PROGRESS: at 32.80% examples, 295161 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:13,740 : INFO : EPOCH 3 - PROGRESS: at 38.10% examples, 294565 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:14,753 : INFO : EPOCH 3 - PROGRESS: at 42.99% examples, 291423 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:15,759 : INFO : EPOCH 3 - PROGRESS: at 48.35% examples, 293806 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:16,797 : INFO : EPOCH 3 - PROGRESS: at 53.59% examples, 292411 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:17,824 : INFO : EPOCH 3 - PROGRESS: at 58.40% examples, 290093 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:18,870 : INFO : EPOCH 3 - PROGRESS: at 63.37% examples, 288391 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:44:19,879 : INFO : EPOCH 3 - PROGRESS: at 71.12% examples, 299348 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:20,893 : INFO : EPOCH 3 - PROGRESS: at 75.72% examples, 296669 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:21,915 : INFO : EPOCH 3 - PROGRESS: at 81.50% examples, 298529 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:22,926 : INFO : EPOCH 3 - PROGRESS: at 89.05% examples, 306138 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:23,940 : INFO : EPOCH 3 - PROGRESS: at 95.55% examples, 311320 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:24,742 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:44:24,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:44:24,764 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:44:24,765 : INFO : EPOCH - 3 : training on 6557240 raw words (5678667 effective words) took 18.2s, 311824 effective words/s\n",
      "2019-06-26 14:44:25,771 : INFO : EPOCH 4 - PROGRESS: at 6.14% examples, 333012 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:26,780 : INFO : EPOCH 4 - PROGRESS: at 11.38% examples, 314189 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:27,809 : INFO : EPOCH 4 - PROGRESS: at 16.12% examples, 300289 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:28,823 : INFO : EPOCH 4 - PROGRESS: at 21.32% examples, 296821 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:29,823 : INFO : EPOCH 4 - PROGRESS: at 26.11% examples, 293847 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:30,828 : INFO : EPOCH 4 - PROGRESS: at 33.39% examples, 314217 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:31,836 : INFO : EPOCH 4 - PROGRESS: at 39.56% examples, 316561 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:32,870 : INFO : EPOCH 4 - PROGRESS: at 44.49% examples, 309890 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:33,886 : INFO : EPOCH 4 - PROGRESS: at 49.47% examples, 306283 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:34,886 : INFO : EPOCH 4 - PROGRESS: at 54.34% examples, 303888 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:35,886 : INFO : EPOCH 4 - PROGRESS: at 58.80% examples, 301115 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:36,902 : INFO : EPOCH 4 - PROGRESS: at 63.68% examples, 299715 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:37,906 : INFO : EPOCH 4 - PROGRESS: at 71.70% examples, 311215 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:38,924 : INFO : EPOCH 4 - PROGRESS: at 79.97% examples, 321429 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:39,944 : INFO : EPOCH 4 - PROGRESS: at 88.76% examples, 332457 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:40,968 : INFO : EPOCH 4 - PROGRESS: at 96.82% examples, 339304 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:41,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:44:41,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:44:41,276 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:44:41,276 : INFO : EPOCH - 4 : training on 6557240 raw words (5679705 effective words) took 16.5s, 344045 effective words/s\n",
      "2019-06-26 14:44:42,325 : INFO : EPOCH 5 - PROGRESS: at 4.67% examples, 245718 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:43,350 : INFO : EPOCH 5 - PROGRESS: at 9.44% examples, 255760 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:44,389 : INFO : EPOCH 5 - PROGRESS: at 14.03% examples, 258205 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:45,430 : INFO : EPOCH 5 - PROGRESS: at 21.86% examples, 294311 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:46,451 : INFO : EPOCH 5 - PROGRESS: at 28.25% examples, 302581 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:47,455 : INFO : EPOCH 5 - PROGRESS: at 35.26% examples, 319527 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:48,468 : INFO : EPOCH 5 - PROGRESS: at 43.27% examples, 338801 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:49,478 : INFO : EPOCH 5 - PROGRESS: at 49.06% examples, 336663 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:50,490 : INFO : EPOCH 5 - PROGRESS: at 54.13% examples, 331233 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:51,508 : INFO : EPOCH 5 - PROGRESS: at 58.99% examples, 325130 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:52,516 : INFO : EPOCH 5 - PROGRESS: at 63.66% examples, 319319 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:53,548 : INFO : EPOCH 5 - PROGRESS: at 69.48% examples, 319564 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:54,550 : INFO : EPOCH 5 - PROGRESS: at 77.25% examples, 329580 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:55,558 : INFO : EPOCH 5 - PROGRESS: at 85.32% examples, 339061 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:56,560 : INFO : EPOCH 5 - PROGRESS: at 93.05% examples, 347088 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:44:57,313 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:44:57,315 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:44:57,325 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:44:57,326 : INFO : EPOCH - 5 : training on 6557240 raw words (5679704 effective words) took 16.0s, 353937 effective words/s\n",
      "2019-06-26 14:44:58,333 : INFO : EPOCH 6 - PROGRESS: at 6.38% examples, 366393 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:44:59,342 : INFO : EPOCH 6 - PROGRESS: at 12.76% examples, 368846 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:00,355 : INFO : EPOCH 6 - PROGRESS: at 17.95% examples, 341125 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:01,381 : INFO : EPOCH 6 - PROGRESS: at 23.05% examples, 324433 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:02,396 : INFO : EPOCH 6 - PROGRESS: at 29.78% examples, 335210 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:03,421 : INFO : EPOCH 6 - PROGRESS: at 35.69% examples, 335167 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:04,422 : INFO : EPOCH 6 - PROGRESS: at 43.94% examples, 352729 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:05,425 : INFO : EPOCH 6 - PROGRESS: at 51.79% examples, 364911 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:06,449 : INFO : EPOCH 6 - PROGRESS: at 59.94% examples, 372683 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:07,461 : INFO : EPOCH 6 - PROGRESS: at 66.28% examples, 372632 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:08,484 : INFO : EPOCH 6 - PROGRESS: at 72.57% examples, 370513 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:09,489 : INFO : EPOCH 6 - PROGRESS: at 79.21% examples, 370726 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:10,495 : INFO : EPOCH 6 - PROGRESS: at 84.57% examples, 365085 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:11,499 : INFO : EPOCH 6 - PROGRESS: at 89.10% examples, 357297 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:12,516 : INFO : EPOCH 6 - PROGRESS: at 94.12% examples, 351896 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:13,483 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:45:13,485 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:45:13,488 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:45:13,489 : INFO : EPOCH - 6 : training on 6557240 raw words (5678491 effective words) took 16.2s, 351379 effective words/s\n",
      "2019-06-26 14:45:14,511 : INFO : EPOCH 7 - PROGRESS: at 4.90% examples, 276596 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:15,523 : INFO : EPOCH 7 - PROGRESS: at 10.09% examples, 281061 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:16,540 : INFO : EPOCH 7 - PROGRESS: at 15.59% examples, 290723 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:17,554 : INFO : EPOCH 7 - PROGRESS: at 20.91% examples, 289484 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:18,555 : INFO : EPOCH 7 - PROGRESS: at 26.11% examples, 287865 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:19,569 : INFO : EPOCH 7 - PROGRESS: at 31.25% examples, 289037 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:20,585 : INFO : EPOCH 7 - PROGRESS: at 37.16% examples, 294646 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:45:21,593 : INFO : EPOCH 7 - PROGRESS: at 42.30% examples, 293867 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:22,603 : INFO : EPOCH 7 - PROGRESS: at 46.87% examples, 290505 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:23,621 : INFO : EPOCH 7 - PROGRESS: at 53.15% examples, 298214 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:24,656 : INFO : EPOCH 7 - PROGRESS: at 58.94% examples, 301094 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:25,675 : INFO : EPOCH 7 - PROGRESS: at 64.72% examples, 301876 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:26,699 : INFO : EPOCH 7 - PROGRESS: at 69.88% examples, 300486 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:27,709 : INFO : EPOCH 7 - PROGRESS: at 75.57% examples, 301961 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:28,720 : INFO : EPOCH 7 - PROGRESS: at 80.29% examples, 299371 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:29,726 : INFO : EPOCH 7 - PROGRESS: at 86.00% examples, 300204 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:30,752 : INFO : EPOCH 7 - PROGRESS: at 90.68% examples, 298587 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:31,765 : INFO : EPOCH 7 - PROGRESS: at 95.94% examples, 298408 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:32,166 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:45:32,174 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:45:32,182 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:45:32,183 : INFO : EPOCH - 7 : training on 6557240 raw words (5679264 effective words) took 18.7s, 303840 effective words/s\n",
      "2019-06-26 14:45:33,202 : INFO : EPOCH 8 - PROGRESS: at 6.23% examples, 361361 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:34,207 : INFO : EPOCH 8 - PROGRESS: at 14.22% examples, 400118 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:35,213 : INFO : EPOCH 8 - PROGRESS: at 21.41% examples, 402480 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:36,218 : INFO : EPOCH 8 - PROGRESS: at 29.68% examples, 418505 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:37,224 : INFO : EPOCH 8 - PROGRESS: at 37.34% examples, 421449 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:38,247 : INFO : EPOCH 8 - PROGRESS: at 42.37% examples, 396829 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 14:45:39,278 : INFO : EPOCH 8 - PROGRESS: at 47.91% examples, 383707 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:40,291 : INFO : EPOCH 8 - PROGRESS: at 53.68% examples, 376623 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:41,292 : INFO : EPOCH 8 - PROGRESS: at 60.22% examples, 377373 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:42,298 : INFO : EPOCH 8 - PROGRESS: at 67.10% examples, 376793 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:43,299 : INFO : EPOCH 8 - PROGRESS: at 74.91% examples, 384273 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:44,337 : INFO : EPOCH 8 - PROGRESS: at 81.05% examples, 379623 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:45,346 : INFO : EPOCH 8 - PROGRESS: at 86.28% examples, 372555 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:46,349 : INFO : EPOCH 8 - PROGRESS: at 91.04% examples, 364881 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:47,375 : INFO : EPOCH 8 - PROGRESS: at 95.85% examples, 358781 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:47,945 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:45:47,962 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:45:47,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:45:47,966 : INFO : EPOCH - 8 : training on 6557240 raw words (5678991 effective words) took 15.8s, 359841 effective words/s\n",
      "2019-06-26 14:45:48,987 : INFO : EPOCH 9 - PROGRESS: at 4.50% examples, 260282 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:49,997 : INFO : EPOCH 9 - PROGRESS: at 10.76% examples, 307052 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:51,010 : INFO : EPOCH 9 - PROGRESS: at 17.64% examples, 333728 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:52,011 : INFO : EPOCH 9 - PROGRESS: at 22.20% examples, 314320 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:53,023 : INFO : EPOCH 9 - PROGRESS: at 27.25% examples, 307298 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:54,052 : INFO : EPOCH 9 - PROGRESS: at 32.18% examples, 301559 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:55,076 : INFO : EPOCH 9 - PROGRESS: at 36.87% examples, 297579 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:45:56,104 : INFO : EPOCH 9 - PROGRESS: at 41.68% examples, 293484 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:57,140 : INFO : EPOCH 9 - PROGRESS: at 46.28% examples, 289083 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:58,177 : INFO : EPOCH 9 - PROGRESS: at 51.72% examples, 289007 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:45:59,177 : INFO : EPOCH 9 - PROGRESS: at 56.64% examples, 289010 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:00,181 : INFO : EPOCH 9 - PROGRESS: at 62.26% examples, 291180 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:01,212 : INFO : EPOCH 9 - PROGRESS: at 69.94% examples, 301911 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:02,219 : INFO : EPOCH 9 - PROGRESS: at 77.80% examples, 311782 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:03,244 : INFO : EPOCH 9 - PROGRESS: at 85.94% examples, 320484 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:04,251 : INFO : EPOCH 9 - PROGRESS: at 93.72% examples, 327452 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:05,257 : INFO : EPOCH 9 - PROGRESS: at 98.44% examples, 323732 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:05,359 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:46:05,364 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:46:05,373 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:46:05,374 : INFO : EPOCH - 9 : training on 6557240 raw words (5678941 effective words) took 17.4s, 326271 effective words/s\n",
      "2019-06-26 14:46:06,386 : INFO : EPOCH 10 - PROGRESS: at 4.45% examples, 253069 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:07,409 : INFO : EPOCH 10 - PROGRESS: at 9.45% examples, 264169 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:08,439 : INFO : EPOCH 10 - PROGRESS: at 16.69% examples, 308816 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:09,448 : INFO : EPOCH 10 - PROGRESS: at 24.51% examples, 343273 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:10,461 : INFO : EPOCH 10 - PROGRESS: at 29.87% examples, 332114 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:11,501 : INFO : EPOCH 10 - PROGRESS: at 34.87% examples, 321824 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:12,521 : INFO : EPOCH 10 - PROGRESS: at 39.64% examples, 314283 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:13,533 : INFO : EPOCH 10 - PROGRESS: at 44.59% examples, 310901 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:14,536 : INFO : EPOCH 10 - PROGRESS: at 52.32% examples, 324333 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:15,541 : INFO : EPOCH 10 - PROGRESS: at 58.90% examples, 328424 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:16,542 : INFO : EPOCH 10 - PROGRESS: at 65.04% examples, 330986 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:17,545 : INFO : EPOCH 10 - PROGRESS: at 70.49% examples, 328837 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:18,547 : INFO : EPOCH 10 - PROGRESS: at 75.28% examples, 325279 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:19,555 : INFO : EPOCH 10 - PROGRESS: at 80.16% examples, 320933 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:20,580 : INFO : EPOCH 10 - PROGRESS: at 85.25% examples, 317822 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:21,595 : INFO : EPOCH 10 - PROGRESS: at 92.32% examples, 322759 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:22,607 : INFO : EPOCH 10 - PROGRESS: at 97.25% examples, 320137 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:23,010 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:46:23,022 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:46:23,030 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:46:23,031 : INFO : EPOCH - 10 : training on 6557240 raw words (5679599 effective words) took 17.7s, 321715 effective words/s\n",
      "2019-06-26 14:46:24,075 : INFO : EPOCH 11 - PROGRESS: at 5.15% examples, 278765 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:25,076 : INFO : EPOCH 11 - PROGRESS: at 9.75% examples, 271326 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:26,089 : INFO : EPOCH 11 - PROGRESS: at 14.20% examples, 265632 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:27,103 : INFO : EPOCH 11 - PROGRESS: at 19.47% examples, 275373 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:28,114 : INFO : EPOCH 11 - PROGRESS: at 24.56% examples, 277849 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:29,119 : INFO : EPOCH 11 - PROGRESS: at 29.04% examples, 275375 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:30,132 : INFO : EPOCH 11 - PROGRESS: at 36.25% examples, 292760 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:31,138 : INFO : EPOCH 11 - PROGRESS: at 42.94% examples, 302808 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:32,168 : INFO : EPOCH 11 - PROGRESS: at 48.72% examples, 303274 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:33,168 : INFO : EPOCH 11 - PROGRESS: at 53.12% examples, 299577 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:34,193 : INFO : EPOCH 11 - PROGRESS: at 57.86% examples, 295712 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:35,226 : INFO : EPOCH 11 - PROGRESS: at 62.66% examples, 292388 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:36,246 : INFO : EPOCH 11 - PROGRESS: at 68.95% examples, 296966 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:37,255 : INFO : EPOCH 11 - PROGRESS: at 77.01% examples, 308321 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:38,269 : INFO : EPOCH 11 - PROGRESS: at 85.59% examples, 319601 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:39,279 : INFO : EPOCH 11 - PROGRESS: at 93.27% examples, 326974 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:40,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:46:40,041 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:46:40,044 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:46:40,045 : INFO : EPOCH - 11 : training on 6557240 raw words (5678697 effective words) took 17.0s, 333824 effective words/s\n",
      "2019-06-26 14:46:41,072 : INFO : EPOCH 12 - PROGRESS: at 5.70% examples, 315815 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:42,082 : INFO : EPOCH 12 - PROGRESS: at 11.64% examples, 331152 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:43,085 : INFO : EPOCH 12 - PROGRESS: at 17.33% examples, 326156 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:44,097 : INFO : EPOCH 12 - PROGRESS: at 22.05% examples, 316125 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:45,112 : INFO : EPOCH 12 - PROGRESS: at 27.68% examples, 315320 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:46,121 : INFO : EPOCH 12 - PROGRESS: at 33.94% examples, 321738 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:47,134 : INFO : EPOCH 12 - PROGRESS: at 41.93% examples, 339757 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:48,142 : INFO : EPOCH 12 - PROGRESS: at 46.57% examples, 329039 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:49,170 : INFO : EPOCH 12 - PROGRESS: at 52.73% examples, 329407 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:50,187 : INFO : EPOCH 12 - PROGRESS: at 57.32% examples, 322390 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:51,191 : INFO : EPOCH 12 - PROGRESS: at 61.98% examples, 317817 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:52,206 : INFO : EPOCH 12 - PROGRESS: at 66.76% examples, 313708 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:53,233 : INFO : EPOCH 12 - PROGRESS: at 71.54% examples, 309337 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:54,246 : INFO : EPOCH 12 - PROGRESS: at 76.40% examples, 306576 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:46:55,248 : INFO : EPOCH 12 - PROGRESS: at 82.55% examples, 308798 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:56,268 : INFO : EPOCH 12 - PROGRESS: at 88.88% examples, 311387 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:57,297 : INFO : EPOCH 12 - PROGRESS: at 95.97% examples, 315597 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:57,946 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:46:57,954 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:46:57,956 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:46:57,957 : INFO : EPOCH - 12 : training on 6557240 raw words (5679825 effective words) took 17.9s, 317124 effective words/s\n",
      "2019-06-26 14:46:58,971 : INFO : EPOCH 13 - PROGRESS: at 5.62% examples, 319979 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:46:59,973 : INFO : EPOCH 13 - PROGRESS: at 12.59% examples, 364855 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:00,973 : INFO : EPOCH 13 - PROGRESS: at 20.84% examples, 399286 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:01,995 : INFO : EPOCH 13 - PROGRESS: at 25.78% examples, 370007 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:03,004 : INFO : EPOCH 13 - PROGRESS: at 31.36% examples, 356914 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:04,011 : INFO : EPOCH 13 - PROGRESS: at 39.00% examples, 371018 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:05,014 : INFO : EPOCH 13 - PROGRESS: at 47.48% examples, 384455 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:06,034 : INFO : EPOCH 13 - PROGRESS: at 55.52% examples, 394195 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:07,048 : INFO : EPOCH 13 - PROGRESS: at 62.99% examples, 396057 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:08,058 : INFO : EPOCH 13 - PROGRESS: at 67.77% examples, 381805 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:09,069 : INFO : EPOCH 13 - PROGRESS: at 72.39% examples, 370780 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:10,073 : INFO : EPOCH 13 - PROGRESS: at 77.05% examples, 362512 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:11,097 : INFO : EPOCH 13 - PROGRESS: at 82.70% examples, 358267 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:12,131 : INFO : EPOCH 13 - PROGRESS: at 87.78% examples, 351371 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:13,134 : INFO : EPOCH 13 - PROGRESS: at 92.94% examples, 347791 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:14,138 : INFO : EPOCH 13 - PROGRESS: at 98.91% examples, 347334 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:14,192 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:47:14,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:47:14,216 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:47:14,217 : INFO : EPOCH - 13 : training on 6557240 raw words (5679861 effective words) took 16.3s, 349368 effective words/s\n",
      "2019-06-26 14:47:15,233 : INFO : EPOCH 14 - PROGRESS: at 4.36% examples, 253580 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:16,238 : INFO : EPOCH 14 - PROGRESS: at 9.35% examples, 262490 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:17,253 : INFO : EPOCH 14 - PROGRESS: at 13.79% examples, 261599 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:18,275 : INFO : EPOCH 14 - PROGRESS: at 18.54% examples, 259106 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:19,287 : INFO : EPOCH 14 - PROGRESS: at 23.56% examples, 262852 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:20,289 : INFO : EPOCH 14 - PROGRESS: at 28.42% examples, 264427 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:21,296 : INFO : EPOCH 14 - PROGRESS: at 33.19% examples, 265366 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:22,309 : INFO : EPOCH 14 - PROGRESS: at 38.85% examples, 273122 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:23,321 : INFO : EPOCH 14 - PROGRESS: at 43.27% examples, 271669 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:24,328 : INFO : EPOCH 14 - PROGRESS: at 50.06% examples, 282559 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:25,329 : INFO : EPOCH 14 - PROGRESS: at 55.44% examples, 285599 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:47:26,334 : INFO : EPOCH 14 - PROGRESS: at 60.72% examples, 285916 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:27,339 : INFO : EPOCH 14 - PROGRESS: at 65.65% examples, 284170 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:28,358 : INFO : EPOCH 14 - PROGRESS: at 72.48% examples, 291348 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:29,387 : INFO : EPOCH 14 - PROGRESS: at 77.47% examples, 290178 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:30,393 : INFO : EPOCH 14 - PROGRESS: at 82.29% examples, 288827 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:31,403 : INFO : EPOCH 14 - PROGRESS: at 90.41% examples, 298656 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:32,414 : INFO : EPOCH 14 - PROGRESS: at 99.03% examples, 309308 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:32,469 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:47:32,472 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:47:32,482 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:47:32,483 : INFO : EPOCH - 14 : training on 6557240 raw words (5679702 effective words) took 18.3s, 311019 effective words/s\n",
      "2019-06-26 14:47:33,490 : INFO : EPOCH 15 - PROGRESS: at 4.65% examples, 263207 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:34,509 : INFO : EPOCH 15 - PROGRESS: at 9.57% examples, 269728 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:35,519 : INFO : EPOCH 15 - PROGRESS: at 14.51% examples, 269944 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:36,523 : INFO : EPOCH 15 - PROGRESS: at 19.62% examples, 274991 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:37,552 : INFO : EPOCH 15 - PROGRESS: at 24.71% examples, 275012 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:38,556 : INFO : EPOCH 15 - PROGRESS: at 30.68% examples, 285801 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:39,603 : INFO : EPOCH 15 - PROGRESS: at 35.80% examples, 283372 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:40,632 : INFO : EPOCH 15 - PROGRESS: at 40.60% examples, 282235 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:41,650 : INFO : EPOCH 15 - PROGRESS: at 45.38% examples, 279756 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:42,678 : INFO : EPOCH 15 - PROGRESS: at 50.22% examples, 279116 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:43,694 : INFO : EPOCH 15 - PROGRESS: at 55.09% examples, 278234 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:44,734 : INFO : EPOCH 15 - PROGRESS: at 59.78% examples, 277662 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:45,755 : INFO : EPOCH 15 - PROGRESS: at 65.47% examples, 279372 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:46,771 : INFO : EPOCH 15 - PROGRESS: at 70.02% examples, 277992 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:47,783 : INFO : EPOCH 15 - PROGRESS: at 74.61% examples, 276922 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:48,799 : INFO : EPOCH 15 - PROGRESS: at 79.78% examples, 277976 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:49,801 : INFO : EPOCH 15 - PROGRESS: at 85.02% examples, 278639 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:50,831 : INFO : EPOCH 15 - PROGRESS: at 89.45% examples, 277871 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:51,852 : INFO : EPOCH 15 - PROGRESS: at 94.32% examples, 277321 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:52,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:47:52,800 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:47:52,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:47:52,810 : INFO : EPOCH - 15 : training on 6557240 raw words (5680094 effective words) took 20.3s, 279460 effective words/s\n",
      "2019-06-26 14:47:53,818 : INFO : EPOCH 16 - PROGRESS: at 4.48% examples, 262995 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:54,823 : INFO : EPOCH 16 - PROGRESS: at 9.35% examples, 263093 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:55,853 : INFO : EPOCH 16 - PROGRESS: at 14.59% examples, 269624 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:56,853 : INFO : EPOCH 16 - PROGRESS: at 19.37% examples, 270115 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:47:57,854 : INFO : EPOCH 16 - PROGRESS: at 25.51% examples, 282592 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:58,860 : INFO : EPOCH 16 - PROGRESS: at 33.93% examples, 314394 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:47:59,864 : INFO : EPOCH 16 - PROGRESS: at 40.03% examples, 318075 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:00,894 : INFO : EPOCH 16 - PROGRESS: at 44.63% examples, 311398 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:01,922 : INFO : EPOCH 16 - PROGRESS: at 50.05% examples, 310026 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:02,968 : INFO : EPOCH 16 - PROGRESS: at 54.74% examples, 304264 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:03,975 : INFO : EPOCH 16 - PROGRESS: at 60.72% examples, 308265 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:04,994 : INFO : EPOCH 16 - PROGRESS: at 65.66% examples, 305555 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:06,025 : INFO : EPOCH 16 - PROGRESS: at 71.17% examples, 305590 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:07,046 : INFO : EPOCH 16 - PROGRESS: at 76.68% examples, 305144 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:08,072 : INFO : EPOCH 16 - PROGRESS: at 81.97% examples, 304669 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:09,102 : INFO : EPOCH 16 - PROGRESS: at 87.04% examples, 303701 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:10,115 : INFO : EPOCH 16 - PROGRESS: at 92.43% examples, 303698 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:11,127 : INFO : EPOCH 16 - PROGRESS: at 97.16% examples, 301873 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:11,513 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:48:11,516 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:48:11,518 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:48:11,519 : INFO : EPOCH - 16 : training on 6557240 raw words (5678591 effective words) took 18.7s, 303556 effective words/s\n",
      "2019-06-26 14:48:12,533 : INFO : EPOCH 17 - PROGRESS: at 4.42% examples, 244934 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:13,540 : INFO : EPOCH 17 - PROGRESS: at 9.16% examples, 258461 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:14,565 : INFO : EPOCH 17 - PROGRESS: at 15.97% examples, 303414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:15,567 : INFO : EPOCH 17 - PROGRESS: at 21.21% examples, 303975 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:16,580 : INFO : EPOCH 17 - PROGRESS: at 29.23% examples, 335605 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:17,582 : INFO : EPOCH 17 - PROGRESS: at 37.36% examples, 353135 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:18,586 : INFO : EPOCH 17 - PROGRESS: at 45.58% examples, 368193 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:19,597 : INFO : EPOCH 17 - PROGRESS: at 54.13% examples, 380354 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:20,612 : INFO : EPOCH 17 - PROGRESS: at 62.49% examples, 389356 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:21,637 : INFO : EPOCH 17 - PROGRESS: at 68.54% examples, 383643 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:22,662 : INFO : EPOCH 17 - PROGRESS: at 73.48% examples, 374406 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:23,689 : INFO : EPOCH 17 - PROGRESS: at 78.78% examples, 366766 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:24,703 : INFO : EPOCH 17 - PROGRESS: at 83.44% examples, 359234 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:25,737 : INFO : EPOCH 17 - PROGRESS: at 88.29% examples, 352119 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:26,769 : INFO : EPOCH 17 - PROGRESS: at 94.13% examples, 350599 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:27,788 : INFO : EPOCH 17 - PROGRESS: at 99.57% examples, 347934 words/s, in_qsize 2, out_qsize 2\n",
      "2019-06-26 14:48:27,789 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:48:27,799 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:48:27,801 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:48:27,801 : INFO : EPOCH - 17 : training on 6557240 raw words (5679747 effective words) took 16.3s, 348870 effective words/s\n",
      "2019-06-26 14:48:28,807 : INFO : EPOCH 18 - PROGRESS: at 4.43% examples, 255663 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:29,810 : INFO : EPOCH 18 - PROGRESS: at 9.54% examples, 272766 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:30,812 : INFO : EPOCH 18 - PROGRESS: at 15.26% examples, 292342 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:31,825 : INFO : EPOCH 18 - PROGRESS: at 20.13% examples, 289140 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:32,880 : INFO : EPOCH 18 - PROGRESS: at 25.14% examples, 286441 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:33,900 : INFO : EPOCH 18 - PROGRESS: at 31.75% examples, 297452 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:34,914 : INFO : EPOCH 18 - PROGRESS: at 37.57% examples, 301815 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:35,917 : INFO : EPOCH 18 - PROGRESS: at 42.94% examples, 302424 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:36,924 : INFO : EPOCH 18 - PROGRESS: at 47.52% examples, 298063 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:37,929 : INFO : EPOCH 18 - PROGRESS: at 52.07% examples, 293703 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:38,932 : INFO : EPOCH 18 - PROGRESS: at 58.48% examples, 297932 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:39,947 : INFO : EPOCH 18 - PROGRESS: at 63.18% examples, 296173 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:40,957 : INFO : EPOCH 18 - PROGRESS: at 68.58% examples, 296706 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:41,976 : INFO : EPOCH 18 - PROGRESS: at 73.04% examples, 293439 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:42,983 : INFO : EPOCH 18 - PROGRESS: at 81.05% examples, 303180 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:43,987 : INFO : EPOCH 18 - PROGRESS: at 89.35% examples, 313354 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:45,018 : INFO : EPOCH 18 - PROGRESS: at 97.30% examples, 320838 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:45,339 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:48:45,342 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:48:45,343 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:48:45,343 : INFO : EPOCH - 18 : training on 6557240 raw words (5680303 effective words) took 17.5s, 323878 effective words/s\n",
      "2019-06-26 14:48:46,350 : INFO : EPOCH 19 - PROGRESS: at 6.94% examples, 399017 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:47,370 : INFO : EPOCH 19 - PROGRESS: at 14.19% examples, 405433 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:48,398 : INFO : EPOCH 19 - PROGRESS: at 20.65% examples, 389370 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:49,444 : INFO : EPOCH 19 - PROGRESS: at 25.69% examples, 361067 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:50,447 : INFO : EPOCH 19 - PROGRESS: at 30.57% examples, 343826 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:51,480 : INFO : EPOCH 19 - PROGRESS: at 35.39% examples, 330446 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:52,483 : INFO : EPOCH 19 - PROGRESS: at 40.73% examples, 324722 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:53,497 : INFO : EPOCH 19 - PROGRESS: at 48.41% examples, 336705 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:54,511 : INFO : EPOCH 19 - PROGRESS: at 54.40% examples, 336660 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:55,511 : INFO : EPOCH 19 - PROGRESS: at 59.69% examples, 333787 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:56,533 : INFO : EPOCH 19 - PROGRESS: at 64.40% examples, 327713 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:57,535 : INFO : EPOCH 19 - PROGRESS: at 69.24% examples, 323203 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:48:58,568 : INFO : EPOCH 19 - PROGRESS: at 74.27% examples, 319860 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:48:59,586 : INFO : EPOCH 19 - PROGRESS: at 78.97% examples, 315570 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:00,595 : INFO : EPOCH 19 - PROGRESS: at 85.96% examples, 320481 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:01,611 : INFO : EPOCH 19 - PROGRESS: at 91.85% examples, 321341 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:02,612 : INFO : EPOCH 19 - PROGRESS: at 97.45% examples, 321055 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:02,867 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:49:02,884 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:49:02,886 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:49:02,887 : INFO : EPOCH - 19 : training on 6557240 raw words (5678601 effective words) took 17.5s, 323712 effective words/s\n",
      "2019-06-26 14:49:03,894 : INFO : EPOCH 20 - PROGRESS: at 4.95% examples, 279881 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:04,898 : INFO : EPOCH 20 - PROGRESS: at 12.06% examples, 335661 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:05,917 : INFO : EPOCH 20 - PROGRESS: at 16.93% examples, 312811 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:06,917 : INFO : EPOCH 20 - PROGRESS: at 23.08% examples, 319969 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:07,928 : INFO : EPOCH 20 - PROGRESS: at 30.24% examples, 338994 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:08,933 : INFO : EPOCH 20 - PROGRESS: at 34.93% examples, 326631 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:09,947 : INFO : EPOCH 20 - PROGRESS: at 39.41% examples, 316036 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:10,986 : INFO : EPOCH 20 - PROGRESS: at 44.69% examples, 312494 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:12,022 : INFO : EPOCH 20 - PROGRESS: at 49.84% examples, 309606 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:13,035 : INFO : EPOCH 20 - PROGRESS: at 54.82% examples, 306438 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:14,042 : INFO : EPOCH 20 - PROGRESS: at 59.64% examples, 303239 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:15,055 : INFO : EPOCH 20 - PROGRESS: at 64.34% examples, 301048 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:16,076 : INFO : EPOCH 20 - PROGRESS: at 69.57% examples, 299757 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:17,077 : INFO : EPOCH 20 - PROGRESS: at 74.90% examples, 300777 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:18,116 : INFO : EPOCH 20 - PROGRESS: at 80.24% examples, 300946 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:19,131 : INFO : EPOCH 20 - PROGRESS: at 85.37% examples, 300041 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:20,137 : INFO : EPOCH 20 - PROGRESS: at 90.25% examples, 298390 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:21,139 : INFO : EPOCH 20 - PROGRESS: at 97.34% examples, 303483 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:21,372 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:49:21,374 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:49:21,375 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:49:21,376 : INFO : EPOCH - 20 : training on 6557240 raw words (5678502 effective words) took 18.5s, 307173 effective words/s\n",
      "2019-06-26 14:49:22,385 : INFO : EPOCH 21 - PROGRESS: at 5.63% examples, 323797 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:23,399 : INFO : EPOCH 21 - PROGRESS: at 10.96% examples, 313633 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:24,401 : INFO : EPOCH 21 - PROGRESS: at 16.12% examples, 303249 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:25,421 : INFO : EPOCH 21 - PROGRESS: at 22.19% examples, 315305 words/s, in_qsize 4, out_qsize 1\n",
      "2019-06-26 14:49:26,428 : INFO : EPOCH 21 - PROGRESS: at 28.75% examples, 326937 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:27,468 : INFO : EPOCH 21 - PROGRESS: at 33.15% examples, 312995 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:28,522 : INFO : EPOCH 21 - PROGRESS: at 38.09% examples, 306361 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:29,553 : INFO : EPOCH 21 - PROGRESS: at 42.72% examples, 301179 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:49:30,563 : INFO : EPOCH 21 - PROGRESS: at 48.28% examples, 302571 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:31,578 : INFO : EPOCH 21 - PROGRESS: at 53.80% examples, 302408 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:32,582 : INFO : EPOCH 21 - PROGRESS: at 59.38% examples, 304310 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:33,626 : INFO : EPOCH 21 - PROGRESS: at 65.47% examples, 306273 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:34,655 : INFO : EPOCH 21 - PROGRESS: at 71.26% examples, 306906 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:35,663 : INFO : EPOCH 21 - PROGRESS: at 76.34% examples, 306151 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:36,671 : INFO : EPOCH 21 - PROGRESS: at 81.90% examples, 304426 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:37,672 : INFO : EPOCH 21 - PROGRESS: at 86.51% examples, 301426 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:38,724 : INFO : EPOCH 21 - PROGRESS: at 91.73% examples, 299899 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:39,748 : INFO : EPOCH 21 - PROGRESS: at 96.84% examples, 299402 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:40,059 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:49:40,062 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:49:40,066 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:49:40,066 : INFO : EPOCH - 21 : training on 6557240 raw words (5679626 effective words) took 18.7s, 303925 effective words/s\n",
      "2019-06-26 14:49:41,073 : INFO : EPOCH 22 - PROGRESS: at 4.07% examples, 237176 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:42,088 : INFO : EPOCH 22 - PROGRESS: at 8.61% examples, 241084 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:43,114 : INFO : EPOCH 22 - PROGRESS: at 14.47% examples, 266500 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:44,142 : INFO : EPOCH 22 - PROGRESS: at 21.81% examples, 295705 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:45,150 : INFO : EPOCH 22 - PROGRESS: at 28.62% examples, 314383 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:46,171 : INFO : EPOCH 22 - PROGRESS: at 33.64% examples, 310766 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:47,178 : INFO : EPOCH 22 - PROGRESS: at 38.77% examples, 309912 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:48,213 : INFO : EPOCH 22 - PROGRESS: at 44.42% examples, 309110 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:49,217 : INFO : EPOCH 22 - PROGRESS: at 49.16% examples, 305005 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:50,248 : INFO : EPOCH 22 - PROGRESS: at 54.05% examples, 302429 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:51,260 : INFO : EPOCH 22 - PROGRESS: at 60.71% examples, 308713 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:52,283 : INFO : EPOCH 22 - PROGRESS: at 65.85% examples, 307280 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:53,317 : INFO : EPOCH 22 - PROGRESS: at 71.32% examples, 306510 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:54,343 : INFO : EPOCH 22 - PROGRESS: at 75.85% examples, 303101 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:55,378 : INFO : EPOCH 22 - PROGRESS: at 80.59% examples, 300493 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:56,400 : INFO : EPOCH 22 - PROGRESS: at 85.05% examples, 296792 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:49:57,407 : INFO : EPOCH 22 - PROGRESS: at 90.20% examples, 295822 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:58,412 : INFO : EPOCH 22 - PROGRESS: at 98.00% examples, 303764 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:49:58,617 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:49:58,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:49:58,622 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:49:58,622 : INFO : EPOCH - 22 : training on 6557240 raw words (5680229 effective words) took 18.6s, 306156 effective words/s\n",
      "2019-06-26 14:49:59,633 : INFO : EPOCH 23 - PROGRESS: at 5.62% examples, 329360 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:00,654 : INFO : EPOCH 23 - PROGRESS: at 10.44% examples, 298433 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:01,671 : INFO : EPOCH 23 - PROGRESS: at 15.11% examples, 288474 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:02,695 : INFO : EPOCH 23 - PROGRESS: at 19.93% examples, 280652 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:03,709 : INFO : EPOCH 23 - PROGRESS: at 25.76% examples, 288763 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:04,712 : INFO : EPOCH 23 - PROGRESS: at 30.79% examples, 287492 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:05,743 : INFO : EPOCH 23 - PROGRESS: at 35.85% examples, 286368 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:06,769 : INFO : EPOCH 23 - PROGRESS: at 44.38% examples, 311065 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:07,769 : INFO : EPOCH 23 - PROGRESS: at 52.61% examples, 327279 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:08,822 : INFO : EPOCH 23 - PROGRESS: at 60.56% examples, 337989 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:09,823 : INFO : EPOCH 23 - PROGRESS: at 65.38% examples, 332099 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:10,859 : INFO : EPOCH 23 - PROGRESS: at 70.43% examples, 327702 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:11,882 : INFO : EPOCH 23 - PROGRESS: at 75.80% examples, 326210 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:12,894 : INFO : EPOCH 23 - PROGRESS: at 80.95% examples, 323950 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:13,909 : INFO : EPOCH 23 - PROGRESS: at 89.04% examples, 331982 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:14,943 : INFO : EPOCH 23 - PROGRESS: at 94.36% examples, 328662 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:15,527 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:50:15,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:50:15,531 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:50:15,531 : INFO : EPOCH - 23 : training on 6557240 raw words (5678340 effective words) took 16.9s, 335874 effective words/s\n",
      "2019-06-26 14:50:16,539 : INFO : EPOCH 24 - PROGRESS: at 5.59% examples, 322513 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:17,549 : INFO : EPOCH 24 - PROGRESS: at 11.06% examples, 322219 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:18,571 : INFO : EPOCH 24 - PROGRESS: at 18.84% examples, 357446 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:19,573 : INFO : EPOCH 24 - PROGRESS: at 27.03% examples, 380530 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:20,580 : INFO : EPOCH 24 - PROGRESS: at 34.95% examples, 392304 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:21,596 : INFO : EPOCH 24 - PROGRESS: at 43.16% examples, 405588 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:22,600 : INFO : EPOCH 24 - PROGRESS: at 49.56% examples, 398684 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:23,615 : INFO : EPOCH 24 - PROGRESS: at 54.29% examples, 382280 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:24,620 : INFO : EPOCH 24 - PROGRESS: at 60.17% examples, 375878 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:25,639 : INFO : EPOCH 24 - PROGRESS: at 65.14% examples, 365801 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:26,664 : INFO : EPOCH 24 - PROGRESS: at 70.91% examples, 361218 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:27,685 : INFO : EPOCH 24 - PROGRESS: at 75.45% examples, 352713 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:28,686 : INFO : EPOCH 24 - PROGRESS: at 80.54% examples, 348533 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:29,689 : INFO : EPOCH 24 - PROGRESS: at 89.04% examples, 357610 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:30,694 : INFO : EPOCH 24 - PROGRESS: at 97.04% examples, 363264 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:30,979 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:50:30,994 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:50:30,995 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:50:30,996 : INFO : EPOCH - 24 : training on 6557240 raw words (5678522 effective words) took 15.5s, 367224 effective words/s\n",
      "2019-06-26 14:50:32,003 : INFO : EPOCH 25 - PROGRESS: at 7.18% examples, 398470 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:33,027 : INFO : EPOCH 25 - PROGRESS: at 15.36% examples, 419900 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:34,029 : INFO : EPOCH 25 - PROGRESS: at 23.58% examples, 438766 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:35,034 : INFO : EPOCH 25 - PROGRESS: at 31.32% examples, 439552 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:36,052 : INFO : EPOCH 25 - PROGRESS: at 39.44% examples, 440486 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:37,056 : INFO : EPOCH 25 - PROGRESS: at 47.65% examples, 443571 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:38,076 : INFO : EPOCH 25 - PROGRESS: at 55.99% examples, 448317 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:39,089 : INFO : EPOCH 25 - PROGRESS: at 64.06% examples, 449249 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:40,104 : INFO : EPOCH 25 - PROGRESS: at 72.22% examples, 448888 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 14:50:41,107 : INFO : EPOCH 25 - PROGRESS: at 80.44% examples, 451695 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:42,112 : INFO : EPOCH 25 - PROGRESS: at 85.28% examples, 436188 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:43,118 : INFO : EPOCH 25 - PROGRESS: at 91.07% examples, 427463 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:44,124 : INFO : EPOCH 25 - PROGRESS: at 96.79% examples, 418839 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:44,607 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:50:44,613 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:50:44,629 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:50:44,630 : INFO : EPOCH - 25 : training on 6557240 raw words (5679917 effective words) took 13.6s, 416674 effective words/s\n",
      "2019-06-26 14:50:45,668 : INFO : EPOCH 26 - PROGRESS: at 6.07% examples, 331099 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:46,691 : INFO : EPOCH 26 - PROGRESS: at 11.16% examples, 308118 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:47,735 : INFO : EPOCH 26 - PROGRESS: at 15.99% examples, 294909 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:48,740 : INFO : EPOCH 26 - PROGRESS: at 21.42% examples, 297475 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:49,789 : INFO : EPOCH 26 - PROGRESS: at 28.38% examples, 313137 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:50,829 : INFO : EPOCH 26 - PROGRESS: at 33.81% examples, 305912 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:51,840 : INFO : EPOCH 26 - PROGRESS: at 38.84% examples, 300994 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:52,842 : INFO : EPOCH 26 - PROGRESS: at 44.66% examples, 303819 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:53,850 : INFO : EPOCH 26 - PROGRESS: at 49.23% examples, 299372 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:54,867 : INFO : EPOCH 26 - PROGRESS: at 55.36% examples, 303842 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:55,873 : INFO : EPOCH 26 - PROGRESS: at 60.38% examples, 302496 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:56,897 : INFO : EPOCH 26 - PROGRESS: at 65.23% examples, 300129 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:57,901 : INFO : EPOCH 26 - PROGRESS: at 70.49% examples, 299837 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:50:58,921 : INFO : EPOCH 26 - PROGRESS: at 75.54% examples, 298780 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:50:59,953 : INFO : EPOCH 26 - PROGRESS: at 80.12% examples, 296404 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:00,965 : INFO : EPOCH 26 - PROGRESS: at 85.01% examples, 295265 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:01,970 : INFO : EPOCH 26 - PROGRESS: at 90.11% examples, 294407 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:02,992 : INFO : EPOCH 26 - PROGRESS: at 95.09% examples, 293476 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:03,874 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:51:03,881 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:51:03,883 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:51:03,884 : INFO : EPOCH - 26 : training on 6557240 raw words (5679960 effective words) took 19.3s, 295037 effective words/s\n",
      "2019-06-26 14:51:04,903 : INFO : EPOCH 27 - PROGRESS: at 4.09% examples, 243238 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:05,920 : INFO : EPOCH 27 - PROGRESS: at 9.26% examples, 264541 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:06,955 : INFO : EPOCH 27 - PROGRESS: at 14.27% examples, 264364 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:07,995 : INFO : EPOCH 27 - PROGRESS: at 21.90% examples, 301703 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:08,996 : INFO : EPOCH 27 - PROGRESS: at 30.32% examples, 334616 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:10,005 : INFO : EPOCH 27 - PROGRESS: at 38.52% examples, 357524 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:11,032 : INFO : EPOCH 27 - PROGRESS: at 45.63% examples, 362323 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:12,033 : INFO : EPOCH 27 - PROGRESS: at 51.62% examples, 359656 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:13,035 : INFO : EPOCH 27 - PROGRESS: at 56.23% examples, 350083 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:14,050 : INFO : EPOCH 27 - PROGRESS: at 62.04% examples, 347038 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:15,063 : INFO : EPOCH 27 - PROGRESS: at 68.83% examples, 349156 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:16,066 : INFO : EPOCH 27 - PROGRESS: at 74.74% examples, 347692 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:17,073 : INFO : EPOCH 27 - PROGRESS: at 80.01% examples, 344435 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:18,095 : INFO : EPOCH 27 - PROGRESS: at 85.67% examples, 342515 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:19,104 : INFO : EPOCH 27 - PROGRESS: at 93.18% examples, 348340 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:20,140 : INFO : EPOCH 27 - PROGRESS: at 98.26% examples, 342982 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:20,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:51:20,322 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:51:20,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:51:20,336 : INFO : EPOCH - 27 : training on 6557240 raw words (5678596 effective words) took 16.4s, 345222 effective words/s\n",
      "2019-06-26 14:51:21,373 : INFO : EPOCH 28 - PROGRESS: at 4.71% examples, 280632 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:22,380 : INFO : EPOCH 28 - PROGRESS: at 9.72% examples, 280032 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:23,386 : INFO : EPOCH 28 - PROGRESS: at 14.73% examples, 285820 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:24,421 : INFO : EPOCH 28 - PROGRESS: at 19.58% examples, 280368 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:25,450 : INFO : EPOCH 28 - PROGRESS: at 24.58% examples, 279267 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:26,456 : INFO : EPOCH 28 - PROGRESS: at 29.21% examples, 276575 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:27,460 : INFO : EPOCH 28 - PROGRESS: at 33.91% examples, 274535 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:28,464 : INFO : EPOCH 28 - PROGRESS: at 38.43% examples, 273347 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:29,471 : INFO : EPOCH 28 - PROGRESS: at 43.20% examples, 272135 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:30,483 : INFO : EPOCH 28 - PROGRESS: at 48.23% examples, 273579 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:31,494 : INFO : EPOCH 28 - PROGRESS: at 53.60% examples, 274837 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:32,502 : INFO : EPOCH 28 - PROGRESS: at 58.61% examples, 275218 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:33,534 : INFO : EPOCH 28 - PROGRESS: at 63.25% examples, 273661 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 14:51:34,534 : INFO : EPOCH 28 - PROGRESS: at 68.11% examples, 274234 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:35,574 : INFO : EPOCH 28 - PROGRESS: at 73.35% examples, 273996 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:36,584 : INFO : EPOCH 28 - PROGRESS: at 78.08% examples, 274277 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:37,592 : INFO : EPOCH 28 - PROGRESS: at 83.20% examples, 275007 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:38,595 : INFO : EPOCH 28 - PROGRESS: at 89.41% examples, 278559 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:39,614 : INFO : EPOCH 28 - PROGRESS: at 93.83% examples, 277149 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:40,632 : INFO : EPOCH 28 - PROGRESS: at 98.58% examples, 276275 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:40,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:51:40,733 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:51:40,737 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:51:40,738 : INFO : EPOCH - 28 : training on 6557240 raw words (5679584 effective words) took 20.4s, 278422 effective words/s\n",
      "2019-06-26 14:51:41,765 : INFO : EPOCH 29 - PROGRESS: at 4.77% examples, 248724 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:42,768 : INFO : EPOCH 29 - PROGRESS: at 9.11% examples, 251911 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:43,774 : INFO : EPOCH 29 - PROGRESS: at 14.00% examples, 258156 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:44,776 : INFO : EPOCH 29 - PROGRESS: at 20.94% examples, 295590 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:45,786 : INFO : EPOCH 29 - PROGRESS: at 26.66% examples, 300721 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:46,800 : INFO : EPOCH 29 - PROGRESS: at 31.69% examples, 299590 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:47,812 : INFO : EPOCH 29 - PROGRESS: at 38.01% examples, 308463 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:48,833 : INFO : EPOCH 29 - PROGRESS: at 46.07% examples, 325389 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:49,859 : INFO : EPOCH 29 - PROGRESS: at 54.25% examples, 341339 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:50,882 : INFO : EPOCH 29 - PROGRESS: at 62.58% examples, 352357 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:51,915 : INFO : EPOCH 29 - PROGRESS: at 71.27% examples, 363378 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:52,924 : INFO : EPOCH 29 - PROGRESS: at 79.63% examples, 371145 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:51:53,942 : INFO : EPOCH 29 - PROGRESS: at 87.77% examples, 378101 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:54,949 : INFO : EPOCH 29 - PROGRESS: at 95.28% examples, 382019 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:55,650 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:51:55,665 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:51:55,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:51:55,669 : INFO : EPOCH - 29 : training on 6557240 raw words (5678998 effective words) took 14.9s, 380405 effective words/s\n",
      "2019-06-26 14:51:56,701 : INFO : EPOCH 30 - PROGRESS: at 5.01% examples, 255997 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:57,702 : INFO : EPOCH 30 - PROGRESS: at 9.71% examples, 264665 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:58,718 : INFO : EPOCH 30 - PROGRESS: at 14.65% examples, 268778 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:51:59,730 : INFO : EPOCH 30 - PROGRESS: at 19.90% examples, 277396 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:52:00,736 : INFO : EPOCH 30 - PROGRESS: at 24.96% examples, 279653 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:52:01,759 : INFO : EPOCH 30 - PROGRESS: at 30.14% examples, 281776 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:52:02,767 : INFO : EPOCH 30 - PROGRESS: at 34.73% examples, 280235 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:52:03,776 : INFO : EPOCH 30 - PROGRESS: at 40.01% examples, 281200 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:52:04,797 : INFO : EPOCH 30 - PROGRESS: at 44.92% examples, 280533 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:52:05,808 : INFO : EPOCH 30 - PROGRESS: at 53.35% examples, 298865 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:52:06,831 : INFO : EPOCH 30 - PROGRESS: at 57.92% examples, 295939 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:52:07,853 : INFO : EPOCH 30 - PROGRESS: at 63.16% examples, 294899 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:52:08,858 : INFO : EPOCH 30 - PROGRESS: at 67.56% examples, 291877 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:52:09,874 : INFO : EPOCH 30 - PROGRESS: at 72.60% examples, 290691 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:52:10,904 : INFO : EPOCH 30 - PROGRESS: at 77.37% examples, 289033 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:52:11,910 : INFO : EPOCH 30 - PROGRESS: at 84.33% examples, 294761 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 14:52:12,937 : INFO : EPOCH 30 - PROGRESS: at 89.71% examples, 295490 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:52:13,962 : INFO : EPOCH 30 - PROGRESS: at 94.71% examples, 293882 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 14:52:14,749 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 14:52:14,761 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 14:52:14,762 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 14:52:14,763 : INFO : EPOCH - 30 : training on 6557240 raw words (5679200 effective words) took 19.1s, 297459 effective words/s\n",
      "2019-06-26 14:52:14,764 : INFO : training on a 196717200 raw words (170380213 effective words) took 524.9s, 324591 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [doc2vec dmm]: 0:08:49.799967\n",
      "Time for [3 - doc2vec model]: 0:16:35.306854\n"
     ]
    }
   ],
   "source": [
    "# 3. train doc2vec model\n",
    "with Timer(\"3 - doc2vec model\"):\n",
    "    model_dbow, model_dmm = train_model(X_train, X_dev, workers=3, epochs=30)\n",
    "\n",
    "    model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "    model_concat = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:04:03.580602Z",
     "start_time": "2019-06-26T12:52:16.731192Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42733/42733 [08:06<00:00, 87.85it/s] \n",
      "100%|██████████| 18315/18315 [03:40<00:00, 83.10it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [4 - vectorize arguments]: 0:11:46.846109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. vectorize arguments\n",
    "with Timer(\"4 - vectorize arguments\"):\n",
    "    # X_train, X_dev = make_vectors(X_train, X_dev, model_dbow)\n",
    "    # X_train, X_dev = make_vectors(X_train, X_dev, model_dmm)\n",
    "    X_train, X_dev = make_vectors(X_train, X_dev, model_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:04:09.437690Z",
     "start_time": "2019-06-26T13:04:04.530256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42733/42733 [00:03<00:00, 12894.11it/s]\n",
      "100%|██████████| 18315/18315 [00:01<00:00, 13026.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [5 - vector comparison of arguments]: 0:00:04.903677\n"
     ]
    }
   ],
   "source": [
    "# 5. combine two argument vectors into a single one\n",
    "# - diff / concat / ...\n",
    "with Timer(\"5 - vector comparison of arguments\"):\n",
    "    X_train_diff, X_dev_diff = make_vector_comparison(X_train, X_dev, mode=\"concat\")\n",
    "\n",
    "X_train_ = X_train_diff\n",
    "X_dev_ = X_dev_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:07:19.942630Z",
     "start_time": "2019-06-26T13:05:09.832430Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [StandardScaler fit]: 0:00:00.741463\n",
      "Time for [StandardScaler transform]: 0:00:00.284643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [SVC (linear) fit]: 0:02:08.898048\n",
      "Time for [SVC predict]: 0:00:00.118778\n",
      "Time for [6 - SVM (train -> predict)]: 0:02:10.060351\n",
      "Confusion Matrix:\n",
      "[[2249 6687]\n",
      " [1927 7452]]\n",
      "\n",
      "Accuracy:  0.53 \n",
      "\n",
      "Report for [SVM]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.54      0.25      0.34      8936\n",
      "        True       0.53      0.79      0.63      9379\n",
      "\n",
      "    accuracy                           0.53     18315\n",
      "   macro avg       0.53      0.52      0.49     18315\n",
      "weighted avg       0.53      0.53      0.49     18315\n",
      "\n",
      "{'macro': 0.49, 'micro': 0.53}\n",
      "Time for [7 - report]: 0:00:00.045468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - SVM (train -> predict)\"):\n",
    "    y_pred_svm = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_svm, name=\"SVM\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:07:47.534950Z",
     "start_time": "2019-06-26T13:07:20.879454Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [LogisticRegression fit]: 0:00:26.509581\n",
      "Time for [LogisticRegression predict]: 0:00:00.093120\n",
      "Time for [6 - LogReg (train -> predict)]: 0:00:26.602942\n",
      "Confusion Matrix:\n",
      "[[4899 4037]\n",
      " [3982 5397]]\n",
      "\n",
      "Accuracy:  0.56 \n",
      "\n",
      "Report for [LogisticRegression]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.55      0.55      0.55      8936\n",
      "        True       0.57      0.58      0.57      9379\n",
      "\n",
      "    accuracy                           0.56     18315\n",
      "   macro avg       0.56      0.56      0.56     18315\n",
      "weighted avg       0.56      0.56      0.56     18315\n",
      "\n",
      "{'macro': 0.56, 'micro': 0.56}\n",
      "Time for [7 - report]: 0:00:00.049659\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - LogReg (train -> predict)\"):\n",
    "    y_pred_logreg = train_test_logreg(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_logreg, name=\"LogisticRegression\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T13:08:07.342162Z",
     "start_time": "2019-06-26T13:07:48.482603Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [SGDClassifier fit]: 0:00:18.710785\n",
      "Time for [SGDClassifier predict]: 0:00:00.093530\n",
      "Time for [6 - SGDClassifier (train -> predict)]: 0:00:18.804574\n",
      "Confusion Matrix:\n",
      "[[6591 2345]\n",
      " [5135 4244]]\n",
      "\n",
      "Accuracy:  0.59 \n",
      "\n",
      "Report for [SGDClassifier]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.74      0.64      8936\n",
      "        True       0.64      0.45      0.53      9379\n",
      "\n",
      "    accuracy                           0.59     18315\n",
      "   macro avg       0.60      0.60      0.58     18315\n",
      "weighted avg       0.60      0.59      0.58     18315\n",
      "\n",
      "{'macro': 0.58, 'micro': 0.59}\n",
      "Time for [7 - report]: 0:00:00.051484\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - SGDClassifier (train -> predict)\"):\n",
    "    y_pred_sgdcla = train_test_sgd(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_sgdcla, name=\"SGDClassifier\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:45:45.813418Z",
     "start_time": "2019-06-26T11:45:45.808878Z"
    },
    "code_folding": [
     0,
     6,
     11,
     16,
     20
    ]
   },
   "outputs": [],
   "source": [
    "# old\n",
    "return\n",
    "\n",
    "asdf\n",
    "\n",
    "# 2. Lemmatizing argument1 and argument2\n",
    "with Timer(\"2 - lemmatize\"):\n",
    "    X_train = X_train.apply(get_lemma, axis=1)\n",
    "    X_dev = X_dev.apply(get_lemma, axis=1)\n",
    "\n",
    "# 3. Extracting features - 1-3 grams lemma\n",
    "with Timer(\"3 - n-grams\"):\n",
    "    X_train_, X_dev_ = extract_n_grams_features(\n",
    "        X_train, X_dev, columns=['argument1_lemmas', 'argument2_lemmas'])\n",
    "\n",
    "# 4. train\n",
    "with Timer(\"4 - SVM (train -> predict)\"):\n",
    "    y_pred = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 5. Evaluate\n",
    "with Timer(\"5 - report\"):\n",
    "    report_training_results(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
