{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:49:00.121142Z",
     "start_time": "2019-06-26T14:48:59.279702Z"
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import time\n",
    "\n",
    "import csv\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "# from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import utils\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:49:01.205180Z",
     "start_time": "2019-06-26T14:49:01.202626Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:49:01.464785Z",
     "start_time": "2019-06-26T14:49:01.246025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ekoerner/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:49:01.521686Z",
     "start_time": "2019-06-26T14:49:01.519330Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:49:01.585842Z",
     "start_time": "2019-06-26T14:49:01.578572Z"
    },
    "code_folding": [
     0,
     4
    ]
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:49:02.770386Z",
     "start_time": "2019-06-26T14:49:02.767195Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:49:06.773745Z",
     "start_time": "2019-06-26T14:49:04.744087Z"
    },
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:00.948239\n",
      "Time for [read within]: 0:00:01.072199\n"
     ]
    }
   ],
   "source": [
    "# escapechar to detect quoting escapes, else it fails\n",
    "\n",
    "# na_filter=False, because pandas automatic \"nan\" detection fails with the topic column, too\n",
    "# cross_test_df['topic'].astype(str)[9270]\n",
    "\n",
    "# within has \"is_same_side\" as string (boolean after latest update)\n",
    "# cross has \"is_same_side\" as boolean (auto cast?)\n",
    "\n",
    "with Timer(\"read cross\"):\n",
    "    # cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                    quotechar='\"',\n",
    "                                    quoting=csv.QUOTE_ALL,\n",
    "                                    encoding='utf-8',\n",
    "                                    escapechar='\\\\',\n",
    "                                    doublequote=False,\n",
    "                                    index_col='id')\n",
    "    cross_test_df = pd.read_csv(data_cross_path.format('test'),\n",
    "                                quotechar='\"',\n",
    "                                quoting=csv.QUOTE_ALL,\n",
    "                                encoding='utf-8',\n",
    "                                escapechar='\\\\',\n",
    "                                doublequote=False,\n",
    "                                index_col='id')\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    # within_traindev_df = pd.read_csv(data_within_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    within_traindev_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                     quotechar='\"',\n",
    "                                     quoting=csv.QUOTE_ALL,\n",
    "                                     encoding='utf-8',\n",
    "                                     escapechar='\\\\',\n",
    "                                     doublequote=False,\n",
    "                                     index_col='id')\n",
    "    within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "                                 quotechar='\"',\n",
    "                                 quoting=csv.QUOTE_ALL,\n",
    "                                 encoding='utf-8',\n",
    "                                 escapechar='\\\\',\n",
    "                                 doublequote=False,\n",
    "                                 index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:04.218056Z",
     "start_time": "2019-06-26T14:49:07.090508Z"
    },
    "code_folding": [
     1,
     12,
     14,
     17,
     19
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag cross traindev]: 0:00:36.762735\n",
      "Time for [tag cross test]: 0:00:20.746263\n",
      "Time for [tag within traindev]: 0:00:39.041026\n",
      "Time for [tag within test]: 0:00:20.569204\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross traindev\"):\n",
    "    cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "with Timer(\"tag cross test\"):\n",
    "    cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within traindev\"):\n",
    "    within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "with Timer(\"tag within test\"):\n",
    "    within_test_df = within_test_df.apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get an overview about each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:04.518101Z",
     "start_time": "2019-06-26T14:51:04.505105Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_overview(df, task='same-side', class_name='is_same_side'):\n",
    "    # Total instance numbers\n",
    "    total = len(df)\n",
    "    print(\"Task: \", task)\n",
    "    print('=' * 40, '\\n')\n",
    "\n",
    "    print('Total instances: ', total)\n",
    "    print('\\n')\n",
    "\n",
    "    print('For each topic:')\n",
    "    for tag, tag_df in df.groupby(['tag']):\n",
    "        print(tag, ': ', len(tag_df), ' instances')\n",
    "        if class_name in df.columns:\n",
    "            for is_same_side, side_df in tag_df.groupby([class_name]):\n",
    "                print('\\t\\t', is_same_side, ': ', len(side_df), ' instances')\n",
    "    print('\\n')\n",
    "\n",
    "    if class_name in df.columns:\n",
    "        print('For each class value:')\n",
    "        for class_value, class_df in df.groupby([class_name]):\n",
    "            print(class_value, ': ', len(class_df), ' instances')\n",
    "        print('\\n')\n",
    "\n",
    "    print('Unique argument1:', len(df['argument1'].unique()))\n",
    "    print('Unique argument2:', len(df['argument2'].unique()))\n",
    "    arguments = df['argument1'].values\n",
    "    arguments = np.concatenate([arguments, df['argument2'].values])\n",
    "\n",
    "    print('Unique total arguments:', len(set(list(arguments))), '\\n')\n",
    "\n",
    "    print('-' * 40, '\\n')\n",
    "\n",
    "    arguments_length_lst = [\n",
    "        len(word_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_length_lst.extend(\n",
    "        [len(word_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Words:')\n",
    "    print('\\tshortest argument:', min(arguments_length_lst), ' words')\n",
    "    print('\\tlongest argument:', max(arguments_length_lst), ' words')\n",
    "    print('\\targument average length:', np.mean(arguments_length_lst),\n",
    "          ' words')\n",
    "\n",
    "    arguments_sent_length_lst = [\n",
    "        len(sent_tokenize(x)) for x in df['argument1'].values\n",
    "    ]\n",
    "    arguments_sent_length_lst.extend(\n",
    "        [len(sent_tokenize(x)) for x in df['argument2'].values])\n",
    "    print('Sentences:')\n",
    "    print('\\tshortest argument:', min(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\tlongest argument:', max(arguments_sent_length_lst), ' sentences')\n",
    "    print('\\targument average length:', np.mean(arguments_sent_length_lst),\n",
    "          ' sentences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:04.810240Z",
     "start_time": "2019-06-26T14:51:04.808685Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# with Timer(\"overview cross\"):\n",
    "#     get_overview(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:05.104301Z",
     "start_time": "2019-06-26T14:51:05.102671Z"
    }
   },
   "outputs": [],
   "source": [
    "# with Timer(\"overview within\"):\n",
    "#     get_overview(within_traindev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to only tagged input?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:05.485171Z",
     "start_time": "2019-06-26T14:51:05.483171Z"
    }
   },
   "outputs": [],
   "source": [
    "# within_traindev_df = within_traindev_df[(within_traindev_df['tag'] == 'gay marriage')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:05.784295Z",
     "start_time": "2019-06-26T14:51:05.782267Z"
    }
   },
   "outputs": [],
   "source": [
    "# cross_traindev_df = cross_traindev_df[(cross_traindev_df['tag'] == 'gay marriage') | (cross_traindev_df['tag'] == 'abortion')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:06.288020Z",
     "start_time": "2019-06-26T14:51:06.279415Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:06.635277Z",
     "start_time": "2019-06-26T14:51:06.628233Z"
    },
    "code_folding": [
     0,
     15,
     22,
     40
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v)\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # As default pos in lemmatization is Noun\n",
    "        return wordnet.NOUN\n",
    "\n",
    "\n",
    "def lemmatize_stemming(token, pos_tag):\n",
    "    '''lemmatize words (with POS information) and then stem'''\n",
    "    stemmer = SnowballStemmer(\n",
    "        \"english\")  # pOrter, M. \"An algorithm for suffix stripping.\"\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(token, pos=pos_tag))\n",
    "\n",
    "\n",
    "def do_segmentation(text):\n",
    "    '''do sentence segmentation, tokenization (with lemmatization&stemming)'''\n",
    "    lemma = []\n",
    "    for sentence in sent_tokenize(text):\n",
    "        sentence = sentence.replace('\\n', ' ').strip()\n",
    "        tokens = [token for token in word_tokenize(sentence)]\n",
    "        pos_tags = nltk.pos_tag(tokens)\n",
    "\n",
    "        for idx in range(0, len(tokens)):\n",
    "            token = tokens[idx].lower()\n",
    "            if token not in gensim.parsing.preprocessing.STOPWORDS and len(\n",
    "                    token) > 3:\n",
    "                wordnet_pos = get_wordnet_pos(pos_tags[idx][1])\n",
    "                l_ = lemmatize_stemming(token, wordnet_pos)\n",
    "                lemma.append(l_)\n",
    "    return lemma\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    '''concat lemmatized words together again'''\n",
    "    lemma = do_segmentation(text)\n",
    "    return ' '.join(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting n grams lemma for argument1 and argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:07.008888Z",
     "start_time": "2019-06-26T14:51:07.001648Z"
    },
    "code_folding": [
     0,
     38
    ]
   },
   "outputs": [],
   "source": [
    "def extract_ngrams(X_train, X_dev, col, idx='id'):\n",
    "    vectorizer = CountVectorizer(min_df=600,\n",
    "                                 max_df=0.7,\n",
    "                                 ngram_range=(3, 3),\n",
    "                                 max_features=5000)\n",
    "\n",
    "    vectorizer.fit(X_train[col])\n",
    "    features = vectorizer.transform(X_train[col])\n",
    "    features_dev = vectorizer.transform(X_dev[col])\n",
    "\n",
    "    train_df = pd.DataFrame(features.todense(),\n",
    "                            columns=vectorizer.get_feature_names())\n",
    "    train_df = train_df.add_prefix(col)\n",
    "\n",
    "    aid_df = X_train[[idx]]\n",
    "\n",
    "    train_df = train_df.merge(aid_df,\n",
    "                              left_index=True,\n",
    "                              right_index=True,\n",
    "                              suffixes=(False, False),\n",
    "                              how='inner')\n",
    "    train_df.set_index(idx, inplace=True)\n",
    "\n",
    "    dev_df = pd.DataFrame(features_dev.todense(),\n",
    "                          columns=vectorizer.get_feature_names())\n",
    "    dev_df = dev_df.add_prefix(col)\n",
    "\n",
    "    aid_dev_df = X_dev[[idx]]\n",
    "\n",
    "    dev_df = dev_df.merge(aid_dev_df,\n",
    "                          left_index=True,\n",
    "                          right_index=True,\n",
    "                          suffixes=(False, False),\n",
    "                          how='inner')\n",
    "    dev_df.set_index(idx, inplace=True)\n",
    "    return train_df, dev_df\n",
    "\n",
    "\n",
    "def extract_n_grams_features(X_train, X_dev, columns, idx='id'):\n",
    "    X_train = X_train.reset_index()\n",
    "    result_train_df = X_train[[idx]]\n",
    "    result_train_df.set_index(idx, inplace=True)\n",
    "\n",
    "    X_dev = X_dev.reset_index()\n",
    "    result_dev_df = X_dev[[idx]]\n",
    "    result_dev_df.set_index(idx, inplace=True)\n",
    "\n",
    "    for col in columns:\n",
    "        result_train_df_, result_dev_df_ = extract_ngrams(X_train, X_dev, col)\n",
    "        result_train_df = result_train_df.join(result_train_df_)\n",
    "        result_dev_df = result_dev_df.join(result_dev_df_)\n",
    "    return result_train_df, result_dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Doc2Vec model and vectorize argument1 and argument2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:07.318359Z",
     "start_time": "2019-06-26T14:51:07.309449Z"
    },
    "code_folding": [
     0,
     15,
     34,
     56
    ]
   },
   "outputs": [],
   "source": [
    "def make_d2v_docs(row):\n",
    "    words1 = do_segmentation(row['argument1'])\n",
    "    words2 = do_segmentation(row['argument2'])\n",
    "\n",
    "    row['argument1_doc'] = TaggedDocument(words=words1,\n",
    "                                          tags=[row['argument1_id']])\n",
    "    row['argument2_doc'] = TaggedDocument(words=words2,\n",
    "                                          tags=[row['argument2_id']])\n",
    "\n",
    "    row['argument1_lemmas'] = ' '.join(words1)\n",
    "    row['argument2_lemmas'] = ' '.join(words2)\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "class DatasetIter:\n",
    "    def __init__(self, ds, shuffle=True):\n",
    "        self.ds = ds\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def _make_taggeddocs(self, row):\n",
    "        yield row['argument1_doc']\n",
    "        yield row['argument2_doc']\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            self.ds = self.ds.sample(frac=1)\n",
    "\n",
    "        for _, row in self.ds.iterrows():\n",
    "            for doc in self._make_taggeddocs(row):\n",
    "                yield doc\n",
    "\n",
    "\n",
    "# https://github.com/RaRe-Technologies/gensim/blob/2024be9053094fbb2e765b9a06b9dc580f55c505/gensim/test/test_doc2vec.py#L501\n",
    "class ConcatenatedDoc2Vec(object):\n",
    "    \"\"\"\n",
    "    Concatenation of multiple models for reproducing the Paragraph Vectors paper.\n",
    "    Models must have exactly-matching vocabulary and document IDs. (Models should\n",
    "    be trained separately; this wrapper just returns concatenated results.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        if hasattr(models[0], 'docvecs'):\n",
    "            self.docvecs = ConcatenatedDocvecs([model.docvecs for model in models])\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return np.concatenate([model[token] for model in self.models])\n",
    "\n",
    "    def infer_vector(self, document, alpha=0.1, min_alpha=0.0001, steps=5):\n",
    "        return np.concatenate([model.infer_vector(document, alpha, min_alpha, steps) for model in self.models])\n",
    "\n",
    "    def train(self, *ignore_args, **ignore_kwargs):\n",
    "        pass  # train subcomponents individually\n",
    "\n",
    "\n",
    "class ConcatenatedDocvecs(object):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def __getitem__(self, token):\n",
    "        return np.concatenate([model[token] for model in self.models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:07.702226Z",
     "start_time": "2019-06-26T14:51:07.695624Z"
    },
    "code_folding": [
     0,
     6,
     19
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(X_train, X_dev, workers=2, epochs=30):\n",
    "    with Timer(\"doc2vec dbow\"):\n",
    "        # columns=['argument1_lemmas', 'argument2_lemmas']\n",
    "        # pd.concat([X_train[columns], X_dev[columns]])\n",
    "        alpha = 0.025  # https://radimrehurek.com/gensim/models/base_any2vec.html#gensim.models.base_any2vec.BaseWordEmbeddingsModel\n",
    "        # %%time\n",
    "        model_dbow = Doc2Vec(DatasetIter(X_train, shuffle=True),\n",
    "                             dm=0,\n",
    "                             vector_size=300,\n",
    "                             negative=5,\n",
    "                             hs=0,\n",
    "                             min_count=2,\n",
    "                             sample=0,\n",
    "                             workers=workers,\n",
    "                             epochs=epochs,\n",
    "                             alpha=alpha,\n",
    "                             min_alpha=alpha - (epochs * 0.002))\n",
    "        \n",
    "    with Timer(\"doc2vec dmm\"):\n",
    "        model_dmm = Doc2Vec(DatasetIter(X_train, shuffle=True),\n",
    "                            dm=1,\n",
    "                            dm_mean=1,\n",
    "                            vector_size=300,\n",
    "                            window=10,\n",
    "                            negative=5,\n",
    "                            min_count=1,\n",
    "                            workers=workers,\n",
    "                            epochs=epochs,\n",
    "                            alpha=0.065,\n",
    "                            min_alpha=0.065 - (epochs * 0.002))\n",
    "        \n",
    "    return model_dbow, model_dmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:08.327234Z",
     "start_time": "2019-06-26T14:51:08.323631Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_vectors(X_train, X_dev, model):\n",
    "    def make_d2v_vecs(row):\n",
    "        vec1 = model.infer_vector(row['argument1_doc'].words, steps=20)\n",
    "        vec2 = model.infer_vector(row['argument2_doc'].words, steps=20)\n",
    "\n",
    "        row['argument1_vec'] = vec1\n",
    "        row['argument2_vec'] = vec2\n",
    "        \n",
    "        return row\n",
    "\n",
    "    X_train = X_train.progress_apply(make_d2v_vecs, axis=1)\n",
    "    X_dev = X_dev.progress_apply(make_d2v_vecs, axis=1)\n",
    "    \n",
    "    return X_train, X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:08.649085Z",
     "start_time": "2019-06-26T14:51:08.644148Z"
    },
    "code_folding": [
     0,
     10,
     20
    ]
   },
   "outputs": [],
   "source": [
    "def make_vector_comparison_diff(X_train, X_dev):\n",
    "    def ret_vec_diff(row):\n",
    "        return row['argument1_vec'] - row['argument2_vec']\n",
    "\n",
    "    X_train_diff = X_train.progress_apply(ret_vec_diff, axis=1)\n",
    "    X_dev_diff = X_dev.progress_apply(ret_vec_diff, axis=1)\n",
    "\n",
    "    return X_train_diff, X_dev_diff\n",
    "\n",
    "\n",
    "def make_vector_comparison_concat(X_train, X_dev):\n",
    "    def ret_vec_concat(row):\n",
    "        return np.concatenate((row['argument1_vec'], row['argument2_vec']))\n",
    "\n",
    "    X_train_concat = X_train.progress_apply(ret_vec_concat, axis=1)\n",
    "    X_dev_concat = X_dev.progress_apply(ret_vec_concat, axis=1)\n",
    "\n",
    "    return X_train_concat, X_dev_concat\n",
    "\n",
    "\n",
    "def make_vector_comparison(X_train, X_dev, mode=\"diff\"):\n",
    "    if mode == \"concat\":\n",
    "        X_train, X_dev = make_vector_comparison_concat(X_train, X_dev)\n",
    "    else:\n",
    "        X_train, X_dev = make_vector_comparison_diff(X_train, X_dev)\n",
    "\n",
    "    # array of array to 2d array\n",
    "    X_train = np.array(list(X_train.values))\n",
    "    X_dev = np.array(list(X_dev.values))\n",
    "\n",
    "    return X_train, X_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:08.938091Z",
     "start_time": "2019-06-26T14:51:08.929472Z"
    },
    "code_folding": [
     0,
     22,
     33,
     44,
     56
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train_test_svm(X_train, y_train, X_test):\n",
    "    with Timer(\"StandardScaler fit\"):\n",
    "        scaler = StandardScaler(copy=True, with_mean=False)\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "    with Timer(\"StandardScaler transform\"):\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # ------------------\n",
    "\n",
    "    with Timer(\"SVC (linear) fit\"):\n",
    "        # svclassifier = SVC(kernel='linear')\n",
    "        svclassifier = LinearSVC()        \n",
    "        svclassifier.fit(X_train, y_train)\n",
    "\n",
    "    with Timer(\"SVC predict\"):\n",
    "        y_pred = svclassifier.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def train_test_logreg(X_train, y_train, X_test):\n",
    "    with Timer(\"LogisticRegression fit\"):\n",
    "        logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "        logreg.fit(X_train, y_train)\n",
    "    \n",
    "    with Timer(\"LogisticRegression predict\"):\n",
    "        y_pred = logreg.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def train_test_sgd(X_train, y_train, X_test):\n",
    "    with Timer(\"SGDClassifier fit\"):\n",
    "        sgdcla = SGDClassifier()\n",
    "        sgdcla.fit(X_train, y_train)\n",
    "    \n",
    "    with Timer(\"SGDClassifier predict\"):\n",
    "        y_pred = sgdcla.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def heatconmat(y_test, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(y_test.unique()))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, name=None, heatmap=True):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    if heatmap:\n",
    "        heatconmat(y_test['is_same_side'], y_pred)\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2), '\\n')  #\n",
    "\n",
    "    print('Report{}:'.format(\"\" if not name else \" for [{}]\".format(name)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    f1_dic = {}\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T14:51:09.322466Z",
     "start_time": "2019-06-26T14:51:09.301371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train]: 0:00:00.018567\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T15:12:40.270389Z",
     "start_time": "2019-06-26T14:51:09.747359Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42733/42733 [15:12<00:00, 46.81it/s]\n",
      "100%|██████████| 18315/18315 [06:17<00:00, 48.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2 - tokenize]: 0:21:30.520007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. tokenize (make doc2vec docs + lemma string)\n",
    "# tqdm.pandas()\n",
    "with Timer(\"2 - tokenize\"):\n",
    "    X_train = X_train.progress_apply(make_d2v_docs, axis=1)\n",
    "    X_dev = X_dev.progress_apply(make_d2v_docs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T16:31:28.572396Z",
     "start_time": "2019-06-26T16:31:21.833507Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2a - pickle]: 0:00:06.731561\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"2a - pickle\"):\n",
    "    X_train.to_pickle(\"data/X_train.cross_td.p\")\n",
    "    X_dev.to_pickle(\"data/X_dev.cross_td.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T15:12:48.927792Z",
     "start_time": "2019-06-26T15:12:46.270163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [2b - unpickle]: 0:00:02.655215\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"2b - unpickle\"):\n",
    "    X_train = pd.read_pickle(\"data/X_train.cross_td.p\")\n",
    "    X_dev = pd.read_pickle(\"data/X_dev.cross_td.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T15:28:12.234360Z",
     "start_time": "2019-06-26T15:12:49.848657Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:12:49,850 : INFO : collecting all words and their counts\n",
      "2019-06-26 17:12:49,863 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-06-26 17:12:50,374 : INFO : PROGRESS: at example #10000, processed 751115 words (1472751/s), 21065 word types, 2130 tags\n",
      "2019-06-26 17:12:50,896 : INFO : PROGRESS: at example #20000, processed 1548613 words (1530059/s), 29037 word types, 3486 tags\n",
      "2019-06-26 17:12:51,414 : INFO : PROGRESS: at example #30000, processed 2316013 words (1484035/s), 32922 word types, 4530 tags\n",
      "2019-06-26 17:12:51,936 : INFO : PROGRESS: at example #40000, processed 3097340 words (1498464/s), 35373 word types, 5319 tags\n",
      "2019-06-26 17:12:52,455 : INFO : PROGRESS: at example #50000, processed 3864183 words (1480769/s), 36689 word types, 5923 tags\n",
      "2019-06-26 17:12:52,972 : INFO : PROGRESS: at example #60000, processed 4617395 words (1460185/s), 37384 word types, 6408 tags\n",
      "2019-06-26 17:12:53,492 : INFO : PROGRESS: at example #70000, processed 5375578 words (1461329/s), 37747 word types, 6766 tags\n",
      "2019-06-26 17:12:54,009 : INFO : PROGRESS: at example #80000, processed 6128054 words (1456423/s), 37969 word types, 7099 tags\n",
      "2019-06-26 17:12:54,295 : INFO : collected 38071 word types and 7236 unique tags from a corpus of 85466 examples and 6557240 words\n",
      "2019-06-26 17:12:54,296 : INFO : Loading a fresh vocabulary\n",
      "2019-06-26 17:12:54,344 : INFO : effective_min_count=2 retains 36901 unique words (96% of original 38071, drops 1170)\n",
      "2019-06-26 17:12:54,345 : INFO : effective_min_count=2 leaves 6556070 word corpus (99% of original 6557240, drops 1170)\n",
      "2019-06-26 17:12:54,419 : INFO : deleting the raw counts dictionary of 38071 items\n",
      "2019-06-26 17:12:54,421 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-06-26 17:12:54,422 : INFO : downsampling leaves estimated 6556070 word corpus (100.0% of prior 6556070)\n",
      "2019-06-26 17:12:54,525 : INFO : estimated required memory for 36901 words and 300 dimensions: 117143300 bytes\n",
      "2019-06-26 17:12:54,526 : INFO : resetting layer weights\n",
      "2019-06-26 17:12:54,903 : INFO : training model with 3 workers on 36901 vocabulary and 300 features, using sg=1 hs=0 sample=0 negative=5 window=5\n",
      "2019-06-26 17:12:55,917 : INFO : EPOCH 1 - PROGRESS: at 8.51% examples, 554122 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:12:56,928 : INFO : EPOCH 1 - PROGRESS: at 17.77% examples, 583623 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:12:57,946 : INFO : EPOCH 1 - PROGRESS: at 27.04% examples, 590721 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:12:58,962 : INFO : EPOCH 1 - PROGRESS: at 36.32% examples, 602706 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:12:59,982 : INFO : EPOCH 1 - PROGRESS: at 44.16% examples, 583859 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:00,997 : INFO : EPOCH 1 - PROGRESS: at 51.87% examples, 569984 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:02,005 : INFO : EPOCH 1 - PROGRESS: at 57.43% examples, 540926 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:03,034 : INFO : EPOCH 1 - PROGRESS: at 63.51% examples, 523909 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:04,044 : INFO : EPOCH 1 - PROGRESS: at 69.80% examples, 511852 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:05,065 : INFO : EPOCH 1 - PROGRESS: at 75.01% examples, 493797 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:06,102 : INFO : EPOCH 1 - PROGRESS: at 81.08% examples, 482937 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:07,121 : INFO : EPOCH 1 - PROGRESS: at 88.07% examples, 479509 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:08,123 : INFO : EPOCH 1 - PROGRESS: at 95.55% examples, 480819 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:08,727 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:13:08,736 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:13:08,737 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:13:08,738 : INFO : EPOCH - 1 : training on 6557240 raw words (6641536 effective words) took 13.8s, 480164 effective words/s\n",
      "2019-06-26 17:13:09,752 : INFO : EPOCH 2 - PROGRESS: at 7.31% examples, 472826 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:10,786 : INFO : EPOCH 2 - PROGRESS: at 13.37% examples, 428551 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:11,794 : INFO : EPOCH 2 - PROGRESS: at 18.85% examples, 408071 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:12,809 : INFO : EPOCH 2 - PROGRESS: at 28.53% examples, 461031 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:13,810 : INFO : EPOCH 2 - PROGRESS: at 37.82% examples, 489773 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:14,824 : INFO : EPOCH 2 - PROGRESS: at 43.08% examples, 466980 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:15,832 : INFO : EPOCH 2 - PROGRESS: at 49.35% examples, 458455 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:16,836 : INFO : EPOCH 2 - PROGRESS: at 58.00% examples, 474049 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:17,840 : INFO : EPOCH 2 - PROGRESS: at 64.73% examples, 470046 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:18,884 : INFO : EPOCH 2 - PROGRESS: at 71.07% examples, 461976 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:19,916 : INFO : EPOCH 2 - PROGRESS: at 76.88% examples, 455130 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:20,922 : INFO : EPOCH 2 - PROGRESS: at 83.78% examples, 455191 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:21,945 : INFO : EPOCH 2 - PROGRESS: at 93.14% examples, 467452 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:22,632 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:13:22,635 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:13:22,644 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:13:22,645 : INFO : EPOCH - 2 : training on 6557240 raw words (6641536 effective words) took 13.9s, 477624 effective words/s\n",
      "2019-06-26 17:13:23,650 : INFO : EPOCH 3 - PROGRESS: at 8.68% examples, 584767 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:24,653 : INFO : EPOCH 3 - PROGRESS: at 17.38% examples, 570986 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:25,690 : INFO : EPOCH 3 - PROGRESS: at 22.35% examples, 487557 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:26,694 : INFO : EPOCH 3 - PROGRESS: at 28.46% examples, 463130 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:27,698 : INFO : EPOCH 3 - PROGRESS: at 35.77% examples, 467754 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:28,727 : INFO : EPOCH 3 - PROGRESS: at 43.15% examples, 470519 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:29,731 : INFO : EPOCH 3 - PROGRESS: at 51.94% examples, 488307 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:30,737 : INFO : EPOCH 3 - PROGRESS: at 61.10% examples, 504240 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:31,743 : INFO : EPOCH 3 - PROGRESS: at 70.41% examples, 516404 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:32,758 : INFO : EPOCH 3 - PROGRESS: at 79.90% examples, 525812 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:33,770 : INFO : EPOCH 3 - PROGRESS: at 89.15% examples, 533554 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:34,773 : INFO : EPOCH 3 - PROGRESS: at 98.68% examples, 540414 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:34,844 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:13:34,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:13:34,848 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:13:34,848 : INFO : EPOCH - 3 : training on 6557240 raw words (6641536 effective words) took 12.2s, 544326 effective words/s\n",
      "2019-06-26 17:13:35,856 : INFO : EPOCH 4 - PROGRESS: at 5.65% examples, 377369 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:36,876 : INFO : EPOCH 4 - PROGRESS: at 12.80% examples, 419260 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:37,876 : INFO : EPOCH 4 - PROGRESS: at 18.38% examples, 399485 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:38,878 : INFO : EPOCH 4 - PROGRESS: at 24.24% examples, 396969 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:39,890 : INFO : EPOCH 4 - PROGRESS: at 32.15% examples, 417997 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:13:40,891 : INFO : EPOCH 4 - PROGRESS: at 41.48% examples, 451395 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:41,893 : INFO : EPOCH 4 - PROGRESS: at 50.66% examples, 475130 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:42,928 : INFO : EPOCH 4 - PROGRESS: at 57.93% examples, 476021 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:43,943 : INFO : EPOCH 4 - PROGRESS: at 64.06% examples, 469942 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:44,954 : INFO : EPOCH 4 - PROGRESS: at 69.50% examples, 459381 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:45,977 : INFO : EPOCH 4 - PROGRESS: at 77.59% examples, 464600 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:46,990 : INFO : EPOCH 4 - PROGRESS: at 86.64% examples, 475075 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:48,005 : INFO : EPOCH 4 - PROGRESS: at 96.38% examples, 486445 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:48,327 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:13:48,332 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:13:48,344 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:13:48,345 : INFO : EPOCH - 4 : training on 6557240 raw words (6641536 effective words) took 13.5s, 492144 effective words/s\n",
      "2019-06-26 17:13:49,360 : INFO : EPOCH 5 - PROGRESS: at 5.58% examples, 366806 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:50,364 : INFO : EPOCH 5 - PROGRESS: at 13.01% examples, 435457 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:51,378 : INFO : EPOCH 5 - PROGRESS: at 20.62% examples, 451348 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:52,381 : INFO : EPOCH 5 - PROGRESS: at 29.60% examples, 482689 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:53,390 : INFO : EPOCH 5 - PROGRESS: at 38.87% examples, 508865 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:54,397 : INFO : EPOCH 5 - PROGRESS: at 48.32% examples, 526298 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:55,419 : INFO : EPOCH 5 - PROGRESS: at 54.53% examples, 510740 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:56,420 : INFO : EPOCH 5 - PROGRESS: at 61.54% examples, 505457 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:13:57,428 : INFO : EPOCH 5 - PROGRESS: at 67.77% examples, 496607 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:58,435 : INFO : EPOCH 5 - PROGRESS: at 73.20% examples, 481797 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:13:59,469 : INFO : EPOCH 5 - PROGRESS: at 79.57% examples, 473073 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:00,494 : INFO : EPOCH 5 - PROGRESS: at 85.62% examples, 465879 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:01,516 : INFO : EPOCH 5 - PROGRESS: at 91.88% examples, 461536 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:02,534 : INFO : EPOCH 5 - PROGRESS: at 97.42% examples, 456528 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:02,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:14:02,770 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:14:02,772 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:14:02,773 : INFO : EPOCH - 5 : training on 6557240 raw words (6641536 effective words) took 14.4s, 460409 effective words/s\n",
      "2019-06-26 17:14:03,776 : INFO : EPOCH 6 - PROGRESS: at 5.67% examples, 361308 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:04,804 : INFO : EPOCH 6 - PROGRESS: at 11.76% examples, 380491 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:05,813 : INFO : EPOCH 6 - PROGRESS: at 20.66% examples, 451626 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:06,837 : INFO : EPOCH 6 - PROGRESS: at 30.25% examples, 492732 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:07,843 : INFO : EPOCH 6 - PROGRESS: at 39.03% examples, 510865 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:08,884 : INFO : EPOCH 6 - PROGRESS: at 44.62% examples, 480772 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:09,888 : INFO : EPOCH 6 - PROGRESS: at 49.98% examples, 464922 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:10,897 : INFO : EPOCH 6 - PROGRESS: at 54.81% examples, 448895 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:11,927 : INFO : EPOCH 6 - PROGRESS: at 62.16% examples, 451685 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:12,927 : INFO : EPOCH 6 - PROGRESS: at 71.26% examples, 466166 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:13,960 : INFO : EPOCH 6 - PROGRESS: at 77.48% examples, 459720 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:14,979 : INFO : EPOCH 6 - PROGRESS: at 83.65% examples, 454069 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:16,007 : INFO : EPOCH 6 - PROGRESS: at 91.94% examples, 461028 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:16,792 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:14:16,794 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:14:16,805 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:14:16,806 : INFO : EPOCH - 6 : training on 6557240 raw words (6641536 effective words) took 14.0s, 473350 effective words/s\n",
      "2019-06-26 17:14:17,832 : INFO : EPOCH 7 - PROGRESS: at 5.44% examples, 349997 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:18,844 : INFO : EPOCH 7 - PROGRESS: at 14.48% examples, 470874 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 17:14:19,865 : INFO : EPOCH 7 - PROGRESS: at 20.36% examples, 443823 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:20,881 : INFO : EPOCH 7 - PROGRESS: at 26.13% examples, 426197 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:21,900 : INFO : EPOCH 7 - PROGRESS: at 31.87% examples, 417432 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:22,907 : INFO : EPOCH 7 - PROGRESS: at 41.19% examples, 448473 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:23,910 : INFO : EPOCH 7 - PROGRESS: at 50.06% examples, 465075 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:24,923 : INFO : EPOCH 7 - PROGRESS: at 59.41% examples, 484296 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:25,948 : INFO : EPOCH 7 - PROGRESS: at 65.76% examples, 475713 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:26,958 : INFO : EPOCH 7 - PROGRESS: at 71.25% examples, 464690 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:27,959 : INFO : EPOCH 7 - PROGRESS: at 77.81% examples, 463101 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:28,980 : INFO : EPOCH 7 - PROGRESS: at 84.75% examples, 461848 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:29,989 : INFO : EPOCH 7 - PROGRESS: at 94.00% examples, 474116 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:30,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:14:30,641 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:14:30,651 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:14:30,652 : INFO : EPOCH - 7 : training on 6557240 raw words (6641536 effective words) took 13.8s, 479756 effective words/s\n",
      "2019-06-26 17:14:31,685 : INFO : EPOCH 8 - PROGRESS: at 5.58% examples, 376707 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:32,694 : INFO : EPOCH 8 - PROGRESS: at 14.63% examples, 483817 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:33,695 : INFO : EPOCH 8 - PROGRESS: at 23.74% examples, 524487 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:34,701 : INFO : EPOCH 8 - PROGRESS: at 29.53% examples, 485581 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:35,706 : INFO : EPOCH 8 - PROGRESS: at 36.89% examples, 489157 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:36,711 : INFO : EPOCH 8 - PROGRESS: at 46.34% examples, 510084 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:37,727 : INFO : EPOCH 8 - PROGRESS: at 53.41% examples, 503184 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:38,729 : INFO : EPOCH 8 - PROGRESS: at 59.07% examples, 486534 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:39,731 : INFO : EPOCH 8 - PROGRESS: at 68.11% examples, 498636 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:40,736 : INFO : EPOCH 8 - PROGRESS: at 75.14% examples, 497583 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:14:41,741 : INFO : EPOCH 8 - PROGRESS: at 80.67% examples, 484863 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:42,752 : INFO : EPOCH 8 - PROGRESS: at 86.63% examples, 476546 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:43,762 : INFO : EPOCH 8 - PROGRESS: at 94.17% examples, 477076 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:44,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:14:44,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:14:44,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:14:44,530 : INFO : EPOCH - 8 : training on 6557240 raw words (6641536 effective words) took 13.9s, 478732 effective words/s\n",
      "2019-06-26 17:14:45,550 : INFO : EPOCH 9 - PROGRESS: at 5.48% examples, 352800 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:46,580 : INFO : EPOCH 9 - PROGRESS: at 11.68% examples, 365646 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:47,583 : INFO : EPOCH 9 - PROGRESS: at 18.17% examples, 383470 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:48,597 : INFO : EPOCH 9 - PROGRESS: at 25.39% examples, 408534 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:49,614 : INFO : EPOCH 9 - PROGRESS: at 34.56% examples, 446536 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:50,621 : INFO : EPOCH 9 - PROGRESS: at 44.25% examples, 477465 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:51,630 : INFO : EPOCH 9 - PROGRESS: at 53.24% examples, 495368 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:52,640 : INFO : EPOCH 9 - PROGRESS: at 62.82% examples, 512474 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:53,681 : INFO : EPOCH 9 - PROGRESS: at 70.69% examples, 509859 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:54,709 : INFO : EPOCH 9 - PROGRESS: at 79.80% examples, 517285 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:55,724 : INFO : EPOCH 9 - PROGRESS: at 87.84% examples, 518523 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:14:56,748 : INFO : EPOCH 9 - PROGRESS: at 95.14% examples, 515980 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:57,443 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:14:57,463 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:14:57,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:14:57,470 : INFO : EPOCH - 9 : training on 6557240 raw words (6641536 effective words) took 12.9s, 513326 effective words/s\n",
      "2019-06-26 17:14:58,475 : INFO : EPOCH 10 - PROGRESS: at 6.60% examples, 419339 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:14:59,483 : INFO : EPOCH 10 - PROGRESS: at 13.65% examples, 438202 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:00,493 : INFO : EPOCH 10 - PROGRESS: at 23.29% examples, 493596 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:01,517 : INFO : EPOCH 10 - PROGRESS: at 31.20% examples, 497669 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:02,541 : INFO : EPOCH 10 - PROGRESS: at 37.55% examples, 479481 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:03,554 : INFO : EPOCH 10 - PROGRESS: at 44.22% examples, 471664 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:04,574 : INFO : EPOCH 10 - PROGRESS: at 50.71% examples, 462978 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:05,588 : INFO : EPOCH 10 - PROGRESS: at 59.36% examples, 479812 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:06,590 : INFO : EPOCH 10 - PROGRESS: at 64.58% examples, 466376 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:07,602 : INFO : EPOCH 10 - PROGRESS: at 69.99% examples, 455270 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:08,609 : INFO : EPOCH 10 - PROGRESS: at 78.84% examples, 468005 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:09,622 : INFO : EPOCH 10 - PROGRESS: at 84.45% examples, 460160 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:10,655 : INFO : EPOCH 10 - PROGRESS: at 90.29% examples, 454291 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:11,656 : INFO : EPOCH 10 - PROGRESS: at 96.64% examples, 451830 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:11,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:15:11,942 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:15:11,953 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:15:11,954 : INFO : EPOCH - 10 : training on 6557240 raw words (6641536 effective words) took 14.5s, 458624 effective words/s\n",
      "2019-06-26 17:15:12,959 : INFO : EPOCH 11 - PROGRESS: at 7.16% examples, 458861 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:13,961 : INFO : EPOCH 11 - PROGRESS: at 16.68% examples, 539216 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:14,971 : INFO : EPOCH 11 - PROGRESS: at 26.11% examples, 563971 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:15,985 : INFO : EPOCH 11 - PROGRESS: at 33.35% examples, 540683 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:16,995 : INFO : EPOCH 11 - PROGRESS: at 38.81% examples, 507657 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:18,012 : INFO : EPOCH 11 - PROGRESS: at 44.82% examples, 489968 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:19,026 : INFO : EPOCH 11 - PROGRESS: at 50.42% examples, 472054 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:20,031 : INFO : EPOCH 11 - PROGRESS: at 55.51% examples, 456595 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:21,038 : INFO : EPOCH 11 - PROGRESS: at 61.12% examples, 446423 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:22,051 : INFO : EPOCH 11 - PROGRESS: at 67.03% examples, 443079 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:23,062 : INFO : EPOCH 11 - PROGRESS: at 72.42% examples, 432555 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:24,095 : INFO : EPOCH 11 - PROGRESS: at 77.74% examples, 424461 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:25,102 : INFO : EPOCH 11 - PROGRESS: at 83.47% examples, 422257 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:26,134 : INFO : EPOCH 11 - PROGRESS: at 88.53% examples, 414780 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:27,141 : INFO : EPOCH 11 - PROGRESS: at 95.93% examples, 419499 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:27,505 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:15:27,511 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:15:27,520 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:15:27,521 : INFO : EPOCH - 11 : training on 6557240 raw words (6641536 effective words) took 15.6s, 426689 effective words/s\n",
      "2019-06-26 17:15:28,550 : INFO : EPOCH 12 - PROGRESS: at 5.58% examples, 370295 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 17:15:29,555 : INFO : EPOCH 12 - PROGRESS: at 11.88% examples, 393371 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:30,567 : INFO : EPOCH 12 - PROGRESS: at 18.13% examples, 397034 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:31,572 : INFO : EPOCH 12 - PROGRESS: at 25.81% examples, 426533 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:32,574 : INFO : EPOCH 12 - PROGRESS: at 32.68% examples, 434685 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:33,578 : INFO : EPOCH 12 - PROGRESS: at 37.90% examples, 420236 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:34,579 : INFO : EPOCH 12 - PROGRESS: at 43.47% examples, 412996 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:35,622 : INFO : EPOCH 12 - PROGRESS: at 50.28% examples, 416444 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:36,650 : INFO : EPOCH 12 - PROGRESS: at 58.60% examples, 431661 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:37,658 : INFO : EPOCH 12 - PROGRESS: at 66.11% examples, 434949 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:38,675 : INFO : EPOCH 12 - PROGRESS: at 71.25% examples, 425844 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:39,705 : INFO : EPOCH 12 - PROGRESS: at 79.42% examples, 433196 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:40,709 : INFO : EPOCH 12 - PROGRESS: at 88.45% examples, 445590 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:41,715 : INFO : EPOCH 12 - PROGRESS: at 94.16% examples, 440050 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:15:42,490 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:15:42,497 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:15:42,504 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:15:42,505 : INFO : EPOCH - 12 : training on 6557240 raw words (6641536 effective words) took 15.0s, 443309 effective words/s\n",
      "2019-06-26 17:15:43,511 : INFO : EPOCH 13 - PROGRESS: at 6.66% examples, 437075 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:44,524 : INFO : EPOCH 13 - PROGRESS: at 15.13% examples, 490496 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:45,537 : INFO : EPOCH 13 - PROGRESS: at 22.24% examples, 475176 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:46,542 : INFO : EPOCH 13 - PROGRESS: at 28.13% examples, 455892 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:47,559 : INFO : EPOCH 13 - PROGRESS: at 35.47% examples, 462675 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:48,575 : INFO : EPOCH 13 - PROGRESS: at 41.70% examples, 450929 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:49,584 : INFO : EPOCH 13 - PROGRESS: at 47.40% examples, 444095 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:50,604 : INFO : EPOCH 13 - PROGRESS: at 53.60% examples, 437614 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:51,613 : INFO : EPOCH 13 - PROGRESS: at 59.56% examples, 431841 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:52,617 : INFO : EPOCH 13 - PROGRESS: at 66.08% examples, 434314 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:53,638 : INFO : EPOCH 13 - PROGRESS: at 74.24% examples, 442129 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:54,649 : INFO : EPOCH 13 - PROGRESS: at 79.97% examples, 437362 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:15:55,652 : INFO : EPOCH 13 - PROGRESS: at 87.55% examples, 441973 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:56,671 : INFO : EPOCH 13 - PROGRESS: at 93.87% examples, 440437 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:57,267 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:15:57,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:15:57,285 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:15:57,285 : INFO : EPOCH - 13 : training on 6557240 raw words (6641536 effective words) took 14.8s, 449395 effective words/s\n",
      "2019-06-26 17:15:58,311 : INFO : EPOCH 14 - PROGRESS: at 6.38% examples, 418898 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:15:59,325 : INFO : EPOCH 14 - PROGRESS: at 15.28% examples, 495362 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:00,328 : INFO : EPOCH 14 - PROGRESS: at 22.18% examples, 482591 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:01,341 : INFO : EPOCH 14 - PROGRESS: at 28.33% examples, 465239 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:02,356 : INFO : EPOCH 14 - PROGRESS: at 35.82% examples, 466835 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:03,357 : INFO : EPOCH 14 - PROGRESS: at 43.40% examples, 470569 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 17:16:04,375 : INFO : EPOCH 14 - PROGRESS: at 50.65% examples, 471916 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:05,391 : INFO : EPOCH 14 - PROGRESS: at 57.87% examples, 473047 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:06,397 : INFO : EPOCH 14 - PROGRESS: at 64.84% examples, 473177 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:07,403 : INFO : EPOCH 14 - PROGRESS: at 72.30% examples, 476315 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:08,418 : INFO : EPOCH 14 - PROGRESS: at 79.14% examples, 471483 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:09,443 : INFO : EPOCH 14 - PROGRESS: at 86.65% examples, 473598 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:10,453 : INFO : EPOCH 14 - PROGRESS: at 93.39% examples, 472178 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:11,274 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:16:11,275 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:16:11,290 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:16:11,291 : INFO : EPOCH - 14 : training on 6557240 raw words (6641536 effective words) took 14.0s, 474277 effective words/s\n",
      "2019-06-26 17:16:12,311 : INFO : EPOCH 15 - PROGRESS: at 7.88% examples, 508695 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:13,315 : INFO : EPOCH 15 - PROGRESS: at 14.62% examples, 482620 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:14,320 : INFO : EPOCH 15 - PROGRESS: at 21.24% examples, 464329 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:15,333 : INFO : EPOCH 15 - PROGRESS: at 27.97% examples, 463695 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:16,352 : INFO : EPOCH 15 - PROGRESS: at 34.34% examples, 453215 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:17,370 : INFO : EPOCH 15 - PROGRESS: at 41.91% examples, 457958 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:18,373 : INFO : EPOCH 15 - PROGRESS: at 48.30% examples, 452518 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:19,403 : INFO : EPOCH 15 - PROGRESS: at 53.97% examples, 444187 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:20,434 : INFO : EPOCH 15 - PROGRESS: at 61.89% examples, 450895 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:21,464 : INFO : EPOCH 15 - PROGRESS: at 69.86% examples, 456327 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:22,465 : INFO : EPOCH 15 - PROGRESS: at 77.32% examples, 459077 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:23,477 : INFO : EPOCH 15 - PROGRESS: at 84.38% examples, 458604 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:24,524 : INFO : EPOCH 15 - PROGRESS: at 91.00% examples, 455478 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:25,530 : INFO : EPOCH 15 - PROGRESS: at 98.16% examples, 457700 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:25,666 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:16:25,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:16:25,678 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:16:25,679 : INFO : EPOCH - 15 : training on 6557240 raw words (6641536 effective words) took 14.4s, 461655 effective words/s\n",
      "2019-06-26 17:16:26,685 : INFO : EPOCH 16 - PROGRESS: at 7.38% examples, 487169 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:27,689 : INFO : EPOCH 16 - PROGRESS: at 13.88% examples, 462134 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:28,696 : INFO : EPOCH 16 - PROGRESS: at 20.59% examples, 459997 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:29,718 : INFO : EPOCH 16 - PROGRESS: at 28.21% examples, 462507 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:30,743 : INFO : EPOCH 16 - PROGRESS: at 35.36% examples, 462944 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:31,760 : INFO : EPOCH 16 - PROGRESS: at 42.56% examples, 460937 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:32,771 : INFO : EPOCH 16 - PROGRESS: at 50.16% examples, 465807 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:33,778 : INFO : EPOCH 16 - PROGRESS: at 57.42% examples, 468014 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 17:16:34,783 : INFO : EPOCH 16 - PROGRESS: at 64.60% examples, 468903 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:35,814 : INFO : EPOCH 16 - PROGRESS: at 71.85% examples, 469450 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:36,814 : INFO : EPOCH 16 - PROGRESS: at 78.79% examples, 467428 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:37,838 : INFO : EPOCH 16 - PROGRESS: at 85.06% examples, 462546 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:38,841 : INFO : EPOCH 16 - PROGRESS: at 91.74% examples, 461565 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:39,854 : INFO : EPOCH 16 - PROGRESS: at 97.60% examples, 457403 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:40,098 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:16:40,109 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:16:40,112 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:16:40,113 : INFO : EPOCH - 16 : training on 6557240 raw words (6641536 effective words) took 14.4s, 460184 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:16:41,129 : INFO : EPOCH 17 - PROGRESS: at 7.11% examples, 472018 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:42,139 : INFO : EPOCH 17 - PROGRESS: at 15.28% examples, 498204 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:43,149 : INFO : EPOCH 17 - PROGRESS: at 22.67% examples, 497086 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:44,157 : INFO : EPOCH 17 - PROGRESS: at 29.04% examples, 474620 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:45,160 : INFO : EPOCH 17 - PROGRESS: at 35.78% examples, 467431 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:46,165 : INFO : EPOCH 17 - PROGRESS: at 43.05% examples, 472070 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:47,173 : INFO : EPOCH 17 - PROGRESS: at 50.85% examples, 476776 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:48,196 : INFO : EPOCH 17 - PROGRESS: at 57.31% examples, 470557 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:49,211 : INFO : EPOCH 17 - PROGRESS: at 64.14% examples, 467465 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:50,213 : INFO : EPOCH 17 - PROGRESS: at 70.91% examples, 467449 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:51,216 : INFO : EPOCH 17 - PROGRESS: at 78.99% examples, 473699 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:52,236 : INFO : EPOCH 17 - PROGRESS: at 85.65% examples, 468567 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:53,243 : INFO : EPOCH 17 - PROGRESS: at 92.42% examples, 468311 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:54,152 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:16:54,158 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:16:54,164 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:16:54,164 : INFO : EPOCH - 17 : training on 6557240 raw words (6641536 effective words) took 14.0s, 472719 effective words/s\n",
      "2019-06-26 17:16:55,197 : INFO : EPOCH 18 - PROGRESS: at 7.28% examples, 494562 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:16:56,204 : INFO : EPOCH 18 - PROGRESS: at 15.40% examples, 509428 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:57,214 : INFO : EPOCH 18 - PROGRESS: at 23.49% examples, 517562 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:58,232 : INFO : EPOCH 18 - PROGRESS: at 29.89% examples, 498314 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:16:59,245 : INFO : EPOCH 18 - PROGRESS: at 36.37% examples, 485089 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:00,266 : INFO : EPOCH 18 - PROGRESS: at 44.80% examples, 492309 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:01,286 : INFO : EPOCH 18 - PROGRESS: at 52.30% examples, 490154 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:02,311 : INFO : EPOCH 18 - PROGRESS: at 60.68% examples, 496938 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:03,322 : INFO : EPOCH 18 - PROGRESS: at 69.01% examples, 500818 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:04,375 : INFO : EPOCH 18 - PROGRESS: at 75.97% examples, 494047 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 17:17:05,397 : INFO : EPOCH 18 - PROGRESS: at 83.57% examples, 495204 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:06,422 : INFO : EPOCH 18 - PROGRESS: at 92.31% examples, 499414 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:07,398 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:17:07,400 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:17:07,403 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:17:07,404 : INFO : EPOCH - 18 : training on 6557240 raw words (6641536 effective words) took 13.2s, 501744 effective words/s\n",
      "2019-06-26 17:17:08,426 : INFO : EPOCH 19 - PROGRESS: at 7.18% examples, 467188 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:09,444 : INFO : EPOCH 19 - PROGRESS: at 13.29% examples, 435112 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:10,456 : INFO : EPOCH 19 - PROGRESS: at 21.84% examples, 477067 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:11,475 : INFO : EPOCH 19 - PROGRESS: at 28.72% examples, 470704 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:12,502 : INFO : EPOCH 19 - PROGRESS: at 35.17% examples, 456264 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:13,503 : INFO : EPOCH 19 - PROGRESS: at 41.28% examples, 449869 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:14,518 : INFO : EPOCH 19 - PROGRESS: at 47.90% examples, 450170 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:15,539 : INFO : EPOCH 19 - PROGRESS: at 54.80% examples, 447737 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:16,563 : INFO : EPOCH 19 - PROGRESS: at 60.74% examples, 442193 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:17,571 : INFO : EPOCH 19 - PROGRESS: at 68.53% examples, 448535 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:18,583 : INFO : EPOCH 19 - PROGRESS: at 76.16% examples, 451770 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:19,588 : INFO : EPOCH 19 - PROGRESS: at 82.44% examples, 449071 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:20,594 : INFO : EPOCH 19 - PROGRESS: at 88.67% examples, 446642 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:21,610 : INFO : EPOCH 19 - PROGRESS: at 94.81% examples, 444230 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:22,144 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:17:22,146 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:17:22,156 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:17:22,157 : INFO : EPOCH - 19 : training on 6557240 raw words (6641536 effective words) took 14.8s, 450240 effective words/s\n",
      "2019-06-26 17:17:23,184 : INFO : EPOCH 20 - PROGRESS: at 6.37% examples, 420596 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:24,198 : INFO : EPOCH 20 - PROGRESS: at 13.55% examples, 441410 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:25,205 : INFO : EPOCH 20 - PROGRESS: at 19.86% examples, 436599 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:26,220 : INFO : EPOCH 20 - PROGRESS: at 27.11% examples, 445474 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:27,233 : INFO : EPOCH 20 - PROGRESS: at 35.55% examples, 468468 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:28,245 : INFO : EPOCH 20 - PROGRESS: at 43.51% examples, 477159 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:29,261 : INFO : EPOCH 20 - PROGRESS: at 51.87% examples, 488973 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:30,298 : INFO : EPOCH 20 - PROGRESS: at 58.39% examples, 480572 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:31,321 : INFO : EPOCH 20 - PROGRESS: at 65.18% examples, 473908 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:32,352 : INFO : EPOCH 20 - PROGRESS: at 71.81% examples, 469066 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:33,383 : INFO : EPOCH 20 - PROGRESS: at 78.97% examples, 466879 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:34,395 : INFO : EPOCH 20 - PROGRESS: at 86.99% examples, 472243 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:35,405 : INFO : EPOCH 20 - PROGRESS: at 96.23% examples, 482127 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:35,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:17:35,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:17:35,775 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:17:35,777 : INFO : EPOCH - 20 : training on 6557240 raw words (6641536 effective words) took 13.6s, 487790 effective words/s\n",
      "2019-06-26 17:17:36,808 : INFO : EPOCH 21 - PROGRESS: at 6.38% examples, 425739 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:37,808 : INFO : EPOCH 21 - PROGRESS: at 13.65% examples, 447279 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:38,823 : INFO : EPOCH 21 - PROGRESS: at 19.74% examples, 433038 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:39,853 : INFO : EPOCH 21 - PROGRESS: at 26.10% examples, 428864 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:40,861 : INFO : EPOCH 21 - PROGRESS: at 32.50% examples, 426303 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:41,873 : INFO : EPOCH 21 - PROGRESS: at 39.51% examples, 430991 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:17:42,892 : INFO : EPOCH 21 - PROGRESS: at 47.14% examples, 442174 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:43,897 : INFO : EPOCH 21 - PROGRESS: at 53.24% examples, 437873 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:44,914 : INFO : EPOCH 21 - PROGRESS: at 61.81% examples, 451401 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:45,939 : INFO : EPOCH 21 - PROGRESS: at 69.94% examples, 457004 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:46,952 : INFO : EPOCH 21 - PROGRESS: at 77.10% examples, 458357 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:47,970 : INFO : EPOCH 21 - PROGRESS: at 83.98% examples, 458352 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:48,995 : INFO : EPOCH 21 - PROGRESS: at 90.61% examples, 455348 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:49,980 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:17:49,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:17:49,989 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:17:49,990 : INFO : EPOCH - 21 : training on 6557240 raw words (6641536 effective words) took 14.2s, 467375 effective words/s\n",
      "2019-06-26 17:17:50,996 : INFO : EPOCH 22 - PROGRESS: at 5.47% examples, 379037 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:52,004 : INFO : EPOCH 22 - PROGRESS: at 13.01% examples, 447137 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:53,021 : INFO : EPOCH 22 - PROGRESS: at 20.81% examples, 465159 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:54,057 : INFO : EPOCH 22 - PROGRESS: at 28.06% examples, 462506 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:55,066 : INFO : EPOCH 22 - PROGRESS: at 36.33% examples, 480774 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:56,070 : INFO : EPOCH 22 - PROGRESS: at 44.64% examples, 491522 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:57,072 : INFO : EPOCH 22 - PROGRESS: at 53.02% examples, 499483 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:17:58,073 : INFO : EPOCH 22 - PROGRESS: at 60.80% examples, 503076 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:17:59,082 : INFO : EPOCH 22 - PROGRESS: at 67.31% examples, 494203 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:00,101 : INFO : EPOCH 22 - PROGRESS: at 73.92% examples, 486071 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:01,108 : INFO : EPOCH 22 - PROGRESS: at 83.80% examples, 501422 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:02,113 : INFO : EPOCH 22 - PROGRESS: at 91.72% examples, 502742 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:03,126 : INFO : EPOCH 22 - PROGRESS: at 99.07% examples, 500557 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:03,166 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:18:03,170 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:18:03,171 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:18:03,172 : INFO : EPOCH - 22 : training on 6557240 raw words (6641536 effective words) took 13.2s, 503917 effective words/s\n",
      "2019-06-26 17:18:04,181 : INFO : EPOCH 23 - PROGRESS: at 5.72% examples, 375200 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:05,205 : INFO : EPOCH 23 - PROGRESS: at 11.87% examples, 382948 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:06,209 : INFO : EPOCH 23 - PROGRESS: at 18.84% examples, 407823 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:07,237 : INFO : EPOCH 23 - PROGRESS: at 25.53% examples, 412945 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:08,249 : INFO : EPOCH 23 - PROGRESS: at 34.02% examples, 446584 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:09,264 : INFO : EPOCH 23 - PROGRESS: at 43.23% examples, 473763 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:10,265 : INFO : EPOCH 23 - PROGRESS: at 52.16% examples, 489941 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:11,281 : INFO : EPOCH 23 - PROGRESS: at 58.71% examples, 482679 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:12,303 : INFO : EPOCH 23 - PROGRESS: at 65.63% examples, 478966 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:13,303 : INFO : EPOCH 23 - PROGRESS: at 73.63% examples, 483925 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:14,311 : INFO : EPOCH 23 - PROGRESS: at 81.60% examples, 486968 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:15,343 : INFO : EPOCH 23 - PROGRESS: at 89.18% examples, 488388 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:16,354 : INFO : EPOCH 23 - PROGRESS: at 97.55% examples, 491921 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:16,551 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:18:16,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:18:16,557 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:18:16,557 : INFO : EPOCH - 23 : training on 6557240 raw words (6641536 effective words) took 13.4s, 496255 effective words/s\n",
      "2019-06-26 17:18:17,561 : INFO : EPOCH 24 - PROGRESS: at 7.58% examples, 497634 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:18,565 : INFO : EPOCH 24 - PROGRESS: at 14.19% examples, 477575 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:19,567 : INFO : EPOCH 24 - PROGRESS: at 21.24% examples, 477684 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:20,575 : INFO : EPOCH 24 - PROGRESS: at 28.37% examples, 477207 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:21,576 : INFO : EPOCH 24 - PROGRESS: at 34.64% examples, 469210 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:22,585 : INFO : EPOCH 24 - PROGRESS: at 41.41% examples, 463728 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:23,618 : INFO : EPOCH 24 - PROGRESS: at 48.46% examples, 460716 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:24,632 : INFO : EPOCH 24 - PROGRESS: at 54.87% examples, 453683 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:25,646 : INFO : EPOCH 24 - PROGRESS: at 63.29% examples, 465603 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:26,665 : INFO : EPOCH 24 - PROGRESS: at 71.46% examples, 471200 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:27,678 : INFO : EPOCH 24 - PROGRESS: at 77.93% examples, 467720 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:28,684 : INFO : EPOCH 24 - PROGRESS: at 85.78% examples, 471755 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:29,694 : INFO : EPOCH 24 - PROGRESS: at 92.05% examples, 466659 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:30,696 : INFO : EPOCH 24 - PROGRESS: at 99.06% examples, 465448 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:30,732 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:18:30,735 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:18:30,738 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:18:30,738 : INFO : EPOCH - 24 : training on 6557240 raw words (6641536 effective words) took 14.2s, 468432 effective words/s\n",
      "2019-06-26 17:18:31,772 : INFO : EPOCH 25 - PROGRESS: at 5.89% examples, 368422 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:32,786 : INFO : EPOCH 25 - PROGRESS: at 13.72% examples, 430376 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:33,833 : INFO : EPOCH 25 - PROGRESS: at 21.02% examples, 439819 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 17:18:34,841 : INFO : EPOCH 25 - PROGRESS: at 28.19% examples, 448491 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:35,866 : INFO : EPOCH 25 - PROGRESS: at 36.27% examples, 460140 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:36,870 : INFO : EPOCH 25 - PROGRESS: at 45.52% examples, 487112 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:37,877 : INFO : EPOCH 25 - PROGRESS: at 53.90% examples, 495206 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:38,892 : INFO : EPOCH 25 - PROGRESS: at 61.00% examples, 491120 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:39,902 : INFO : EPOCH 25 - PROGRESS: at 68.02% examples, 488053 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:40,922 : INFO : EPOCH 25 - PROGRESS: at 75.13% examples, 485258 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:41,958 : INFO : EPOCH 25 - PROGRESS: at 82.71% examples, 485012 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:18:42,989 : INFO : EPOCH 25 - PROGRESS: at 89.55% examples, 481642 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:44,009 : INFO : EPOCH 25 - PROGRESS: at 96.90% examples, 483042 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:44,345 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:18:44,354 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:18:44,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:18:44,363 : INFO : EPOCH - 25 : training on 6557240 raw words (6641536 effective words) took 13.6s, 487542 effective words/s\n",
      "2019-06-26 17:18:45,375 : INFO : EPOCH 26 - PROGRESS: at 7.50% examples, 475396 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:46,390 : INFO : EPOCH 26 - PROGRESS: at 14.87% examples, 493153 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:47,411 : INFO : EPOCH 26 - PROGRESS: at 22.05% examples, 488341 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:48,414 : INFO : EPOCH 26 - PROGRESS: at 27.95% examples, 461184 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:49,436 : INFO : EPOCH 26 - PROGRESS: at 34.22% examples, 452986 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:50,439 : INFO : EPOCH 26 - PROGRESS: at 41.34% examples, 453929 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:51,471 : INFO : EPOCH 26 - PROGRESS: at 49.19% examples, 460967 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:52,477 : INFO : EPOCH 26 - PROGRESS: at 55.56% examples, 457841 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:53,487 : INFO : EPOCH 26 - PROGRESS: at 62.44% examples, 457472 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:54,502 : INFO : EPOCH 26 - PROGRESS: at 69.03% examples, 454191 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:55,510 : INFO : EPOCH 26 - PROGRESS: at 76.18% examples, 453532 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:56,528 : INFO : EPOCH 26 - PROGRESS: at 82.51% examples, 449188 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:57,542 : INFO : EPOCH 26 - PROGRESS: at 88.22% examples, 445546 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:18:58,553 : INFO : EPOCH 26 - PROGRESS: at 95.15% examples, 445522 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:18:59,170 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:18:59,181 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:18:59,188 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:18:59,189 : INFO : EPOCH - 26 : training on 6557240 raw words (6641536 effective words) took 14.8s, 448046 effective words/s\n",
      "2019-06-26 17:19:00,209 : INFO : EPOCH 27 - PROGRESS: at 5.93% examples, 391651 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:01,223 : INFO : EPOCH 27 - PROGRESS: at 12.30% examples, 403048 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:02,239 : INFO : EPOCH 27 - PROGRESS: at 18.92% examples, 423160 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:03,249 : INFO : EPOCH 27 - PROGRESS: at 25.89% examples, 431233 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:04,256 : INFO : EPOCH 27 - PROGRESS: at 32.75% examples, 436081 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:05,267 : INFO : EPOCH 27 - PROGRESS: at 39.51% examples, 440710 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:06,268 : INFO : EPOCH 27 - PROGRESS: at 47.24% examples, 451428 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:07,274 : INFO : EPOCH 27 - PROGRESS: at 53.29% examples, 444632 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:08,281 : INFO : EPOCH 27 - PROGRESS: at 59.54% examples, 441435 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:09,294 : INFO : EPOCH 27 - PROGRESS: at 68.03% examples, 451648 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:10,295 : INFO : EPOCH 27 - PROGRESS: at 76.75% examples, 463907 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:11,297 : INFO : EPOCH 27 - PROGRESS: at 82.77% examples, 457712 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:12,320 : INFO : EPOCH 27 - PROGRESS: at 89.76% examples, 456392 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:13,334 : INFO : EPOCH 27 - PROGRESS: at 96.55% examples, 453286 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:13,744 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:19:13,752 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:19:13,758 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:19:13,758 : INFO : EPOCH - 27 : training on 6557240 raw words (6641536 effective words) took 14.6s, 455944 effective words/s\n",
      "2019-06-26 17:19:14,774 : INFO : EPOCH 28 - PROGRESS: at 6.56% examples, 442349 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:15,776 : INFO : EPOCH 28 - PROGRESS: at 13.58% examples, 454421 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:16,781 : INFO : EPOCH 28 - PROGRESS: at 20.82% examples, 464674 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:17,804 : INFO : EPOCH 28 - PROGRESS: at 28.53% examples, 470681 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:18,811 : INFO : EPOCH 28 - PROGRESS: at 34.79% examples, 458212 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:19,834 : INFO : EPOCH 28 - PROGRESS: at 42.37% examples, 464732 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:20,844 : INFO : EPOCH 28 - PROGRESS: at 49.53% examples, 467361 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:21,850 : INFO : EPOCH 28 - PROGRESS: at 58.43% examples, 483243 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:22,857 : INFO : EPOCH 28 - PROGRESS: at 64.72% examples, 474843 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:23,876 : INFO : EPOCH 28 - PROGRESS: at 71.65% examples, 472313 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:24,887 : INFO : EPOCH 28 - PROGRESS: at 78.43% examples, 469658 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:25,899 : INFO : EPOCH 28 - PROGRESS: at 85.41% examples, 469056 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:26,904 : INFO : EPOCH 28 - PROGRESS: at 92.64% examples, 469418 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 17:19:27,760 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:19:27,763 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:19:27,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:19:27,775 : INFO : EPOCH - 28 : training on 6557240 raw words (6641536 effective words) took 14.0s, 473919 effective words/s\n",
      "2019-06-26 17:19:28,782 : INFO : EPOCH 29 - PROGRESS: at 6.76% examples, 447896 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:29,790 : INFO : EPOCH 29 - PROGRESS: at 15.41% examples, 506189 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:30,791 : INFO : EPOCH 29 - PROGRESS: at 23.37% examples, 513497 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:31,813 : INFO : EPOCH 29 - PROGRESS: at 31.48% examples, 514736 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:32,831 : INFO : EPOCH 29 - PROGRESS: at 38.26% examples, 500253 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:33,833 : INFO : EPOCH 29 - PROGRESS: at 44.42% examples, 484828 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:34,848 : INFO : EPOCH 29 - PROGRESS: at 51.02% examples, 476033 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:35,850 : INFO : EPOCH 29 - PROGRESS: at 59.39% examples, 484908 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:36,867 : INFO : EPOCH 29 - PROGRESS: at 66.82% examples, 485394 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:37,871 : INFO : EPOCH 29 - PROGRESS: at 74.38% examples, 487619 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:38,882 : INFO : EPOCH 29 - PROGRESS: at 82.78% examples, 496177 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:39,897 : INFO : EPOCH 29 - PROGRESS: at 90.91% examples, 500655 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:40,913 : INFO : EPOCH 29 - PROGRESS: at 97.63% examples, 494744 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:41,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:19:41,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:19:41,071 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:19:41,072 : INFO : EPOCH - 29 : training on 6557240 raw words (6641536 effective words) took 13.3s, 499569 effective words/s\n",
      "2019-06-26 17:19:42,086 : INFO : EPOCH 30 - PROGRESS: at 5.73% examples, 393628 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:43,098 : INFO : EPOCH 30 - PROGRESS: at 13.88% examples, 458239 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:44,120 : INFO : EPOCH 30 - PROGRESS: at 22.64% examples, 497400 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:45,134 : INFO : EPOCH 30 - PROGRESS: at 31.29% examples, 511094 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:46,151 : INFO : EPOCH 30 - PROGRESS: at 38.14% examples, 497297 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:47,172 : INFO : EPOCH 30 - PROGRESS: at 45.08% examples, 487817 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:48,193 : INFO : EPOCH 30 - PROGRESS: at 52.45% examples, 486466 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:49,214 : INFO : EPOCH 30 - PROGRESS: at 59.16% examples, 480698 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:50,223 : INFO : EPOCH 30 - PROGRESS: at 65.86% examples, 476787 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:51,225 : INFO : EPOCH 30 - PROGRESS: at 72.87% examples, 475857 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:52,245 : INFO : EPOCH 30 - PROGRESS: at 79.89% examples, 475347 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:53,278 : INFO : EPOCH 30 - PROGRESS: at 85.72% examples, 466964 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:19:54,289 : INFO : EPOCH 30 - PROGRESS: at 92.39% examples, 464387 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:19:55,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:19:55,268 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:19:55,274 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:19:55,275 : INFO : EPOCH - 30 : training on 6557240 raw words (6641536 effective words) took 14.2s, 467678 effective words/s\n",
      "2019-06-26 17:19:55,276 : INFO : training on a 196717200 raw words (199246080 effective words) took 420.4s, 473976 effective words/s\n",
      "2019-06-26 17:19:55,282 : INFO : collecting all words and their counts\n",
      "2019-06-26 17:19:55,302 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [doc2vec dbow]: 0:07:05.432712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:19:55,841 : INFO : PROGRESS: at example #10000, processed 769107 words (1429876/s), 20976 word types, 2141 tags\n",
      "2019-06-26 17:19:56,340 : INFO : PROGRESS: at example #20000, processed 1525244 words (1517898/s), 28526 word types, 3501 tags\n",
      "2019-06-26 17:19:56,836 : INFO : PROGRESS: at example #30000, processed 2289251 words (1542602/s), 32810 word types, 4549 tags\n",
      "2019-06-26 17:19:57,334 : INFO : PROGRESS: at example #40000, processed 3067423 words (1567663/s), 35082 word types, 5341 tags\n",
      "2019-06-26 17:19:57,837 : INFO : PROGRESS: at example #50000, processed 3843979 words (1544550/s), 36582 word types, 5946 tags\n",
      "2019-06-26 17:19:58,335 : INFO : PROGRESS: at example #60000, processed 4626312 words (1573650/s), 37319 word types, 6408 tags\n",
      "2019-06-26 17:19:58,829 : INFO : PROGRESS: at example #70000, processed 5366029 words (1501829/s), 37702 word types, 6758 tags\n",
      "2019-06-26 17:19:59,333 : INFO : PROGRESS: at example #80000, processed 6121569 words (1502776/s), 37993 word types, 7090 tags\n",
      "2019-06-26 17:19:59,607 : INFO : collected 38071 word types and 7236 unique tags from a corpus of 85466 examples and 6557240 words\n",
      "2019-06-26 17:19:59,608 : INFO : Loading a fresh vocabulary\n",
      "2019-06-26 17:20:00,085 : INFO : effective_min_count=1 retains 38071 unique words (100% of original 38071, drops 0)\n",
      "2019-06-26 17:20:00,086 : INFO : effective_min_count=1 leaves 6557240 word corpus (100% of original 6557240, drops 0)\n",
      "2019-06-26 17:20:00,172 : INFO : deleting the raw counts dictionary of 38071 items\n",
      "2019-06-26 17:20:00,174 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2019-06-26 17:20:00,175 : INFO : downsampling leaves estimated 5593924 word corpus (85.3% of prior 6557240)\n",
      "2019-06-26 17:20:00,282 : INFO : estimated required memory for 38071 words and 300 dimensions: 120536300 bytes\n",
      "2019-06-26 17:20:00,283 : INFO : resetting layer weights\n",
      "2019-06-26 17:20:00,680 : INFO : training model with 3 workers on 38071 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-06-26 17:20:01,691 : INFO : EPOCH 1 - PROGRESS: at 6.48% examples, 354047 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:02,702 : INFO : EPOCH 1 - PROGRESS: at 11.32% examples, 315972 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:03,732 : INFO : EPOCH 1 - PROGRESS: at 17.03% examples, 318247 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:04,734 : INFO : EPOCH 1 - PROGRESS: at 21.60% examples, 304726 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:05,765 : INFO : EPOCH 1 - PROGRESS: at 28.35% examples, 313597 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:06,771 : INFO : EPOCH 1 - PROGRESS: at 35.11% examples, 326365 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:07,777 : INFO : EPOCH 1 - PROGRESS: at 41.19% examples, 329557 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:08,803 : INFO : EPOCH 1 - PROGRESS: at 49.27% examples, 342483 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:09,828 : INFO : EPOCH 1 - PROGRESS: at 56.85% examples, 351708 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:10,848 : INFO : EPOCH 1 - PROGRESS: at 63.38% examples, 355101 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:11,862 : INFO : EPOCH 1 - PROGRESS: at 68.42% examples, 348897 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:12,885 : INFO : EPOCH 1 - PROGRESS: at 73.45% examples, 342784 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:13,888 : INFO : EPOCH 1 - PROGRESS: at 79.37% examples, 341976 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:14,892 : INFO : EPOCH 1 - PROGRESS: at 86.47% examples, 346128 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:15,898 : INFO : EPOCH 1 - PROGRESS: at 91.97% examples, 344583 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:16,907 : INFO : EPOCH 1 - PROGRESS: at 97.46% examples, 341678 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:17,238 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:20:17,242 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:20:17,258 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:20:17,258 : INFO : EPOCH - 1 : training on 6557240 raw words (5678779 effective words) took 16.6s, 342601 effective words/s\n",
      "2019-06-26 17:20:18,288 : INFO : EPOCH 2 - PROGRESS: at 5.69% examples, 299352 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:19,295 : INFO : EPOCH 2 - PROGRESS: at 13.36% examples, 368504 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:20,311 : INFO : EPOCH 2 - PROGRESS: at 19.37% examples, 352581 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:21,328 : INFO : EPOCH 2 - PROGRESS: at 24.63% examples, 339682 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:22,329 : INFO : EPOCH 2 - PROGRESS: at 29.64% examples, 331464 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:23,337 : INFO : EPOCH 2 - PROGRESS: at 34.68% examples, 325708 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:24,357 : INFO : EPOCH 2 - PROGRESS: at 40.22% examples, 322095 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:25,365 : INFO : EPOCH 2 - PROGRESS: at 47.14% examples, 330332 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:26,403 : INFO : EPOCH 2 - PROGRESS: at 54.98% examples, 341362 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:27,406 : INFO : EPOCH 2 - PROGRESS: at 62.28% examples, 349543 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:28,407 : INFO : EPOCH 2 - PROGRESS: at 70.18% examples, 359598 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:29,415 : INFO : EPOCH 2 - PROGRESS: at 78.19% examples, 367844 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:30,417 : INFO : EPOCH 2 - PROGRESS: at 83.84% examples, 363231 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:31,425 : INFO : EPOCH 2 - PROGRESS: at 90.70% examples, 365108 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:32,450 : INFO : EPOCH 2 - PROGRESS: at 96.25% examples, 360084 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:32,906 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:20:32,920 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:20:32,922 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:20:32,922 : INFO : EPOCH - 2 : training on 6557240 raw words (5679305 effective words) took 15.7s, 362627 effective words/s\n",
      "2019-06-26 17:20:33,940 : INFO : EPOCH 3 - PROGRESS: at 5.90% examples, 337427 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:34,987 : INFO : EPOCH 3 - PROGRESS: at 11.25% examples, 311260 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:35,994 : INFO : EPOCH 3 - PROGRESS: at 16.87% examples, 317778 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:37,021 : INFO : EPOCH 3 - PROGRESS: at 25.24% examples, 350775 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:38,051 : INFO : EPOCH 3 - PROGRESS: at 30.53% examples, 338288 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:39,073 : INFO : EPOCH 3 - PROGRESS: at 35.59% examples, 329269 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:40,123 : INFO : EPOCH 3 - PROGRESS: at 40.98% examples, 325230 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:41,125 : INFO : EPOCH 3 - PROGRESS: at 46.18% examples, 321824 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:42,148 : INFO : EPOCH 3 - PROGRESS: at 51.57% examples, 318488 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:43,159 : INFO : EPOCH 3 - PROGRESS: at 57.38% examples, 318746 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:44,164 : INFO : EPOCH 3 - PROGRESS: at 63.22% examples, 320491 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:45,176 : INFO : EPOCH 3 - PROGRESS: at 69.83% examples, 324626 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:46,183 : INFO : EPOCH 3 - PROGRESS: at 74.78% examples, 321789 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:47,186 : INFO : EPOCH 3 - PROGRESS: at 81.72% examples, 326698 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:48,208 : INFO : EPOCH 3 - PROGRESS: at 86.96% examples, 324446 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:49,245 : INFO : EPOCH 3 - PROGRESS: at 92.04% examples, 321103 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:50,270 : INFO : EPOCH 3 - PROGRESS: at 98.72% examples, 323238 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:20:50,359 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:20:50,360 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:20:50,361 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:20:50,362 : INFO : EPOCH - 3 : training on 6557240 raw words (5679245 effective words) took 17.4s, 325685 effective words/s\n",
      "2019-06-26 17:20:51,365 : INFO : EPOCH 4 - PROGRESS: at 5.98% examples, 342070 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:52,375 : INFO : EPOCH 4 - PROGRESS: at 11.52% examples, 322969 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:53,402 : INFO : EPOCH 4 - PROGRESS: at 18.61% examples, 348292 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:54,455 : INFO : EPOCH 4 - PROGRESS: at 25.08% examples, 348412 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:55,465 : INFO : EPOCH 4 - PROGRESS: at 30.44% examples, 338280 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:56,468 : INFO : EPOCH 4 - PROGRESS: at 35.75% examples, 331396 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:57,471 : INFO : EPOCH 4 - PROGRESS: at 40.66% examples, 324407 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:20:58,481 : INFO : EPOCH 4 - PROGRESS: at 45.46% examples, 317755 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:20:59,486 : INFO : EPOCH 4 - PROGRESS: at 53.02% examples, 331371 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:00,499 : INFO : EPOCH 4 - PROGRESS: at 58.46% examples, 328457 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:01,507 : INFO : EPOCH 4 - PROGRESS: at 63.95% examples, 326277 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:02,511 : INFO : EPOCH 4 - PROGRESS: at 71.61% examples, 334445 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:03,514 : INFO : EPOCH 4 - PROGRESS: at 79.64% examples, 343980 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:04,519 : INFO : EPOCH 4 - PROGRESS: at 86.83% examples, 348549 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:05,530 : INFO : EPOCH 4 - PROGRESS: at 94.46% examples, 354045 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:06,135 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:21:06,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:21:06,141 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:21:06,142 : INFO : EPOCH - 4 : training on 6557240 raw words (5678975 effective words) took 15.8s, 359935 effective words/s\n",
      "2019-06-26 17:21:07,157 : INFO : EPOCH 5 - PROGRESS: at 6.98% examples, 377153 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:08,167 : INFO : EPOCH 5 - PROGRESS: at 13.65% examples, 387166 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:09,187 : INFO : EPOCH 5 - PROGRESS: at 19.06% examples, 352665 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:10,203 : INFO : EPOCH 5 - PROGRESS: at 25.22% examples, 348775 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:11,243 : INFO : EPOCH 5 - PROGRESS: at 32.24% examples, 354673 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:12,250 : INFO : EPOCH 5 - PROGRESS: at 37.42% examples, 343709 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:13,270 : INFO : EPOCH 5 - PROGRESS: at 43.04% examples, 340109 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:14,280 : INFO : EPOCH 5 - PROGRESS: at 48.12% examples, 333365 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:15,299 : INFO : EPOCH 5 - PROGRESS: at 53.19% examples, 327121 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:16,308 : INFO : EPOCH 5 - PROGRESS: at 58.15% examples, 322451 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:17,315 : INFO : EPOCH 5 - PROGRESS: at 64.20% examples, 323970 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:18,319 : INFO : EPOCH 5 - PROGRESS: at 69.92% examples, 323864 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:19,341 : INFO : EPOCH 5 - PROGRESS: at 75.39% examples, 322806 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:20,362 : INFO : EPOCH 5 - PROGRESS: at 81.77% examples, 325367 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:21,396 : INFO : EPOCH 5 - PROGRESS: at 86.65% examples, 322312 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:22,418 : INFO : EPOCH 5 - PROGRESS: at 91.58% examples, 319300 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:23,419 : INFO : EPOCH 5 - PROGRESS: at 97.56% examples, 320561 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:23,643 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:21:23,654 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:21:23,663 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:21:23,664 : INFO : EPOCH - 5 : training on 6557240 raw words (5679206 effective words) took 17.5s, 324164 effective words/s\n",
      "2019-06-26 17:21:24,667 : INFO : EPOCH 6 - PROGRESS: at 6.23% examples, 366458 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:25,701 : INFO : EPOCH 6 - PROGRESS: at 11.06% examples, 311071 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:26,716 : INFO : EPOCH 6 - PROGRESS: at 16.25% examples, 302868 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:27,741 : INFO : EPOCH 6 - PROGRESS: at 21.07% examples, 293765 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:28,746 : INFO : EPOCH 6 - PROGRESS: at 25.77% examples, 289241 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:29,762 : INFO : EPOCH 6 - PROGRESS: at 31.03% examples, 290212 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:30,778 : INFO : EPOCH 6 - PROGRESS: at 36.64% examples, 290969 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:31,789 : INFO : EPOCH 6 - PROGRESS: at 42.55% examples, 294443 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:32,818 : INFO : EPOCH 6 - PROGRESS: at 49.14% examples, 302399 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:33,841 : INFO : EPOCH 6 - PROGRESS: at 54.21% examples, 301348 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:34,850 : INFO : EPOCH 6 - PROGRESS: at 61.37% examples, 309239 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:35,859 : INFO : EPOCH 6 - PROGRESS: at 67.95% examples, 314380 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:36,889 : INFO : EPOCH 6 - PROGRESS: at 76.37% examples, 327995 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:37,897 : INFO : EPOCH 6 - PROGRESS: at 83.27% examples, 332928 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:38,930 : INFO : EPOCH 6 - PROGRESS: at 90.49% examples, 336591 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:39,949 : INFO : EPOCH 6 - PROGRESS: at 95.95% examples, 334913 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:40,538 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:21:40,542 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:21:40,552 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:21:40,552 : INFO : EPOCH - 6 : training on 6557240 raw words (5678870 effective words) took 16.9s, 336311 effective words/s\n",
      "2019-06-26 17:21:41,585 : INFO : EPOCH 7 - PROGRESS: at 5.24% examples, 280556 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:42,591 : INFO : EPOCH 7 - PROGRESS: at 13.12% examples, 360321 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:43,612 : INFO : EPOCH 7 - PROGRESS: at 21.50% examples, 398370 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:44,613 : INFO : EPOCH 7 - PROGRESS: at 27.27% examples, 384094 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:45,630 : INFO : EPOCH 7 - PROGRESS: at 33.58% examples, 377653 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:46,632 : INFO : EPOCH 7 - PROGRESS: at 41.32% examples, 385770 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:47,642 : INFO : EPOCH 7 - PROGRESS: at 48.65% examples, 389830 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:48,659 : INFO : EPOCH 7 - PROGRESS: at 54.62% examples, 381889 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:49,660 : INFO : EPOCH 7 - PROGRESS: at 59.88% examples, 372584 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:50,691 : INFO : EPOCH 7 - PROGRESS: at 65.21% examples, 364145 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:21:51,716 : INFO : EPOCH 7 - PROGRESS: at 70.25% examples, 355921 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:52,724 : INFO : EPOCH 7 - PROGRESS: at 75.57% examples, 351679 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:53,739 : INFO : EPOCH 7 - PROGRESS: at 81.36% examples, 350550 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:54,770 : INFO : EPOCH 7 - PROGRESS: at 89.08% examples, 356482 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:55,792 : INFO : EPOCH 7 - PROGRESS: at 96.99% examples, 361746 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:21:56,068 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:21:56,077 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:21:56,082 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:21:56,083 : INFO : EPOCH - 7 : training on 6557240 raw words (5679751 effective words) took 15.5s, 365800 effective words/s\n",
      "2019-06-26 17:21:57,090 : INFO : EPOCH 8 - PROGRESS: at 5.23% examples, 297689 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:58,113 : INFO : EPOCH 8 - PROGRESS: at 10.56% examples, 294556 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:21:59,128 : INFO : EPOCH 8 - PROGRESS: at 16.08% examples, 302713 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:00,135 : INFO : EPOCH 8 - PROGRESS: at 21.39% examples, 299195 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:01,145 : INFO : EPOCH 8 - PROGRESS: at 27.46% examples, 309986 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:02,170 : INFO : EPOCH 8 - PROGRESS: at 32.80% examples, 308340 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:03,185 : INFO : EPOCH 8 - PROGRESS: at 40.11% examples, 322019 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:04,194 : INFO : EPOCH 8 - PROGRESS: at 47.43% examples, 332427 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:05,195 : INFO : EPOCH 8 - PROGRESS: at 55.42% examples, 346553 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:06,197 : INFO : EPOCH 8 - PROGRESS: at 62.96% examples, 353602 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:07,208 : INFO : EPOCH 8 - PROGRESS: at 70.91% examples, 362222 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:08,234 : INFO : EPOCH 8 - PROGRESS: at 76.79% examples, 359258 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:09,238 : INFO : EPOCH 8 - PROGRESS: at 82.65% examples, 357135 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:10,242 : INFO : EPOCH 8 - PROGRESS: at 87.60% examples, 351659 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:11,276 : INFO : EPOCH 8 - PROGRESS: at 93.27% examples, 347944 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:12,308 : INFO : EPOCH 8 - PROGRESS: at 97.96% examples, 343098 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:12,550 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:22:12,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:22:12,561 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:22:12,562 : INFO : EPOCH - 8 : training on 6557240 raw words (5679462 effective words) took 16.5s, 344673 effective words/s\n",
      "2019-06-26 17:22:13,573 : INFO : EPOCH 9 - PROGRESS: at 4.74% examples, 269330 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:14,575 : INFO : EPOCH 9 - PROGRESS: at 12.77% examples, 359968 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:15,601 : INFO : EPOCH 9 - PROGRESS: at 20.80% examples, 390151 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:16,610 : INFO : EPOCH 9 - PROGRESS: at 26.63% examples, 372963 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:17,630 : INFO : EPOCH 9 - PROGRESS: at 31.73% examples, 355348 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:18,664 : INFO : EPOCH 9 - PROGRESS: at 37.95% examples, 353861 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:19,677 : INFO : EPOCH 9 - PROGRESS: at 45.49% examples, 364577 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:20,702 : INFO : EPOCH 9 - PROGRESS: at 50.61% examples, 353194 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:21,729 : INFO : EPOCH 9 - PROGRESS: at 56.85% examples, 351968 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:22,733 : INFO : EPOCH 9 - PROGRESS: at 64.74% examples, 361611 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:23,760 : INFO : EPOCH 9 - PROGRESS: at 72.75% examples, 368904 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:24,782 : INFO : EPOCH 9 - PROGRESS: at 77.69% examples, 361151 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:25,797 : INFO : EPOCH 9 - PROGRESS: at 82.89% examples, 356058 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:26,808 : INFO : EPOCH 9 - PROGRESS: at 89.55% examples, 357783 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:27,809 : INFO : EPOCH 9 - PROGRESS: at 97.54% examples, 363375 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:28,038 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:22:28,046 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:22:28,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:22:28,049 : INFO : EPOCH - 9 : training on 6557240 raw words (5679894 effective words) took 15.5s, 366788 effective words/s\n",
      "2019-06-26 17:22:29,067 : INFO : EPOCH 10 - PROGRESS: at 5.73% examples, 321433 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:30,069 : INFO : EPOCH 10 - PROGRESS: at 10.58% examples, 309752 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:31,082 : INFO : EPOCH 10 - PROGRESS: at 15.73% examples, 301699 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:32,084 : INFO : EPOCH 10 - PROGRESS: at 20.91% examples, 294793 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:33,089 : INFO : EPOCH 10 - PROGRESS: at 26.29% examples, 295675 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:34,116 : INFO : EPOCH 10 - PROGRESS: at 31.51% examples, 294816 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:35,136 : INFO : EPOCH 10 - PROGRESS: at 36.88% examples, 293259 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:36,171 : INFO : EPOCH 10 - PROGRESS: at 41.89% examples, 290613 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:37,176 : INFO : EPOCH 10 - PROGRESS: at 47.21% examples, 293155 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:38,201 : INFO : EPOCH 10 - PROGRESS: at 54.99% examples, 305634 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:39,207 : INFO : EPOCH 10 - PROGRESS: at 63.59% examples, 321603 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:40,229 : INFO : EPOCH 10 - PROGRESS: at 69.14% examples, 319888 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:41,275 : INFO : EPOCH 10 - PROGRESS: at 75.92% examples, 324829 words/s, in_qsize 4, out_qsize 1\n",
      "2019-06-26 17:22:42,303 : INFO : EPOCH 10 - PROGRESS: at 81.55% examples, 324720 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:43,316 : INFO : EPOCH 10 - PROGRESS: at 86.82% examples, 323240 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:44,351 : INFO : EPOCH 10 - PROGRESS: at 92.51% examples, 322112 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:45,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:22:45,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:22:45,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:22:45,336 : INFO : EPOCH - 10 : training on 6557240 raw words (5679465 effective words) took 17.3s, 328629 effective words/s\n",
      "2019-06-26 17:22:46,352 : INFO : EPOCH 11 - PROGRESS: at 4.65% examples, 261206 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:47,376 : INFO : EPOCH 11 - PROGRESS: at 9.68% examples, 268310 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:48,399 : INFO : EPOCH 11 - PROGRESS: at 14.70% examples, 267551 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:49,412 : INFO : EPOCH 11 - PROGRESS: at 20.09% examples, 276198 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:50,421 : INFO : EPOCH 11 - PROGRESS: at 25.61% examples, 281914 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:51,442 : INFO : EPOCH 11 - PROGRESS: at 31.80% examples, 291938 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:22:52,460 : INFO : EPOCH 11 - PROGRESS: at 38.81% examples, 306469 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:53,466 : INFO : EPOCH 11 - PROGRESS: at 44.82% examples, 311654 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:54,466 : INFO : EPOCH 11 - PROGRESS: at 51.21% examples, 318744 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:55,484 : INFO : EPOCH 11 - PROGRESS: at 56.55% examples, 316354 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:56,514 : INFO : EPOCH 11 - PROGRESS: at 62.98% examples, 320205 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:57,541 : INFO : EPOCH 11 - PROGRESS: at 68.58% examples, 318973 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:22:58,557 : INFO : EPOCH 11 - PROGRESS: at 76.37% examples, 328594 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:22:59,570 : INFO : EPOCH 11 - PROGRESS: at 82.33% examples, 329173 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:00,605 : INFO : EPOCH 11 - PROGRESS: at 89.86% examples, 334707 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:01,630 : INFO : EPOCH 11 - PROGRESS: at 95.28% examples, 332068 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:02,431 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:23:02,434 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:23:02,438 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:23:02,438 : INFO : EPOCH - 11 : training on 6557240 raw words (5679243 effective words) took 17.1s, 332113 effective words/s\n",
      "2019-06-26 17:23:03,444 : INFO : EPOCH 12 - PROGRESS: at 4.47% examples, 263038 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:04,465 : INFO : EPOCH 12 - PROGRESS: at 9.84% examples, 281657 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:05,475 : INFO : EPOCH 12 - PROGRESS: at 15.56% examples, 288966 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:06,491 : INFO : EPOCH 12 - PROGRESS: at 22.08% examples, 307569 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:07,510 : INFO : EPOCH 12 - PROGRESS: at 28.52% examples, 316284 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:08,520 : INFO : EPOCH 12 - PROGRESS: at 36.42% examples, 336626 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:09,549 : INFO : EPOCH 12 - PROGRESS: at 41.65% examples, 332412 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:10,552 : INFO : EPOCH 12 - PROGRESS: at 49.05% examples, 343892 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:11,557 : INFO : EPOCH 12 - PROGRESS: at 54.68% examples, 339630 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:12,574 : INFO : EPOCH 12 - PROGRESS: at 60.87% examples, 340903 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:13,620 : INFO : EPOCH 12 - PROGRESS: at 66.89% examples, 338658 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:14,621 : INFO : EPOCH 12 - PROGRESS: at 72.95% examples, 338902 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:15,625 : INFO : EPOCH 12 - PROGRESS: at 79.50% examples, 342164 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:16,635 : INFO : EPOCH 12 - PROGRESS: at 88.06% examples, 352131 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:17,647 : INFO : EPOCH 12 - PROGRESS: at 94.17% examples, 351739 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:18,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:23:18,364 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:23:18,367 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:23:18,368 : INFO : EPOCH - 12 : training on 6557240 raw words (5679899 effective words) took 15.9s, 356613 effective words/s\n",
      "2019-06-26 17:23:19,369 : INFO : EPOCH 13 - PROGRESS: at 6.18% examples, 333678 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:20,384 : INFO : EPOCH 13 - PROGRESS: at 13.38% examples, 368747 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:21,385 : INFO : EPOCH 13 - PROGRESS: at 18.24% examples, 339297 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:22,413 : INFO : EPOCH 13 - PROGRESS: at 23.82% examples, 328770 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:23,424 : INFO : EPOCH 13 - PROGRESS: at 29.23% examples, 322180 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:24,426 : INFO : EPOCH 13 - PROGRESS: at 35.79% examples, 329796 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:25,441 : INFO : EPOCH 13 - PROGRESS: at 44.66% examples, 351397 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:26,458 : INFO : EPOCH 13 - PROGRESS: at 50.01% examples, 346087 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:27,461 : INFO : EPOCH 13 - PROGRESS: at 55.76% examples, 345475 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:28,465 : INFO : EPOCH 13 - PROGRESS: at 61.86% examples, 345767 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:29,468 : INFO : EPOCH 13 - PROGRESS: at 68.55% examples, 348287 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:30,494 : INFO : EPOCH 13 - PROGRESS: at 76.52% examples, 356121 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:31,521 : INFO : EPOCH 13 - PROGRESS: at 83.30% examples, 358054 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:32,550 : INFO : EPOCH 13 - PROGRESS: at 89.81% examples, 359743 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:33,558 : INFO : EPOCH 13 - PROGRESS: at 95.35% examples, 357227 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:34,263 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:23:34,274 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:23:34,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:23:34,280 : INFO : EPOCH - 13 : training on 6557240 raw words (5679069 effective words) took 15.9s, 356941 effective words/s\n",
      "2019-06-26 17:23:35,282 : INFO : EPOCH 14 - PROGRESS: at 4.93% examples, 272500 words/s, in_qsize 4, out_qsize 1\n",
      "2019-06-26 17:23:36,297 : INFO : EPOCH 14 - PROGRESS: at 10.86% examples, 300499 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:37,304 : INFO : EPOCH 14 - PROGRESS: at 18.81% examples, 349788 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:38,332 : INFO : EPOCH 14 - PROGRESS: at 25.04% examples, 349237 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:39,355 : INFO : EPOCH 14 - PROGRESS: at 30.53% examples, 341247 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:40,358 : INFO : EPOCH 14 - PROGRESS: at 35.69% examples, 335544 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:41,361 : INFO : EPOCH 14 - PROGRESS: at 41.40% examples, 336270 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:42,375 : INFO : EPOCH 14 - PROGRESS: at 47.85% examples, 337365 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:43,378 : INFO : EPOCH 14 - PROGRESS: at 53.68% examples, 337815 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:44,386 : INFO : EPOCH 14 - PROGRESS: at 61.03% examples, 344714 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:45,389 : INFO : EPOCH 14 - PROGRESS: at 68.49% examples, 351269 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:46,403 : INFO : EPOCH 14 - PROGRESS: at 74.90% examples, 352254 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:47,419 : INFO : EPOCH 14 - PROGRESS: at 80.00% examples, 345893 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:48,422 : INFO : EPOCH 14 - PROGRESS: at 86.17% examples, 346752 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:49,429 : INFO : EPOCH 14 - PROGRESS: at 91.81% examples, 345046 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:50,469 : INFO : EPOCH 14 - PROGRESS: at 97.02% examples, 340796 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:50,785 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:23:50,786 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:23:50,807 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:23:50,808 : INFO : EPOCH - 14 : training on 6557240 raw words (5679103 effective words) took 16.5s, 343639 effective words/s\n",
      "2019-06-26 17:23:51,836 : INFO : EPOCH 15 - PROGRESS: at 7.21% examples, 399292 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:52,848 : INFO : EPOCH 15 - PROGRESS: at 13.64% examples, 376460 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:23:53,852 : INFO : EPOCH 15 - PROGRESS: at 18.25% examples, 339183 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:54,860 : INFO : EPOCH 15 - PROGRESS: at 23.73% examples, 330764 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:55,864 : INFO : EPOCH 15 - PROGRESS: at 28.74% examples, 322476 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:56,872 : INFO : EPOCH 15 - PROGRESS: at 34.27% examples, 319487 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:23:57,912 : INFO : EPOCH 15 - PROGRESS: at 39.59% examples, 313426 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:58,925 : INFO : EPOCH 15 - PROGRESS: at 46.90% examples, 326704 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:23:59,926 : INFO : EPOCH 15 - PROGRESS: at 54.88% examples, 339556 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:00,939 : INFO : EPOCH 15 - PROGRESS: at 61.66% examples, 343599 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:01,948 : INFO : EPOCH 15 - PROGRESS: at 68.93% examples, 350846 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:02,956 : INFO : EPOCH 15 - PROGRESS: at 75.25% examples, 350557 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:03,959 : INFO : EPOCH 15 - PROGRESS: at 82.07% examples, 353642 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:04,987 : INFO : EPOCH 15 - PROGRESS: at 86.87% examples, 347266 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:06,000 : INFO : EPOCH 15 - PROGRESS: at 92.86% examples, 345988 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:07,014 : INFO : EPOCH 15 - PROGRESS: at 97.63% examples, 342174 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:07,307 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:24:07,325 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:24:07,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:24:07,327 : INFO : EPOCH - 15 : training on 6557240 raw words (5678740 effective words) took 16.5s, 343827 effective words/s\n",
      "2019-06-26 17:24:08,359 : INFO : EPOCH 16 - PROGRESS: at 5.51% examples, 297481 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:09,381 : INFO : EPOCH 16 - PROGRESS: at 10.66% examples, 294944 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:10,390 : INFO : EPOCH 16 - PROGRESS: at 16.16% examples, 295152 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:11,402 : INFO : EPOCH 16 - PROGRESS: at 21.84% examples, 301540 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:12,402 : INFO : EPOCH 16 - PROGRESS: at 30.10% examples, 334743 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:13,415 : INFO : EPOCH 16 - PROGRESS: at 37.31% examples, 346379 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:14,438 : INFO : EPOCH 16 - PROGRESS: at 42.40% examples, 337421 words/s, in_qsize 4, out_qsize 1\n",
      "2019-06-26 17:24:15,439 : INFO : EPOCH 16 - PROGRESS: at 48.39% examples, 336822 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:16,481 : INFO : EPOCH 16 - PROGRESS: at 54.36% examples, 337778 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:17,513 : INFO : EPOCH 16 - PROGRESS: at 62.54% examples, 348104 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:18,514 : INFO : EPOCH 16 - PROGRESS: at 67.98% examples, 344259 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:19,520 : INFO : EPOCH 16 - PROGRESS: at 75.86% examples, 353472 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:20,541 : INFO : EPOCH 16 - PROGRESS: at 82.72% examples, 355861 words/s, in_qsize 6, out_qsize 1\n",
      "2019-06-26 17:24:21,565 : INFO : EPOCH 16 - PROGRESS: at 90.08% examples, 359031 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:22,570 : INFO : EPOCH 16 - PROGRESS: at 96.16% examples, 357777 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:22,975 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:24:22,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:24:22,985 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:24:22,985 : INFO : EPOCH - 16 : training on 6557240 raw words (5679655 effective words) took 15.7s, 362757 effective words/s\n",
      "2019-06-26 17:24:23,989 : INFO : EPOCH 17 - PROGRESS: at 6.61% examples, 382267 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:24,995 : INFO : EPOCH 17 - PROGRESS: at 14.27% examples, 407921 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:26,019 : INFO : EPOCH 17 - PROGRESS: at 22.49% examples, 419416 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:27,050 : INFO : EPOCH 17 - PROGRESS: at 28.67% examples, 397131 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:28,074 : INFO : EPOCH 17 - PROGRESS: at 34.44% examples, 379211 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:29,076 : INFO : EPOCH 17 - PROGRESS: at 40.36% examples, 370105 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:30,092 : INFO : EPOCH 17 - PROGRESS: at 47.32% examples, 373756 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:31,095 : INFO : EPOCH 17 - PROGRESS: at 54.82% examples, 381282 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:32,120 : INFO : EPOCH 17 - PROGRESS: at 61.56% examples, 380636 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:33,133 : INFO : EPOCH 17 - PROGRESS: at 68.73% examples, 381923 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:34,141 : INFO : EPOCH 17 - PROGRESS: at 76.27% examples, 385575 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:35,142 : INFO : EPOCH 17 - PROGRESS: at 81.64% examples, 379102 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:36,157 : INFO : EPOCH 17 - PROGRESS: at 87.58% examples, 375745 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:37,166 : INFO : EPOCH 17 - PROGRESS: at 95.33% examples, 380268 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:37,819 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:24:37,820 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:24:37,827 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:24:37,828 : INFO : EPOCH - 17 : training on 6557240 raw words (5678451 effective words) took 14.8s, 382618 effective words/s\n",
      "2019-06-26 17:24:38,831 : INFO : EPOCH 18 - PROGRESS: at 4.70% examples, 274278 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:39,832 : INFO : EPOCH 18 - PROGRESS: at 10.93% examples, 315806 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:40,858 : INFO : EPOCH 18 - PROGRESS: at 19.52% examples, 366868 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:41,903 : INFO : EPOCH 18 - PROGRESS: at 26.31% examples, 368845 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:42,914 : INFO : EPOCH 18 - PROGRESS: at 32.70% examples, 367577 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:43,940 : INFO : EPOCH 18 - PROGRESS: at 37.83% examples, 354587 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:44,945 : INFO : EPOCH 18 - PROGRESS: at 45.71% examples, 365617 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:45,971 : INFO : EPOCH 18 - PROGRESS: at 52.95% examples, 369972 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:46,988 : INFO : EPOCH 18 - PROGRESS: at 59.18% examples, 366282 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:48,014 : INFO : EPOCH 18 - PROGRESS: at 63.59% examples, 353732 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:49,026 : INFO : EPOCH 18 - PROGRESS: at 69.47% examples, 351466 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:50,028 : INFO : EPOCH 18 - PROGRESS: at 77.46% examples, 359573 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:51,045 : INFO : EPOCH 18 - PROGRESS: at 84.26% examples, 361612 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:52,079 : INFO : EPOCH 18 - PROGRESS: at 90.27% examples, 359855 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:53,080 : INFO : EPOCH 18 - PROGRESS: at 96.65% examples, 360858 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:53,592 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:24:53,596 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:24:53,606 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:24:53,607 : INFO : EPOCH - 18 : training on 6557240 raw words (5680323 effective words) took 15.8s, 360057 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:24:54,616 : INFO : EPOCH 19 - PROGRESS: at 5.04% examples, 280435 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:55,639 : INFO : EPOCH 19 - PROGRESS: at 10.61% examples, 303106 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:24:56,659 : INFO : EPOCH 19 - PROGRESS: at 17.50% examples, 324574 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:57,672 : INFO : EPOCH 19 - PROGRESS: at 22.49% examples, 315083 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:58,697 : INFO : EPOCH 19 - PROGRESS: at 27.76% examples, 311767 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:24:59,703 : INFO : EPOCH 19 - PROGRESS: at 35.20% examples, 330331 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:00,710 : INFO : EPOCH 19 - PROGRESS: at 40.19% examples, 324144 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:01,736 : INFO : EPOCH 19 - PROGRESS: at 45.97% examples, 324269 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:02,747 : INFO : EPOCH 19 - PROGRESS: at 51.92% examples, 326412 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:03,748 : INFO : EPOCH 19 - PROGRESS: at 57.22% examples, 324492 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:04,751 : INFO : EPOCH 19 - PROGRESS: at 64.38% examples, 330567 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:05,765 : INFO : EPOCH 19 - PROGRESS: at 71.43% examples, 335307 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:06,779 : INFO : EPOCH 19 - PROGRESS: at 76.68% examples, 332214 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:07,801 : INFO : EPOCH 19 - PROGRESS: at 83.60% examples, 335882 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:08,805 : INFO : EPOCH 19 - PROGRESS: at 91.91% examples, 343543 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:09,820 : INFO : EPOCH 19 - PROGRESS: at 97.84% examples, 342601 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:10,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:25:10,101 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:25:10,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:25:10,109 : INFO : EPOCH - 19 : training on 6557240 raw words (5679506 effective words) took 16.5s, 344213 effective words/s\n",
      "2019-06-26 17:25:11,134 : INFO : EPOCH 20 - PROGRESS: at 7.37% examples, 408640 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:12,151 : INFO : EPOCH 20 - PROGRESS: at 14.10% examples, 397606 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:13,153 : INFO : EPOCH 20 - PROGRESS: at 19.29% examples, 364328 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:14,160 : INFO : EPOCH 20 - PROGRESS: at 24.61% examples, 347921 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:15,168 : INFO : EPOCH 20 - PROGRESS: at 30.97% examples, 349269 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:16,173 : INFO : EPOCH 20 - PROGRESS: at 37.93% examples, 356261 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:17,178 : INFO : EPOCH 20 - PROGRESS: at 43.19% examples, 347800 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:18,224 : INFO : EPOCH 20 - PROGRESS: at 48.74% examples, 340873 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:19,237 : INFO : EPOCH 20 - PROGRESS: at 54.28% examples, 336751 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:20,244 : INFO : EPOCH 20 - PROGRESS: at 59.57% examples, 334246 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:21,262 : INFO : EPOCH 20 - PROGRESS: at 64.70% examples, 330471 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:22,265 : INFO : EPOCH 20 - PROGRESS: at 70.67% examples, 330617 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:23,270 : INFO : EPOCH 20 - PROGRESS: at 78.62% examples, 339755 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:24,286 : INFO : EPOCH 20 - PROGRESS: at 85.02% examples, 341765 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:25,296 : INFO : EPOCH 20 - PROGRESS: at 90.40% examples, 339258 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:26,298 : INFO : EPOCH 20 - PROGRESS: at 96.73% examples, 339452 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:26,750 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:25:26,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:25:26,784 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:25:26,784 : INFO : EPOCH - 20 : training on 6557240 raw words (5678465 effective words) took 16.7s, 340568 effective words/s\n",
      "2019-06-26 17:25:27,788 : INFO : EPOCH 21 - PROGRESS: at 6.52% examples, 374195 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:28,790 : INFO : EPOCH 21 - PROGRESS: at 11.70% examples, 327320 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:29,833 : INFO : EPOCH 21 - PROGRESS: at 16.59% examples, 307580 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:30,847 : INFO : EPOCH 21 - PROGRESS: at 21.10% examples, 295603 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:31,875 : INFO : EPOCH 21 - PROGRESS: at 28.35% examples, 318054 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:32,916 : INFO : EPOCH 21 - PROGRESS: at 34.63% examples, 319833 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:33,929 : INFO : EPOCH 21 - PROGRESS: at 40.59% examples, 322172 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:34,931 : INFO : EPOCH 21 - PROGRESS: at 46.33% examples, 322407 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:35,948 : INFO : EPOCH 21 - PROGRESS: at 51.58% examples, 320203 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:36,960 : INFO : EPOCH 21 - PROGRESS: at 56.44% examples, 316212 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:37,966 : INFO : EPOCH 21 - PROGRESS: at 63.90% examples, 324357 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:38,994 : INFO : EPOCH 21 - PROGRESS: at 69.19% examples, 322090 words/s, in_qsize 5, out_qsize 1\n",
      "2019-06-26 17:25:40,001 : INFO : EPOCH 21 - PROGRESS: at 77.17% examples, 331110 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:41,016 : INFO : EPOCH 21 - PROGRESS: at 84.21% examples, 334491 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:42,028 : INFO : EPOCH 21 - PROGRESS: at 91.54% examples, 340717 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:43,032 : INFO : EPOCH 21 - PROGRESS: at 96.94% examples, 338558 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:43,494 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:25:43,506 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:25:43,513 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:25:43,514 : INFO : EPOCH - 21 : training on 6557240 raw words (5679099 effective words) took 16.7s, 339508 effective words/s\n",
      "2019-06-26 17:25:44,527 : INFO : EPOCH 22 - PROGRESS: at 6.23% examples, 346682 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:45,552 : INFO : EPOCH 22 - PROGRESS: at 11.74% examples, 325851 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:46,572 : INFO : EPOCH 22 - PROGRESS: at 18.55% examples, 339686 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:47,580 : INFO : EPOCH 22 - PROGRESS: at 24.26% examples, 337177 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:48,586 : INFO : EPOCH 22 - PROGRESS: at 30.80% examples, 344080 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:49,587 : INFO : EPOCH 22 - PROGRESS: at 36.39% examples, 337750 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:50,611 : INFO : EPOCH 22 - PROGRESS: at 42.08% examples, 334896 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:51,616 : INFO : EPOCH 22 - PROGRESS: at 49.20% examples, 344762 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:52,621 : INFO : EPOCH 22 - PROGRESS: at 57.29% examples, 358264 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:53,635 : INFO : EPOCH 22 - PROGRESS: at 63.70% examples, 358816 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:54,643 : INFO : EPOCH 22 - PROGRESS: at 70.25% examples, 359956 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:55,651 : INFO : EPOCH 22 - PROGRESS: at 75.07% examples, 352547 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:56,652 : INFO : EPOCH 22 - PROGRESS: at 80.27% examples, 347694 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:57,703 : INFO : EPOCH 22 - PROGRESS: at 85.90% examples, 345407 words/s, in_qsize 6, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:25:58,709 : INFO : EPOCH 22 - PROGRESS: at 91.05% examples, 341647 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:25:59,725 : INFO : EPOCH 22 - PROGRESS: at 98.11% examples, 343951 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:25:59,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:25:59,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:25:59,918 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:25:59,918 : INFO : EPOCH - 22 : training on 6557240 raw words (5679481 effective words) took 16.4s, 346267 effective words/s\n",
      "2019-06-26 17:26:00,924 : INFO : EPOCH 23 - PROGRESS: at 5.75% examples, 322423 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:01,944 : INFO : EPOCH 23 - PROGRESS: at 11.15% examples, 311543 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:02,972 : INFO : EPOCH 23 - PROGRESS: at 16.69% examples, 309890 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:03,984 : INFO : EPOCH 23 - PROGRESS: at 22.76% examples, 314656 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:04,987 : INFO : EPOCH 23 - PROGRESS: at 29.34% examples, 328304 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:05,998 : INFO : EPOCH 23 - PROGRESS: at 36.93% examples, 339742 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:07,009 : INFO : EPOCH 23 - PROGRESS: at 42.07% examples, 333145 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:08,010 : INFO : EPOCH 23 - PROGRESS: at 49.33% examples, 343594 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:09,016 : INFO : EPOCH 23 - PROGRESS: at 54.96% examples, 341261 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:10,019 : INFO : EPOCH 23 - PROGRESS: at 60.06% examples, 336120 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:11,041 : INFO : EPOCH 23 - PROGRESS: at 66.86% examples, 342124 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:12,044 : INFO : EPOCH 23 - PROGRESS: at 74.90% examples, 351063 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:13,048 : INFO : EPOCH 23 - PROGRESS: at 80.26% examples, 346300 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:14,084 : INFO : EPOCH 23 - PROGRESS: at 85.10% examples, 341488 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:15,102 : INFO : EPOCH 23 - PROGRESS: at 92.40% examples, 345576 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:16,129 : INFO : EPOCH 23 - PROGRESS: at 97.57% examples, 341525 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:16,472 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:26:16,473 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:26:16,480 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:26:16,481 : INFO : EPOCH - 23 : training on 6557240 raw words (5678740 effective words) took 16.6s, 342906 effective words/s\n",
      "2019-06-26 17:26:17,523 : INFO : EPOCH 24 - PROGRESS: at 4.74% examples, 262371 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:18,525 : INFO : EPOCH 24 - PROGRESS: at 11.72% examples, 317747 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:19,545 : INFO : EPOCH 24 - PROGRESS: at 19.78% examples, 360231 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:20,565 : INFO : EPOCH 24 - PROGRESS: at 26.24% examples, 358120 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:21,576 : INFO : EPOCH 24 - PROGRESS: at 31.06% examples, 339076 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:22,589 : INFO : EPOCH 24 - PROGRESS: at 36.93% examples, 336125 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:23,598 : INFO : EPOCH 24 - PROGRESS: at 42.30% examples, 331678 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:24,602 : INFO : EPOCH 24 - PROGRESS: at 47.41% examples, 328471 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:25,613 : INFO : EPOCH 24 - PROGRESS: at 52.02% examples, 321843 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:26,668 : INFO : EPOCH 24 - PROGRESS: at 56.83% examples, 316983 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:27,688 : INFO : EPOCH 24 - PROGRESS: at 63.20% examples, 320081 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:28,706 : INFO : EPOCH 24 - PROGRESS: at 69.02% examples, 321307 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:29,748 : INFO : EPOCH 24 - PROGRESS: at 75.77% examples, 325768 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:30,765 : INFO : EPOCH 24 - PROGRESS: at 80.88% examples, 322270 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:31,779 : INFO : EPOCH 24 - PROGRESS: at 85.56% examples, 318146 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:32,788 : INFO : EPOCH 24 - PROGRESS: at 91.04% examples, 316699 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:33,813 : INFO : EPOCH 24 - PROGRESS: at 97.21% examples, 318143 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:34,166 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:26:34,177 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:26:34,178 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:26:34,178 : INFO : EPOCH - 24 : training on 6557240 raw words (5679046 effective words) took 17.7s, 320921 effective words/s\n",
      "2019-06-26 17:26:35,186 : INFO : EPOCH 25 - PROGRESS: at 5.88% examples, 339523 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:36,187 : INFO : EPOCH 25 - PROGRESS: at 12.76% examples, 366000 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:37,194 : INFO : EPOCH 25 - PROGRESS: at 20.89% examples, 393789 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:38,198 : INFO : EPOCH 25 - PROGRESS: at 26.31% examples, 369901 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:39,207 : INFO : EPOCH 25 - PROGRESS: at 30.98% examples, 350142 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:40,216 : INFO : EPOCH 25 - PROGRESS: at 36.23% examples, 339629 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:41,265 : INFO : EPOCH 25 - PROGRESS: at 41.53% examples, 332741 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:42,273 : INFO : EPOCH 25 - PROGRESS: at 46.32% examples, 326056 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:43,295 : INFO : EPOCH 25 - PROGRESS: at 51.91% examples, 325019 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:44,333 : INFO : EPOCH 25 - PROGRESS: at 58.16% examples, 327109 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:45,357 : INFO : EPOCH 25 - PROGRESS: at 64.90% examples, 331533 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:46,389 : INFO : EPOCH 25 - PROGRESS: at 71.98% examples, 336381 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:47,402 : INFO : EPOCH 25 - PROGRESS: at 78.69% examples, 341478 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:48,407 : INFO : EPOCH 25 - PROGRESS: at 83.91% examples, 338314 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:49,418 : INFO : EPOCH 25 - PROGRESS: at 89.95% examples, 336582 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:50,418 : INFO : EPOCH 25 - PROGRESS: at 96.37% examples, 337367 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:50,980 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:26:50,984 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:26:50,986 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:26:50,987 : INFO : EPOCH - 25 : training on 6557240 raw words (5680570 effective words) took 16.8s, 338003 effective words/s\n",
      "2019-06-26 17:26:52,010 : INFO : EPOCH 26 - PROGRESS: at 5.91% examples, 325793 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:53,049 : INFO : EPOCH 26 - PROGRESS: at 12.18% examples, 335499 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:54,096 : INFO : EPOCH 26 - PROGRESS: at 17.37% examples, 318830 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:55,106 : INFO : EPOCH 26 - PROGRESS: at 22.29% examples, 309118 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:56,111 : INFO : EPOCH 26 - PROGRESS: at 27.33% examples, 306745 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:26:57,120 : INFO : EPOCH 26 - PROGRESS: at 32.40% examples, 306177 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:26:58,133 : INFO : EPOCH 26 - PROGRESS: at 39.59% examples, 319909 words/s, in_qsize 6, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:26:59,158 : INFO : EPOCH 26 - PROGRESS: at 45.60% examples, 320654 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:00,166 : INFO : EPOCH 26 - PROGRESS: at 53.80% examples, 334824 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:01,176 : INFO : EPOCH 26 - PROGRESS: at 60.51% examples, 340136 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:02,177 : INFO : EPOCH 26 - PROGRESS: at 65.72% examples, 337079 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:03,188 : INFO : EPOCH 26 - PROGRESS: at 71.12% examples, 333560 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:04,195 : INFO : EPOCH 26 - PROGRESS: at 77.70% examples, 335237 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:05,212 : INFO : EPOCH 26 - PROGRESS: at 84.13% examples, 336502 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:06,216 : INFO : EPOCH 26 - PROGRESS: at 90.16% examples, 336700 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:07,218 : INFO : EPOCH 26 - PROGRESS: at 98.54% examples, 344829 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:07,315 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:27:07,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:27:07,335 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:27:07,336 : INFO : EPOCH - 26 : training on 6557240 raw words (5679617 effective words) took 16.3s, 347433 effective words/s\n",
      "2019-06-26 17:27:08,377 : INFO : EPOCH 27 - PROGRESS: at 5.01% examples, 279146 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:09,381 : INFO : EPOCH 27 - PROGRESS: at 13.52% examples, 367525 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:10,393 : INFO : EPOCH 27 - PROGRESS: at 19.94% examples, 365976 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:11,395 : INFO : EPOCH 27 - PROGRESS: at 26.22% examples, 363790 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:12,435 : INFO : EPOCH 27 - PROGRESS: at 32.68% examples, 361482 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:13,446 : INFO : EPOCH 27 - PROGRESS: at 40.05% examples, 368704 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:14,452 : INFO : EPOCH 27 - PROGRESS: at 47.84% examples, 377808 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:15,472 : INFO : EPOCH 27 - PROGRESS: at 55.38% examples, 382878 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:16,489 : INFO : EPOCH 27 - PROGRESS: at 60.64% examples, 373809 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:17,507 : INFO : EPOCH 27 - PROGRESS: at 65.93% examples, 367466 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:18,525 : INFO : EPOCH 27 - PROGRESS: at 72.01% examples, 364603 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:19,531 : INFO : EPOCH 27 - PROGRESS: at 77.92% examples, 363211 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:20,564 : INFO : EPOCH 27 - PROGRESS: at 84.00% examples, 360779 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:21,565 : INFO : EPOCH 27 - PROGRESS: at 89.17% examples, 355850 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:22,580 : INFO : EPOCH 27 - PROGRESS: at 94.12% examples, 351235 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:23,245 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:27:23,257 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:27:23,266 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:27:23,267 : INFO : EPOCH - 27 : training on 6557240 raw words (5679174 effective words) took 15.9s, 356540 effective words/s\n",
      "2019-06-26 17:27:24,292 : INFO : EPOCH 28 - PROGRESS: at 6.17% examples, 351826 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:25,298 : INFO : EPOCH 28 - PROGRESS: at 12.00% examples, 336737 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:26,312 : INFO : EPOCH 28 - PROGRESS: at 18.90% examples, 359641 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:27,321 : INFO : EPOCH 28 - PROGRESS: at 25.24% examples, 358366 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:28,325 : INFO : EPOCH 28 - PROGRESS: at 32.95% examples, 370050 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:29,342 : INFO : EPOCH 28 - PROGRESS: at 38.25% examples, 358758 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:30,383 : INFO : EPOCH 28 - PROGRESS: at 43.21% examples, 348083 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:31,391 : INFO : EPOCH 28 - PROGRESS: at 49.96% examples, 354359 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:32,414 : INFO : EPOCH 28 - PROGRESS: at 57.13% examples, 359540 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:33,417 : INFO : EPOCH 28 - PROGRESS: at 64.47% examples, 363686 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:34,435 : INFO : EPOCH 28 - PROGRESS: at 72.58% examples, 369421 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:35,446 : INFO : EPOCH 28 - PROGRESS: at 80.41% examples, 375384 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:36,448 : INFO : EPOCH 28 - PROGRESS: at 86.53% examples, 372785 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:37,452 : INFO : EPOCH 28 - PROGRESS: at 92.93% examples, 372282 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:38,417 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:27:38,439 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:27:38,453 : INFO : EPOCH 28 - PROGRESS: at 100.00% examples, 373943 words/s, in_qsize 0, out_qsize 1\n",
      "2019-06-26 17:27:38,454 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:27:38,455 : INFO : EPOCH - 28 : training on 6557240 raw words (5678259 effective words) took 15.2s, 373903 effective words/s\n",
      "2019-06-26 17:27:39,462 : INFO : EPOCH 29 - PROGRESS: at 4.47% examples, 256091 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:40,474 : INFO : EPOCH 29 - PROGRESS: at 9.03% examples, 258458 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:41,478 : INFO : EPOCH 29 - PROGRESS: at 14.25% examples, 274253 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:42,493 : INFO : EPOCH 29 - PROGRESS: at 21.63% examples, 306701 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:43,494 : INFO : EPOCH 29 - PROGRESS: at 26.41% examples, 299943 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:44,498 : INFO : EPOCH 29 - PROGRESS: at 32.37% examples, 305142 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:45,509 : INFO : EPOCH 29 - PROGRESS: at 40.31% examples, 324414 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:46,531 : INFO : EPOCH 29 - PROGRESS: at 48.50% examples, 340637 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:47,533 : INFO : EPOCH 29 - PROGRESS: at 55.83% examples, 349902 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:48,549 : INFO : EPOCH 29 - PROGRESS: at 63.79% examples, 358712 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:49,549 : INFO : EPOCH 29 - PROGRESS: at 69.17% examples, 354092 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:50,568 : INFO : EPOCH 29 - PROGRESS: at 74.47% examples, 349061 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:51,587 : INFO : EPOCH 29 - PROGRESS: at 82.51% examples, 357669 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:52,601 : INFO : EPOCH 29 - PROGRESS: at 88.75% examples, 356877 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:53,606 : INFO : EPOCH 29 - PROGRESS: at 94.18% examples, 352892 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:54,538 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:27:54,542 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:27:54,550 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:27:54,551 : INFO : EPOCH - 29 : training on 6557240 raw words (5679982 effective words) took 16.1s, 352936 effective words/s\n",
      "2019-06-26 17:27:55,573 : INFO : EPOCH 30 - PROGRESS: at 5.43% examples, 301410 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:56,581 : INFO : EPOCH 30 - PROGRESS: at 11.41% examples, 328160 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:27:57,584 : INFO : EPOCH 30 - PROGRESS: at 19.07% examples, 354306 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:27:58,603 : INFO : EPOCH 30 - PROGRESS: at 24.24% examples, 341182 words/s, in_qsize 5, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-26 17:27:59,623 : INFO : EPOCH 30 - PROGRESS: at 30.63% examples, 341465 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:28:00,660 : INFO : EPOCH 30 - PROGRESS: at 36.33% examples, 335268 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:28:01,670 : INFO : EPOCH 30 - PROGRESS: at 42.43% examples, 335638 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:28:02,691 : INFO : EPOCH 30 - PROGRESS: at 48.97% examples, 336479 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:28:03,705 : INFO : EPOCH 30 - PROGRESS: at 54.31% examples, 332739 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:28:04,736 : INFO : EPOCH 30 - PROGRESS: at 60.85% examples, 335990 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:28:05,743 : INFO : EPOCH 30 - PROGRESS: at 66.54% examples, 335502 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:28:06,757 : INFO : EPOCH 30 - PROGRESS: at 70.94% examples, 328615 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:28:07,765 : INFO : EPOCH 30 - PROGRESS: at 75.96% examples, 327370 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:28:08,816 : INFO : EPOCH 30 - PROGRESS: at 81.18% examples, 324281 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:28:09,831 : INFO : EPOCH 30 - PROGRESS: at 86.84% examples, 323377 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:28:10,862 : INFO : EPOCH 30 - PROGRESS: at 91.77% examples, 319650 words/s, in_qsize 6, out_qsize 0\n",
      "2019-06-26 17:28:11,903 : INFO : EPOCH 30 - PROGRESS: at 97.52% examples, 318780 words/s, in_qsize 5, out_qsize 0\n",
      "2019-06-26 17:28:12,208 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-06-26 17:28:12,214 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-06-26 17:28:12,227 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-06-26 17:28:12,227 : INFO : EPOCH - 30 : training on 6557240 raw words (5679079 effective words) took 17.7s, 321332 effective words/s\n",
      "2019-06-26 17:28:12,227 : INFO : training on a 196717200 raw words (170378453 effective words) took 491.5s, 346617 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [doc2vec dmm]: 0:08:16.949758\n",
      "Time for [3 - doc2vec model]: 0:15:22.382699\n"
     ]
    }
   ],
   "source": [
    "# 3. train doc2vec model\n",
    "with Timer(\"3 - doc2vec model\"):\n",
    "    model_dbow, model_dmm = train_model(X_train, X_dev, workers=3, epochs=30)\n",
    "\n",
    "    model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "    model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "    model_concat = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T15:41:30.189516Z",
     "start_time": "2019-06-26T15:28:13.175670Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42733/42733 [09:11<00:00, 77.49it/s] \n",
      "100%|██████████| 18315/18315 [04:04<00:00, 82.95it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [4 - vectorize arguments]: 0:13:17.009946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. vectorize arguments\n",
    "with Timer(\"4 - vectorize arguments\"):\n",
    "    # X_train, X_dev = make_vectors(X_train, X_dev, model_dbow)\n",
    "    # X_train, X_dev = make_vectors(X_train, X_dev, model_dmm)\n",
    "    X_train, X_dev = make_vectors(X_train, X_dev, model_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T16:31:37.666973Z",
     "start_time": "2019-06-26T16:31:32.806740Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42733/42733 [00:03<00:00, 13011.80it/s]\n",
      "100%|██████████| 18315/18315 [00:01<00:00, 13006.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [5 - vector comparison of arguments]: 0:00:04.853041\n"
     ]
    }
   ],
   "source": [
    "# 5. combine two argument vectors into a single one\n",
    "# - diff / concat / ...\n",
    "with Timer(\"5 - vector comparison of arguments\"):\n",
    "    X_train_diff, X_dev_diff = make_vector_comparison(X_train, X_dev, mode=\"concat\")\n",
    "\n",
    "X_train_ = X_train_diff\n",
    "X_dev_ = X_dev_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T16:33:47.141357Z",
     "start_time": "2019-06-26T16:31:39.230286Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [StandardScaler fit]: 0:00:00.770995\n",
      "Time for [StandardScaler transform]: 0:00:00.295924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [SVC (linear) fit]: 0:02:06.679089\n",
      "Time for [SVC predict]: 0:00:00.094965\n",
      "Time for [6 - SVM (train -> predict)]: 0:02:07.860045\n",
      "Confusion Matrix:\n",
      "[[5061 3875]\n",
      " [4041 5338]]\n",
      "\n",
      "Accuracy:  0.57 \n",
      "\n",
      "Report for [SVM]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.57      0.56      8936\n",
      "        True       0.58      0.57      0.57      9379\n",
      "\n",
      "    accuracy                           0.57     18315\n",
      "   macro avg       0.57      0.57      0.57     18315\n",
      "weighted avg       0.57      0.57      0.57     18315\n",
      "\n",
      "{'macro': 0.57, 'micro': 0.57}\n",
      "Time for [7 - report]: 0:00:00.048020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - SVM (train -> predict)\"):\n",
    "    y_pred_svm = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_svm, name=\"SVM\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T16:34:13.534930Z",
     "start_time": "2019-06-26T16:33:48.678208Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [LogisticRegression fit]: 0:00:24.710920\n",
      "Time for [LogisticRegression predict]: 0:00:00.091657\n",
      "Time for [6 - LogReg (train -> predict)]: 0:00:24.802823\n",
      "Confusion Matrix:\n",
      "[[5047 3889]\n",
      " [3974 5405]]\n",
      "\n",
      "Accuracy:  0.57 \n",
      "\n",
      "Report for [LogisticRegression]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.56      0.56      0.56      8936\n",
      "        True       0.58      0.58      0.58      9379\n",
      "\n",
      "    accuracy                           0.57     18315\n",
      "   macro avg       0.57      0.57      0.57     18315\n",
      "weighted avg       0.57      0.57      0.57     18315\n",
      "\n",
      "{'macro': 0.57, 'micro': 0.57}\n",
      "Time for [7 - report]: 0:00:00.049836\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - LogReg (train -> predict)\"):\n",
    "    y_pred_logreg = train_test_logreg(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_logreg, name=\"LogisticRegression\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T16:34:31.115401Z",
     "start_time": "2019-06-26T16:34:15.078360Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [SGDClassifier fit]: 0:00:15.890665\n",
      "Time for [SGDClassifier predict]: 0:00:00.092300\n",
      "Time for [6 - SGDClassifier (train -> predict)]: 0:00:15.983215\n",
      "Confusion Matrix:\n",
      "[[4644 4292]\n",
      " [3525 5854]]\n",
      "\n",
      "Accuracy:  0.57 \n",
      "\n",
      "Report for [SGDClassifier]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      0.52      0.54      8936\n",
      "        True       0.58      0.62      0.60      9379\n",
      "\n",
      "    accuracy                           0.57     18315\n",
      "   macro avg       0.57      0.57      0.57     18315\n",
      "weighted avg       0.57      0.57      0.57     18315\n",
      "\n",
      "{'macro': 0.57, 'micro': 0.57}\n",
      "Time for [7 - report]: 0:00:00.049750\n"
     ]
    }
   ],
   "source": [
    "# 6. train\n",
    "with Timer(\"6 - SGDClassifier (train -> predict)\"):\n",
    "    y_pred_sgdcla = train_test_sgd(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 7. Evaluate\n",
    "with Timer(\"7 - report\"):\n",
    "    print(report_training_results(y_dev, y_pred_sgdcla, name=\"SGDClassifier\", heatmap=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T11:45:45.813418Z",
     "start_time": "2019-06-26T11:45:45.808878Z"
    },
    "code_folding": [
     0,
     6,
     11,
     16,
     20
    ]
   },
   "outputs": [],
   "source": [
    "# old\n",
    "return\n",
    "\n",
    "asdf\n",
    "\n",
    "# 2. Lemmatizing argument1 and argument2\n",
    "with Timer(\"2 - lemmatize\"):\n",
    "    X_train = X_train.apply(get_lemma, axis=1)\n",
    "    X_dev = X_dev.apply(get_lemma, axis=1)\n",
    "\n",
    "# 3. Extracting features - 1-3 grams lemma\n",
    "with Timer(\"3 - n-grams\"):\n",
    "    X_train_, X_dev_ = extract_n_grams_features(\n",
    "        X_train, X_dev, columns=['argument1_lemmas', 'argument2_lemmas'])\n",
    "\n",
    "# 4. train\n",
    "with Timer(\"4 - SVM (train -> predict)\"):\n",
    "    y_pred = train_test_svm(X_train_, y_train, X_dev_)\n",
    "\n",
    "# 5. Evaluate\n",
    "with Timer(\"5 - report\"):\n",
    "    report_training_results(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
