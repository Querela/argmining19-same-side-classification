{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gluon-nlp.mxnet.io/install.html\n",
    "\n",
    "```\n",
    "pip install --upgrade 'mxnet>=1.3.0'\n",
    "pip install gluonnlp\n",
    "wget https://gluon-nlp.mxnet.io/_downloads/sentence_embedding.zip\n",
    "unzip sentence_embedding.zip\n",
    "ln -s sentence_embedding/bert bert\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:04:12.775611Z",
     "start_time": "2019-07-12T20:04:12.770616Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import csv\n",
    "import gluonnlp as nlp\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from bert import *\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon.data import Dataset, SimpleDataset\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:04:12.786550Z",
     "start_time": "2019-07-12T20:04:12.778248Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:04:12.797427Z",
     "start_time": "2019-07-12T20:04:12.788057Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# set repeatable random state\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:04:12.808133Z",
     "start_time": "2019-07-12T20:04:12.799196Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:04:12.851139Z",
     "start_time": "2019-07-12T20:04:12.810608Z"
    },
    "init_cell": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a121f40c209d47739fc108f22f918d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make tqdm jupyter friendly\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# for .progress_apply() we have to hack it like this?\n",
    "tqdm().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:04:12.860682Z",
     "start_time": "2019-07-12T20:04:12.853433Z"
    },
    "code_folding": [
     0,
     4
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:04:12.872786Z",
     "start_time": "2019-07-12T20:04:12.862556Z"
    },
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:04:15.147021Z",
     "start_time": "2019-07-12T20:04:12.875057Z"
    },
    "code_folding": [
     11,
     18,
     29,
     36
    ],
    "hide_input": false,
    "init_cell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:01.097146\n",
      "Time for [read within]: 0:00:01.159655\n"
     ]
    }
   ],
   "source": [
    "# escapechar to detect quoting escapes, else it fails\n",
    "\n",
    "# na_filter=False, because pandas automatic \"nan\" detection fails with the topic column, too\n",
    "# cross_test_df['topic'].astype(str)[9270]\n",
    "\n",
    "# within has \"is_same_side\" as string (boolean after latest update)\n",
    "# cross has \"is_same_side\" as boolean (auto cast?)\n",
    "\n",
    "with Timer(\"read cross\"):\n",
    "    # cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                    quotechar='\"',\n",
    "                                    quoting=csv.QUOTE_ALL,\n",
    "                                    encoding='utf-8',\n",
    "                                    escapechar='\\\\',\n",
    "                                    doublequote=False,\n",
    "                                    index_col='id')\n",
    "    cross_test_df = pd.read_csv(data_cross_path.format('test'),\n",
    "                                quotechar='\"',\n",
    "                                quoting=csv.QUOTE_ALL,\n",
    "                                encoding='utf-8',\n",
    "                                escapechar='\\\\',\n",
    "                                doublequote=False,\n",
    "                                index_col='id')\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    # within_traindev_df = pd.read_csv(data_within_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    within_traindev_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                     quotechar='\"',\n",
    "                                     quoting=csv.QUOTE_ALL,\n",
    "                                     encoding='utf-8',\n",
    "                                     escapechar='\\\\',\n",
    "                                     doublequote=False,\n",
    "                                     index_col='id')\n",
    "    within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "                                 quotechar='\"',\n",
    "                                 quoting=csv.QUOTE_ALL,\n",
    "                                 encoding='utf-8',\n",
    "                                 escapechar='\\\\',\n",
    "                                 doublequote=False,\n",
    "                                 index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.068442Z",
     "start_time": "2019-07-12T20:04:15.148228Z"
    },
    "code_folding": [
     1
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a68c43bb9b44049d10847f07540f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=61048), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag cross traindev]: 0:00:34.304106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a946d83d1b734d3a81def62f2afdc8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34330), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag cross test]: 0:00:19.343720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f952c6b5e74b359bef0c43b7e32d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=63903), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag within traindev]: 0:00:36.578005\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b362fbb7c0475d82d02ded0e25f7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [tag within test]: 0:00:17.689106\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross traindev\"):\n",
    "    cross_traindev_df = cross_traindev_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag cross test\"):\n",
    "    cross_test_df = cross_test_df.progress_apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within traindev\"):\n",
    "    within_traindev_df = within_traindev_df.progress_apply(add_tag, axis=1)\n",
    "with Timer(\"tag within test\"):\n",
    "    within_test_df = within_test_df.progress_apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.073291Z",
     "start_time": "2019-07-12T20:06:03.069790Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "- https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.087083Z",
     "start_time": "2019-07-12T20:06:03.075929Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyBERTDataset(SimpleDataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        super(MyBERTDataset, self).__init__(self._convert())\n",
    "\n",
    "    def _convert(self):\n",
    "        allsamples = list()\n",
    "\n",
    "        if self._y is not None:\n",
    "            df = self._X.merge(self._y, left_index=True, right_index=True)\n",
    "            for _, row in df.iterrows():\n",
    "                allsamples.append([\n",
    "                    row['argument1'], row['argument2'],\n",
    "                    \"1\" if str(row['is_same_side']) == \"True\" else \"0\"\n",
    "                ])\n",
    "        else:\n",
    "            for _, row in self._X.iterrows():\n",
    "                allsamples.append([row['argument1'], row['argument2'], None])\n",
    "\n",
    "        return allsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.102160Z",
     "start_time": "2019-07-12T20:06:03.089524Z"
    },
    "code_folding": [
     3
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from gluonnlp.data import BERTSentenceTransform\n",
    "\n",
    "\n",
    "class MiddlePartBERTSentenceTransform(BERTSentenceTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, pad=True, pair=True):\n",
    "        super(MiddlePartBERTSentenceTransform, self).__init__(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "\n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\n",
    "        Removes from end of token list.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # two tokens at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "                tokens_a.pop(0)\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "                tokens_b.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.114938Z",
     "start_time": "2019-07-12T20:06:03.104551Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "class MiddlePartBERTDatasetTransform(dataset.BERTDatasetTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, labels=None, pad=True, pair=True, label_dtype='float32'):\n",
    "        super(MiddlePartBERTDatasetTransform, self).__init__(tokenizer, max_seq_length, labels=labels, pad=pad, pair=pair, label_dtype=label_dtype)\n",
    "        self._bert_xform = MiddlePartBERTSentenceTransform(tokenizer, max_seq_length, pad=pad, pair=pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.131693Z",
     "start_time": "2019-07-12T20:06:03.117513Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_bert():\n",
    "    # change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "    ctx = mx.gpu(0)\n",
    "    # ctx =  mx.gpu() if mx.context.num_gpus() else mx.cpu()\n",
    "    # ctx = mx.cpu()\n",
    "    \n",
    "    bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                                 dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                                 pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                                                 use_decoder=False, use_classifier=False)\n",
    "    print(bert_base)\n",
    "    \n",
    "    model = bert.BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
    "    # only need to initialize the classifier layer.\n",
    "    model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "    model.hybridize(static_alloc=True)\n",
    "\n",
    "    # softmax cross entropy loss for classification\n",
    "    loss_function = gluon.loss.SoftmaxCELoss()\n",
    "    loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "    metric = mx.metric.Accuracy()\n",
    "    \n",
    "    # use the vocabulary from pre-trained model for tokenization\n",
    "    bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "    # maximum sequence length\n",
    "    # max_len = 128  # + batch_size: 32\n",
    "    max_len = 512  # + batch_size: 6 ?\n",
    "    # the labels for the two classes\n",
    "    all_labels = [\"0\", \"1\"]\n",
    "    # whether to transform the data as sentence pairs.\n",
    "    # for single sentence classification, set pair=False\n",
    "    transform = MiddlePartBERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                               labels=all_labels,\n",
    "                                               label_dtype='int32',\n",
    "                                               pad=True,\n",
    "                                               pair=True)\n",
    "\n",
    "    return model, vocabulary, ctx, bert_tokenizer, transform, loss_function, metric, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.144552Z",
     "start_time": "2019-07-12T20:06:03.133991Z"
    },
    "code_folding": [
     0,
     6
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def transform_dataset(X, y, transform):\n",
    "    data_train_raw = MyBERTDataset(X, y)\n",
    "    data_train = data_train_raw.transform(transform)\n",
    "    return data_train_raw, data_train\n",
    "\n",
    "\n",
    "def predict_out_to_ys(all_predictions, all_labels):\n",
    "    y_true, y_pred = list(), list()\n",
    "    \n",
    "    for _, y_true_many, y_pred_many in all_predictions:\n",
    "        y_true_many = y_true_many.T[0].asnumpy()\n",
    "        # https://mxnet.incubator.apache.org/api/python/gluon/loss.html#mxnet.gluon.loss.SoftmaxCrossEntropyLoss\n",
    "        # pred: the prediction tensor, where the batch_axis dimension ranges over batch size and axis dimension ranges over the number of classes.\n",
    "        y_pred_many = np.argmax(y_pred_many, axis=1).asnumpy()\n",
    "\n",
    "        y_true.extend(list(y_true_many))\n",
    "        y_pred.extend(list(y_pred_many))\n",
    "        # TODO: convert label_id to label?\n",
    "        # y_pred.extend(all_labels[c] for c in list(y_pred_many))\n",
    "        \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.176377Z",
     "start_time": "2019-07-12T20:06:03.146620Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3, checkpoint_dir=\"data\", use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(\n",
    "            lengths=[int(item[1]) for item in tqdm(data_train)],\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(), 'adam', {\n",
    "            'learning_rate': lr,\n",
    "            'epsilon': 1e-9\n",
    "        })\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [p for p in model.collect_params().values() if p.grad_req != 'null']\n",
    "\n",
    "    log_interval = 300\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               label) in enumerate(tqdm(bert_dataloader)):\n",
    "                    with mx.autograd.record():\n",
    "\n",
    "                        # load data to GPU\n",
    "                        token_ids = token_ids.as_in_context(ctx)\n",
    "                        valid_length = valid_length.as_in_context(ctx)\n",
    "                        segment_ids = segment_ids.as_in_context(ctx)\n",
    "                        label = label.as_in_context(ctx)\n",
    "\n",
    "                        # forward computation\n",
    "                        out = model(token_ids, segment_ids,\n",
    "                                    valid_length.astype('float32'))\n",
    "                        ls = loss_function(out, label).mean()\n",
    "\n",
    "                    # backward computation\n",
    "                    ls.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1)\n",
    "\n",
    "                    step_loss += ls.asscalar()\n",
    "                    metric.update([label], [out])\n",
    "                    stats.append((metric.get()[1], ls.asscalar()))\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f} - time {}'\n",
    "                            .format(epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                    step_loss / log_interval, trainer.learning_rate,\n",
    "                                    metric.get()[1],\n",
    "                                    datetime.timedelta(seconds=(time.time() - t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "            \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.192259Z",
     "start_time": "2019-07-12T20:06:03.178042Z"
    },
    "code_folding": [
     0
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def predict(model, data_predict, ctx, metric, loss_function, batch_size=32):\n",
    "    bert_dataloader = mx.gluon.data.DataLoader(data_predict, batch_size=batch_size)\n",
    "    \n",
    "    all_predictions = list()\n",
    "\n",
    "    with Timer(\"prediction\"):\n",
    "        metric.reset()\n",
    "        cum_loss = 0\n",
    "        for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                       label) in enumerate(tqdm(bert_dataloader)):\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            out = model(token_ids, segment_ids,\n",
    "                        valid_length.astype('float32'))\n",
    "            ls = loss_function(out, label).mean()\n",
    "\n",
    "            metric.update([label], [out])\n",
    "            cum_loss += ls.asscalar()  # .sum() ?\n",
    "            all_predictions.append((batch_id, label, out))\n",
    "            \n",
    "    return all_predictions, cum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.209736Z",
     "start_time": "2019-07-12T20:06:03.194077Z"
    },
    "code_folding": [
     0,
     21
    ],
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def print_infos(vocabulary, data_train_raw, data_train):\n",
    "    sample_id = 0\n",
    "\n",
    "    # sentence a\n",
    "    print(data_train_raw[sample_id][0])\n",
    "    # sentence b\n",
    "    print(data_train_raw[sample_id][1])\n",
    "    # 1 means equivalent, 0 means not equivalent\n",
    "    print(data_train_raw[sample_id][2])\n",
    "\n",
    "    print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
    "    print('[PAD] token id = %s'%(vocabulary['[PAD]']))\n",
    "    print('[CLS] token id = %s'%(vocabulary['[CLS]']))\n",
    "    print('[SEP] token id = %s'%(vocabulary['[SEP]']))\n",
    "\n",
    "    print('token ids = \\n%s'%data_train[sample_id][0])\n",
    "    print('valid length = \\n%s'%data_train[sample_id][1])\n",
    "    print('segment ids = \\n%s'%data_train[sample_id][2])\n",
    "    print('label = \\n%s'%data_train[sample_id][3])\n",
    "    \n",
    "\n",
    "def plot_train_stats(stats):\n",
    "    if not stats:\n",
    "        print(\"no stats to plot\")\n",
    "        return\n",
    "\n",
    "    x = np.arange(len(stats))  # arange/linspace\n",
    "\n",
    "    acc_dots, loss_dots = zip(*stats)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(x, acc_dots)  # Linie: '-', 'o-', '.-'\n",
    "    plt.title('Training BERTClassifier')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(x, loss_dots)\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:06:03.227380Z",
     "start_time": "2019-07-12T20:06:03.211388Z"
    },
    "code_folding": [
     0,
     12
    ],
    "init_cell": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def heatconmat(y_test, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(np.unique(y_test)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, name=None, heatmap=True):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    if heatmap:\n",
    "        heatconmat(y_test, y_pred)\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2), '\\n')  #\n",
    "\n",
    "    print('Report{}:'.format(\"\" if not name else \" for [{}]\".format(name)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    f1_dic = {}\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T12:32:05.919852Z",
     "start_time": "2019-07-12T12:32:05.891234Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train split]: 0:00:00.023732\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T12:32:08.895895Z",
     "start_time": "2019-07-12T12:32:06.566801Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTModel(\n",
      "  (encoder): BERTEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (1): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (2): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (3): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (4): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (5): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (6): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (7): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (8): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (9): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (10): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (11): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_embed): HybridSequential(\n",
      "    (0): Embedding(30522 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (token_type_embed): HybridSequential(\n",
      "    (0): Embedding(2 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (pooler): Dense(768 -> 768, Activation(tanh))\n",
      ")\n",
      "Time for [2 - setup BERT model]: 0:00:02.326062\n"
     ]
    }
   ],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T12:32:11.732055Z",
     "start_time": "2019-07-12T12:32:09.414828Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wanted fetuses are beloved \"babies\"; unwanted ones are \"tissue\" (inconsistent)\n",
      "abortions are emotionally and psychologically unsafe.\n",
      "1\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  2359 10768  5809  2229  2024 11419  1000 10834  1000  1025 18162\n",
      "  3924  2024  1000  8153  1000  1006 20316  1007     3 11324  2015  2024\n",
      " 14868  1998  8317  2135 25135  1012     3     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "31\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[1]\n",
      "Time for [3 - prepare training data]: 0:00:02.314010\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:02:18.383898Z",
     "start_time": "2019-07-12T12:32:19.232452Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c0b484b1af48a3a21c6c762f493652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=44732), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [setup training]: 0:03:05.833237\n",
      "loaded checkpoint for epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82467be967b84e619f5d41504853884f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7459), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1 Batch 300/7459] loss=0.3101, lr=0.0000050, acc=0.825 - time 0:04:23.971195\n",
      "[Epoch 1 Batch 600/7459] loss=0.3020, lr=0.0000050, acc=0.826 - time 0:04:23.230661\n",
      "[Epoch 1 Batch 900/7459] loss=0.2970, lr=0.0000050, acc=0.829 - time 0:04:23.854026\n",
      "[Epoch 1 Batch 1200/7459] loss=0.2955, lr=0.0000050, acc=0.837 - time 0:04:23.769608\n",
      "[Epoch 1 Batch 1500/7459] loss=0.3031, lr=0.0000050, acc=0.838 - time 0:04:24.070495\n",
      "[Epoch 1 Batch 1800/7459] loss=0.3151, lr=0.0000050, acc=0.838 - time 0:04:24.602069\n",
      "[Epoch 1 Batch 2100/7459] loss=0.3161, lr=0.0000050, acc=0.837 - time 0:04:25.391182\n",
      "[Epoch 1 Batch 2400/7459] loss=0.3017, lr=0.0000050, acc=0.837 - time 0:04:25.448332\n",
      "[Epoch 1 Batch 2700/7459] loss=0.2808, lr=0.0000050, acc=0.839 - time 0:04:24.769686\n",
      "[Epoch 1 Batch 3000/7459] loss=0.2782, lr=0.0000050, acc=0.842 - time 0:04:25.255252\n",
      "[Epoch 1 Batch 3300/7459] loss=0.2676, lr=0.0000050, acc=0.845 - time 0:04:23.653459\n",
      "[Epoch 1 Batch 3600/7459] loss=0.3192, lr=0.0000050, acc=0.844 - time 0:04:26.165466\n",
      "[Epoch 1 Batch 3900/7459] loss=0.3070, lr=0.0000050, acc=0.844 - time 0:04:26.821456\n",
      "[Epoch 1 Batch 4200/7459] loss=0.2949, lr=0.0000050, acc=0.844 - time 0:04:25.645025\n",
      "[Epoch 1 Batch 4500/7459] loss=0.3098, lr=0.0000050, acc=0.844 - time 0:04:26.934672\n",
      "[Epoch 1 Batch 4800/7459] loss=0.2886, lr=0.0000050, acc=0.845 - time 0:04:25.058859\n",
      "[Epoch 1 Batch 5100/7459] loss=0.2786, lr=0.0000050, acc=0.846 - time 0:04:24.657877\n",
      "[Epoch 1 Batch 5400/7459] loss=0.2591, lr=0.0000050, acc=0.847 - time 0:04:24.878627\n",
      "[Epoch 1 Batch 5700/7459] loss=0.2804, lr=0.0000050, acc=0.849 - time 0:04:25.567250\n",
      "[Epoch 1 Batch 6000/7459] loss=0.2610, lr=0.0000050, acc=0.850 - time 0:04:24.786678\n",
      "[Epoch 1 Batch 6300/7459] loss=0.2678, lr=0.0000050, acc=0.851 - time 0:04:25.761685\n",
      "[Epoch 1 Batch 6600/7459] loss=0.2908, lr=0.0000050, acc=0.852 - time 0:04:25.918398\n",
      "[Epoch 1 Batch 6900/7459] loss=0.2727, lr=0.0000050, acc=0.853 - time 0:04:25.089684\n",
      "[Epoch 1 Batch 7200/7459] loss=0.2552, lr=0.0000050, acc=0.854 - time 0:04:24.993234\n",
      "\n",
      "Time for [epoch 1]: 1:49:48.947375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba232a8b1ee7461e8013c34be4dc2ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7459), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2 Batch 300/7459] loss=0.2474, lr=0.0000050, acc=0.897 - time 0:04:25.059841\n",
      "[Epoch 2 Batch 600/7459] loss=0.2423, lr=0.0000050, acc=0.895 - time 0:04:25.224910\n",
      "[Epoch 2 Batch 900/7459] loss=0.2590, lr=0.0000050, acc=0.890 - time 0:04:26.536187\n",
      "[Epoch 2 Batch 1200/7459] loss=0.2572, lr=0.0000050, acc=0.891 - time 0:04:24.941209\n",
      "[Epoch 2 Batch 1500/7459] loss=0.2517, lr=0.0000050, acc=0.891 - time 0:04:25.505545\n",
      "[Epoch 2 Batch 1800/7459] loss=0.2529, lr=0.0000050, acc=0.890 - time 0:04:25.312696\n",
      "[Epoch 2 Batch 2100/7459] loss=0.2710, lr=0.0000050, acc=0.888 - time 0:04:25.819212\n",
      "[Epoch 2 Batch 2400/7459] loss=0.2561, lr=0.0000050, acc=0.888 - time 0:04:25.821377\n",
      "[Epoch 2 Batch 2700/7459] loss=0.2811, lr=0.0000050, acc=0.887 - time 0:04:26.523284\n",
      "[Epoch 2 Batch 3000/7459] loss=0.2458, lr=0.0000050, acc=0.887 - time 0:04:26.004571\n",
      "[Epoch 2 Batch 3300/7459] loss=0.2600, lr=0.0000050, acc=0.888 - time 0:04:24.683110\n",
      "[Epoch 2 Batch 3600/7459] loss=0.2356, lr=0.0000050, acc=0.889 - time 0:04:24.973708\n",
      "[Epoch 2 Batch 3900/7459] loss=0.2428, lr=0.0000050, acc=0.889 - time 0:04:25.360496\n",
      "[Epoch 2 Batch 4200/7459] loss=0.2537, lr=0.0000050, acc=0.889 - time 0:04:25.528127\n",
      "[Epoch 2 Batch 4500/7459] loss=0.2221, lr=0.0000050, acc=0.890 - time 0:04:24.201222\n",
      "[Epoch 2 Batch 4800/7459] loss=0.2332, lr=0.0000050, acc=0.891 - time 0:04:23.877100\n",
      "[Epoch 2 Batch 5100/7459] loss=0.2484, lr=0.0000050, acc=0.891 - time 0:04:25.807516\n",
      "[Epoch 2 Batch 5400/7459] loss=0.2382, lr=0.0000050, acc=0.892 - time 0:04:25.284083\n",
      "[Epoch 2 Batch 5700/7459] loss=0.2893, lr=0.0000050, acc=0.891 - time 0:04:26.973354\n",
      "[Epoch 2 Batch 6000/7459] loss=0.2758, lr=0.0000050, acc=0.890 - time 0:04:26.038108\n",
      "[Epoch 2 Batch 6300/7459] loss=0.2723, lr=0.0000050, acc=0.889 - time 0:04:26.885580\n",
      "[Epoch 2 Batch 6900/7459] loss=0.2606, lr=0.0000050, acc=0.888 - time 0:04:24.704569\n",
      "[Epoch 2 Batch 7200/7459] loss=0.2741, lr=0.0000050, acc=0.887 - time 0:04:26.464221\n",
      "\n",
      "Time for [epoch 2]: 1:50:01.274064\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e7347e1ca6419a9305070216162134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7459), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3 Batch 300/7459] loss=0.2012, lr=0.0000050, acc=0.933 - time 0:04:24.555556\n",
      "[Epoch 3 Batch 600/7459] loss=0.1947, lr=0.0000050, acc=0.927 - time 0:04:25.320385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3 Batch 6300/7459] loss=0.2351, lr=0.0000050, acc=0.917 - time 0:04:24.249716\n",
      "[Epoch 3 Batch 6600/7459] loss=0.2032, lr=0.0000050, acc=0.917 - time 0:04:24.026482\n",
      "[Epoch 3 Batch 6900/7459] loss=0.1817, lr=0.0000050, acc=0.918 - time 0:04:23.779357\n",
      "[Epoch 3 Batch 7200/7459] loss=0.2199, lr=0.0000050, acc=0.917 - time 0:04:25.502182\n",
      "\n",
      "Time for [epoch 3]: 1:49:54.631470\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24fa65a3908f4bf3a3729ce573dbf049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7459), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4 Batch 300/7459] loss=0.1655, lr=0.0000050, acc=0.942 - time 0:04:25.151816\n",
      "[Epoch 4 Batch 600/7459] loss=0.1666, lr=0.0000050, acc=0.943 - time 0:04:23.776129\n",
      "[Epoch 4 Batch 900/7459] loss=0.1712, lr=0.0000050, acc=0.942 - time 0:04:25.151824\n",
      "[Epoch 4 Batch 1200/7459] loss=0.1953, lr=0.0000050, acc=0.942 - time 0:04:25.257615\n",
      "[Epoch 4 Batch 1500/7459] loss=0.2254, lr=0.0000050, acc=0.939 - time 0:04:25.780583\n",
      "[Epoch 4 Batch 1800/7459] loss=0.1653, lr=0.0000050, acc=0.940 - time 0:04:24.611233\n",
      "[Epoch 4 Batch 2100/7459] loss=0.1335, lr=0.0000050, acc=0.943 - time 0:04:23.383859\n",
      "[Epoch 4 Batch 2400/7459] loss=0.1808, lr=0.0000050, acc=0.943 - time 0:04:23.259588\n",
      "[Epoch 4 Batch 2700/7459] loss=0.1745, lr=0.0000050, acc=0.943 - time 0:04:25.802622\n",
      "[Epoch 4 Batch 3000/7459] loss=0.2128, lr=0.0000050, acc=0.941 - time 0:04:26.327539\n",
      "[Epoch 4 Batch 3300/7459] loss=0.1879, lr=0.0000050, acc=0.941 - time 0:04:27.056316\n",
      "[Epoch 4 Batch 3600/7459] loss=0.1552, lr=0.0000050, acc=0.941 - time 0:04:26.731183\n",
      "[Epoch 4 Batch 3900/7459] loss=0.1932, lr=0.0000050, acc=0.940 - time 0:04:28.018853\n",
      "[Epoch 4 Batch 4200/7459] loss=0.1382, lr=0.0000050, acc=0.941 - time 0:04:24.263817\n",
      "[Epoch 4 Batch 4500/7459] loss=0.1779, lr=0.0000050, acc=0.940 - time 0:04:25.772614\n",
      "[Epoch 4 Batch 4800/7459] loss=0.1846, lr=0.0000050, acc=0.940 - time 0:04:24.512132\n",
      "[Epoch 4 Batch 5100/7459] loss=0.1865, lr=0.0000050, acc=0.939 - time 0:11:30.080142\n",
      "[Epoch 4 Batch 5400/7459] loss=0.1703, lr=0.0000050, acc=0.939 - time 0:04:25.596823\n",
      "[Epoch 4 Batch 5700/7459] loss=0.1797, lr=0.0000050, acc=0.939 - time 0:04:26.575184\n",
      "[Epoch 4 Batch 6000/7459] loss=0.2002, lr=0.0000050, acc=0.939 - time 0:04:25.213074\n",
      "[Epoch 4 Batch 6300/7459] loss=0.2065, lr=0.0000050, acc=0.938 - time 0:04:26.712553\n",
      "[Epoch 4 Batch 6600/7459] loss=0.1774, lr=0.0000050, acc=0.938 - time 0:04:25.862730\n",
      "[Epoch 4 Batch 6900/7459] loss=0.1783, lr=0.0000050, acc=0.938 - time 0:04:25.489450\n",
      "[Epoch 4 Batch 7200/7459] loss=0.1934, lr=0.0000050, acc=0.938 - time 0:04:26.337737\n",
      "\n",
      "Time for [epoch 4]: 1:57:05.423060\n",
      "Time for [training]: 7:26:52.494566\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [4 - train model]: 7:29:59.145579\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"4 - train model\"):\n",
    "    # train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3)\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=5, checkpoint_dir=\"data/within_traindev_mid512\")\n",
    "    # model.save_parameters(\"data/same-side-classification/within-topic/bert.model.params\")\n",
    "    model.save_parameters(\"data/within_traindev_mid512/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:13:18.978234Z",
     "start_time": "2019-07-12T20:13:17.867797Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abortion opens the door to the sexual exploitation of women the existence of abortion gives men a little more of a safeguard against unintentionally impregnating a woman. as a result, men will be more aggressive in their sexual exploitation of women.\n",
      "the fact that a child is likely to have a short life does not justify further shortening it:\n",
      "0\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2 11324  7480  1996  2341  2000  1996  4424 14427  1997  2308  1996\n",
      "  4598  1997 11324  3957  2273  1037  2210  2062  1997  1037 28805  2114\n",
      "  4895 18447  4765 19301  2135 17727  2890 16989  3436  1037  2450  1012\n",
      "  2004  1037  2765  1010  2273  2097  2022  2062  9376  1999  2037  4424\n",
      " 14427  1997  2308  1012     3  1996  2755  2008  1037  2775  2003  3497\n",
      "  2000  2031  1037  2460  2166  2515  2025 16114  2582  2460  7406  2009\n",
      "  1024     3     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "74\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[0]\n",
      "Time for [5 - prepare eval data]: 0:00:01.105989\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-12T20:23:13.749154Z",
     "start_time": "2019-07-12T20:13:24.109817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2784cd9e35743e9a34ba8d263de02d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time for [prediction]: 0:09:49.406347\n",
      "Accuracy: 0.8796619894632518\n",
      "Confusion Matrix:\n",
      "[[8181  652]\n",
      " [1655 8683]]\n",
      "\n",
      "Accuracy:  0.88 \n",
      "\n",
      "Report for [BERTClassifier]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88      8833\n",
      "           1       0.93      0.84      0.88     10338\n",
      "\n",
      "    accuracy                           0.88     19171\n",
      "   macro avg       0.88      0.88      0.88     19171\n",
      "weighted avg       0.88      0.88      0.88     19171\n",
      "\n",
      "Time for [6 - evaluate]: 0:09:49.633114\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"6 - evaluate\"):\n",
    "    # model.load_parameters(\"data/same-side-classification/within-topic/bert.model.params\", ctx=ctx)\n",
    "    #model.load_parameters(\"data/within_traindev_mid512/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        # stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        # all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6)  # seq_len: 512\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - middle part\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        # stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=6, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        # all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function, batch_size=6)  # seq_len: 512\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier - last part\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*may need to use **binary_cross_entrophy**?* (can I use a single label or do I have to use \"0\" and \"1\"?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"):\n",
    "    # train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3)\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=2)\n",
    "    # model.save_parameters(\"data/same-side-classification/cross-topic/bert.model.params\")\n",
    "    model.save_parameters(\"data/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"):\n",
    "    # model.load_parameters(\"data/same-side-classification/cross-topic/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred = predict_out_to_ys(all_predictions, all_labels)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
