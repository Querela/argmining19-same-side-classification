{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gluon-nlp.mxnet.io/install.html\n",
    "\n",
    "```\n",
    "pip install --upgrade 'mxnet>=1.3.0'\n",
    "pip install gluonnlp\n",
    "wget https://gluon-nlp.mxnet.io/_downloads/sentence_embedding.zip\n",
    "unzip sentence_embedding.zip\n",
    "ln -s sentence_embedding/bert bert\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:15:39.344220Z",
     "start_time": "2019-07-05T11:15:37.713547Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import csv\n",
    "import gluonnlp as nlp\n",
    "import matplotlib.pyplot as plt\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from bert import *\n",
    "from gluonnlp.data import BERTSentenceTransform\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon.data import Dataset, SimpleDataset\n",
    "from sklearn.metrics import (accuracy_score, classification_report,\n",
    "                             confusion_matrix, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:15:40.711776Z",
     "start_time": "2019-07-05T11:15:40.707240Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:15:48.873736Z",
     "start_time": "2019-07-05T11:15:48.869109Z"
    }
   },
   "outputs": [],
   "source": [
    "# set repeatable random state\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "mx.random.seed(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:15:49.430081Z",
     "start_time": "2019-07-05T11:15:49.426495Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply progress bars for pandas .apply() -> .progress_apply()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:15:50.141233Z",
     "start_time": "2019-07-05T11:15:50.132683Z"
    },
    "code_folding": [
     0,
     4
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Timer:\n",
    "    def __init__(self, name=None):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.time_start = time.time()\n",
    "\n",
    "    def __exit__(self, *exc):\n",
    "        time_end = time.time()\n",
    "        time_delta = datetime.timedelta(seconds=(time_end - self.time_start))\n",
    "        if self.name:\n",
    "            print((\"Time for [{}]: {}\".format(self.name, time_delta)))\n",
    "        else:\n",
    "            print((\"Time: {}\".format(time_delta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Same Side Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:15:54.554283Z",
     "start_time": "2019-07-05T11:15:54.550778Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load within-topics and cross-topics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:15:59.986916Z",
     "start_time": "2019-07-05T11:15:55.972606Z"
    },
    "code_folding": [
     11,
     18,
     29,
     36
    ],
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [read cross]: 0:00:02.042737\n",
      "Time for [read within]: 0:00:01.959090\n"
     ]
    }
   ],
   "source": [
    "# escapechar to detect quoting escapes, else it fails\n",
    "\n",
    "# na_filter=False, because pandas automatic \"nan\" detection fails with the topic column, too\n",
    "# cross_test_df['topic'].astype(str)[9270]\n",
    "\n",
    "# within has \"is_same_side\" as string (boolean after latest update)\n",
    "# cross has \"is_same_side\" as boolean (auto cast?)\n",
    "\n",
    "with Timer(\"read cross\"):\n",
    "    # cross_traindev_df = pd.read_csv(data_cross_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # cross_test_df = pd.read_csv(data_cross_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    cross_traindev_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                    quotechar='\"',\n",
    "                                    quoting=csv.QUOTE_ALL,\n",
    "                                    encoding='utf-8',\n",
    "                                    escapechar='\\\\',\n",
    "                                    doublequote=False,\n",
    "                                    index_col='id')\n",
    "    cross_test_df = pd.read_csv(data_cross_path.format('test'),\n",
    "                                quotechar='\"',\n",
    "                                quoting=csv.QUOTE_ALL,\n",
    "                                encoding='utf-8',\n",
    "                                escapechar='\\\\',\n",
    "                                doublequote=False,\n",
    "                                index_col='id')\n",
    "\n",
    "with Timer(\"read within\"):\n",
    "    # within_traindev_df = pd.read_csv(data_within_path.format('training'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    # within_test_df = pd.read_csv(data_within_path.format('test'), index_col='id', escapechar='\\\\', na_filter=False)\n",
    "    within_traindev_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                     quotechar='\"',\n",
    "                                     quoting=csv.QUOTE_ALL,\n",
    "                                     encoding='utf-8',\n",
    "                                     escapechar='\\\\',\n",
    "                                     doublequote=False,\n",
    "                                     index_col='id')\n",
    "    within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "                                 quotechar='\"',\n",
    "                                 quoting=csv.QUOTE_ALL,\n",
    "                                 encoding='utf-8',\n",
    "                                 escapechar='\\\\',\n",
    "                                 doublequote=False,\n",
    "                                 index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:17:46.696461Z",
     "start_time": "2019-07-05T11:16:06.831523Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [tag cross traindev]: 0:00:31.630622\n",
      "Time for [tag cross test]: 0:00:17.953293\n",
      "Time for [tag within traindev]: 0:00:33.695087\n",
      "Time for [tag within test]: 0:00:16.573657\n"
     ]
    }
   ],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\"  in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "with Timer(\"tag cross traindev\"):\n",
    "    cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "with Timer(\"tag cross test\"):\n",
    "    cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "with Timer(\"tag within traindev\"):\n",
    "    within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "with Timer(\"tag within test\"):\n",
    "    within_test_df = within_test_df.apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model - Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train dev set - 70% 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:21:18.023286Z",
     "start_time": "2019-07-05T11:21:18.016314Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic', 'tag']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=ratio,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT\n",
    "\n",
    "- https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:17:46.971497Z",
     "start_time": "2019-07-05T11:17:46.962542Z"
    },
    "code_folding": [
     0,
     24
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class AdvBERTDataset(SimpleDataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        super(AdvBERTDataset, self).__init__(self._convert())\n",
    "\n",
    "    def _convert(self):\n",
    "        allsamples = list()\n",
    "\n",
    "        if self._y is not None:\n",
    "            df = self._X.merge(self._y, left_index=True, right_index=True)\n",
    "            for _, row in df.iterrows():\n",
    "                allsamples.append([\n",
    "                    row['argument1'], row['argument2'],\n",
    "                    (\"1\" if str(row['is_same_side']) == \"True\" else \"0\",\n",
    "                     row['tag'])\n",
    "                ])\n",
    "        else:\n",
    "            for _, row in self._X.iterrows():\n",
    "                allsamples.append([row['argument1'], row['argument2'], None])\n",
    "\n",
    "        return allsamples\n",
    "\n",
    "\n",
    "class AdvBERTDatasetTransform(object):\n",
    "    def __init__(self,\n",
    "                 tokenizer,\n",
    "                 max_seq_length,\n",
    "                 labels=None,\n",
    "                 labels_adv=None,\n",
    "                 pad=True,\n",
    "                 pair=True,\n",
    "                 label_dtype='float32',\n",
    "                 label_adv_dtype='float32'):\n",
    "        self.label_dtype = label_dtype\n",
    "        self.label_adv_dtype = label_adv_dtype\n",
    "        self.labels = labels\n",
    "        self.labels_adv = labels_adv\n",
    "        if self.labels:\n",
    "            self._label_map = {}\n",
    "            for (i, label) in enumerate(labels):\n",
    "                self._label_map[label] = i\n",
    "        if self.labels_adv:\n",
    "            self._label_adv_map = {}\n",
    "            for (i, label_adv) in enumerate(labels_adv):\n",
    "                self._label_adv_map[label_adv] = i\n",
    "        self._bert_xform = BERTSentenceTransform(tokenizer,\n",
    "                                                 max_seq_length,\n",
    "                                                 pad=pad,\n",
    "                                                 pair=pair)\n",
    "\n",
    "    def __call__(self, line):\n",
    "        input_ids, valid_length, segment_ids = self._bert_xform(line[:-1])\n",
    "\n",
    "        label, label_adv = line[-1]\n",
    "        if self.labels:  # for classification task\n",
    "            label = self._label_map[label]\n",
    "        if self.labels_adv:\n",
    "            label_adv = self._label_adv_map[label_adv]\n",
    "        label = np.array([label], dtype=self.label_dtype)\n",
    "        label_adv = np.array([label_adv], dtype=self.label_adv_dtype)\n",
    "\n",
    "        return input_ids, valid_length, segment_ids, (label, label_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: my own `BERTDatasetTransform` for extracting chunks from arguments or last part etc.\n",
    "\n",
    "```python\n",
    "transform = dataset.BERTDatasetTransform(bert_tokenizer, 512,\n",
    "                                         labels=['0', '1'],\n",
    "                                         label_dtype='int32',\n",
    "                                         pad=True,\n",
    "                                         pair=True)\n",
    "```\n",
    "\n",
    "http://localhost:9001/edit/bert/dataset.py @454\n",
    "```python\n",
    "# substitute with my own (e. g. last part, many parts etc.)\n",
    "def __init__(...):\n",
    "    self._bert_xform = BERTSentenceTransform(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "```\n",
    "https://gluon-nlp.mxnet.io/master/_modules/gluonnlp/data/transforms.html#BERTSentenceTransform\n",
    "```python\n",
    "# substitute with my own (e. g. only last part (trim from start))\n",
    "self._truncate_seq_pair(tokens_a, tokens_b, self._max_seq_length - 3)\n",
    "```\n",
    "\n",
    "https://mxnet.incubator.apache.org/_modules/mxnet/gluon/data/dataset.html#Dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:17:47.112244Z",
     "start_time": "2019-07-05T11:17:47.104355Z"
    },
    "code_folding": [
     0,
     16
    ]
   },
   "outputs": [],
   "source": [
    "class AdvSigmoidBinaryCrossEntropyLoss(gluon.loss.SigmoidBinaryCrossEntropyLoss):\n",
    "    def __init__(self, from_sigmoid=False, weight=None, batch_axis=0, **kwargs):\n",
    "        super(AdvSigmoidBinaryCrossEntropyLoss, self).__init__(from_sigmoid=from_sigmoid, weight=weight, batch_axis=batch_axis, **kwargs)\n",
    "\n",
    "    def hybrid_forward(self, F, pred, label, sample_weight=None):\n",
    "        label = _reshape_like(F, label, pred)\n",
    "        if not self._from_sigmoid:\n",
    "            # We use the stable formula: max(x, 0) - x * z + log(1 + exp(-abs(x)))\n",
    "            loss = F.relu(pred) - pred * label + F.Activation(-F.abs(pred), act_type='softrelu')\n",
    "        else:\n",
    "            loss = -(F.log(pred+1e-12)*label + F.log(1.-pred+1e-12)*(1.-label))\n",
    "        loss = _apply_weighting(F, loss, self._weight, sample_weight)\n",
    "        loss = -loss  # EK\n",
    "        return F.mean(loss, axis=self._batch_axis, exclude=True)\n",
    "\n",
    "\n",
    "class AdvSoftmaxCrossEntropyLoss(gluon.loss.SoftmaxCrossEntropyLoss):\n",
    "    def __init__(self, axis=-1, sparse_label=True, from_logits=False, weight=None,\n",
    "                 batch_axis=0, **kwargs):\n",
    "        super(AdvSoftmaxCrossEntropyLoss, self).__init__(axis=axis, sparse_label=sparse_label, from_logits=from_logits, weight=weight, batch_axis=batch_axis, **kwargs)\n",
    "\n",
    "    def hybrid_forward(self, F, pred, label, sample_weight=None):\n",
    "        if not self._from_logits:\n",
    "            pred = F.log_softmax(pred, self._axis)\n",
    "        if self._sparse_label:\n",
    "            loss = -F.pick(pred, label, axis=self._axis, keepdims=True)\n",
    "        else:\n",
    "            label = _reshape_like(F, label, pred)\n",
    "            loss = -F.sum(pred*label, axis=self._axis, keepdims=True)\n",
    "        loss = _apply_weighting(F, loss, self._weight, sample_weight)\n",
    "        loss = -loss  # EK\n",
    "        return F.mean(loss, axis=self._batch_axis, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:19:29.795397Z",
     "start_time": "2019-07-05T11:19:29.779969Z"
    },
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import Block\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "\n",
    "class BERTAdversarialClassifier(Block):\n",
    "    \"\"\"Model for sentence (pair) classification task with BERT.\n",
    "\n",
    "    The model feeds token ids and token type ids into BERT to get the\n",
    "    pooled BERT sequence representation, then apply a Dense layer for\n",
    "    classification. Does this also for an adversarial classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bert: BERTModel\n",
    "        Bidirectional encoder with transformer.\n",
    "    num_classes : int, default is 2\n",
    "        The number of target classes.\n",
    "    num_classes_adv : int, default is 2\n",
    "        The number of target classes for adversarial classifier.\n",
    "    dropout : float or None, default 0.0.\n",
    "        Dropout probability for the bert output.\n",
    "    prefix : str or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    params : ParameterDict or None\n",
    "        See document of `mx.gluon.Block`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 num_classes=2,\n",
    "                 num_classes_adv=2,\n",
    "                 dropout=0.0,\n",
    "                 prefix=None,\n",
    "                 params=None):\n",
    "        super(BERTAdversarialClassifier, self).__init__(prefix=prefix, params=params)\n",
    "        self.bert = bert\n",
    "        with self.name_scope():\n",
    "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.classifier.add(nn.Dense(units=num_classes))\n",
    "\n",
    "            self.adversarial_classifier = nn.HybridSequential(prefix=prefix)\n",
    "            if dropout:\n",
    "                self.adversarial_classifier.add(nn.Dropout(rate=dropout))\n",
    "            self.adversarial_classifier.add(nn.Dense(units=num_classes_adv))\n",
    "\n",
    "    def forward(self, inputs, token_types, valid_length=None):  # pylint: disable=arguments-differ\n",
    "        \"\"\"Generate the unnormalized scores for the given the input sequences.\n",
    "        From both classifiers (classifier + adversarial_classifier).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs : NDArray, shape (batch_size, seq_length)\n",
    "            Input words for the sequences.\n",
    "        token_types : NDArray, shape (batch_size, seq_length)\n",
    "            Token types for the sequences, used to indicate whether the word belongs to the\n",
    "            first sentence or the second one.\n",
    "        valid_length : NDArray or None, shape (batch_size)\n",
    "            Valid length of the sequence. This is used to mask the padded tokens.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        outputs : NDArray\n",
    "            Shape (batch_size, num_classes), outputs of classifier.\n",
    "        outputs_adv : NDArray\n",
    "            Shape (batch_size, num_classes_adv), outputs of adversarial classifier.\n",
    "        \"\"\"\n",
    "        _, pooler_out = self.bert(inputs, token_types, valid_length)\n",
    "        classifier_out = self.classifier(pooler_out)\n",
    "        adversarial_classifier_out = self.adversarial_classifier(pooler_out)\n",
    "        return (classifier_out, adversarial_classifier_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:17:47.386963Z",
     "start_time": "2019-07-05T11:17:47.381708Z"
    },
    "code_folding": [
     7,
     50
    ]
   },
   "outputs": [],
   "source": [
    "# for chunked arguments, we may have to compute it all at once beforehand, should not be that much\n",
    "# since we call with any `*BERTSentenceTransform` object, \n",
    "#    splitting the lines may have to be done before a transformation of a line?\n",
    "#    -> chunking / sentence splitting, then feeding the result into the transformer, ...\n",
    "from mxnet.gluon.data import Dataset, SimpleDataset\n",
    "\n",
    "\n",
    "class MySimpleDataset(SimpleDataset):\n",
    "    \"\"\"Simple Dataset wrapper for lists and arrays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : dataset-like object\n",
    "        Any object that implements `len()` and `[]`.\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self._data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self._data[idx]\n",
    "    \n",
    "    def transform(self, fn, lazy=True):\n",
    "        \"\"\"Returns a new dataset with each sample transformed by the\n",
    "        transformer function `fn`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fn : callable\n",
    "            A transformer function that takes a sample as input and\n",
    "            returns the transformed sample.\n",
    "        lazy : bool, default True\n",
    "            If False, transforms all samples at once. Otherwise,\n",
    "            transforms each sample on demand. Note that if `fn`\n",
    "            is stochastic, you must set lazy to True or you will\n",
    "            get the same result on all epochs.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Dataset\n",
    "            The transformed dataset.\n",
    "        \"\"\"\n",
    "        trans = _MyLazyTransformDataset(self, fn)\n",
    "        if lazy:\n",
    "            return trans\n",
    "        return SimpleDataset([i for i in trans])\n",
    "\n",
    "\n",
    "class _MyLazyTransformDataset(Dataset):\n",
    "    \"\"\"Lazily transformed dataset.\"\"\"\n",
    "    def __init__(self, data, fn):\n",
    "        self._data = data\n",
    "        self._fn = fn\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self._data[idx]\n",
    "        if isinstance(item, tuple):\n",
    "            return self._fn(*item)\n",
    "        return self._fn(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:17:47.520548Z",
     "start_time": "2019-07-05T11:17:47.516365Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from gluonnlp.data import BERTSentenceTransform\n",
    "\n",
    "\n",
    "class LastPartBERTSentenceTransform(BERTSentenceTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, pad=True, pair=True):\n",
    "        super(MyBERTSentenceTransform, self).__init__(tokenizer, max_seq_length, pad=pad, pair=pair)\n",
    "\n",
    "\n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\n",
    "        Removes from end of token list.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop(0)\n",
    "            else:\n",
    "                tokens_b.pop(0)\n",
    "\n",
    "\n",
    "# TODO: random trim ? --> bad probably\n",
    "# TODO: segment-wise, e. g. 0 for normal, 1 for tokens after normal tokens, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:17:47.670277Z",
     "start_time": "2019-07-05T11:17:47.667271Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class LastPartBERTDatasetTransform(dataset.BERTDatasetTransform):\n",
    "    def __init__(self, tokenizer, max_seq_length, labels=None, pad=True, pair=True, label_dtype='float32'):\n",
    "        super(MyBERTDatasetTransform, self).__init__(tokenizer, max_seq_length, labels=labels, pad=pad, pair=pair, label_dtype=label_dtype)\n",
    "        self._bert_xform = LastPartBERTSentenceTransform(tokenizer, max_seq_length, pad=pad, pair=pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:31:31.370839Z",
     "start_time": "2019-07-05T11:31:31.354531Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def setup_bert():\n",
    "    # change `ctx` to `mx.cpu()` if no GPU is available.\n",
    "    ctx = mx.gpu(0)\n",
    "    # ctx =  mx.gpu() if mx.context.num_gpus() else mx.cpu()\n",
    "    # ctx = mx.cpu()\n",
    "    \n",
    "    bert_base, vocabulary = nlp.model.get_model('bert_12_768_12',\n",
    "                                                 dataset_name='book_corpus_wiki_en_uncased',\n",
    "                                                 pretrained=True, ctx=ctx, use_pooler=True,\n",
    "                                                 use_decoder=False, use_classifier=False)\n",
    "    print(bert_base)\n",
    "    \n",
    "    model = BERTAdversarialClassifier(bert_base, num_classes=2, num_classes_adv=2, dropout=0.1)\n",
    "    # only need to initialize the classifier layer.\n",
    "    model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "    model.adversarial_classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
    "    model.hybridize(static_alloc=True)\n",
    "\n",
    "    # softmax cross entropy loss for classification\n",
    "    loss_function = gluon.loss.SoftmaxCELoss()\n",
    "    loss_function.hybridize(static_alloc=True)\n",
    "    #adv_loss_function = AdvSoftmaxCrossEntropyLoss()\n",
    "    adv_loss_function = gluon.loss.SoftmaxCELoss()\n",
    "    adv_loss_function.hybridize(static_alloc=True)\n",
    "\n",
    "    metric = mx.metric.Accuracy()\n",
    "    adv_metric = mx.metric.Accuracy()\n",
    "    \n",
    "    # use the vocabulary from pre-trained model for tokenization\n",
    "    bert_tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=True)\n",
    "    # maximum sequence length\n",
    "    max_len = 128  # + batch_size: 32\n",
    "    # max_len = 512  # + batch_size: 6 ?\n",
    "    # the labels for the two classes\n",
    "    all_labels = [\"0\", \"1\"]\n",
    "    all_adv_labels = [\"gay marriage\", \"abortion\"]\n",
    "    # whether to transform the data as sentence pairs.\n",
    "    # for single sentence classification, set pair=False\n",
    "    pair = True\n",
    "    # TODO: own dataset transformer\n",
    "    transform = AdvBERTDatasetTransform(bert_tokenizer, max_len,\n",
    "                                             labels=all_labels,\n",
    "                                             labels_adv=all_adv_labels,\n",
    "                                             label_dtype='int32',\n",
    "                                             label_adv_dtype='int32',\n",
    "                                             pad=True,\n",
    "                                             pair=pair)\n",
    "\n",
    "    return model, vocabulary, ctx, bert_tokenizer, transform, (loss_function, adv_loss_function), (metric, adv_metric), (all_labels, all_adv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:18:46.011711Z",
     "start_time": "2019-07-05T11:18:45.999115Z"
    },
    "code_folding": [
     0,
     6
    ]
   },
   "outputs": [],
   "source": [
    "def transform_dataset(X, y, transform):\n",
    "    data_train_raw = AdvBERTDataset(X, y)\n",
    "    data_train = data_train_raw.transform(transform)\n",
    "    return data_train_raw, data_train\n",
    "\n",
    "\n",
    "def predict_out_to_ys(all_predictions):\n",
    "    y_true, y_pred = list(), list()\n",
    "    y_adv_true, y_adv_pred = list(), list()\n",
    "    \n",
    "    for _, y_true_many, y_pred_many, y_adv_true_many, y_adv_pred_many in all_predictions:\n",
    "        y_true_many = y_true_many.T[0].asnumpy()\n",
    "        y_pred_many = np.argmax(y_pred_many, axis=1).asnumpy()\n",
    "        y_adv_true_many = y_adv_true_many.T[0].asnumpy()\n",
    "        y_adv_pred_many = np.argmax(y_adv_pred_many, axis=1).asnumpy()\n",
    "\n",
    "        y_true.extend(list(y_true_many))\n",
    "        y_pred.extend(list(y_pred_many))\n",
    "        y_adv_true.extend(list(y_adv_true_many))\n",
    "        y_adv_pred.extend(list(y_adv_pred_many))\n",
    "        \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_adv_true = np.array(y_adv_true)\n",
    "    y_adv_pred = np.array(y_adv_pred)\n",
    "    \n",
    "    return y_true, y_pred, y_adv_true, y_adv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:36:45.782708Z",
     "start_time": "2019-07-05T11:36:45.754850Z"
    },
    "code_folding": [
     12
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          data_train,\n",
    "          ctx,\n",
    "          metric,\n",
    "          adv_metric,\n",
    "          loss_function,\n",
    "          adv_loss_function,\n",
    "          batch_size=32,\n",
    "          lr=5e-6,\n",
    "          num_epochs=3,\n",
    "          checkpoint_dir=\"data\",\n",
    "          use_checkpoints=True):\n",
    "    with Timer(\"setup training\"):\n",
    "        train_sampler = nlp.data.FixedBucketSampler(lengths=[\n",
    "            int(item[1])\n",
    "            for item in tqdm(data_train, desc=\"compute sample lengths\")\n",
    "        ],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True)\n",
    "        bert_dataloader = mx.gluon.data.DataLoader(data_train,\n",
    "                                                   batch_sampler=train_sampler)\n",
    "\n",
    "        trainer = gluon.Trainer(model.collect_params(), 'adam', {\n",
    "            'learning_rate': lr,\n",
    "            'epsilon': 1e-9\n",
    "        })\n",
    "\n",
    "        # collect all differentiable parameters\n",
    "        # grad_req == 'null' indicates no gradients are calculated (e.g. constant parameters)\n",
    "        # the gradients for these params are clipped later\n",
    "        params = [\n",
    "            p for p in model.collect_params().values() if p.grad_req != 'null'\n",
    "        ]\n",
    "\n",
    "    log_interval = 10\n",
    "    with Timer(\"training\"):\n",
    "        stats = list()\n",
    "        for epoch_id in range(num_epochs):\n",
    "            if use_checkpoints:\n",
    "                epoch_checkpoint_savefile = \"bert.model.checkpoint{}.params\".format(\n",
    "                    epoch_id)\n",
    "                if checkpoint_dir is not None:\n",
    "                    epoch_checkpoint_savefile = os.path.join(\n",
    "                        checkpoint_dir, epoch_checkpoint_savefile)\n",
    "                if os.path.exists(epoch_checkpoint_savefile):\n",
    "                    model.load_parameters(epoch_checkpoint_savefile, ctx=ctx)\n",
    "                    print(\"loaded checkpoint for epoch {}\".format(epoch_id))\n",
    "                    continue\n",
    "\n",
    "            with Timer(\"epoch {}\".format(epoch_id)):\n",
    "                metric.reset()\n",
    "                step_loss = 0\n",
    "                t_p = time.time()  # time keeping\n",
    "                for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                               (label,\n",
    "                                label_adv)) in enumerate(bert_dataloader):\n",
    "                    with mx.autograd.record():\n",
    "\n",
    "                        # load data to GPU\n",
    "                        token_ids = token_ids.as_in_context(ctx)\n",
    "                        valid_length = valid_length.as_in_context(ctx)\n",
    "                        segment_ids = segment_ids.as_in_context(ctx)\n",
    "                        label = label.as_in_context(ctx)\n",
    "                        label_adv = label_adv.as_in_context(ctx)\n",
    "\n",
    "                        # forward computation\n",
    "                        (out, out_adv) = model(token_ids, segment_ids,\n",
    "                                               valid_length.astype('float32'))\n",
    "                        ls = loss_function(out, label).mean()\n",
    "                        ls_adv = adv_loss_function(out_adv, label_adv).mean()\n",
    "\n",
    "                    # backward computation\n",
    "                    if batch_id % 2 == 1:\n",
    "                        ls.backward()\n",
    "                    else:\n",
    "                        ls_adv.backward()\n",
    "\n",
    "                    # gradient clipping\n",
    "                    trainer.allreduce_grads()\n",
    "                    nlp.utils.clip_grad_global_norm(params, 1)\n",
    "                    trainer.update(1, ignore_stale_grad=True)\n",
    "\n",
    "                    step_loss += ls.asscalar()\n",
    "                    metric.update([label], [out])\n",
    "                    adv_metric.update([label_adv], [out_adv])\n",
    "                    stats.append((metric.get()[1], ls.asscalar(),\n",
    "                                  adv_metric.get()[1], ls_adv.asscalar()))\n",
    "                    if (batch_id + 1) % (log_interval) == 0:\n",
    "                        print(\n",
    "                            '[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}, acc_adv={:.3f} - time {}'\n",
    "                            .format(\n",
    "                                epoch_id, batch_id + 1, len(bert_dataloader),\n",
    "                                step_loss / log_interval,\n",
    "                                trainer.learning_rate,\n",
    "                                metric.get()[1],\n",
    "                                adv_metric.get()[1],\n",
    "                                datetime.timedelta(seconds=(time.time() -\n",
    "                                                            t_p))))\n",
    "                        t_p = time.time()\n",
    "                        step_loss = 0\n",
    "\n",
    "            if use_checkpoints:\n",
    "                model.save_parameters(epoch_checkpoint_savefile)\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:18:48.430755Z",
     "start_time": "2019-07-05T11:18:48.416435Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def predict(model, data_predict, ctx, metric, adv_metric, loss_function, adv_loss_function, batch_size=32):\n",
    "    bert_dataloader = mx.gluon.data.DataLoader(data_predict, batch_size=batch_size)\n",
    "    \n",
    "    all_predictions = list()\n",
    "\n",
    "    with Timer(\"prediction\"):\n",
    "        metric.reset()\n",
    "        cum_loss = 0\n",
    "        cum_loss_adv = 0\n",
    "        for batch_id, (token_ids, valid_length, segment_ids,\n",
    "                       (label, label_adv)) in enumerate(tqdm(bert_dataloader)):\n",
    "            # load data to GPU\n",
    "            token_ids = token_ids.as_in_context(ctx)\n",
    "            valid_length = valid_length.as_in_context(ctx)\n",
    "            segment_ids = segment_ids.as_in_context(ctx)\n",
    "            label = label.as_in_context(ctx)\n",
    "            label_adv = label_adv.as_in_context(ctx)\n",
    "\n",
    "            # forward computation\n",
    "            (out, out_adv) = model(token_ids, segment_ids,\n",
    "                        valid_length.astype('float32'))\n",
    "            ls = loss_function(out, label).mean()\n",
    "            ls_adv = adv_loss_function(out_adv, label_adv).mean()\n",
    "\n",
    "            metric.update([label], [out])\n",
    "            adv_metric.update([label_adv], [out_adv])\n",
    "            cum_loss += ls.asscalar()  # .sum() ?\n",
    "            cum_loss_adv += ls_adv.asscalar()\n",
    "            all_predictions.append((batch_id, label, out, label_adv, out_adv))\n",
    "            \n",
    "    return all_predictions, cum_loss, cum_loss_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:22:14.887955Z",
     "start_time": "2019-07-05T11:22:14.870717Z"
    },
    "code_folding": [
     0,
     22
    ]
   },
   "outputs": [],
   "source": [
    "def print_infos(vocabulary, data_train_raw, data_train):\n",
    "    sample_id = 0\n",
    "\n",
    "    # sentence a\n",
    "    print(data_train_raw[sample_id][0])\n",
    "    # sentence b\n",
    "    print(data_train_raw[sample_id][1])\n",
    "    # 1 means equivalent, 0 means not equivalent\n",
    "    print(data_train_raw[sample_id][2])\n",
    "\n",
    "    print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
    "    print('[PAD] token id = %s'%(vocabulary['[PAD]']))\n",
    "    print('[CLS] token id = %s'%(vocabulary['[CLS]']))\n",
    "    print('[SEP] token id = %s'%(vocabulary['[SEP]']))\n",
    "\n",
    "    print('token ids = \\n%s'%data_train[sample_id][0])\n",
    "    print('valid length = \\n%s'%data_train[sample_id][1])\n",
    "    print('segment ids = \\n%s'%data_train[sample_id][2])\n",
    "    print('label = \\n%s'%data_train[sample_id][3][0])\n",
    "    print('label_adv = \\n%s'%data_train[sample_id][3][1])\n",
    "    \n",
    "\n",
    "def plot_train_stats(stats):\n",
    "    if not stats:\n",
    "        print(\"no stats to plot\")\n",
    "        return\n",
    "\n",
    "    x = np.arange(len(stats))  # arange/linspace\n",
    "\n",
    "    acc_dots, loss_dots, adv_acc_dots, adv_loss_dots = zip(*stats)\n",
    "\n",
    "    plt.subplot(4, 1, 1)\n",
    "    plt.plot(x, acc_dots)  # Linie: '-', 'o-', '.-'\n",
    "    plt.title('Training BERTClassifier')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.subplot(4, 1, 2)\n",
    "    plt.plot(x, loss_dots)\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(4, 1, 3)\n",
    "    plt.plot(x, adv_acc_dots)  # Linie: '-', 'o-', '.-'\n",
    "    plt.ylabel('Adv Accuracy')\n",
    "\n",
    "    plt.subplot(4, 1, 4)\n",
    "    plt.plot(x, adv_loss_dots)\n",
    "    plt.xlabel('Batches')\n",
    "    plt.ylabel('Adv Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:18:54.323555Z",
     "start_time": "2019-07-05T11:18:54.309757Z"
    },
    "code_folding": [
     0,
     12
    ],
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def heatconmat(y_test, y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    sns.heatmap(confusion_matrix(y_test, y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(np.unique(y_test)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def report_training_results(y_test, y_pred, name=None, heatmap=True):\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    if heatmap:\n",
    "        heatconmat(y_test, y_pred)\n",
    "    print()\n",
    "    print('Accuracy: ', round(accuracy_score(y_test, y_pred), 2), '\\n')  #\n",
    "\n",
    "    print('Report{}:'.format(\"\" if not name else \" for [{}]\".format(name)))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    f1_dic = {}\n",
    "    f1_dic['macro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='macro'), 2)\n",
    "    f1_dic['micro'] = round(\n",
    "        f1_score(y_pred=y_pred, y_true=y_test, average='micro'), 2)\n",
    "    return f1_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Within topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:21:26.088099Z",
     "start_time": "2019-07-05T11:21:26.057416Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [1 - test/train split]: 0:00:00.026474\n"
     ]
    }
   ],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:32:04.585687Z",
     "start_time": "2019-07-05T11:32:03.797253Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTModel(\n",
      "  (encoder): BERTEncoder(\n",
      "    (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "    (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "    (transformer_cells): HybridSequential(\n",
      "      (0): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (1): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (2): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (3): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (4): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (5): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (6): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (7): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (8): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (9): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (10): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "      (11): BERTEncoderCell(\n",
      "        (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "        (attention_cell): MultiHeadAttentionCell(\n",
      "          (_base_cell): DotProductAttentionCell(\n",
      "            (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          )\n",
      "          (proj_query): Dense(768 -> 768, linear)\n",
      "          (proj_key): Dense(768 -> 768, linear)\n",
      "          (proj_value): Dense(768 -> 768, linear)\n",
      "        )\n",
      "        (proj): Dense(768 -> 768, linear)\n",
      "        (ffn): BERTPositionwiseFFN(\n",
      "          (ffn_1): Dense(768 -> 3072, linear)\n",
      "          (activation): GELU()\n",
      "          (ffn_2): Dense(3072 -> 768, linear)\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_embed): HybridSequential(\n",
      "    (0): Embedding(30522 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (token_type_embed): HybridSequential(\n",
      "    (0): Embedding(2 -> 768, float32)\n",
      "    (1): Dropout(p = 0.1, axes=())\n",
      "  )\n",
      "  (pooler): Dense(768 -> 768, Activation(tanh))\n",
      ")\n",
      "Time for [2 - setup BERT model]: 0:00:00.782968\n"
     ]
    }
   ],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, (loss_function, adv_loss_function), (metric, adv_metric), (all_labels, all_adv_labels) = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:32:08.342371Z",
     "start_time": "2019-07-05T11:32:08.334854Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTAdversarialClassifier(\n",
      "  (bert): BERTModel(\n",
      "    (encoder): BERTEncoder(\n",
      "      (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "      (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "      (transformer_cells): HybridSequential(\n",
      "        (0): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (1): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (2): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (3): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (4): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (5): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (6): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (7): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (8): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (9): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (10): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "        (11): BERTEncoderCell(\n",
      "          (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "          (attention_cell): MultiHeadAttentionCell(\n",
      "            (_base_cell): DotProductAttentionCell(\n",
      "              (_dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            )\n",
      "            (proj_query): Dense(768 -> 768, linear)\n",
      "            (proj_key): Dense(768 -> 768, linear)\n",
      "            (proj_value): Dense(768 -> 768, linear)\n",
      "          )\n",
      "          (proj): Dense(768 -> 768, linear)\n",
      "          (ffn): BERTPositionwiseFFN(\n",
      "            (ffn_1): Dense(768 -> 3072, linear)\n",
      "            (activation): GELU()\n",
      "            (ffn_2): Dense(3072 -> 768, linear)\n",
      "            (dropout_layer): Dropout(p = 0.1, axes=())\n",
      "            (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "          )\n",
      "          (layer_norm): BERTLayerNorm(eps=1e-12, axis=-1, center=True, scale=True, in_channels=768)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (word_embed): HybridSequential(\n",
      "      (0): Embedding(30522 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (token_type_embed): HybridSequential(\n",
      "      (0): Embedding(2 -> 768, float32)\n",
      "      (1): Dropout(p = 0.1, axes=())\n",
      "    )\n",
      "    (pooler): Dense(768 -> 768, Activation(tanh))\n",
      "  )\n",
      "  (classifier): HybridSequential(\n",
      "    (0): Dropout(p = 0.1, axes=())\n",
      "    (1): Dense(None -> 2, linear)\n",
      "  )\n",
      "  (adversarial_classifier): HybridSequential(\n",
      "    (0): Dropout(p = 0.1, axes=())\n",
      "    (1): Dense(None -> 2, linear)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:22:26.345814Z",
     "start_time": "2019-07-05T11:22:23.712709Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wanted fetuses are beloved \"babies\"; unwanted ones are \"tissue\" (inconsistent)\n",
      "abortions are emotionally and psychologically unsafe.\n",
      "('1', 'abortion')\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2  2359 10768  5809  2229  2024 11419  1000 10834  1000  1025 18162\n",
      "  3924  2024  1000  8153  1000  1006 20316  1007     3 11324  2015  2024\n",
      " 14868  1998  8317  2135 25135  1012     3     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "31\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[1]\n",
      "label_adv = \n",
      "[1]\n",
      "Time for [3 - prepare training data]: 0:00:02.626350\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:59:14.421221Z",
     "start_time": "2019-07-05T11:36:54.780679Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute sample lengths: 100%|██████████| 44732/44732 [03:17<00:00, 226.44it/s]\n",
      "  0%|          | 0/1401 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [setup training]: 0:03:17.564300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1401 [00:08<19:56,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 10/1401] loss=0.7088, lr=0.0000050, acc=0.472, acc_adv=0.675 - time 0:00:08.421452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 20/1401 [00:16<17:58,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 20/1401] loss=0.6852, lr=0.0000050, acc=0.519, acc_adv=0.647 - time 0:00:07.946128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/1401 [00:24<17:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 30/1401] loss=0.7136, lr=0.0000050, acc=0.495, acc_adv=0.654 - time 0:00:08.312066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 40/1401 [00:32<18:49,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 40/1401] loss=0.7066, lr=0.0000050, acc=0.491, acc_adv=0.655 - time 0:00:08.070998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 50/1401 [00:40<18:15,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 50/1401] loss=0.6772, lr=0.0000050, acc=0.501, acc_adv=0.666 - time 0:00:08.061635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 60/1401 [00:49<17:13,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 60/1401] loss=0.6703, lr=0.0000050, acc=0.519, acc_adv=0.685 - time 0:00:08.305338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 70/1401 [00:57<17:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 70/1401] loss=0.6867, lr=0.0000050, acc=0.525, acc_adv=0.705 - time 0:00:08.219753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 80/1401 [01:06<18:49,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 80/1401] loss=0.7190, lr=0.0000050, acc=0.523, acc_adv=0.721 - time 0:00:08.665112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 90/1401 [01:14<18:42,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 90/1401] loss=0.7190, lr=0.0000050, acc=0.524, acc_adv=0.742 - time 0:00:08.495211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 100/1401 [01:22<17:07,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 100/1401] loss=0.7023, lr=0.0000050, acc=0.522, acc_adv=0.758 - time 0:00:08.075305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 110/1401 [01:30<16:40,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 110/1401] loss=0.7052, lr=0.0000050, acc=0.521, acc_adv=0.776 - time 0:00:07.858756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 120/1401 [01:38<18:24,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 120/1401] loss=0.6925, lr=0.0000050, acc=0.522, acc_adv=0.789 - time 0:00:08.438726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 130/1401 [01:46<17:15,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 130/1401] loss=0.6822, lr=0.0000050, acc=0.523, acc_adv=0.804 - time 0:00:07.925404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 140/1401 [01:53<15:12,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 140/1401] loss=0.7100, lr=0.0000050, acc=0.522, acc_adv=0.816 - time 0:00:06.912647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 150/1401 [02:02<16:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 150/1401] loss=0.6882, lr=0.0000050, acc=0.523, acc_adv=0.827 - time 0:00:08.257079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 160/1401 [02:09<15:48,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 160/1401] loss=0.7072, lr=0.0000050, acc=0.522, acc_adv=0.837 - time 0:00:07.896651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 170/1401 [02:17<15:21,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 170/1401] loss=0.6912, lr=0.0000050, acc=0.524, acc_adv=0.846 - time 0:00:07.881633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 180/1401 [02:26<17:55,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 180/1401] loss=0.6860, lr=0.0000050, acc=0.527, acc_adv=0.854 - time 0:00:08.896705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 190/1401 [02:35<16:57,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 190/1401] loss=0.6808, lr=0.0000050, acc=0.528, acc_adv=0.860 - time 0:00:08.383667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 200/1401 [02:43<15:22,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 200/1401] loss=0.7008, lr=0.0000050, acc=0.528, acc_adv=0.867 - time 0:00:08.146203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 210/1401 [02:51<15:40,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 210/1401] loss=0.7001, lr=0.0000050, acc=0.527, acc_adv=0.873 - time 0:00:08.145179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 220/1401 [02:59<16:32,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 220/1401] loss=0.6850, lr=0.0000050, acc=0.529, acc_adv=0.878 - time 0:00:07.977356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 230/1401 [03:07<16:35,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 230/1401] loss=0.7023, lr=0.0000050, acc=0.528, acc_adv=0.883 - time 0:00:07.876282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 240/1401 [03:15<15:51,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 240/1401] loss=0.6848, lr=0.0000050, acc=0.528, acc_adv=0.888 - time 0:00:08.076623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 250/1401 [03:23<14:32,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 250/1401] loss=0.6818, lr=0.0000050, acc=0.530, acc_adv=0.891 - time 0:00:08.209861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 260/1401 [03:31<15:17,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 260/1401] loss=0.6916, lr=0.0000050, acc=0.530, acc_adv=0.895 - time 0:00:08.049471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 270/1401 [03:40<16:30,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 270/1401] loss=0.6880, lr=0.0000050, acc=0.531, acc_adv=0.899 - time 0:00:08.633450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 280/1401 [03:48<14:24,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 280/1401] loss=0.6702, lr=0.0000050, acc=0.533, acc_adv=0.902 - time 0:00:07.986422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 290/1401 [03:56<14:31,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 290/1401] loss=0.6545, lr=0.0000050, acc=0.537, acc_adv=0.905 - time 0:00:08.307470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 300/1401 [04:05<15:49,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 300/1401] loss=0.6778, lr=0.0000050, acc=0.538, acc_adv=0.908 - time 0:00:08.547732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 310/1401 [04:13<14:54,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 310/1401] loss=0.6757, lr=0.0000050, acc=0.538, acc_adv=0.910 - time 0:00:08.579035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 320/1401 [04:21<14:07,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 320/1401] loss=0.6735, lr=0.0000050, acc=0.540, acc_adv=0.913 - time 0:00:08.213460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 330/1401 [04:30<15:32,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 330/1401] loss=0.6593, lr=0.0000050, acc=0.542, acc_adv=0.915 - time 0:00:08.634081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 340/1401 [04:39<15:39,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 340/1401] loss=0.6861, lr=0.0000050, acc=0.541, acc_adv=0.917 - time 0:00:08.641706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 350/1401 [04:47<15:21,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 350/1401] loss=0.6982, lr=0.0000050, acc=0.541, acc_adv=0.920 - time 0:00:08.542147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 360/1401 [04:56<15:17,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 360/1401] loss=0.6595, lr=0.0000050, acc=0.544, acc_adv=0.922 - time 0:00:08.495775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 370/1401 [05:04<13:56,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 370/1401] loss=0.6663, lr=0.0000050, acc=0.545, acc_adv=0.924 - time 0:00:08.216595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 380/1401 [05:13<15:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 380/1401] loss=0.6532, lr=0.0000050, acc=0.546, acc_adv=0.925 - time 0:00:08.884722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 390/1401 [05:21<14:06,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 390/1401] loss=0.6841, lr=0.0000050, acc=0.546, acc_adv=0.927 - time 0:00:08.102727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 400/1401 [05:29<12:21,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 400/1401] loss=0.6558, lr=0.0000050, acc=0.547, acc_adv=0.929 - time 0:00:08.291999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 410/1401 [05:37<12:06,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 410/1401] loss=0.6872, lr=0.0000050, acc=0.548, acc_adv=0.930 - time 0:00:08.018012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 420/1401 [05:45<12:18,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 420/1401] loss=0.6936, lr=0.0000050, acc=0.547, acc_adv=0.932 - time 0:00:07.352963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 430/1401 [05:53<13:06,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 430/1401] loss=0.6928, lr=0.0000050, acc=0.546, acc_adv=0.933 - time 0:00:08.324260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 440/1401 [06:01<12:44,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 440/1401] loss=0.6871, lr=0.0000050, acc=0.546, acc_adv=0.934 - time 0:00:08.085284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 450/1401 [06:09<12:33,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 450/1401] loss=0.6669, lr=0.0000050, acc=0.547, acc_adv=0.936 - time 0:00:07.903609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 460/1401 [06:17<13:06,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 460/1401] loss=0.6560, lr=0.0000050, acc=0.548, acc_adv=0.937 - time 0:00:08.264186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 470/1401 [06:26<13:01,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 470/1401] loss=0.6855, lr=0.0000050, acc=0.549, acc_adv=0.938 - time 0:00:08.485773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 480/1401 [06:33<11:42,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 480/1401] loss=0.6783, lr=0.0000050, acc=0.549, acc_adv=0.939 - time 0:00:07.781750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 490/1401 [06:42<12:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 490/1401] loss=0.6911, lr=0.0000050, acc=0.549, acc_adv=0.940 - time 0:00:08.568622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 500/1401 [06:50<12:11,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 500/1401] loss=0.6971, lr=0.0000050, acc=0.549, acc_adv=0.941 - time 0:00:07.761616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 510/1401 [06:58<11:42,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 510/1401] loss=0.6713, lr=0.0000050, acc=0.549, acc_adv=0.943 - time 0:00:07.840696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 520/1401 [07:06<12:26,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 520/1401] loss=0.6762, lr=0.0000050, acc=0.548, acc_adv=0.943 - time 0:00:07.956493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 530/1401 [07:14<12:24,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 530/1401] loss=0.6806, lr=0.0000050, acc=0.549, acc_adv=0.944 - time 0:00:08.179183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 540/1401 [07:22<12:16,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 540/1401] loss=0.6558, lr=0.0000050, acc=0.550, acc_adv=0.945 - time 0:00:08.280812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 550/1401 [07:31<12:20,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 550/1401] loss=0.6751, lr=0.0000050, acc=0.550, acc_adv=0.946 - time 0:00:08.973166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 560/1401 [07:39<12:04,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 560/1401] loss=0.6570, lr=0.0000050, acc=0.551, acc_adv=0.947 - time 0:00:08.400901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 570/1401 [07:48<12:20,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 570/1401] loss=0.6691, lr=0.0000050, acc=0.551, acc_adv=0.948 - time 0:00:08.907186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 580/1401 [07:56<09:40,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 580/1401] loss=0.6671, lr=0.0000050, acc=0.552, acc_adv=0.949 - time 0:00:07.248846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 590/1401 [08:03<10:31,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 590/1401] loss=0.6845, lr=0.0000050, acc=0.552, acc_adv=0.949 - time 0:00:07.785948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 600/1401 [08:12<11:38,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 600/1401] loss=0.6741, lr=0.0000050, acc=0.552, acc_adv=0.950 - time 0:00:08.354235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 610/1401 [08:20<09:58,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 610/1401] loss=0.6855, lr=0.0000050, acc=0.552, acc_adv=0.951 - time 0:00:08.013308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 620/1401 [08:28<10:54,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 620/1401] loss=0.6608, lr=0.0000050, acc=0.552, acc_adv=0.952 - time 0:00:08.378455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 630/1401 [08:36<09:52,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 630/1401] loss=0.6528, lr=0.0000050, acc=0.553, acc_adv=0.952 - time 0:00:08.084666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 640/1401 [08:44<10:41,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 640/1401] loss=0.6630, lr=0.0000050, acc=0.554, acc_adv=0.953 - time 0:00:08.002946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 650/1401 [08:52<10:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 650/1401] loss=0.6754, lr=0.0000050, acc=0.554, acc_adv=0.954 - time 0:00:07.614580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 660/1401 [08:59<09:50,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 660/1401] loss=0.6655, lr=0.0000050, acc=0.554, acc_adv=0.954 - time 0:00:07.563440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 670/1401 [09:07<09:41,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 670/1401] loss=0.6735, lr=0.0000050, acc=0.554, acc_adv=0.955 - time 0:00:08.091305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 680/1401 [09:16<10:13,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 680/1401] loss=0.6457, lr=0.0000050, acc=0.555, acc_adv=0.955 - time 0:00:08.443271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 690/1401 [09:24<09:25,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 690/1401] loss=0.6870, lr=0.0000050, acc=0.555, acc_adv=0.956 - time 0:00:07.853791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 700/1401 [09:31<08:43,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 700/1401] loss=0.6838, lr=0.0000050, acc=0.555, acc_adv=0.956 - time 0:00:07.521405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 710/1401 [09:40<09:03,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 710/1401] loss=0.6656, lr=0.0000050, acc=0.555, acc_adv=0.957 - time 0:00:08.235796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 720/1401 [09:47<08:19,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 720/1401] loss=0.6734, lr=0.0000050, acc=0.555, acc_adv=0.957 - time 0:00:07.720361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 730/1401 [09:55<09:01,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 730/1401] loss=0.6668, lr=0.0000050, acc=0.556, acc_adv=0.958 - time 0:00:07.778630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 740/1401 [10:03<08:59,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 740/1401] loss=0.6842, lr=0.0000050, acc=0.556, acc_adv=0.958 - time 0:00:08.071807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 750/1401 [10:11<08:34,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 750/1401] loss=0.6769, lr=0.0000050, acc=0.556, acc_adv=0.959 - time 0:00:07.727762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 760/1401 [10:20<09:42,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 760/1401] loss=0.6641, lr=0.0000050, acc=0.556, acc_adv=0.959 - time 0:00:08.770859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 770/1401 [10:28<08:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 770/1401] loss=0.6592, lr=0.0000050, acc=0.557, acc_adv=0.960 - time 0:00:07.910243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 780/1401 [10:36<08:17,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 780/1401] loss=0.6528, lr=0.0000050, acc=0.558, acc_adv=0.960 - time 0:00:08.170712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 790/1401 [10:43<07:26,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 790/1401] loss=0.6829, lr=0.0000050, acc=0.557, acc_adv=0.960 - time 0:00:07.619949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 800/1401 [10:52<08:34,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 800/1401] loss=0.6636, lr=0.0000050, acc=0.558, acc_adv=0.961 - time 0:00:08.529886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 810/1401 [11:00<08:10,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 810/1401] loss=0.6632, lr=0.0000050, acc=0.558, acc_adv=0.961 - time 0:00:08.257863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 820/1401 [11:09<08:35,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 820/1401] loss=0.6499, lr=0.0000050, acc=0.559, acc_adv=0.961 - time 0:00:08.761111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 830/1401 [11:16<07:18,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 830/1401] loss=0.6806, lr=0.0000050, acc=0.559, acc_adv=0.962 - time 0:00:07.565023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 840/1401 [11:25<07:37,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 840/1401] loss=0.6553, lr=0.0000050, acc=0.559, acc_adv=0.962 - time 0:00:08.460625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 850/1401 [11:33<07:16,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 850/1401] loss=0.6717, lr=0.0000050, acc=0.559, acc_adv=0.963 - time 0:00:08.264150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 860/1401 [11:41<06:41,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 860/1401] loss=0.6878, lr=0.0000050, acc=0.559, acc_adv=0.963 - time 0:00:07.678530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 870/1401 [11:49<06:59,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 870/1401] loss=0.6734, lr=0.0000050, acc=0.559, acc_adv=0.963 - time 0:00:07.905712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 880/1401 [11:57<06:38,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 880/1401] loss=0.6460, lr=0.0000050, acc=0.560, acc_adv=0.963 - time 0:00:07.951071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 890/1401 [12:05<07:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 890/1401] loss=0.6652, lr=0.0000050, acc=0.560, acc_adv=0.964 - time 0:00:08.561501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 900/1401 [12:13<06:47,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 900/1401] loss=0.6630, lr=0.0000050, acc=0.560, acc_adv=0.964 - time 0:00:08.090749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 910/1401 [12:22<06:39,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 910/1401] loss=0.6501, lr=0.0000050, acc=0.561, acc_adv=0.964 - time 0:00:08.340977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 920/1401 [12:30<06:33,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 920/1401] loss=0.6624, lr=0.0000050, acc=0.561, acc_adv=0.965 - time 0:00:08.192752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 930/1401 [12:38<06:20,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 930/1401] loss=0.6597, lr=0.0000050, acc=0.561, acc_adv=0.965 - time 0:00:08.286205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 940/1401 [12:46<06:19,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 940/1401] loss=0.6710, lr=0.0000050, acc=0.561, acc_adv=0.965 - time 0:00:07.973544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 950/1401 [12:54<05:50,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 950/1401] loss=0.6557, lr=0.0000050, acc=0.561, acc_adv=0.966 - time 0:00:07.846744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 960/1401 [13:01<05:26,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 960/1401] loss=0.6602, lr=0.0000050, acc=0.562, acc_adv=0.966 - time 0:00:07.404494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 970/1401 [13:09<05:29,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 970/1401] loss=0.6550, lr=0.0000050, acc=0.562, acc_adv=0.966 - time 0:00:07.990674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 980/1401 [13:17<05:10,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 980/1401] loss=0.6571, lr=0.0000050, acc=0.562, acc_adv=0.966 - time 0:00:07.645624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 990/1401 [13:25<05:09,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 990/1401] loss=0.6639, lr=0.0000050, acc=0.563, acc_adv=0.966 - time 0:00:07.734962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 1000/1401 [13:33<05:25,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1000/1401] loss=0.6797, lr=0.0000050, acc=0.563, acc_adv=0.967 - time 0:00:07.719757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1010/1401 [13:41<05:36,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1010/1401] loss=0.6640, lr=0.0000050, acc=0.563, acc_adv=0.967 - time 0:00:08.205901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1020/1401 [13:49<05:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1020/1401] loss=0.6432, lr=0.0000050, acc=0.564, acc_adv=0.967 - time 0:00:08.591203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 1030/1401 [13:58<05:28,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1030/1401] loss=0.6562, lr=0.0000050, acc=0.563, acc_adv=0.968 - time 0:00:08.604965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1040/1401 [14:07<05:20,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1040/1401] loss=0.6280, lr=0.0000050, acc=0.564, acc_adv=0.968 - time 0:00:08.705703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1050/1401 [14:15<04:26,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1050/1401] loss=0.6556, lr=0.0000050, acc=0.564, acc_adv=0.968 - time 0:00:08.049031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1060/1401 [14:23<04:50,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1060/1401] loss=0.6651, lr=0.0000050, acc=0.564, acc_adv=0.968 - time 0:00:08.218961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 1070/1401 [14:31<04:21,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1070/1401] loss=0.6564, lr=0.0000050, acc=0.564, acc_adv=0.969 - time 0:00:07.663829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1080/1401 [14:39<04:50,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1080/1401] loss=0.6411, lr=0.0000050, acc=0.565, acc_adv=0.969 - time 0:00:08.204374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1090/1401 [14:47<04:02,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1090/1401] loss=0.6335, lr=0.0000050, acc=0.566, acc_adv=0.969 - time 0:00:08.217617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 1100/1401 [14:55<04:06,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1100/1401] loss=0.6263, lr=0.0000050, acc=0.566, acc_adv=0.969 - time 0:00:08.419333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1110/1401 [15:03<03:35,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1110/1401] loss=0.6625, lr=0.0000050, acc=0.567, acc_adv=0.969 - time 0:00:07.375978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1120/1401 [15:11<04:04,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1120/1401] loss=0.6350, lr=0.0000050, acc=0.567, acc_adv=0.970 - time 0:00:08.442038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1130/1401 [15:20<03:44,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1130/1401] loss=0.6414, lr=0.0000050, acc=0.568, acc_adv=0.970 - time 0:00:08.364810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 1140/1401 [15:28<03:21,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1140/1401] loss=0.6542, lr=0.0000050, acc=0.568, acc_adv=0.970 - time 0:00:07.959781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1150/1401 [15:36<03:26,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1150/1401] loss=0.6269, lr=0.0000050, acc=0.569, acc_adv=0.970 - time 0:00:08.412931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1160/1401 [15:44<03:14,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1160/1401] loss=0.6240, lr=0.0000050, acc=0.569, acc_adv=0.970 - time 0:00:08.137760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 1170/1401 [15:52<03:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1170/1401] loss=0.6679, lr=0.0000050, acc=0.570, acc_adv=0.971 - time 0:00:07.923003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1180/1401 [16:00<02:38,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1180/1401] loss=0.6447, lr=0.0000050, acc=0.570, acc_adv=0.971 - time 0:00:07.684225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1190/1401 [16:08<02:40,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1190/1401] loss=0.6546, lr=0.0000050, acc=0.570, acc_adv=0.971 - time 0:00:07.891693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1200/1401 [16:16<02:47,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1200/1401] loss=0.6447, lr=0.0000050, acc=0.571, acc_adv=0.971 - time 0:00:08.276304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 1210/1401 [16:24<02:39,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1210/1401] loss=0.6461, lr=0.0000050, acc=0.571, acc_adv=0.971 - time 0:00:08.312675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1220/1401 [16:33<02:37,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1220/1401] loss=0.6066, lr=0.0000050, acc=0.572, acc_adv=0.971 - time 0:00:08.405964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1230/1401 [16:41<02:24,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1230/1401] loss=0.6149, lr=0.0000050, acc=0.572, acc_adv=0.972 - time 0:00:08.282503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1240/1401 [16:49<02:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1240/1401] loss=0.6268, lr=0.0000050, acc=0.572, acc_adv=0.972 - time 0:00:08.097860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1250/1401 [16:58<02:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1250/1401] loss=0.6423, lr=0.0000050, acc=0.573, acc_adv=0.972 - time 0:00:08.659085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1260/1401 [17:06<01:57,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1260/1401] loss=0.5781, lr=0.0000050, acc=0.574, acc_adv=0.972 - time 0:00:08.229800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1270/1401 [17:14<01:48,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1270/1401] loss=0.6216, lr=0.0000050, acc=0.574, acc_adv=0.972 - time 0:00:08.036589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 1280/1401 [17:22<01:31,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1280/1401] loss=0.6459, lr=0.0000050, acc=0.574, acc_adv=0.972 - time 0:00:07.932153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1290/1401 [17:30<01:23,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1290/1401] loss=0.6218, lr=0.0000050, acc=0.575, acc_adv=0.972 - time 0:00:07.765650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1300/1401 [17:37<01:19,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1300/1401] loss=0.6332, lr=0.0000050, acc=0.575, acc_adv=0.973 - time 0:00:07.689333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1310/1401 [17:46<01:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1310/1401] loss=0.6245, lr=0.0000050, acc=0.575, acc_adv=0.973 - time 0:00:08.181424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1320/1401 [17:54<01:10,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1320/1401] loss=0.5784, lr=0.0000050, acc=0.576, acc_adv=0.973 - time 0:00:08.624589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1330/1401 [18:02<01:01,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1330/1401] loss=0.6138, lr=0.0000050, acc=0.577, acc_adv=0.973 - time 0:00:08.240998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1340/1401 [18:10<00:47,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1340/1401] loss=0.6222, lr=0.0000050, acc=0.578, acc_adv=0.973 - time 0:00:07.844579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1350/1401 [18:19<00:42,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1350/1401] loss=0.5896, lr=0.0000050, acc=0.578, acc_adv=0.973 - time 0:00:08.236978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1360/1401 [18:27<00:35,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1360/1401] loss=0.6269, lr=0.0000050, acc=0.578, acc_adv=0.974 - time 0:00:08.772155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1370/1401 [18:35<00:26,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1370/1401] loss=0.6308, lr=0.0000050, acc=0.578, acc_adv=0.974 - time 0:00:08.135095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1380/1401 [18:44<00:16,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1380/1401] loss=0.5878, lr=0.0000050, acc=0.579, acc_adv=0.974 - time 0:00:08.140705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1390/1401 [18:52<00:09,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1390/1401] loss=0.6152, lr=0.0000050, acc=0.580, acc_adv=0.974 - time 0:00:08.385790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1400/1401 [18:59<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 Batch 1400/1401] loss=0.6349, lr=0.0000050, acc=0.580, acc_adv=0.974 - time 0:00:07.310794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1401/1401 [19:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [epoch 0]: 0:19:00.752625\n",
      "Time for [training]: 0:19:01.269586\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [4 - train model]: 0:22:19.634800\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"4 - train model\"):\n",
    "    # train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3)\n",
    "    stats = train(model, data_train, ctx, metric, adv_metric, loss_function, adv_loss_function, batch_size=32, lr=5e-6, num_epochs=1)\n",
    "    # model.save_parameters(\"data/same-side-classification/within-topic/bert.model.params\")\n",
    "    model.save_parameters(\"data/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T11:25:28.821860Z",
     "start_time": "2019-07-05T11:25:27.677293Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abortion opens the door to the sexual exploitation of women the existence of abortion gives men a little more of a safeguard against unintentionally impregnating a woman. as a result, men will be more aggressive in their sexual exploitation of women.\n",
      "the fact that a child is likely to have a short life does not justify further shortening it:\n",
      "('0', 'abortion')\n",
      "vocabulary used for tokenization = \n",
      "Vocab(size=30522, unk=\"[UNK]\", reserved=\"['[PAD]', '[CLS]', '[SEP]', '[MASK]']\")\n",
      "[PAD] token id = 1\n",
      "[CLS] token id = 2\n",
      "[SEP] token id = 3\n",
      "token ids = \n",
      "[    2 11324  7480  1996  2341  2000  1996  4424 14427  1997  2308  1996\n",
      "  4598  1997 11324  3957  2273  1037  2210  2062  1997  1037 28805  2114\n",
      "  4895 18447  4765 19301  2135 17727  2890 16989  3436  1037  2450  1012\n",
      "  2004  1037  2765  1010  2273  2097  2022  2062  9376  1999  2037  4424\n",
      " 14427  1997  2308  1012     3  1996  2755  2008  1037  2775  2003  3497\n",
      "  2000  2031  1037  2460  2166  2515  2025 16114  2582  2460  7406  2009\n",
      "  1024     3     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "valid length = \n",
      "74\n",
      "segment ids = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "label = \n",
      "[0]\n",
      "label_adv = \n",
      "[1]\n",
      "Time for [5 - prepare eval data]: 0:00:01.139071\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-05T12:03:26.466645Z",
     "start_time": "2019-07-05T12:00:20.598862Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/600 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/600 [00:00<03:01,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/600 [00:00<03:13,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 3/600 [00:00<03:12,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 4/600 [00:01<03:08,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 5/600 [00:01<03:08,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 6/600 [00:01<03:02,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 7/600 [00:02<03:03,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏         | 8/600 [00:02<03:01,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 9/600 [00:02<03:04,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 10/600 [00:03<02:55,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 11/600 [00:03<02:50,  3.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 12/600 [00:03<03:07,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 13/600 [00:04<03:06,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 14/600 [00:04<03:14,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▎         | 15/600 [00:04<03:13,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 16/600 [00:05<03:09,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 17/600 [00:05<03:11,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 18/600 [00:05<03:05,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 19/600 [00:06<03:02,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 20/600 [00:06<02:51,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 21/600 [00:06<03:00,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 22/600 [00:06<03:00,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 23/600 [00:07<03:09,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 24/600 [00:07<03:08,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 25/600 [00:07<03:16,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 26/600 [00:08<03:13,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 27/600 [00:08<03:17,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 28/600 [00:09<03:16,  2.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 29/600 [00:09<03:07,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 30/600 [00:09<02:55,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 31/600 [00:09<02:53,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 32/600 [00:10<02:42,  3.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 33/600 [00:10<02:45,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 34/600 [00:10<02:54,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 35/600 [00:11<02:55,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 36/600 [00:11<02:56,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 37/600 [00:11<02:50,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 38/600 [00:11<02:43,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 39/600 [00:12<02:47,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 40/600 [00:12<02:34,  3.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 41/600 [00:12<02:29,  3.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 42/600 [00:13<02:49,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 43/600 [00:13<02:49,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 44/600 [00:13<02:46,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 45/600 [00:14<02:53,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 46/600 [00:14<03:02,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 47/600 [00:14<02:56,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 48/600 [00:15<02:49,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 49/600 [00:15<02:54,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 50/600 [00:15<02:41,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 51/600 [00:15<02:39,  3.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▊         | 52/600 [00:16<02:48,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 53/600 [00:16<02:46,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 54/600 [00:16<02:56,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 55/600 [00:17<02:52,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 56/600 [00:17<02:52,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 57/600 [00:17<02:52,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 58/600 [00:18<02:53,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 59/600 [00:18<02:59,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 60/600 [00:18<02:56,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 61/600 [00:19<03:03,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 62/600 [00:19<03:03,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 63/600 [00:19<02:59,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 64/600 [00:20<02:58,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 65/600 [00:20<02:56,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 66/600 [00:20<02:56,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 67/600 [00:21<03:04,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 68/600 [00:21<02:51,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 69/600 [00:21<02:49,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 70/600 [00:22<02:42,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 71/600 [00:22<02:49,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 72/600 [00:22<02:48,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 73/600 [00:23<02:49,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 74/600 [00:23<02:40,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▎        | 75/600 [00:23<02:40,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 76/600 [00:23<02:35,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 77/600 [00:24<02:42,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 78/600 [00:24<02:50,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 79/600 [00:24<02:51,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 80/600 [00:25<02:41,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 81/600 [00:25<02:29,  3.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 82/600 [00:25<02:25,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 83/600 [00:25<02:18,  3.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 84/600 [00:26<02:23,  3.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 85/600 [00:26<02:19,  3.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 86/600 [00:26<02:24,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 87/600 [00:27<02:24,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 88/600 [00:27<02:24,  3.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 89/600 [00:27<02:29,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 90/600 [00:28<02:33,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 91/600 [00:28<02:39,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 92/600 [00:28<02:33,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 93/600 [00:28<02:27,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 94/600 [00:29<02:23,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 95/600 [00:29<02:27,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 96/600 [00:29<02:36,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 97/600 [00:30<02:33,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 98/600 [00:30<02:41,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 99/600 [00:30<02:37,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 100/600 [00:31<02:42,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 101/600 [00:31<02:31,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 102/600 [00:31<02:34,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 103/600 [00:32<02:33,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 104/600 [00:32<02:27,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 105/600 [00:32<02:30,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 106/600 [00:32<02:25,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 107/600 [00:33<02:33,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 108/600 [00:33<02:30,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 109/600 [00:33<02:27,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 110/600 [00:34<02:24,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 111/600 [00:34<02:19,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▊        | 112/600 [00:34<02:23,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 113/600 [00:34<02:23,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 114/600 [00:35<02:26,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 115/600 [00:35<02:28,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 116/600 [00:35<02:34,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 117/600 [00:36<02:35,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 118/600 [00:36<02:26,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 119/600 [00:36<02:22,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 120/600 [00:37<02:16,  3.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 121/600 [00:37<02:31,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 122/600 [00:37<02:23,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 123/600 [00:38<02:26,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 124/600 [00:38<02:32,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 125/600 [00:38<02:27,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 126/600 [00:39<02:31,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 127/600 [00:39<02:27,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██▏       | 128/600 [00:39<02:34,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 129/600 [00:39<02:29,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 130/600 [00:40<02:20,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 131/600 [00:40<02:22,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 132/600 [00:40<02:21,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 133/600 [00:41<02:25,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 134/600 [00:41<02:23,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▎       | 135/600 [00:41<02:24,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 136/600 [00:42<02:22,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 137/600 [00:42<02:26,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 138/600 [00:42<02:20,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 139/600 [00:43<02:19,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 140/600 [00:43<02:23,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 141/600 [00:43<02:23,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 142/600 [00:43<02:16,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 143/600 [00:44<02:22,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 144/600 [00:44<02:11,  3.46it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 145/600 [00:44<02:11,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 146/600 [00:45<02:13,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 147/600 [00:45<02:11,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 148/600 [00:45<02:15,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 149/600 [00:46<02:18,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 150/600 [00:46<02:23,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 151/600 [00:46<02:21,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 152/600 [00:46<02:18,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 153/600 [00:47<02:25,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 154/600 [00:47<02:23,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 155/600 [00:47<02:18,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 156/600 [00:48<02:19,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 157/600 [00:48<02:24,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 158/600 [00:48<02:21,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 159/600 [00:49<02:15,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 160/600 [00:49<02:20,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 161/600 [00:49<02:15,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 162/600 [00:50<02:10,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 163/600 [00:50<02:06,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 164/600 [00:50<02:12,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 165/600 [00:51<02:10,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 166/600 [00:51<02:12,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 167/600 [00:51<02:20,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 168/600 [00:51<02:15,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 169/600 [00:52<02:10,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 170/600 [00:52<02:09,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 171/600 [00:52<02:16,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▊       | 172/600 [00:53<02:12,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 173/600 [00:53<02:21,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 174/600 [00:53<02:25,  2.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 175/600 [00:54<02:16,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 176/600 [00:54<02:11,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 177/600 [00:54<02:12,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 178/600 [00:55<02:07,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 179/600 [00:55<02:11,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 180/600 [00:55<02:04,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 181/600 [00:56<02:04,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 182/600 [00:56<02:02,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 183/600 [00:56<02:05,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 184/600 [00:56<02:12,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 185/600 [00:57<02:07,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 186/600 [00:57<02:18,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 187/600 [00:57<02:07,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 188/600 [00:58<02:04,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 189/600 [00:58<02:02,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 190/600 [00:58<01:59,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 191/600 [00:59<02:05,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 192/600 [00:59<02:07,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 193/600 [00:59<02:06,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 194/600 [01:00<02:08,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▎      | 195/600 [01:00<02:04,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 196/600 [01:00<02:05,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 197/600 [01:00<02:05,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 198/600 [01:01<02:01,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 199/600 [01:01<02:03,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 200/600 [01:01<02:06,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 201/600 [01:02<02:01,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 202/600 [01:02<02:00,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 203/600 [01:02<01:51,  3.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 204/600 [01:03<01:57,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 205/600 [01:03<01:46,  3.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 206/600 [01:03<01:44,  3.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 207/600 [01:03<01:40,  3.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 208/600 [01:04<01:45,  3.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 209/600 [01:04<01:47,  3.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 210/600 [01:04<01:46,  3.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 211/600 [01:04<01:45,  3.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 212/600 [01:05<01:46,  3.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 213/600 [01:05<01:45,  3.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 214/600 [01:05<01:55,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 215/600 [01:06<01:55,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 216/600 [01:06<01:59,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 217/600 [01:06<02:09,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 218/600 [01:07<02:06,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 219/600 [01:07<02:13,  2.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 220/600 [01:07<02:12,  2.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 221/600 [01:08<02:04,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 222/600 [01:08<01:55,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 223/600 [01:08<01:52,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 224/600 [01:08<01:51,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 225/600 [01:09<01:50,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 226/600 [01:09<01:56,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 227/600 [01:09<01:51,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 228/600 [01:10<01:51,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 229/600 [01:10<01:54,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 230/600 [01:10<01:54,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 231/600 [01:11<01:51,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▊      | 232/600 [01:11<01:50,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 233/600 [01:11<01:52,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 234/600 [01:12<01:53,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 235/600 [01:12<01:53,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 236/600 [01:12<01:56,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 237/600 [01:12<01:50,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 238/600 [01:13<02:01,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 239/600 [01:13<02:01,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 240/600 [01:14<01:59,  3.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 241/600 [01:14<01:51,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 242/600 [01:14<01:54,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 243/600 [01:15<02:02,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 244/600 [01:15<02:02,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 245/600 [01:15<02:04,  2.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 246/600 [01:16<01:54,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 247/600 [01:16<01:53,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████▏     | 248/600 [01:16<01:50,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 249/600 [01:16<01:47,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 250/600 [01:17<01:44,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 251/600 [01:17<01:51,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 252/600 [01:17<01:44,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 253/600 [01:18<01:42,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 254/600 [01:18<01:44,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▎     | 255/600 [01:18<01:46,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 256/600 [01:19<01:49,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 257/600 [01:19<01:45,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 258/600 [01:19<01:48,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 259/600 [01:20<01:52,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 260/600 [01:20<01:47,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 261/600 [01:20<01:41,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 262/600 [01:20<01:37,  3.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 263/600 [01:21<01:42,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 264/600 [01:21<01:39,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 265/600 [01:21<01:35,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 266/600 [01:22<01:39,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 267/600 [01:22<01:40,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 268/600 [01:22<01:38,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 269/600 [01:22<01:37,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 270/600 [01:23<01:58,  2.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 271/600 [01:23<01:56,  2.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 272/600 [01:24<01:49,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 273/600 [01:24<01:43,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 274/600 [01:24<01:40,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 275/600 [01:25<01:42,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 276/600 [01:25<01:42,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 277/600 [01:25<01:46,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 278/600 [01:26<01:46,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 279/600 [01:26<01:41,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 280/600 [01:26<01:40,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 281/600 [01:26<01:34,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 282/600 [01:27<01:37,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 283/600 [01:27<01:41,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 284/600 [01:27<01:37,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 285/600 [01:28<01:40,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 286/600 [01:28<01:43,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 287/600 [01:28<01:49,  2.85it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 288/600 [01:29<01:46,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 289/600 [01:29<01:48,  2.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 290/600 [01:29<01:42,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 291/600 [01:30<01:40,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▊     | 292/600 [01:30<01:38,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 293/600 [01:30<01:41,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 294/600 [01:31<01:45,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 295/600 [01:31<01:41,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 296/600 [01:31<01:36,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 297/600 [01:32<01:36,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 298/600 [01:32<01:34,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 299/600 [01:32<01:28,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 300/600 [01:32<01:28,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 301/600 [01:33<01:31,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 302/600 [01:33<01:32,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 303/600 [01:33<01:27,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 304/600 [01:34<01:27,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 305/600 [01:34<01:28,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 306/600 [01:34<01:32,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 307/600 [01:35<01:30,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████▏    | 308/600 [01:35<01:27,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 309/600 [01:35<01:26,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 310/600 [01:36<01:28,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 311/600 [01:36<01:29,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 312/600 [01:36<01:25,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 313/600 [01:36<01:28,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 314/600 [01:37<01:28,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▎    | 315/600 [01:37<01:24,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 316/600 [01:37<01:27,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 317/600 [01:38<01:28,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 318/600 [01:38<01:29,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 319/600 [01:38<01:28,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 320/600 [01:39<01:28,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 321/600 [01:39<01:29,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 322/600 [01:39<01:31,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 323/600 [01:40<01:32,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 324/600 [01:40<01:28,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 325/600 [01:40<01:29,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 326/600 [01:41<01:24,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 327/600 [01:41<01:26,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 328/600 [01:41<01:26,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 329/600 [01:42<01:23,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 330/600 [01:42<01:28,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 331/600 [01:42<01:26,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 332/600 [01:43<01:27,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 333/600 [01:43<01:29,  3.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 334/600 [01:43<01:25,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 335/600 [01:44<01:29,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 336/600 [01:44<01:24,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 337/600 [01:44<01:24,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 338/600 [01:45<01:25,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 339/600 [01:45<01:19,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 340/600 [01:45<01:20,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 341/600 [01:45<01:26,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 342/600 [01:46<01:21,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 343/600 [01:46<01:19,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 344/600 [01:46<01:18,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▊    | 345/600 [01:47<01:17,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 346/600 [01:47<01:18,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 347/600 [01:47<01:20,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 348/600 [01:48<01:21,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 349/600 [01:48<01:18,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 350/600 [01:48<01:16,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 351/600 [01:49<01:16,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 352/600 [01:49<01:14,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 353/600 [01:49<01:12,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 354/600 [01:49<01:14,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 355/600 [01:50<01:08,  3.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 356/600 [01:50<01:11,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 357/600 [01:50<01:15,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 358/600 [01:51<01:11,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 359/600 [01:51<01:11,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 360/600 [01:51<01:10,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 361/600 [01:51<01:12,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 362/600 [01:52<01:08,  3.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 363/600 [01:52<01:10,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 364/600 [01:52<01:12,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 365/600 [01:53<01:09,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 366/600 [01:53<01:08,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 367/600 [01:53<01:06,  3.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████▏   | 368/600 [01:53<01:05,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 369/600 [01:54<01:06,  3.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 370/600 [01:54<01:07,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 371/600 [01:54<01:05,  3.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 372/600 [01:55<01:08,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 373/600 [01:55<01:07,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 374/600 [01:55<01:04,  3.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▎   | 375/600 [01:56<01:07,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 376/600 [01:56<01:06,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 377/600 [01:56<01:06,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 378/600 [01:56<01:04,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 379/600 [01:57<01:03,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 380/600 [01:57<01:02,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 381/600 [01:57<00:59,  3.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 382/600 [01:58<00:59,  3.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 383/600 [01:58<01:01,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 384/600 [01:58<01:01,  3.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 385/600 [01:58<01:03,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 386/600 [01:59<01:00,  3.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 387/600 [01:59<00:57,  3.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 388/600 [01:59<00:58,  3.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 389/600 [01:59<00:57,  3.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 390/600 [02:00<00:58,  3.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 391/600 [02:00<01:06,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 392/600 [02:00<01:00,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 393/600 [02:01<01:02,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 394/600 [02:01<01:00,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 395/600 [02:01<00:59,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 396/600 [02:02<00:59,  3.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 397/600 [02:02<00:55,  3.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 398/600 [02:02<00:58,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 399/600 [02:02<00:56,  3.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 400/600 [02:03<00:55,  3.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 401/600 [02:03<00:54,  3.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 402/600 [02:03<00:58,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 403/600 [02:04<00:57,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 404/600 [02:04<00:57,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 405/600 [02:04<00:57,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 406/600 [02:05<01:02,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 407/600 [02:05<00:59,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 408/600 [02:05<00:56,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 409/600 [02:05<00:56,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 410/600 [02:06<00:53,  3.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 411/600 [02:06<00:52,  3.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▊   | 412/600 [02:06<00:55,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 413/600 [02:07<01:01,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 414/600 [02:07<01:01,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 415/600 [02:07<00:59,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 416/600 [02:08<00:58,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 417/600 [02:08<00:55,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 418/600 [02:08<01:01,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 419/600 [02:09<00:58,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 420/600 [02:09<00:53,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 421/600 [02:09<00:50,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 422/600 [02:09<00:52,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 423/600 [02:10<00:51,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 424/600 [02:10<00:50,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 425/600 [02:10<00:51,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 426/600 [02:11<00:51,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 427/600 [02:11<00:53,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████▏  | 428/600 [02:11<00:53,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 429/600 [02:12<00:52,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 430/600 [02:12<00:52,  3.22it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 431/600 [02:12<00:53,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 432/600 [02:13<00:56,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 433/600 [02:13<00:52,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 434/600 [02:13<00:56,  2.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▎  | 435/600 [02:13<00:51,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 436/600 [02:14<00:50,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 437/600 [02:14<00:51,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 438/600 [02:14<00:52,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 439/600 [02:15<00:48,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 440/600 [02:15<00:46,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 441/600 [02:15<00:48,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 442/600 [02:16<00:46,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 443/600 [02:16<00:45,  3.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 444/600 [02:16<00:44,  3.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 445/600 [02:16<00:44,  3.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 446/600 [02:17<00:43,  3.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 447/600 [02:17<00:42,  3.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 448/600 [02:17<00:44,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 449/600 [02:18<00:43,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 450/600 [02:18<00:45,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 451/600 [02:18<00:41,  3.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 452/600 [02:18<00:43,  3.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 453/600 [02:19<00:41,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 454/600 [02:19<00:41,  3.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 455/600 [02:19<00:40,  3.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 456/600 [02:20<00:42,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 457/600 [02:20<00:40,  3.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 458/600 [02:20<00:41,  3.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 459/600 [02:20<00:39,  3.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 460/600 [02:21<00:41,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 461/600 [02:21<00:41,  3.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 462/600 [02:21<00:44,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 463/600 [02:22<00:43,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 464/600 [02:22<00:43,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 465/600 [02:22<00:42,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 466/600 [02:23<00:39,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 467/600 [02:23<00:39,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 468/600 [02:23<00:39,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 469/600 [02:24<00:39,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 470/600 [02:24<00:39,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 471/600 [02:24<00:37,  3.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▊  | 472/600 [02:24<00:38,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 473/600 [02:25<00:36,  3.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 474/600 [02:25<00:36,  3.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 475/600 [02:25<00:37,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 476/600 [02:26<00:37,  3.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 477/600 [02:26<00:37,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 478/600 [02:26<00:35,  3.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 479/600 [02:26<00:36,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 480/600 [02:27<00:37,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 481/600 [02:27<00:37,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 482/600 [02:27<00:38,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 483/600 [02:28<00:38,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 484/600 [02:28<00:39,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 485/600 [02:28<00:36,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 486/600 [02:29<00:38,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 487/600 [02:29<00:35,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 488/600 [02:29<00:35,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 489/600 [02:30<00:35,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 490/600 [02:30<00:36,  3.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 491/600 [02:30<00:35,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 492/600 [02:31<00:34,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 493/600 [02:31<00:34,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 494/600 [02:31<00:36,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▎ | 495/600 [02:32<00:36,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 496/600 [02:32<00:35,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 497/600 [02:32<00:35,  2.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 498/600 [02:33<00:36,  2.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 499/600 [02:33<00:35,  2.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 500/600 [02:34<00:33,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 501/600 [02:34<00:32,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 502/600 [02:34<00:29,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 503/600 [02:34<00:30,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 504/600 [02:35<00:29,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 505/600 [02:35<00:29,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 506/600 [02:35<00:29,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 507/600 [02:36<00:29,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 508/600 [02:36<00:30,  3.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 509/600 [02:36<00:29,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 510/600 [02:37<00:28,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 511/600 [02:37<00:27,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 512/600 [02:37<00:29,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 513/600 [02:38<00:27,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 514/600 [02:38<00:27,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 515/600 [02:38<00:25,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 516/600 [02:39<00:25,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 517/600 [02:39<00:25,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 518/600 [02:39<00:24,  3.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 519/600 [02:39<00:25,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 520/600 [02:40<00:25,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 521/600 [02:40<00:25,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 522/600 [02:40<00:25,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 523/600 [02:41<00:27,  2.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 524/600 [02:41<00:25,  2.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 525/600 [02:42<00:25,  2.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 526/600 [02:42<00:24,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 527/600 [02:42<00:23,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 528/600 [02:43<00:26,  2.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 529/600 [02:43<00:23,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 530/600 [02:43<00:23,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 531/600 [02:44<00:23,  2.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▊ | 532/600 [02:44<00:21,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 533/600 [02:44<00:20,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 534/600 [02:44<00:20,  3.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 535/600 [02:45<00:20,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 536/600 [02:45<00:19,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 537/600 [02:45<00:19,  3.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 538/600 [02:46<00:19,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 539/600 [02:46<00:18,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 540/600 [02:46<00:18,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 541/600 [02:47<00:18,  3.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 542/600 [02:47<00:18,  3.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 543/600 [02:47<00:18,  3.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 544/600 [02:48<00:19,  2.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 545/600 [02:48<00:18,  2.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 546/600 [02:48<00:17,  3.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 547/600 [02:49<00:16,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████▏| 548/600 [02:49<00:16,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 549/600 [02:49<00:15,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 550/600 [02:50<00:15,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 551/600 [02:50<00:14,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 552/600 [02:50<00:14,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 553/600 [02:50<00:14,  3.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 554/600 [02:51<00:13,  3.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▎| 555/600 [02:51<00:13,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 556/600 [02:51<00:14,  3.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 557/600 [02:52<00:14,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 558/600 [02:52<00:13,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 559/600 [02:52<00:13,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 560/600 [02:53<00:12,  3.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 561/600 [02:53<00:11,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 562/600 [02:53<00:11,  3.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 563/600 [02:54<00:11,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 564/600 [02:54<00:10,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 565/600 [02:54<00:10,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 566/600 [02:54<00:09,  3.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 567/600 [02:55<00:10,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 568/600 [02:55<00:09,  3.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 569/600 [02:55<00:09,  3.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 570/600 [02:56<00:09,  3.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 571/600 [02:56<00:09,  3.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 572/600 [02:56<00:08,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 573/600 [02:57<00:08,  3.35it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 574/600 [02:57<00:07,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 575/600 [02:57<00:07,  3.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 576/600 [02:58<00:07,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 577/600 [02:58<00:06,  3.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 578/600 [02:58<00:06,  3.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 579/600 [02:58<00:06,  3.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 580/600 [02:59<00:05,  3.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 581/600 [02:59<00:05,  3.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 582/600 [02:59<00:05,  3.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 583/600 [03:00<00:05,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 584/600 [03:00<00:04,  3.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 585/600 [03:00<00:04,  3.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 586/600 [03:01<00:04,  3.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 587/600 [03:01<00:04,  2.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 588/600 [03:01<00:04,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 589/600 [03:02<00:03,  3.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 590/600 [03:02<00:03,  2.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 591/600 [03:02<00:02,  3.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▊| 592/600 [03:03<00:02,  3.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 593/600 [03:03<00:02,  3.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 594/600 [03:03<00:01,  3.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 595/600 [03:03<00:01,  3.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 596/600 [03:04<00:01,  3.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 597/600 [03:04<00:00,  3.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 598/600 [03:04<00:00,  3.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 599/600 [03:05<00:00,  3.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 600/600 [03:05<00:00,  3.24it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for [prediction]: 0:03:05.226104\n",
      "Accuracy: 0.6514527150383391\n",
      "Confusion Matrix:\n",
      "[[8113  720]\n",
      " [5962 4376]]\n",
      "\n",
      "Accuracy:  0.65 \n",
      "\n",
      "Report for [BERTClassifier]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71      8833\n",
      "           1       0.86      0.42      0.57     10338\n",
      "\n",
      "    accuracy                           0.65     19171\n",
      "   macro avg       0.72      0.67      0.64     19171\n",
      "weighted avg       0.73      0.65      0.63     19171\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 6749    92]\n",
      " [   29 12301]]\n",
      "\n",
      "Accuracy:  0.99 \n",
      "\n",
      "Report for [BERTAdvClassifier]:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      6841\n",
      "           1       0.99      1.00      1.00     12330\n",
      "\n",
      "    accuracy                           0.99     19171\n",
      "   macro avg       0.99      0.99      0.99     19171\n",
      "weighted avg       0.99      0.99      0.99     19171\n",
      "\n",
      "Time for [6 - evaluate]: 0:03:05.860144\n"
     ]
    }
   ],
   "source": [
    "with Timer(\"6 - evaluate\"):\n",
    "    # model.load_parameters(\"data/same-side-classification/within-topic/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss, cum_loss_adv = predict(model, data_dev, ctx, metric, adv_metric, loss_function, adv_loss_function)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred, y_adv_true, y_adv_pred = predict_out_to_ys(all_predictions)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)\n",
    "    report_training_results(y_adv_true, y_adv_pred, name=\"BERTAdvClassifier\", heatmap=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        stats = train(model, data_train, ctx, metric, adv_metric, loss_function, adv_loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        all_predictions, cum_loss, cum_loss_adv = predict(model, data_dev, ctx, metric, adv_metric, loss_function, adv_loss_function, batch_size=6)  # seq_len: 512\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred, y_adv_true, y_adv_pred = predict_out_to_ys(all_predictions)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        stats = train(model, data_train, ctx, metric, adv_metric, loss_function, adv_loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)  # seq_len: 512\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        all_predictions, cum_loss, cum_loss_adv = predict(model, data_dev, ctx, metric, adv_metric, loss_function, adv_loss_function, batch_size=6)  # seq_len: 512\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred, y_adv_true, y_adv_pred = predict_out_to_ys(all_predictions)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*may need to use **binary_cross_entrophy**?* (can I use a single label or do I have to use \"0\" and \"1\"?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross topic - Training and evaluating model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Getting train and dev data\n",
    "with Timer(\"1 - test/train split\"):\n",
    "    X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. setup\n",
    "with Timer(\"2 - setup BERT model\"):\n",
    "    model, vocabulary, ctx, tokenizer, transform, loss_function, metric, all_labels = setup_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"3 - prepare training data\"):\n",
    "    data_train_raw, data_train = transform_dataset(X_train, y_train, transform)\n",
    "    print_infos(vocabulary, data_train_raw, data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"4 - train model\"):\n",
    "    # train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=3)\n",
    "    stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=2)\n",
    "    # model.save_parameters(\"data/same-side-classification/cross-topic/bert.model.params\")\n",
    "    model.save_parameters(\"data/bert.model.params\")\n",
    "\n",
    "    plot_train_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"5 - prepare eval data\"):\n",
    "    data_dev_raw, data_dev = transform_dataset(X_dev, y_dev, transform)\n",
    "    print_infos(vocabulary, data_dev_raw, data_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Timer(\"6 - evaluate\"):\n",
    "    # model.load_parameters(\"data/same-side-classification/cross-topic/bert.model.params\", ctx=ctx)\n",
    "    model.load_parameters(\"data/bert.model.params\", ctx=ctx)\n",
    "    all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "    print(\"Accuracy:\", metric.get()[1])\n",
    "\n",
    "    y_true, y_pred, y_adv_true, y_adv_pred = predict_out_to_ys(all_predictions)\n",
    "    report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch_id in range(5):\n",
    "    with Timer(\"4 - train model - {}\".format(epoch_id)):\n",
    "        stats = train(model, data_train, ctx, metric, loss_function, batch_size=32, lr=5e-6, num_epochs=epoch_id + 1)\n",
    "        plot_train_stats(stats)\n",
    "\n",
    "    with Timer(\"6 - evaluate - {}\".format(epoch_id)):\n",
    "        all_predictions, cum_loss = predict(model, data_dev, ctx, metric, loss_function)\n",
    "        print(\"Accuracy in epoch {}:\".format(epoch_id), metric.get()[1])\n",
    "        y_true, y_pred, y_adv_true, y_adv_pred = predict_out_to_ys(all_predictions)\n",
    "        report_training_results(y_true, y_pred, name=\"BERTClassifier\", heatmap=False)\n",
    "\n",
    "    model.save_parameters(\"data/bert.model.params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
