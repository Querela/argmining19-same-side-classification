{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RATIO 2019 - Benchmarking Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zihangdai/xlnet\n",
    "\n",
    "https://github.com/zihangdai/xlnet/blob/master/notebooks/colab_imdb_gpu.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda env create -f environment.yml\n",
    "! conda activate argmining19-ssc && conda install -y -c conda-forge git-lfs && git lfs install && git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install sentencepiece\n",
    "! pip install absl-py\n",
    "# ! pip install tensorflow-auto-detect\n",
    "! pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('data/xlnet_cased_L-24_H-1024_A-16'):\n",
    "    ! wget https://storage.googleapis.com/xlnet/released_models/cased_L-24_H-1024_A-16.zip\n",
    "    ! mv cased_L-24_H-1024_A-16.zip data/\n",
    "    ! cd data/ && unzip cased_L-24_H-1024_A-16.zip\n",
    "else:\n",
    "    print('Have XLNet model already!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('xlnet'):\n",
    "    ! git clone https://github.com/zihangdai/xlnet.git\n",
    "else:\n",
    "    print('Should have repo already!')\n",
    "    ! cd xlnet && git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLUE STS-B reproduction ?\n",
    "\n",
    "https://github.com/zihangdai/xlnet#1-sts-b-sentence-pair-relevance-regression-with-gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T08:54:03.980658Z",
     "start_time": "2019-07-11T08:53:19.843295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and extracting CoLA...\n",
      "\tCompleted!\n",
      "Downloading and extracting SST...\n",
      "\tCompleted!\n",
      "Processing MRPC...\n",
      "Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n",
      "\tCompleted!\n",
      "Downloading and extracting QQP...\n",
      "\tCompleted!\n",
      "Downloading and extracting STS...\n",
      "\tCompleted!\n",
      "Downloading and extracting MNLI...\n",
      "\tCompleted!\n",
      "Downloading and extracting SNLI...\n",
      "\tCompleted!\n",
      "Downloading and extracting QNLI...\n",
      "\tCompleted!\n",
      "Downloading and extracting RTE...\n",
      "\tCompleted!\n",
      "Downloading and extracting WNLI...\n",
      "\tCompleted!\n",
      "Downloading and extracting diagnostic...\n",
      "\tCompleted!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd xlnet/scripts\n",
    "python download_glue_data.py --data_dir ../glue --tasks all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T09:34:38.621260Z",
     "start_time": "2019-07-11T09:26:42.693309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0711 11:26:43.831812 140232776353600 model_utils.py:36] Single device mode.\n",
      "W0711 11:26:44.281025 140232776353600 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "I0711 11:26:44.281518 140232776353600 estimator.py:209] Using config: {'_model_dir': 'data/xlnet-chkp/glue-stsb-chkp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 600, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f89eb882828>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=600, num_shards=1, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
      "W0711 11:26:44.281732 140232776353600 model_fn.py:630] Estimator's model_fn (<function get_model_fn.<locals>.model_fn at 0x7f8a5dfa37b8>) includes params argument, but params are not passed to Estimator.\n",
      "I0711 11:26:44.281846 140232776353600 run_classifier.py:713] Use tfrecord file data/xlnet-out/glue-stsb-out/spiece.model.len-128.train.tf_record\n",
      "I0711 11:26:44.312360 140232776353600 run_classifier.py:717] Num of train samples: 5749\n",
      "I0711 11:26:44.312530 140232776353600 run_classifier.py:410] Do not overwrite tfrecord data/xlnet-out/glue-stsb-out/spiece.model.len-128.train.tf_record exists.\n",
      "I0711 11:26:44.312624 140232776353600 run_classifier.py:467] Input tfrecord file data/xlnet-out/glue-stsb-out/spiece.model.len-128.train.tf_record\n",
      "W0711 11:26:44.320623 140232776353600 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0711 11:26:44.337521 140232776353600 deprecation.py:323] From xlnet/run_classifier.py:512: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "W0711 11:26:44.337626 140232776353600 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "I0711 11:26:44.350327 140232776353600 estimator.py:1145] Calling model_fn.\n",
      "I0711 11:26:44.355868 140232776353600 modeling.py:453] memory input None\n",
      "I0711 11:26:44.355947 140232776353600 modeling.py:455] Use float type <dtype: 'float32'>\n",
      "W0711 11:26:44.391800 140232776353600 deprecation.py:323] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/modeling.py:535: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0711 11:26:44.581588 140232776353600 deprecation.py:323] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/modeling.py:67: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0711 11:26:49.357631 140232776353600 deprecation_wrapper.py:119] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/function_builder.py:199: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "I0711 11:26:49.374923 140232776353600 run_classifier.py:535] #params: 361318401\n",
      "W0711 11:26:49.375046 140232776353600 deprecation_wrapper.py:119] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/model_utils.py:61: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "I0711 11:26:49.375111 140232776353600 model_utils.py:71] Initialize from the ckpt data/xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt\n",
      "I0711 11:26:49.944500 140232776353600 model_utils.py:85] **** Global Variables ****\n",
      "I0711 11:26:49.944637 140232776353600 model_utils.py:91]   name = model/transformer/r_w_bias:0, shape = (24, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.944714 140232776353600 model_utils.py:91]   name = model/transformer/r_r_bias:0, shape = (24, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.944762 140232776353600 model_utils.py:91]   name = model/transformer/word_embedding/lookup_table:0, shape = (32000, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.944805 140232776353600 model_utils.py:91]   name = model/transformer/r_s_bias:0, shape = (24, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.944847 140232776353600 model_utils.py:91]   name = model/transformer/seg_embed:0, shape = (24, 2, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.944890 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.944931 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.944972 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945013 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945053 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945093 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945131 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945167 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945205 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945243 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945282 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945320 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945356 140232776353600 model_utils.py:91]   name = model/transformer/layer_0/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945393 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945433 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945472 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945511 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945551 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945590 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945626 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945662 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945701 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945739 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945777 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945813 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945850 140232776353600 model_utils.py:91]   name = model/transformer/layer_1/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945887 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945925 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.945964 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946003 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946044 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946084 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946121 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946159 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946197 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946233 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946271 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946307 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946344 140232776353600 model_utils.py:91]   name = model/transformer/layer_2/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946380 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946419 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946457 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946496 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946534 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946573 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946609 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946645 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946684 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946722 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946760 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946797 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946834 140232776353600 model_utils.py:91]   name = model/transformer/layer_3/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946871 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946909 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946947 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.946986 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947025 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947065 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947101 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947138 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947175 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947211 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947248 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947285 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947321 140232776353600 model_utils.py:91]   name = model/transformer/layer_4/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947357 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947395 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947433 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947471 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947510 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947556 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947595 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947632 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947670 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947708 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947746 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947783 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947820 140232776353600 model_utils.py:91]   name = model/transformer/layer_5/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947857 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947896 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947934 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.947974 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948013 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948051 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948087 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948123 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948161 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948198 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948236 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948273 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948309 140232776353600 model_utils.py:91]   name = model/transformer/layer_6/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948345 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948384 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948421 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948477 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948516 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948555 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948592 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948630 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948679 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948714 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948752 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948788 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948823 140232776353600 model_utils.py:91]   name = model/transformer/layer_7/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948859 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948896 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948934 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.948971 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949009 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949047 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949082 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949118 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949155 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949191 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949228 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949264 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949300 140232776353600 model_utils.py:91]   name = model/transformer/layer_8/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949335 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949373 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949410 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949448 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949486 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949523 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949559 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949594 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949631 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949667 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949704 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949740 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949775 140232776353600 model_utils.py:91]   name = model/transformer/layer_9/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949812 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949850 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949889 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949928 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.949967 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950006 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950042 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950078 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950116 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950152 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950190 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950227 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950263 140232776353600 model_utils.py:91]   name = model/transformer/layer_10/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950299 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950339 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950377 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950416 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950456 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950496 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950532 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950569 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950607 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950644 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950682 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950718 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950755 140232776353600 model_utils.py:91]   name = model/transformer/layer_11/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950791 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950831 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950871 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950911 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950950 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.950990 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951028 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951064 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951102 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951138 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951176 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951212 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951247 140232776353600 model_utils.py:91]   name = model/transformer/layer_12/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951284 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951323 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951362 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951401 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951440 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951479 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951516 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951556 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951595 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951633 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951671 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951708 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951744 140232776353600 model_utils.py:91]   name = model/transformer/layer_13/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951780 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951819 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951858 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951898 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951938 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.951977 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952014 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952051 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952088 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952125 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952162 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952198 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952234 140232776353600 model_utils.py:91]   name = model/transformer/layer_14/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952271 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952311 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952350 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952390 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952430 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952470 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952506 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952543 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952580 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952617 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952656 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952692 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952728 140232776353600 model_utils.py:91]   name = model/transformer/layer_15/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952765 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952804 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952844 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952882 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952922 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952961 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.952998 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953035 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953072 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953109 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953146 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953183 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953220 140232776353600 model_utils.py:91]   name = model/transformer/layer_16/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953256 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953295 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953334 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953373 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953413 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953453 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953489 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953525 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953563 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953600 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953638 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953675 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953711 140232776353600 model_utils.py:91]   name = model/transformer/layer_17/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953748 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953788 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953828 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953867 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953906 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953946 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.953984 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954020 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954057 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954093 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954130 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954167 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954204 140232776353600 model_utils.py:91]   name = model/transformer/layer_18/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954240 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954278 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954317 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954356 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954394 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954435 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954471 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954507 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954545 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954581 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954619 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954655 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954692 140232776353600 model_utils.py:91]   name = model/transformer/layer_19/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954727 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954767 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954806 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954845 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954885 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954924 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954961 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.954998 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955035 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955072 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955109 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955146 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955182 140232776353600 model_utils.py:91]   name = model/transformer/layer_20/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955218 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955257 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955295 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955334 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955374 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955413 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955449 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955486 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955524 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955565 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955627 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955665 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955702 140232776353600 model_utils.py:91]   name = model/transformer/layer_21/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955739 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955779 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955819 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955859 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955900 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955940 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.955978 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956016 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956054 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956092 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956130 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956167 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956204 140232776353600 model_utils.py:91]   name = model/transformer/layer_22/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956241 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956281 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956322 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956362 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956401 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956441 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956478 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956516 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956555 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956592 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956630 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956668 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956705 140232776353600 model_utils.py:91]   name = model/transformer/layer_23/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\n",
      "I0711 11:26:49.956753 140232776353600 model_utils.py:91]   name = model/sequnece_summary/summary/kernel:0, shape = (1024, 1024)\n",
      "I0711 11:26:49.956790 140232776353600 model_utils.py:91]   name = model/sequnece_summary/summary/bias:0, shape = (1024,)\n",
      "I0711 11:26:49.956827 140232776353600 model_utils.py:91]   name = model/regression_sts-b/logit/kernel:0, shape = (1024, 1)\n",
      "I0711 11:26:49.956865 140232776353600 model_utils.py:91]   name = model/regression_sts-b/logit/bias:0, shape = (1,)\n",
      "W0711 11:26:49.962725 140232776353600 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0711 11:26:49.965861 140232776353600 deprecation.py:323] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/model_utils.py:123: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "I0711 11:27:00.601332 140232776353600 estimator.py:1147] Done calling model_fn.\n",
      "I0711 11:27:00.602269 140232776353600 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0711 11:27:04.545615 140232776353600 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-11 11:27:04.545889: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-07-11 11:27:04.571711: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2019-07-11 11:27:04.572705: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b152a8e050 executing computations on platform Host. Devices:\n",
      "2019-07-11 11:27:04.572744: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-11 11:27:04.574447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-07-11 11:27:04.587339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:17:00.0\n",
      "2019-07-11 11:27:04.587622: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-11 11:27:04.589094: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-11 11:27:04.590424: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-11 11:27:04.590812: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-11 11:27:04.592546: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-11 11:27:04.593770: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-11 11:27:04.597016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-11 11:27:04.598373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-11 11:27:04.598421: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-11 11:27:04.730741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-11 11:27:04.730766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-11 11:27:04.730770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-11 11:27:04.732406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10468 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2019-07-11 11:27:04.733862: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b15e4f1600 executing computations on platform CUDA. Devices:\n",
      "2019-07-11 11:27:04.733878: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "W0711 11:27:04.735203 140232776353600 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0711 11:27:04.736666 140232776353600 saver.py:1280] Restoring parameters from data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1200\n",
      "W0711 11:27:10.853884 140232776353600 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "2019-07-11 11:27:12.083751: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0711 11:27:12.186906 140232776353600 session_manager.py:500] Running local_init_op.\n",
      "I0711 11:27:12.511058 140232776353600 session_manager.py:502] Done running local_init_op.\n",
      "I0711 11:27:23.101828 140232776353600 basic_session_run_hooks.py:606] Saving checkpoints for 1200 into data/xlnet-chkp/glue-stsb-chkp/model.ckpt.\n",
      "2019-07-11 11:28:15.491447: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "I0711 11:28:15.950692 140232776353600 basic_session_run_hooks.py:262] loss = 0.42724407, step = 1200\n",
      "I0711 11:28:55.822893 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 2.50798\n",
      "I0711 11:28:55.823926 140232776353600 basic_session_run_hooks.py:260] loss = 3.5192876, step = 1300 (39.873 sec)\n",
      "I0711 11:29:25.842127 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.3312\n",
      "I0711 11:29:25.843346 140232776353600 basic_session_run_hooks.py:260] loss = 0.49941307, step = 1400 (30.019 sec)\n",
      "I0711 11:29:55.934773 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.32307\n",
      "I0711 11:29:55.935912 140232776353600 basic_session_run_hooks.py:260] loss = 0.84845746, step = 1500 (30.093 sec)\n",
      "I0711 11:30:26.040263 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.32164\n",
      "I0711 11:30:26.040939 140232776353600 basic_session_run_hooks.py:260] loss = 0.5270011, step = 1600 (30.105 sec)\n",
      "I0711 11:30:56.150121 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.32118\n",
      "I0711 11:30:56.151206 140232776353600 basic_session_run_hooks.py:260] loss = 0.7376736, step = 1700 (30.110 sec)\n",
      "I0711 11:31:25.976643 140232776353600 basic_session_run_hooks.py:606] Saving checkpoints for 1800 into data/xlnet-chkp/glue-stsb-chkp/model.ckpt.\n",
      "I0711 11:31:29.187404 140232776353600 checkpoint_management.py:95] data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1800 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "I0711 11:31:31.062828 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 2.86429\n",
      "I0711 11:31:31.064039 140232776353600 basic_session_run_hooks.py:260] loss = 0.18964419, step = 1800 (34.913 sec)\n",
      "I0711 11:32:01.167753 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.32171\n",
      "I0711 11:32:01.168766 140232776353600 basic_session_run_hooks.py:260] loss = 0.62429106, step = 1900 (30.105 sec)\n",
      "I0711 11:32:31.269597 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.32205\n",
      "I0711 11:32:31.270550 140232776353600 basic_session_run_hooks.py:260] loss = 1.5620623, step = 2000 (30.102 sec)\n",
      "I0711 11:33:01.387222 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.32032\n",
      "I0711 11:33:01.388438 140232776353600 basic_session_run_hooks.py:260] loss = 0.45021614, step = 2100 (30.118 sec)\n",
      "I0711 11:33:31.510616 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.31967\n",
      "I0711 11:33:31.511340 140232776353600 basic_session_run_hooks.py:260] loss = 0.12786752, step = 2200 (30.123 sec)\n",
      "I0711 11:34:01.645177 140232776353600 basic_session_run_hooks.py:692] global_step/sec: 3.31846\n",
      "I0711 11:34:01.646229 140232776353600 basic_session_run_hooks.py:260] loss = 0.17149991, step = 2300 (30.135 sec)\n",
      "I0711 11:34:31.484309 140232776353600 basic_session_run_hooks.py:606] Saving checkpoints for 2400 into data/xlnet-chkp/glue-stsb-chkp/model.ckpt.\n",
      "I0711 11:34:34.676702 140232776353600 checkpoint_management.py:95] data/xlnet-chkp/glue-stsb-chkp/model.ckpt-2400 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "I0711 11:34:36.502206 140232776353600 estimator.py:368] Loss for final step: 0.33709666.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "export SCRIPT_DIR=\"xlnet/\"\n",
    "export GLUE_DIR=\"xlnet/glue\"\n",
    "export LARGE_DIR=\"data/xlnet_cased_L-24_H-1024_A-16\"\n",
    "export OUTPUT_DIR=\"data/xlnet-out/glue-stsb-out\"\n",
    "export CHECKPOINT_DIR=\"data/xlnet-chkp/glue-stsb-chkp\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 python3 ${SCRIPT_DIR}run_classifier.py \\\n",
    "  --do_train=True \\\n",
    "  --do_eval=False \\\n",
    "  --task_name=sts-b \\\n",
    "  --data_dir=${GLUE_DIR}/STS-B \\\n",
    "  --output_dir=${OUTPUT_DIR} \\\n",
    "  --model_dir=${CHECKPOINT_DIR} \\\n",
    "  --uncased=False \\\n",
    "  --spiece_model_file=${LARGE_DIR}/spiece.model \\\n",
    "  --model_config_path=${LARGE_DIR}/xlnet_config.json \\\n",
    "  --init_checkpoint=${LARGE_DIR}/xlnet_model.ckpt \\\n",
    "  --max_seq_length=128 \\\n",
    "  --train_batch_size=4 \\\n",
    "  --num_hosts=1 \\\n",
    "  --num_core_per_host=1 \\\n",
    "  --learning_rate=5e-5 \\\n",
    "  --train_steps=2400 \\\n",
    "  --warmup_steps=120 \\\n",
    "  --save_steps=600 \\\n",
    "  --is_regression=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T09:44:30.730577Z",
     "start_time": "2019-07-11T09:40:54.452071Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0711 11:40:55.583007 140643517712192 model_utils.py:36] Single device mode.\n",
      "W0711 11:40:56.031778 140643517712192 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "I0711 11:40:56.032244 140643517712192 estimator.py:209] Using config: {'_model_dir': 'data/xlnet-chkp/glue-stsb-chkp', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe9ffb1ada0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=1, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
      "W0711 11:40:56.032457 140643517712192 model_fn.py:630] Estimator's model_fn (<function get_model_fn.<locals>.model_fn at 0x7fea0011f7b8>) includes params argument, but params are not passed to Estimator.\n",
      "I0711 11:40:56.040049 140643517712192 run_classifier.py:737] Num of eval samples: 1500\n",
      "I0711 11:40:56.040186 140643517712192 run_classifier.py:410] Do not overwrite tfrecord data/xlnet-out/glue-stsb-out/spiece.model.len-128.dev.eval.tf_record exists.\n",
      "I0711 11:40:56.040266 140643517712192 run_classifier.py:467] Input tfrecord file data/xlnet-out/glue-stsb-out/spiece.model.len-128.dev.eval.tf_record\n",
      "I0711 11:40:56.040385 140643517712192 run_classifier.py:776] Add data/xlnet-chkp/glue-stsb-chkp/model.ckpt-0 to eval list.\n",
      "I0711 11:40:56.040425 140643517712192 run_classifier.py:776] Add data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1800 to eval list.\n",
      "I0711 11:40:56.040458 140643517712192 run_classifier.py:776] Add data/xlnet-chkp/glue-stsb-chkp/model.ckpt-600 to eval list.\n",
      "I0711 11:40:56.040490 140643517712192 run_classifier.py:776] Add data/xlnet-chkp/glue-stsb-chkp/model.ckpt-2400 to eval list.\n",
      "I0711 11:40:56.040520 140643517712192 run_classifier.py:776] Add data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1200 to eval list.\n",
      "W0711 11:40:56.054031 140643517712192 deprecation.py:323] From xlnet/run_classifier.py:512: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "W0711 11:40:56.054142 140643517712192 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "I0711 11:40:56.066909 140643517712192 estimator.py:1145] Calling model_fn.\n",
      "I0711 11:40:56.072256 140643517712192 modeling.py:453] memory input None\n",
      "I0711 11:40:56.072328 140643517712192 modeling.py:455] Use float type <dtype: 'float32'>\n",
      "W0711 11:40:56.108368 140643517712192 deprecation.py:323] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/modeling.py:535: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0711 11:40:56.277534 140643517712192 deprecation.py:323] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/modeling.py:67: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0711 11:41:00.394492 140643517712192 deprecation_wrapper.py:119] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/function_builder.py:199: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "I0711 11:41:00.411527 140643517712192 run_classifier.py:535] #params: 361318401\n",
      "W0711 11:41:00.411658 140643517712192 deprecation_wrapper.py:119] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/model_utils.py:61: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0711 11:41:00.442209 140643517712192 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/contrib/metrics/python/ops/metric_ops.py:3259: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "I0711 11:41:00.495944 140643517712192 estimator.py:1147] Done calling model_fn.\n",
      "I0711 11:41:00.507367 140643517712192 evaluation.py:255] Starting evaluation at 2019-07-11T11:41:00Z\n",
      "I0711 11:41:01.071150 140643517712192 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-11 11:41:01.071406: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-07-11 11:41:01.095703: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2019-07-11 11:41:01.096700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5569b55754c0 executing computations on platform Host. Devices:\n",
      "2019-07-11 11:41:01.096744: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-11 11:41:01.098459: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-07-11 11:41:01.110841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:17:00.0\n",
      "2019-07-11 11:41:01.111250: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-11 11:41:01.113097: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-11 11:41:01.114590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-11 11:41:01.114999: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-11 11:41:01.117049: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-11 11:41:01.118601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-11 11:41:01.122904: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-11 11:41:01.124340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-11 11:41:01.124387: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-11 11:41:01.273523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-11 11:41:01.273547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-11 11:41:01.273553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-11 11:41:01.277504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10468 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2019-07-11 11:41:01.279149: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5569b6424a70 executing computations on platform CUDA. Devices:\n",
      "2019-07-11 11:41:01.279164: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "W0711 11:41:01.280048 140643517712192 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0711 11:41:01.282081 140643517712192 saver.py:1280] Restoring parameters from data/xlnet-chkp/glue-stsb-chkp/model.ckpt-0\n",
      "2019-07-11 11:41:03.654580: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0711 11:41:03.685070 140643517712192 session_manager.py:500] Running local_init_op.\n",
      "I0711 11:41:03.791596 140643517712192 session_manager.py:502] Done running local_init_op.\n",
      "2019-07-11 11:41:07.982467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "I0711 11:41:11.029264 140643517712192 evaluation.py:167] Evaluation [18/188]\n",
      "I0711 11:41:13.952734 140643517712192 evaluation.py:167] Evaluation [36/188]\n",
      "I0711 11:41:16.888483 140643517712192 evaluation.py:167] Evaluation [54/188]\n",
      "I0711 11:41:19.824990 140643517712192 evaluation.py:167] Evaluation [72/188]\n",
      "I0711 11:41:22.767906 140643517712192 evaluation.py:167] Evaluation [90/188]\n",
      "I0711 11:41:25.715908 140643517712192 evaluation.py:167] Evaluation [108/188]\n",
      "I0711 11:41:28.667619 140643517712192 evaluation.py:167] Evaluation [126/188]\n",
      "I0711 11:41:31.622834 140643517712192 evaluation.py:167] Evaluation [144/188]\n",
      "I0711 11:41:34.588833 140643517712192 evaluation.py:167] Evaluation [162/188]\n",
      "I0711 11:41:37.555593 140643517712192 evaluation.py:167] Evaluation [180/188]\n",
      "I0711 11:41:38.876455 140643517712192 evaluation.py:167] Evaluation [188/188]\n",
      "I0711 11:41:39.059348 140643517712192 evaluation.py:275] Finished evaluation at 2019-07-11-11:41:39\n",
      "I0711 11:41:39.059587 140643517712192 estimator.py:2039] Saving dict for global step 0: eval_loss = 8.614786, eval_pearsonr = 0.13147868, global_step = 0, loss = 8.591885\n",
      "I0711 11:41:39.862783 140643517712192 estimator.py:2099] Saving 'checkpoint_path' summary for global step 0: data/xlnet-chkp/glue-stsb-chkp/model.ckpt-0\n",
      "I0711 11:41:39.863268 140643517712192 run_classifier.py:796] ================================================================================\n",
      "I0711 11:41:39.863373 140643517712192 run_classifier.py:800] Eval result | eval_loss 8.614786148071289 | eval_pearsonr 0.1314786821603775 | global_step 0 | loss 8.59188461303711 | path data/xlnet-chkp/glue-stsb-chkp/model.ckpt-0 | step 0 | \n",
      "I0711 11:41:39.884105 140643517712192 estimator.py:1145] Calling model_fn.\n",
      "I0711 11:41:39.889539 140643517712192 modeling.py:453] memory input None\n",
      "I0711 11:41:39.889633 140643517712192 modeling.py:455] Use float type <dtype: 'float32'>\n",
      "I0711 11:41:44.165055 140643517712192 run_classifier.py:535] #params: 361318401\n",
      "I0711 11:41:44.249171 140643517712192 estimator.py:1147] Done calling model_fn.\n",
      "I0711 11:41:44.260561 140643517712192 evaluation.py:255] Starting evaluation at 2019-07-11T11:41:44Z\n",
      "I0711 11:41:44.704470 140643517712192 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-11 11:41:44.705344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:17:00.0\n",
      "2019-07-11 11:41:44.705416: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-11 11:41:44.705429: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-11 11:41:44.705441: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-11 11:41:44.705451: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-11 11:41:44.705461: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-11 11:41:44.705472: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-11 11:41:44.705483: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-11 11:41:44.706272: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-11 11:41:44.706294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-11 11:41:44.706299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-11 11:41:44.706304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-11 11:41:44.707141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10468 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "I0711 11:41:44.708240 140643517712192 saver.py:1280] Restoring parameters from data/xlnet-chkp/glue-stsb-chkp/model.ckpt-600\n",
      "I0711 11:41:46.313641 140643517712192 session_manager.py:500] Running local_init_op.\n",
      "I0711 11:41:46.416827 140643517712192 session_manager.py:502] Done running local_init_op.\n",
      "I0711 11:41:53.479057 140643517712192 evaluation.py:167] Evaluation [18/188]\n",
      "I0711 11:41:56.444801 140643517712192 evaluation.py:167] Evaluation [36/188]\n",
      "I0711 11:41:59.422103 140643517712192 evaluation.py:167] Evaluation [54/188]\n",
      "I0711 11:42:02.396754 140643517712192 evaluation.py:167] Evaluation [72/188]\n",
      "I0711 11:42:05.380403 140643517712192 evaluation.py:167] Evaluation [90/188]\n",
      "I0711 11:42:08.367272 140643517712192 evaluation.py:167] Evaluation [108/188]\n",
      "I0711 11:42:11.360982 140643517712192 evaluation.py:167] Evaluation [126/188]\n",
      "I0711 11:42:14.353618 140643517712192 evaluation.py:167] Evaluation [144/188]\n",
      "I0711 11:42:17.346246 140643517712192 evaluation.py:167] Evaluation [162/188]\n",
      "I0711 11:42:20.340421 140643517712192 evaluation.py:167] Evaluation [180/188]\n",
      "I0711 11:42:21.678080 140643517712192 evaluation.py:167] Evaluation [188/188]\n",
      "I0711 11:42:21.859275 140643517712192 evaluation.py:275] Finished evaluation at 2019-07-11-11:42:21\n",
      "I0711 11:42:21.859464 140643517712192 estimator.py:2039] Saving dict for global step 600: eval_loss = 1.6576071, eval_pearsonr = 0.66614336, global_step = 600, loss = 1.673743\n",
      "I0711 11:42:21.859786 140643517712192 estimator.py:2099] Saving 'checkpoint_path' summary for global step 600: data/xlnet-chkp/glue-stsb-chkp/model.ckpt-600\n",
      "I0711 11:42:21.860134 140643517712192 run_classifier.py:796] ================================================================================\n",
      "I0711 11:42:21.860220 140643517712192 run_classifier.py:800] Eval result | eval_loss 1.657607078552246 | eval_pearsonr 0.6661433577537537 | global_step 600 | loss 1.6737430095672607 | path data/xlnet-chkp/glue-stsb-chkp/model.ckpt-600 | step 600 | \n",
      "I0711 11:42:21.880942 140643517712192 estimator.py:1145] Calling model_fn.\n",
      "I0711 11:42:21.886151 140643517712192 modeling.py:453] memory input None\n",
      "I0711 11:42:21.886223 140643517712192 modeling.py:455] Use float type <dtype: 'float32'>\n",
      "I0711 11:42:26.147634 140643517712192 run_classifier.py:535] #params: 361318401\n",
      "I0711 11:42:26.233500 140643517712192 estimator.py:1147] Done calling model_fn.\n",
      "I0711 11:42:26.245178 140643517712192 evaluation.py:255] Starting evaluation at 2019-07-11T11:42:26Z\n",
      "I0711 11:42:26.684597 140643517712192 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-11 11:42:26.686990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:17:00.0\n",
      "2019-07-11 11:42:26.687047: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-11 11:42:26.687055: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-11 11:42:26.687061: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-11 11:42:26.687068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-11 11:42:26.687074: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-11 11:42:26.687081: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-11 11:42:26.687087: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-11 11:42:26.687891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-11 11:42:26.687914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-11 11:42:26.687918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-11 11:42:26.687921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-11 11:42:26.688751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10468 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "I0711 11:42:26.689829 140643517712192 saver.py:1280] Restoring parameters from data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1200\n",
      "I0711 11:42:28.302063 140643517712192 session_manager.py:500] Running local_init_op.\n",
      "I0711 11:42:28.404710 140643517712192 session_manager.py:502] Done running local_init_op.\n",
      "I0711 11:42:35.593642 140643517712192 evaluation.py:167] Evaluation [18/188]\n",
      "I0711 11:42:38.580402 140643517712192 evaluation.py:167] Evaluation [36/188]\n",
      "I0711 11:42:41.567523 140643517712192 evaluation.py:167] Evaluation [54/188]\n",
      "I0711 11:42:44.561248 140643517712192 evaluation.py:167] Evaluation [72/188]\n",
      "I0711 11:42:47.556590 140643517712192 evaluation.py:167] Evaluation [90/188]\n",
      "I0711 11:42:50.552341 140643517712192 evaluation.py:167] Evaluation [108/188]\n",
      "I0711 11:42:53.552232 140643517712192 evaluation.py:167] Evaluation [126/188]\n",
      "I0711 11:42:56.576166 140643517712192 evaluation.py:167] Evaluation [144/188]\n",
      "I0711 11:42:59.614749 140643517712192 evaluation.py:167] Evaluation [162/188]\n",
      "I0711 11:43:02.707036 140643517712192 evaluation.py:167] Evaluation [180/188]\n",
      "I0711 11:43:04.102820 140643517712192 evaluation.py:167] Evaluation [188/188]\n",
      "I0711 11:43:04.286196 140643517712192 evaluation.py:275] Finished evaluation at 2019-07-11-11:43:04\n",
      "I0711 11:43:04.286382 140643517712192 estimator.py:2039] Saving dict for global step 1200: eval_loss = 0.64030874, eval_pearsonr = 0.8513772, global_step = 1200, loss = 0.6572416\n",
      "I0711 11:43:04.286842 140643517712192 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1200: data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1200\n",
      "I0711 11:43:04.287222 140643517712192 run_classifier.py:796] ================================================================================\n",
      "I0711 11:43:04.287298 140643517712192 run_classifier.py:800] Eval result | eval_loss 0.6403087377548218 | eval_pearsonr 0.8513771891593933 | global_step 1200 | loss 0.6572415828704834 | path data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1200 | step 1200 | \n",
      "I0711 11:43:04.308525 140643517712192 estimator.py:1145] Calling model_fn.\n",
      "I0711 11:43:04.313782 140643517712192 modeling.py:453] memory input None\n",
      "I0711 11:43:04.313860 140643517712192 modeling.py:455] Use float type <dtype: 'float32'>\n",
      "I0711 11:43:08.685817 140643517712192 run_classifier.py:535] #params: 361318401\n",
      "I0711 11:43:08.769568 140643517712192 estimator.py:1147] Done calling model_fn.\n",
      "I0711 11:43:08.780919 140643517712192 evaluation.py:255] Starting evaluation at 2019-07-11T11:43:08Z\n",
      "I0711 11:43:09.227590 140643517712192 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-11 11:43:09.228448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:17:00.0\n",
      "2019-07-11 11:43:09.228508: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-11 11:43:09.228518: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-11 11:43:09.228524: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-11 11:43:09.228531: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-11 11:43:09.228538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-11 11:43:09.228544: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-11 11:43:09.228550: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-11 11:43:09.229315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-11 11:43:09.229337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-11 11:43:09.229342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-11 11:43:09.229345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-11 11:43:09.230173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10468 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "I0711 11:43:09.231287 140643517712192 saver.py:1280] Restoring parameters from data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1800\n",
      "I0711 11:43:10.833962 140643517712192 session_manager.py:500] Running local_init_op.\n",
      "I0711 11:43:10.940055 140643517712192 session_manager.py:502] Done running local_init_op.\n",
      "I0711 11:43:18.198366 140643517712192 evaluation.py:167] Evaluation [18/188]\n",
      "I0711 11:43:21.194160 140643517712192 evaluation.py:167] Evaluation [36/188]\n",
      "I0711 11:43:24.189100 140643517712192 evaluation.py:167] Evaluation [54/188]\n",
      "I0711 11:43:27.184609 140643517712192 evaluation.py:167] Evaluation [72/188]\n",
      "I0711 11:43:30.185204 140643517712192 evaluation.py:167] Evaluation [90/188]\n",
      "I0711 11:43:33.191348 140643517712192 evaluation.py:167] Evaluation [108/188]\n",
      "I0711 11:43:36.247446 140643517712192 evaluation.py:167] Evaluation [126/188]\n",
      "I0711 11:43:39.350127 140643517712192 evaluation.py:167] Evaluation [144/188]\n",
      "I0711 11:43:42.435407 140643517712192 evaluation.py:167] Evaluation [162/188]\n",
      "I0711 11:43:45.571877 140643517712192 evaluation.py:167] Evaluation [180/188]\n",
      "I0711 11:43:46.948443 140643517712192 evaluation.py:167] Evaluation [188/188]\n",
      "I0711 11:43:47.116312 140643517712192 evaluation.py:275] Finished evaluation at 2019-07-11-11:43:47\n",
      "I0711 11:43:47.116500 140643517712192 estimator.py:2039] Saving dict for global step 1800: eval_loss = 0.5516741, eval_pearsonr = 0.8788372, global_step = 1800, loss = 0.56277686\n",
      "I0711 11:43:47.117028 140643517712192 estimator.py:2099] Saving 'checkpoint_path' summary for global step 1800: data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1800\n",
      "I0711 11:43:47.117427 140643517712192 run_classifier.py:796] ================================================================================\n",
      "I0711 11:43:47.117516 140643517712192 run_classifier.py:800] Eval result | eval_loss 0.5516741275787354 | eval_pearsonr 0.8788372278213501 | global_step 1800 | loss 0.5627768635749817 | path data/xlnet-chkp/glue-stsb-chkp/model.ckpt-1800 | step 1800 | \n",
      "I0711 11:43:47.138417 140643517712192 estimator.py:1145] Calling model_fn.\n",
      "I0711 11:43:47.143651 140643517712192 modeling.py:453] memory input None\n",
      "I0711 11:43:47.143729 140643517712192 modeling.py:455] Use float type <dtype: 'float32'>\n",
      "I0711 11:43:51.388132 140643517712192 run_classifier.py:535] #params: 361318401\n",
      "I0711 11:43:51.471653 140643517712192 estimator.py:1147] Done calling model_fn.\n",
      "I0711 11:43:51.482949 140643517712192 evaluation.py:255] Starting evaluation at 2019-07-11T11:43:51Z\n",
      "I0711 11:43:51.923652 140643517712192 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-11 11:43:51.924496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:17:00.0\n",
      "2019-07-11 11:43:51.924555: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-11 11:43:51.924564: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-11 11:43:51.924572: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-11 11:43:51.924578: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-11 11:43:51.924584: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-11 11:43:51.924590: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-11 11:43:51.924597: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-11 11:43:51.925360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-11 11:43:51.925380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-11 11:43:51.925384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-11 11:43:51.925388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-11 11:43:51.926197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10468 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "I0711 11:43:51.927384 140643517712192 saver.py:1280] Restoring parameters from data/xlnet-chkp/glue-stsb-chkp/model.ckpt-2400\n",
      "I0711 11:43:53.539577 140643517712192 session_manager.py:500] Running local_init_op.\n",
      "I0711 11:43:53.644468 140643517712192 session_manager.py:502] Done running local_init_op.\n",
      "I0711 11:44:00.813183 140643517712192 evaluation.py:167] Evaluation [18/188]\n",
      "I0711 11:44:03.803793 140643517712192 evaluation.py:167] Evaluation [36/188]\n",
      "I0711 11:44:06.797514 140643517712192 evaluation.py:167] Evaluation [54/188]\n",
      "I0711 11:44:09.799580 140643517712192 evaluation.py:167] Evaluation [72/188]\n",
      "I0711 11:44:12.803678 140643517712192 evaluation.py:167] Evaluation [90/188]\n",
      "I0711 11:44:15.812219 140643517712192 evaluation.py:167] Evaluation [108/188]\n",
      "I0711 11:44:18.891718 140643517712192 evaluation.py:167] Evaluation [126/188]\n",
      "I0711 11:44:21.976187 140643517712192 evaluation.py:167] Evaluation [144/188]\n",
      "I0711 11:44:25.125647 140643517712192 evaluation.py:167] Evaluation [162/188]\n",
      "I0711 11:44:28.280249 140643517712192 evaluation.py:167] Evaluation [180/188]\n",
      "I0711 11:44:29.688298 140643517712192 evaluation.py:167] Evaluation [188/188]\n",
      "I0711 11:44:29.868187 140643517712192 evaluation.py:275] Finished evaluation at 2019-07-11-11:44:29\n",
      "I0711 11:44:29.868374 140643517712192 estimator.py:2039] Saving dict for global step 2400: eval_loss = 0.45027885, eval_pearsonr = 0.8955718, global_step = 2400, loss = 0.46555915\n",
      "I0711 11:44:29.868834 140643517712192 estimator.py:2099] Saving 'checkpoint_path' summary for global step 2400: data/xlnet-chkp/glue-stsb-chkp/model.ckpt-2400\n",
      "I0711 11:44:29.869211 140643517712192 run_classifier.py:796] ================================================================================\n",
      "I0711 11:44:29.869291 140643517712192 run_classifier.py:800] Eval result | eval_loss 0.4502788484096527 | eval_pearsonr 0.8955718278884888 | global_step 2400 | loss 0.4655591547489166 | path data/xlnet-chkp/glue-stsb-chkp/model.ckpt-2400 | step 2400 | \n",
      "I0711 11:44:29.869334 140643517712192 run_classifier.py:805] ================================================================================\n",
      "I0711 11:44:29.869371 140643517712192 run_classifier.py:812] Best result | eval_loss 0.4502788484096527 | eval_pearsonr 0.8955718278884888 | global_step 2400 | loss 0.4655591547489166 | path data/xlnet-chkp/glue-stsb-chkp/model.ckpt-2400 | step 2400 | \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "export SCRIPT_DIR=\"xlnet/\"\n",
    "export GLUE_DIR=\"xlnet/glue\"\n",
    "export LARGE_DIR=\"data/xlnet_cased_L-24_H-1024_A-16\"\n",
    "export OUTPUT_DIR=\"data/xlnet-out/glue-stsb-out\"\n",
    "export CHECKPOINT_DIR=\"data/xlnet-chkp/glue-stsb-chkp\"\n",
    "\n",
    "CUDA_VISIBLE_DEVICES=0 python3 ${SCRIPT_DIR}run_classifier.py \\\n",
    "  --do_train=False \\\n",
    "  --do_eval=True \\\n",
    "  --task_name=sts-b \\\n",
    "  --data_dir=${GLUE_DIR}/STS-B \\\n",
    "  --output_dir=${OUTPUT_DIR} \\\n",
    "  --model_dir=${CHECKPOINT_DIR} \\\n",
    "  --uncased=False \\\n",
    "  --spiece_model_file=${LARGE_DIR}/spiece.model \\\n",
    "  --model_config_path=${LARGE_DIR}/xlnet_config.json \\\n",
    "  --max_seq_length=128 \\\n",
    "  --eval_batch_size=8 \\\n",
    "  --num_hosts=1 \\\n",
    "  --num_core_per_host=1 \\\n",
    "  --eval_all_ckpt=True \\\n",
    "  --is_regression=True\n",
    "\n",
    "# Expected performance: \"eval_pearsonr 0.916+ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data format\n",
    "\n",
    "https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T09:38:14.839983Z",
     "start_time": "2019-07-11T09:38:14.585368Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T09:38:17.109284Z",
     "start_time": "2019-07-11T09:38:14.844068Z"
    },
    "code_folding": [
     3,
     10,
     18,
     25
    ]
   },
   "outputs": [],
   "source": [
    "data_cross_path = 'data/same-side-classification/cross-topic/{}.csv'\n",
    "data_within_path = 'data/same-side-classification/within-topic/{}.csv'\n",
    "\n",
    "cross_traindev_df = pd.read_csv(data_cross_path.format('training'),\n",
    "                                quotechar='\"',\n",
    "                                quoting=csv.QUOTE_ALL,\n",
    "                                encoding='utf-8',\n",
    "                                escapechar='\\\\',\n",
    "                                doublequote=False,\n",
    "                                index_col='id')\n",
    "cross_test_df = pd.read_csv(data_cross_path.format('test'),\n",
    "                            quotechar='\"',\n",
    "                            quoting=csv.QUOTE_ALL,\n",
    "                            encoding='utf-8',\n",
    "                            escapechar='\\\\',\n",
    "                            doublequote=False,\n",
    "                            index_col='id')\n",
    "\n",
    "within_traindev_df = pd.read_csv(data_within_path.format('training'),\n",
    "                                 quotechar='\"',\n",
    "                                 quoting=csv.QUOTE_ALL,\n",
    "                                 encoding='utf-8',\n",
    "                                 escapechar='\\\\',\n",
    "                                 doublequote=False,\n",
    "                                 index_col='id')\n",
    "within_test_df = pd.read_csv(data_within_path.format('test'),\n",
    "                             quotechar='\"',\n",
    "                             quoting=csv.QUOTE_ALL,\n",
    "                             encoding='utf-8',\n",
    "                             escapechar='\\\\',\n",
    "                             doublequote=False,\n",
    "                             index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T09:39:58.863505Z",
     "start_time": "2019-07-11T09:38:17.141230Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Adding a tag for the topics in focus: \"gay marriage\" and \"abortion\"\n",
    "def add_tag(row):\n",
    "    title = row['topic'].lower().strip()\n",
    "    if \"abortion\" in title:\n",
    "        row['tag'] = 'abortion'\n",
    "    elif \"gay marriage\" in title:\n",
    "        row['tag'] = 'gay marriage'\n",
    "    else:\n",
    "        row['tag'] = 'NA'\n",
    "    return row\n",
    "\n",
    "\n",
    "cross_traindev_df = cross_traindev_df.apply(add_tag, axis=1)\n",
    "cross_test_df = cross_test_df.apply(add_tag, axis=1)\n",
    "\n",
    "within_traindev_df = within_traindev_df.apply(add_tag, axis=1)\n",
    "within_test_df = within_test_df.apply(add_tag, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T09:39:59.079790Z",
     "start_time": "2019-07-11T09:39:58.898018Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def get_train_test_sets(df, ratio=0.30, random_state=1):\n",
    "    X = df[['argument1', 'argument2', 'argument1_id', 'argument2_id', 'topic']]\n",
    "    y = df[['is_same_side']]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=ratio, random_state=random_state, shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T09:39:59.136753Z",
     "start_time": "2019-07-11T09:39:59.114872Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = get_train_test_sets(within_traindev_df)\n",
    "X_test = within_test_df\n",
    "# X_train, X_dev, y_train, y_dev = get_train_test_sets(cross_traindev_df)\n",
    "# X_test = cross_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T09:40:05.189638Z",
     "start_time": "2019-07-11T09:39:59.191086Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44732it [00:02, 16427.73it/s]\n",
      "19171it [00:01, 16312.33it/s]\n",
      "31475it [00:01, 17884.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "DATA_DIR = 'data/xlnet-in'\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)\n",
    "    \n",
    "DATA_DIR = os.path.join(DATA_DIR, 'ssc-within')\n",
    "# DATA_DIR = os.path.join(DATA_DIR, 'ssc-cross')\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.mkdir(DATA_DIR)\n",
    "\n",
    "train_df = X_train.join(y_train)\n",
    "dev_df = X_dev.join(y_dev)\n",
    "test_df = X_test\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'train.tsv'), 'w', encoding='utf-8') as fh:\n",
    "    fh.write(\"label\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n",
    "    for _, row in tqdm(train_df.iterrows()):\n",
    "        fh.write(\"{}\\t{}\\t{}\\n\".format(\n",
    "            (1 if row['is_same_side'] else 0), row['argument1'], row['argument2']))\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'dev.tsv'), 'w', encoding='utf-8') as fh:\n",
    "    fh.write(\"label\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n",
    "    for _, row in tqdm(dev_df.iterrows()):\n",
    "        fh.write(\"{}\\t{}\\t{}\\n\".format(\n",
    "            (1 if row['is_same_side'] else 0), row['argument1'], row['argument2']))\n",
    "\n",
    "with open(os.path.join(DATA_DIR, 'test.tsv'), 'w', encoding='utf-8') as fh:\n",
    "    fh.write(\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\")\n",
    "    for id_, row in tqdm(test_df.iterrows()):\n",
    "        fh.write(\"{}\\t{}\\t{}\\n\".format(id_, row['argument1'], row['argument2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 2 data/xlnet-in/ssc-within/train.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T14:11:37.843776Z",
     "start_time": "2019-07-11T14:11:36.450870Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()\n",
    "\n",
    "\n",
    "def search_tab(row):\n",
    "    return \"\\t\" in row['argument1'] or \"\\t\" in row['argument2']\n",
    "\n",
    "\n",
    "print(np.unique(train_df.progress_apply(search_tab, axis=1)))\n",
    "print(np.unique(dev_df.progress_apply(search_tab, axis=1)))\n",
    "print(np.unique(test_df.progress_apply(search_tab, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T16:00:12.855786Z",
     "start_time": "2019-07-14T16:00:12.849732Z"
    }
   },
   "outputs": [],
   "source": [
    "TASK_NAME = 'ssc-within' #@param{type:\"string\"}\n",
    "SCRIPTS_DIR = 'xlnet' #@param {type:\"string\"}\n",
    "DATA_DIR = 'data/xlnet-in/ssc-within' #@param {type:\"string\"}\n",
    "OUTPUT_DIR = 'data/xlnet-out/ssc-within5' #@param {type:\"string\"}\n",
    "PRETRAINED_MODEL_DIR = 'data/xlnet_cased_L-24_H-1024_A-16' #@param {type:\"string\"}\n",
    "CHECKPOINT_DIR = 'data/xlnet-chkp/ssc-within5' #@param {type:\"string\"}\n",
    "\n",
    "DO_TRAIN = True\n",
    "DO_EVAL = True\n",
    "\n",
    "MAX_SEQ_LEN = '128'  # '512'  # '256'  # '128'\n",
    "BATCH_SIZE = '6'  # '1'  # '3'  # '6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run model (training & evaluation)\n",
    "\n",
    "*not sure what **train/dev/test** data split is when using XLNet...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Patch file `xlnet/run_classifier.py` for using our own data\n",
    "\n",
    "See at the end a diff/patch snippet\n",
    "\n",
    "--- \n",
    "\n",
    "```python\n",
    "# at line: 343\n",
    "\n",
    "class SSCProcessor(GLUEProcessor):\n",
    "  def __init__(self):\n",
    "    super(SSCProcessor, self).__init__()\n",
    "    self.label_column = 0\n",
    "    self.text_a_column = 1  # 3\n",
    "    self.text_b_column = 2  # 4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# in: def main(_)\n",
    "# variable: processors = {}\n",
    "# at line: 660\n",
    "\n",
    "      'ssc-within': SSCProcessor,\n",
    "      'ssc-cross': SSCProcessor,\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-14T16:11:41.359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0714 18:11:40.128664 140278410770240 model_utils.py:36] Single device mode.\n",
      "W0714 18:11:40.636371 140278410770240 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "I0714 18:11:40.636813 140278410770240 estimator.py:209] Using config: {'_model_dir': 'data/xlnet-chkp/ssc-within5', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 500, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 0, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f948ec96710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=500, num_shards=1, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': None}\n",
      "W0714 18:11:40.636938 140278410770240 model_fn.py:630] Estimator's model_fn (<function get_model_fn.<locals>.model_fn at 0x7f950095da60>) includes params argument, but params are not passed to Estimator.\n",
      "I0714 18:11:40.637125 140278410770240 run_classifier.py:726] Use tfrecord file data/xlnet-out/ssc-within5/spiece.model.len-128.train.tf_record\n",
      "======================================================================\n",
      "======================================================================\n",
      "Dump some data ...\n",
      "train-1 \n",
      "\t wanted fetuses are beloved \"babies\"; unwanted ones are \"tissue\" (inconsistent) \n",
      "\t abortions are emotionally and psychologically unsafe. \n",
      "\t 1\n",
      "train-2 \n",
      "\t abortions are mostly sought when birth control fails clayton h. mccracken, director of inter mountain planned parenthood, fall 2000 - \"most of the patients come to our abortion clinic as a result of failure of a birth control method, or a failure of our system to provide birth control.\"[26] \n",
      "\t a fetus cannot have a right to a woman's body to sustain its life \n",
      "\t 1\n",
      "train-3 \n",
      "\t gay marriage is a negligible change to institution of marriage \n",
      "\t if gays get civil unions, why withhold \"marriage\"? \n",
      "\t 1\n",
      "train-4 \n",
      "\t well it is still a living thing :) and it is wrong because you are basically murdering an innocent child so i believe that you should not kill innocent children unless you want to be known as a murderer \n",
      "\t \"i believe that even \"a clump of cells\" is still life.... it is forming into something so precious that god has given you\" i never denied it was life. i never even denied the unborns humanity. what i did deny was whether the unborn are people. you have not even touched this aspect of my argument. \"i think abortion is wrong in any and all ways.\" you still have to prove it. \"if you want to have sex then you will have to deal with the consequences.\" my case has been basically dropped by my opponent. i believe i addressed this above. extend my attack. \n",
      "\t 0\n",
      "train-5 \n",
      "\t hypocritical to protect fetuses, but casually wage war rick claro - \"george w. bush will protect your unborn fetus, then send your grown child to die in war.\"[5] this is a common argument that undermines the notion of \"the sanctity of life\" and the notion that it is \"inviolable\". clearly, in war, humans frequently justify killing other human beings. \n",
      "\t a fetus is no more a human than an acorn is a tree judith jarvis thomson. \"a defense of abortion\". philosophy & public affairs, vol. 1, no. 1 (fall 1971). - \"most opposition to abortion relies on the premise that the fetus is a human being, a person, from the moment of conception. the premise is argued for, but, as i think, not well. take, for example, the most common argument. we are asked to notice that the development of a human being from conception through birth into childhood is continuous; then it is said that to draw a line, to choose a point in this development and say \"before this point the thing is not a person, after this point it is a person\" is to make an arbitrary choice, a choice for which in the nature of things no good reason can be given. it is concluded that the fetus is or anyway that we had better say it is, a person from the moment of conception. but this conclusion does not follow. similar things might be said about the development of an acorn into an oak trees, and it does not follow that acorns are oak trees, or that we had better say they are...a newly fertilized ovum, a newly implanted clump of cells, is no more a person than an acorn is an oak tree.\" \n",
      "\t 1\n",
      "======================================================================\n",
      "======================================================================\n",
      "I0714 18:11:41.536060 140278410770240 run_classifier.py:730] Num of train samples: 44732\n",
      "I0714 18:11:41.536261 140278410770240 run_classifier.py:423] Do not overwrite tfrecord data/xlnet-out/ssc-within5/spiece.model.len-128.train.tf_record exists.\n",
      "I0714 18:11:41.536340 140278410770240 run_classifier.py:480] Input tfrecord file data/xlnet-out/ssc-within5/spiece.model.len-128.train.tf_record\n",
      "W0714 18:11:41.545256 140278410770240 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0714 18:11:41.565254 140278410770240 deprecation.py:323] From xlnet/run_classifier.py:525: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "W0714 18:11:41.565382 140278410770240 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "I0714 18:11:41.577913 140278410770240 estimator.py:1145] Calling model_fn.\n",
      "I0714 18:11:41.583029 140278410770240 modeling.py:453] memory input None\n",
      "I0714 18:11:41.583117 140278410770240 modeling.py:455] Use float type <dtype: 'float32'>\n",
      "W0714 18:11:41.617086 140278410770240 deprecation.py:323] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/modeling.py:535: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0714 18:11:41.802165 140278410770240 deprecation.py:323] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/modeling.py:67: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0714 18:11:46.230792 140278410770240 deprecation_wrapper.py:119] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/function_builder.py:156: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "I0714 18:11:46.248230 140278410770240 run_classifier.py:548] #params: 361319426\n",
      "W0714 18:11:46.248348 140278410770240 deprecation_wrapper.py:119] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/model_utils.py:61: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "I0714 18:11:46.248408 140278410770240 model_utils.py:71] Initialize from the ckpt data/xlnet_cased_L-24_H-1024_A-16/xlnet_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0714 18:11:46.770989 140278410770240 model_utils.py:85] **** Global Variables ****\r\n",
      "I0714 18:11:46.771130 140278410770240 model_utils.py:91]   name = model/transformer/r_w_bias:0, shape = (24, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771188 140278410770240 model_utils.py:91]   name = model/transformer/r_r_bias:0, shape = (24, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771228 140278410770240 model_utils.py:91]   name = model/transformer/word_embedding/lookup_table:0, shape = (32000, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771264 140278410770240 model_utils.py:91]   name = model/transformer/r_s_bias:0, shape = (24, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771298 140278410770240 model_utils.py:91]   name = model/transformer/seg_embed:0, shape = (24, 2, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771333 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771367 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771400 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771434 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771469 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771502 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771534 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771572 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771605 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771636 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771668 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771699 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771729 140278410770240 model_utils.py:91]   name = model/transformer/layer_0/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771760 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771793 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771827 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771860 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771894 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771927 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771958 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.771989 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772037 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772068 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772101 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772132 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772162 140278410770240 model_utils.py:91]   name = model/transformer/layer_1/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772194 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772227 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772261 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772294 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772328 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772362 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772393 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772424 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772455 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772487 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772520 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772551 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772581 140278410770240 model_utils.py:91]   name = model/transformer/layer_2/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772613 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772646 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772689 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772722 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772754 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772786 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772817 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772847 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772878 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772908 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772938 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772969 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.772998 140278410770240 model_utils.py:91]   name = model/transformer/layer_3/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773028 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773061 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773094 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773125 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773157 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773189 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773219 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773249 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773280 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773310 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773341 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773371 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773401 140278410770240 model_utils.py:91]   name = model/transformer/layer_4/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773431 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773462 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773493 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773524 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773556 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773588 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773618 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773648 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773679 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773710 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773741 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773771 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0714 18:11:46.773800 140278410770240 model_utils.py:91]   name = model/transformer/layer_5/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773831 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773863 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773895 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773926 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773958 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.773991 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774021 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774051 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774082 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774112 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774143 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774173 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774202 140278410770240 model_utils.py:91]   name = model/transformer/layer_6/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774231 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774263 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774295 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774326 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774358 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774390 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774420 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774450 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774482 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774512 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774542 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774572 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774601 140278410770240 model_utils.py:91]   name = model/transformer/layer_7/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774631 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774663 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774694 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774726 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774756 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774788 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774817 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774847 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774878 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774907 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774938 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774967 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.774996 140278410770240 model_utils.py:91]   name = model/transformer/layer_8/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775025 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775056 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775087 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775119 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775151 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775199 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775233 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775279 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775321 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775354 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775386 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775416 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775447 140278410770240 model_utils.py:91]   name = model/transformer/layer_9/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775478 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775512 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775546 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775586 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775620 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775655 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775686 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775717 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775750 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775781 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775815 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775846 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775877 140278410770240 model_utils.py:91]   name = model/transformer/layer_10/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775908 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775942 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.775975 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776010 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776044 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776077 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776108 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776139 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776172 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776204 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776236 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776268 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776299 140278410770240 model_utils.py:91]   name = model/transformer/layer_11/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776330 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776364 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776398 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776432 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776476 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776509 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776539 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776570 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776602 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776633 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776664 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776695 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776726 140278410770240 model_utils.py:91]   name = model/transformer/layer_12/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776757 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776789 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776822 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776855 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776888 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776937 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.776968 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777000 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777032 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777063 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777096 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777127 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777157 140278410770240 model_utils.py:91]   name = model/transformer/layer_13/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777188 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777222 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777256 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777288 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777322 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777356 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777386 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777418 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777450 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777482 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777514 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777546 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777576 140278410770240 model_utils.py:91]   name = model/transformer/layer_14/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777608 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777641 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777675 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777709 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777743 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777778 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777809 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777840 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777873 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777905 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777937 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.777968 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778000 140278410770240 model_utils.py:91]   name = model/transformer/layer_15/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778031 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778064 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778097 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778130 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778164 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778198 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778228 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778259 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778291 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778322 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778355 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778386 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778417 140278410770240 model_utils.py:91]   name = model/transformer/layer_16/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778448 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778482 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778515 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778558 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778592 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778625 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778655 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778686 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778717 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778748 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778780 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778810 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778841 140278410770240 model_utils.py:91]   name = model/transformer/layer_17/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778872 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778905 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778938 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.778971 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779004 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779036 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779067 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779097 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779129 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779160 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779191 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779221 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779252 140278410770240 model_utils.py:91]   name = model/transformer/layer_18/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779282 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779315 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779347 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779380 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779412 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779445 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779475 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779506 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779538 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779573 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779604 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779634 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779665 140278410770240 model_utils.py:91]   name = model/transformer/layer_19/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779695 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779728 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779760 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779793 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779826 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779860 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779889 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779920 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779951 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.779981 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780012 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780042 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780071 140278410770240 model_utils.py:91]   name = model/transformer/layer_20/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780101 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780133 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780166 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780198 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780230 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780263 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780293 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780323 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780354 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780385 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780416 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780446 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780476 140278410770240 model_utils.py:91]   name = model/transformer/layer_21/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780505 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780537 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780570 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780602 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780635 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780666 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780696 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780726 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780758 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780788 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780820 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780850 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780880 140278410770240 model_utils.py:91]   name = model/transformer/layer_22/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780910 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/q/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780941 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/k/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.780974 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/v/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781007 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/r/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781039 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/o/kernel:0, shape = (1024, 16, 64), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781071 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781101 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/rel_attn/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781131 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/ff/layer_1/kernel:0, shape = (1024, 4096), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781161 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/ff/layer_1/bias:0, shape = (4096,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781191 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/ff/layer_2/kernel:0, shape = (4096, 1024), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781221 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/ff/layer_2/bias:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781251 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/ff/LayerNorm/beta:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781281 140278410770240 model_utils.py:91]   name = model/transformer/layer_23/ff/LayerNorm/gamma:0, shape = (1024,), *INIT_FROM_CKPT*\r\n",
      "I0714 18:11:46.781311 140278410770240 model_utils.py:91]   name = model/sequnece_summary/summary/kernel:0, shape = (1024, 1024)\r\n",
      "I0714 18:11:46.781342 140278410770240 model_utils.py:91]   name = model/sequnece_summary/summary/bias:0, shape = (1024,)\r\n",
      "I0714 18:11:46.781372 140278410770240 model_utils.py:91]   name = model/classification_ssc-within/logit/kernel:0, shape = (1024, 2)\r\n",
      "I0714 18:11:46.781404 140278410770240 model_utils.py:91]   name = model/classification_ssc-within/logit/bias:0, shape = (2,)\r\n",
      "W0714 18:11:46.786724 140278410770240 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/learning_rate_schedule.py:409: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Deprecated in favor of operator or tf.math.divide.\r\n",
      "W0714 18:11:46.789703 140278410770240 deprecation.py:323] From /disk1/users/ekoerner/same-side-classification/argmining19-same-side-classification/xlnet/model_utils.py:123: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0714 18:11:56.602547 140278410770240 estimator.py:1147] Done calling model_fn.\n",
      "I0714 18:11:56.603410 140278410770240 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0714 18:11:59.965594 140278410770240 monitored_session.py:240] Graph was finalized.\n",
      "2019-07-14 18:11:59.965868: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2019-07-14 18:11:59.987948: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2019-07-14 18:11:59.988892: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a78569580 executing computations on platform Host. Devices:\n",
      "2019-07-14 18:11:59.988925: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2019-07-14 18:11:59.990659: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2019-07-14 18:12:00.029419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62\n",
      "pciBusID: 0000:17:00.0\n",
      "2019-07-14 18:12:00.029676: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-14 18:12:00.030791: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "2019-07-14 18:12:00.031847: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0\n",
      "2019-07-14 18:12:00.032158: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0\n",
      "2019-07-14 18:12:00.033471: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2019-07-14 18:12:00.034395: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2019-07-14 18:12:00.036907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2019-07-14 18:12:00.038099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
      "2019-07-14 18:12:00.038137: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\n",
      "2019-07-14 18:12:00.186990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2019-07-14 18:12:00.187016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
      "2019-07-14 18:12:00.187026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
      "2019-07-14 18:12:00.188647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10468 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\n",
      "2019-07-14 18:12:00.190147: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a8e331c30 executing computations on platform CUDA. Devices:\n",
      "2019-07-14 18:12:00.190172: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "W0714 18:12:00.191231 140278410770240 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0714 18:12:00.192436 140278410770240 saver.py:1280] Restoring parameters from data/xlnet-chkp/ssc-within5/model.ckpt-0\n",
      "W0714 18:12:06.199840 140278410770240 deprecation.py:323] From /home/ekoerner/.conda/envs/argmining19-ssc/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "2019-07-14 18:12:07.398047: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\n",
      "I0714 18:12:07.501719 140278410770240 session_manager.py:500] Running local_init_op.\n",
      "I0714 18:12:07.816813 140278410770240 session_manager.py:502] Done running local_init_op.\n",
      "I0714 18:12:16.847003 140278410770240 basic_session_run_hooks.py:606] Saving checkpoints for 0 into data/xlnet-chkp/ssc-within5/model.ckpt.\n",
      "2019-07-14 18:13:08.955904: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0\n",
      "I0714 18:13:09.511802 140278410770240 basic_session_run_hooks.py:262] loss = 0.76076216, step = 0\n"
     ]
    }
   ],
   "source": [
    "train_command = \"CUDA_VISIBLE_DEVICES=0 python3 \" + SCRIPTS_DIR + \"/run_classifier.py \\\n",
    "  --do_train=\" + str(DO_TRAIN) + \" \\\n",
    "  --do_eval=\" + str(DO_EVAL) + \" \\\n",
    "  --eval_all_ckpt=True \\\n",
    "  --task_name=\" + TASK_NAME + \" \\\n",
    "  --data_dir=\" + DATA_DIR + \" \\\n",
    "  --output_dir=\" + OUTPUT_DIR + \" \\\n",
    "  --model_dir=\" + CHECKPOINT_DIR + \" \\\n",
    "  --uncased=False \\\n",
    "  --spiece_model_file=\" + PRETRAINED_MODEL_DIR + \"/spiece.model \\\n",
    "  --model_config_path=\" + PRETRAINED_MODEL_DIR + \"/xlnet_config.json \\\n",
    "  --init_checkpoint=\" + PRETRAINED_MODEL_DIR + \"/xlnet_model.ckpt \\\n",
    "  --max_seq_length=\" + MAX_SEQ_LEN + \" \\\n",
    "  --train_batch_size=\" + BATCH_SIZE + \" \\\n",
    "  --eval_batch_size=\" + BATCH_SIZE + \" \\\n",
    "  --num_hosts=1 \\\n",
    "  --num_core_per_host=1 \\\n",
    "  --learning_rate=2e-5 \\\n",
    "  --train_steps=6000 \\\n",
    "  --warmup_steps=500 \\\n",
    "  --save_steps=500 \\\n",
    "  --iterations=1000\"\n",
    "\n",
    "! {train_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T16:02:11.649824Z",
     "start_time": "2019-07-14T16:02:09.099388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "       USAGE: xlnet/run_classifier.py [flags]\r\n",
      "flags:\r\n",
      "\r\n",
      "xlnet/run_classifier.py:\r\n",
      "  --adam_epsilon: Adam epsilon\r\n",
      "    (default: '1e-08')\r\n",
      "    (a number)\r\n",
      "  --clamp_len: Clamp length\r\n",
      "    (default: '-1')\r\n",
      "    (an integer)\r\n",
      "  --clip: Gradient clipping\r\n",
      "    (default: '1.0')\r\n",
      "    (a number)\r\n",
      "  --cls_scope: Classifier layer scope.\r\n",
      "  --data_dir: Directory for input data.\r\n",
      "    (default: '')\r\n",
      "  --decay_method: poly or cos\r\n",
      "    (default: 'poly')\r\n",
      "  --[no]do_eval: whether to do eval\r\n",
      "    (default: 'false')\r\n",
      "  --[no]do_predict: whether to do prediction\r\n",
      "    (default: 'false')\r\n",
      "  --[no]do_train: whether to do training\r\n",
      "    (default: 'false')\r\n",
      "  --dropatt: Attention dropout rate.\r\n",
      "    (default: '0.1')\r\n",
      "    (a number)\r\n",
      "  --dropout: Dropout rate.\r\n",
      "    (default: '0.1')\r\n",
      "    (a number)\r\n",
      "  --[no]eval_all_ckpt: Eval all ckpts. If False, only evaluate the last one.\r\n",
      "    (default: 'false')\r\n",
      "  --eval_batch_size: batch size for evaluation\r\n",
      "    (default: '128')\r\n",
      "    (an integer)\r\n",
      "  --eval_split: could be dev or test\r\n",
      "    (default: 'dev')\r\n",
      "  --gcp_project: gcp project.\r\n",
      "  --init: <normal|uniform>: Initialization method.\r\n",
      "    (default: 'normal')\r\n",
      "  --init_checkpoint: checkpoint path for initializing the model. Could be a\r\n",
      "    pretrained model or a finetuned model.\r\n",
      "  --init_range: Initialization std when init is uniform.\r\n",
      "    (default: '0.1')\r\n",
      "    (a number)\r\n",
      "  --init_std: Initialization std when init is normal.\r\n",
      "    (default: '0.02')\r\n",
      "    (a number)\r\n",
      "  --[no]is_regression: Whether it's a regression task.\r\n",
      "    (default: 'false')\r\n",
      "  --iterations: number of iterations per TPU training loop.\r\n",
      "    (default: '1000')\r\n",
      "    (an integer)\r\n",
      "  --learning_rate: initial learning rate\r\n",
      "    (default: '1e-05')\r\n",
      "    (a number)\r\n",
      "  --lr_layer_decay_rate: Top layer: lr[L] = FLAGS.learning_rate.Low layer:\r\n",
      "    lr[l-1] = lr[l] * lr_layer_decay_rate.\r\n",
      "    (default: '1.0')\r\n",
      "    (a number)\r\n",
      "  --master: master\r\n",
      "  --max_save: Max number of checkpoints to save. Use 0 to save all.\r\n",
      "    (default: '0')\r\n",
      "    (an integer)\r\n",
      "  --max_seq_length: Max sequence length\r\n",
      "    (default: '128')\r\n",
      "    (an integer)\r\n",
      "  --min_lr_ratio: min lr ratio for cos decay.\r\n",
      "    (default: '0.0')\r\n",
      "    (a number)\r\n",
      "  --model_config_path: Model config path.\r\n",
      "  --model_dir: Directory for saving the finetuned model.\r\n",
      "    (default: '')\r\n",
      "  --num_core_per_host: 8 for TPU v2 and v3-8, 16 for larger TPU v3 pod. In the\r\n",
      "    context of GPU training, it refers to the number of GPUs used.\r\n",
      "    (default: '8')\r\n",
      "    (an integer)\r\n",
      "  --num_hosts: How many TPU hosts.\r\n",
      "    (default: '1')\r\n",
      "    (an integer)\r\n",
      "  --num_passes: Num passes for processing training data. This is use to batch\r\n",
      "    data without loss for TPUs.\r\n",
      "    (default: '1')\r\n",
      "    (an integer)\r\n",
      "  --output_dir: Output dir for TF records.\r\n",
      "    (default: '')\r\n",
      "  --[no]overwrite_data: If False, will use cached data if available.\r\n",
      "    (default: 'false')\r\n",
      "  --predict_batch_size: batch size for prediction.\r\n",
      "    (default: '128')\r\n",
      "    (an integer)\r\n",
      "  --predict_ckpt: Ckpt path for do_predict. If None, use the last one.\r\n",
      "  --predict_dir: Dir for saving prediction files.\r\n",
      "  --predict_threshold: Threshold for binary prediction.\r\n",
      "    (default: '0.0')\r\n",
      "    (a number)\r\n",
      "  --save_steps: Save the model for every save_steps. If None, not to save any\r\n",
      "    model.\r\n",
      "    (an integer)\r\n",
      "  --shuffle_buffer: Buffer size used for shuffle.\r\n",
      "    (default: '2048')\r\n",
      "    (an integer)\r\n",
      "  --spiece_model_file: Sentence Piece model path.\r\n",
      "    (default: '')\r\n",
      "  --summary_type: Method used to summarize a sequence into a compact vector.\r\n",
      "    (default: 'last')\r\n",
      "  --task_name: Task name\r\n",
      "  --tpu: TPU name.\r\n",
      "  --tpu_job_name: TPU worker job name.\r\n",
      "  --tpu_zone: TPU zone.\r\n",
      "  --train_batch_size: Batch size for training\r\n",
      "    (default: '8')\r\n",
      "    (an integer)\r\n",
      "  --train_steps: Number of training steps\r\n",
      "    (default: '1000')\r\n",
      "    (an integer)\r\n",
      "  --[no]uncased: Use uncased.\r\n",
      "    (default: 'false')\r\n",
      "  --[no]use_bfloat16: Whether to use bfloat16.\r\n",
      "    (default: 'false')\r\n",
      "  --[no]use_summ_proj: Whether to use projection for summarizing sequences.\r\n",
      "    (default: 'true')\r\n",
      "  --[no]use_tpu: whether to use TPU.\r\n",
      "    (default: 'false')\r\n",
      "  --warmup_steps: number of warmup steps\r\n",
      "    (default: '0')\r\n",
      "    (an integer)\r\n",
      "  --weight_decay: Weight decay rate\r\n",
      "    (default: '0.0')\r\n",
      "    (a number)\r\n",
      "\r\n",
      "Try --helpfull to get a list of all flags.\r\n"
     ]
    }
   ],
   "source": [
    "help_command = \"python3 \" + SCRIPTS_DIR + \"/run_classifier.py --help\"\n",
    "\n",
    "! {help_command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T10:35:16.401842Z",
     "start_time": "2019-07-03T10:35:16.396365Z"
    }
   },
   "source": [
    "```python\n",
    "# %load xlnet/patch.diff\n",
    "```\n",
    "\n",
    "Patch in https://github.com/zihangdai/xlnet.git at index: a4ea77132e2954a0b3e6d8db5f97cd198b056c3a (origin/master)  \n",
    "Also update some warnings in tensorflow.\n",
    "\n",
    "```diff\n",
    "diff --git a/function_builder.py b/function_builder.py\n",
    "index 54cf894..15cf917 100644\n",
    "--- a/function_builder.py\n",
    "+++ b/function_builder.py\n",
    "@@ -95,7 +95,7 @@ def two_stream_loss(FLAGS, features, labels, mems, is_training):\n",
    " \n",
    "   initializer = xlnet_model.get_initializer()\n",
    " \n",
    "-  with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "+  with tf.variable_scope(\"model\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "     # LM loss\n",
    "     lm_loss = modeling.lm_loss(\n",
    "         hidden=output,\n",
    "@@ -153,7 +153,7 @@ def get_classification_loss(\n",
    " \n",
    "   summary = xlnet_model.get_pooled_out(FLAGS.summary_type, FLAGS.use_summ_proj)\n",
    " \n",
    "-  with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "+  with tf.variable_scope(\"model\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    " \n",
    "     if FLAGS.cls_scope is not None and FLAGS.cls_scope:\n",
    "       cls_scope = \"classification_{}\".format(FLAGS.cls_scope)\n",
    "@@ -196,7 +196,7 @@ def get_regression_loss(\n",
    " \n",
    "   summary = xlnet_model.get_pooled_out(FLAGS.summary_type, FLAGS.use_summ_proj)\n",
    " \n",
    "-  with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "+  with tf.variable_scope(\"model\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "     per_example_loss, logits = modeling.regression_loss(\n",
    "         hidden=summary,\n",
    "         labels=label,\n",
    "diff --git a/model_utils.py b/model_utils.py\n",
    "index c8e4295..a6a4d40 100644\n",
    "--- a/model_utils.py\n",
    "+++ b/model_utils.py\n",
    "@@ -24,20 +24,20 @@ def configure_tpu(FLAGS):\n",
    "     tpu_cluster = None\n",
    "     master = FLAGS.master\n",
    " \n",
    "-  session_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "+  session_config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "   # Uncomment the following line if you hope to monitor GPU RAM growth\n",
    "   # session_config.gpu_options.allow_growth = True\n",
    " \n",
    "   if FLAGS.use_tpu:\n",
    "     strategy = None\n",
    "-    tf.logging.info('Use TPU without distribute strategy.')\n",
    "+    tf.compat.v1.logging.info('Use TPU without distribute strategy.')\n",
    "   elif FLAGS.num_core_per_host == 1:\n",
    "     strategy = None\n",
    "-    tf.logging.info('Single device mode.')\n",
    "+    tf.compat.v1.logging.info('Single device mode.')\n",
    "   else:\n",
    "     strategy = tf.contrib.distribute.MirroredStrategy(\n",
    "         num_gpus=FLAGS.num_core_per_host)\n",
    "-    tf.logging.info('Use MirroredStrategy with %d devices.',\n",
    "+    tf.compat.v1.logging.info('Use MirroredStrategy with %d devices.',\n",
    "                     strategy.num_replicas_in_sync)\n",
    " \n",
    "   per_host_input = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "@@ -64,36 +64,36 @@ def init_from_checkpoint(FLAGS, global_vars=False):\n",
    "   if FLAGS.init_checkpoint is not None:\n",
    "     if FLAGS.init_checkpoint.endswith(\"latest\"):\n",
    "       ckpt_dir = os.path.dirname(FLAGS.init_checkpoint)\n",
    "-      init_checkpoint = tf.train.latest_checkpoint(ckpt_dir)\n",
    "+      init_checkpoint = tf.compat.v1.train.latest_checkpoint(ckpt_dir)\n",
    "     else:\n",
    "       init_checkpoint = FLAGS.init_checkpoint\n",
    " \n",
    "-    tf.logging.info(\"Initialize from the ckpt {}\".format(init_checkpoint))\n",
    "+    tf.compat.v1.logging.info(\"Initialize from the ckpt {}\".format(init_checkpoint))\n",
    " \n",
    "     (assignment_map, initialized_variable_names\n",
    "     ) = get_assignment_map_from_checkpoint(tvars, init_checkpoint)\n",
    "     if FLAGS.use_tpu:\n",
    "       def tpu_scaffold():\n",
    "-        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "-        return tf.train.Scaffold()\n",
    "+        tf.compat.v1.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "+        return tf.compat.v1.train.Scaffold()\n",
    " \n",
    "       scaffold_fn = tpu_scaffold\n",
    "     else:\n",
    "-      tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    "+      tf.compat.v1.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
    " \n",
    "     # Log customized initialization\n",
    "-    tf.logging.info(\"**** Global Variables ****\")\n",
    "+    tf.compat.v1.logging.info(\"**** Global Variables ****\")\n",
    "     for var in tvars:\n",
    "       init_string = \"\"\n",
    "       if var.name in initialized_variable_names:\n",
    "         init_string = \", *INIT_FROM_CKPT*\"\n",
    "-      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
    "+      tf.compat.v1.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
    "                       init_string)\n",
    "   return scaffold_fn\n",
    " \n",
    " \n",
    " def get_train_op(FLAGS, total_loss, grads_and_vars=None):\n",
    "-  global_step = tf.train.get_or_create_global_step()\n",
    "+  global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    " \n",
    "   # increase the learning rate linearly\n",
    "   if FLAGS.warmup_steps > 0:\n",
    "@@ -105,13 +105,13 @@ def get_train_op(FLAGS, total_loss, grads_and_vars=None):\n",
    " \n",
    "   # decay the learning rate\n",
    "   if FLAGS.decay_method == \"poly\":\n",
    "-    decay_lr = tf.train.polynomial_decay(\n",
    "+    decay_lr = tf.compat.v1.train.polynomial_decay(\n",
    "         FLAGS.learning_rate,\n",
    "         global_step=global_step - FLAGS.warmup_steps,\n",
    "         decay_steps=FLAGS.train_steps - FLAGS.warmup_steps,\n",
    "         end_learning_rate=FLAGS.learning_rate * FLAGS.min_lr_ratio)\n",
    "   elif FLAGS.decay_method == \"cos\":\n",
    "-    decay_lr = tf.train.cosine_decay(\n",
    "+    decay_lr = tf.compat.v1.train.cosine_decay(\n",
    "         FLAGS.learning_rate,\n",
    "         global_step=global_step - FLAGS.warmup_steps,\n",
    "         decay_steps=FLAGS.train_steps - FLAGS.warmup_steps,\n",
    "@@ -128,7 +128,7 @@ def get_train_op(FLAGS, total_loss, grads_and_vars=None):\n",
    "                      \"training so far.\")\n",
    " \n",
    "   if FLAGS.weight_decay == 0:\n",
    "-    optimizer = tf.train.AdamOptimizer(\n",
    "+    optimizer = tf.compat.v1.train.AdamOptimizer(\n",
    "         learning_rate=learning_rate,\n",
    "         epsilon=FLAGS.adam_epsilon)\n",
    "   else:\n",
    "@@ -158,7 +158,7 @@ def get_train_op(FLAGS, total_loss, grads_and_vars=None):\n",
    "         if \"model/transformer/layer_{}/\".format(l) in variables[i].name:\n",
    "           abs_rate = FLAGS.lr_layer_decay_rate ** (n_layer - 1 - l)\n",
    "           clipped[i] *= abs_rate\n",
    "-          tf.logging.info(\"Apply mult {:.4f} to layer-{} grad of {}\".format(\n",
    "+          tf.compat.v1.logging.info(\"Apply mult {:.4f} to layer-{} grad of {}\".format(\n",
    "               abs_rate, l, variables[i].name))\n",
    "           break\n",
    " \n",
    "@@ -184,11 +184,11 @@ def clean_ckpt(_):\n",
    "   for (name, shape) in var_list:\n",
    "     if not name.startswith(\"global_step\") and \"adam\" not in name.lower():\n",
    "       var_values[name] = None\n",
    "-      tf.logging.info(\"Include {}\".format(name))\n",
    "+      tf.compat.v1.logging.info(\"Include {}\".format(name))\n",
    "     else:\n",
    "-      tf.logging.info(\"Exclude {}\".format(name))\n",
    "+      tf.compat.v1.logging.info(\"Exclude {}\".format(name))\n",
    " \n",
    "-  tf.logging.info(\"Loading from {}\".format(input_ckpt))\n",
    "+  tf.compat.v1.logging.info(\"Loading from {}\".format(input_ckpt))\n",
    "   reader = tf.contrib.framework.load_checkpoint(input_ckpt)\n",
    "   for name in var_values:\n",
    "     tensor = reader.get_tensor(name)\n",
    "@@ -204,7 +204,7 @@ def clean_ckpt(_):\n",
    "   assign_ops = [tf.assign(v, p) for (v, p) in zip(tf_vars, placeholders)]\n",
    "   global_step = tf.Variable(\n",
    "       0, name=\"global_step\", trainable=False, dtype=tf.int64)\n",
    "-  saver = tf.train.Saver(tf.all_variables())\n",
    "+  saver = tf.compat.v1.train.Saver(tf.all_variables())\n",
    " \n",
    "   if not tf.gfile.Exists(output_model_dir):\n",
    "     tf.gfile.MakeDirs(output_model_dir)\n",
    "@@ -224,7 +224,7 @@ def clean_ckpt(_):\n",
    " def avg_checkpoints(model_dir, output_model_dir, last_k):\n",
    "   tf.reset_default_graph()\n",
    " \n",
    "-  checkpoint_state = tf.train.get_checkpoint_state(model_dir)\n",
    "+  checkpoint_state = tf.compat.v1.train.get_checkpoint_state(model_dir)\n",
    "   checkpoints = checkpoint_state.all_model_checkpoint_paths[- last_k:]\n",
    "   var_list = tf.contrib.framework.list_variables(checkpoints[0])\n",
    "   var_values, var_dtypes = {}, {}\n",
    "@@ -237,7 +237,7 @@ def avg_checkpoints(model_dir, output_model_dir, last_k):\n",
    "       tensor = reader.get_tensor(name)\n",
    "       var_dtypes[name] = tensor.dtype\n",
    "       var_values[name] += tensor\n",
    "-    tf.logging.info(\"Read from checkpoint %s\", checkpoint)\n",
    "+    tf.compat.v1.logging.info(\"Read from checkpoint %s\", checkpoint)\n",
    "   for name in var_values:  # Average.\n",
    "     var_values[name] /= len(checkpoints)\n",
    " \n",
    "@@ -250,7 +250,7 @@ def avg_checkpoints(model_dir, output_model_dir, last_k):\n",
    "   assign_ops = [tf.assign(v, p) for (v, p) in zip(tf_vars, placeholders)]\n",
    "   global_step = tf.Variable(\n",
    "       0, name=\"global_step\", trainable=False, dtype=tf.int64)\n",
    "-  saver = tf.train.Saver(tf.all_variables())\n",
    "+  saver = tf.compat.v1.train.Saver(tf.all_variables())\n",
    " \n",
    "   # Build a model consisting only of variables, set them to the average values.\n",
    "   with tf.Session() as sess:\n",
    "@@ -276,12 +276,12 @@ def get_assignment_map_from_checkpoint(tvars, init_checkpoint):\n",
    "       name = m.group(1)\n",
    "     name_to_variable[name] = var\n",
    " \n",
    "-  init_vars = tf.train.list_variables(init_checkpoint)\n",
    "+  init_vars = tf.compat.v1.train.list_variables(init_checkpoint)\n",
    " \n",
    "   assignment_map = collections.OrderedDict()\n",
    "   for x in init_vars:\n",
    "     (name, var) = (x[0], x[1])\n",
    "-    # tf.logging.info('original name: %s', name)\n",
    "+    # tf.compat.v1.logging.info('original name: %s', name)\n",
    "     if name not in name_to_variable:\n",
    "       continue\n",
    "     # assignment_map[name] = name\n",
    "@@ -292,7 +292,7 @@ def get_assignment_map_from_checkpoint(tvars, init_checkpoint):\n",
    "   return (assignment_map, initialized_variable_names)\n",
    " \n",
    " \n",
    "-class AdamWeightDecayOptimizer(tf.train.Optimizer):\n",
    "+class AdamWeightDecayOptimizer(tf.compat.v1.train.Optimizer):\n",
    "   \"\"\"A basic Adam optimizer that includes \"correct\" L2 weight decay.\"\"\"\n",
    " \n",
    "   def __init__(self,\n",
    "@@ -378,7 +378,7 @@ class AdamWeightDecayOptimizer(tf.train.Optimizer):\n",
    "     if self.exclude_from_weight_decay:\n",
    "       for r in self.exclude_from_weight_decay:\n",
    "         if re.search(r, param_name) is not None:\n",
    "-          tf.logging.info('Adam WD excludes {}'.format(param_name))\n",
    "+          tf.compat.v1.logging.info('Adam WD excludes {}'.format(param_name))\n",
    "           return False\n",
    "     return True\n",
    " \n",
    "diff --git a/modeling.py b/modeling.py\n",
    "index a7d719c..d9b24b8 100644\n",
    "--- a/modeling.py\n",
    "+++ b/modeling.py\n",
    "@@ -25,8 +25,8 @@ def gelu(x):\n",
    " def embedding_lookup(x, n_token, d_embed, initializer, use_tpu=True,\n",
    "                      scope='embedding', reuse=None, dtype=tf.float32):\n",
    "   \"\"\"TPU and GPU embedding_lookup function.\"\"\"\n",
    "-  with tf.variable_scope(scope, reuse=reuse):\n",
    "-    lookup_table = tf.get_variable('lookup_table', [n_token, d_embed],\n",
    "+  with tf.compat.v1.variable_scope(scope, reuse=reuse):\n",
    "+    lookup_table = tf.compat.v1.get_variable('lookup_table', [n_token, d_embed],\n",
    "                                    dtype=dtype, initializer=initializer)\n",
    "     if use_tpu:\n",
    "       one_hot_idx = tf.one_hot(x, n_token, dtype=dtype)\n",
    "@@ -61,7 +61,7 @@ def positionwise_ffn(inp, d_model, d_inner, dropout, kernel_initializer,\n",
    "     raise ValueError('Unsupported activation type {}'.format(activation_type))\n",
    " \n",
    "   output = inp\n",
    "-  with tf.variable_scope(scope, reuse=reuse):\n",
    "+  with tf.compat.v1.variable_scope(scope, reuse=reuse):\n",
    "     output = tf.layers.dense(output, d_inner, activation=activation,\n",
    "                              kernel_initializer=kernel_initializer,\n",
    "                              name='layer_1')\n",
    "@@ -79,7 +79,7 @@ def positionwise_ffn(inp, d_model, d_inner, dropout, kernel_initializer,\n",
    " \n",
    " def head_projection(h, d_model, n_head, d_head, kernel_initializer, name):\n",
    "   \"\"\"Project hidden states to a specific head with a 4D-shape.\"\"\"\n",
    "-  proj_weight = tf.get_variable('{}/kernel'.format(name),\n",
    "+  proj_weight = tf.compat.v1.get_variable('{}/kernel'.format(name),\n",
    "                                 [d_model, n_head, d_head], dtype=h.dtype,\n",
    "                                 initializer=kernel_initializer)\n",
    "   head = tf.einsum('ibh,hnd->ibnd', h, proj_weight)\n",
    "@@ -91,7 +91,7 @@ def post_attention(h, attn_vec, d_model, n_head, d_head, dropout, is_training,\n",
    "                    kernel_initializer, residual=True):\n",
    "   \"\"\"Post-attention processing.\"\"\"\n",
    "   # post-attention projection (back to `d_model`)\n",
    "-  proj_o = tf.get_variable('o/kernel', [d_model, n_head, d_head],\n",
    "+  proj_o = tf.compat.v1.get_variable('o/kernel', [d_model, n_head, d_head],\n",
    "                            dtype=h.dtype, initializer=kernel_initializer)\n",
    "   attn_out = tf.einsum('ibnd,hnd->ibh', attn_vec, proj_o)\n",
    " \n",
    "@@ -258,7 +258,7 @@ def multihead_attn(q, k, v, attn_mask, d_model, n_head, d_head, dropout,\n",
    "   \"\"\"Standard multi-head attention with absolute positional embedding.\"\"\"\n",
    " \n",
    "   scale = 1 / (d_head ** 0.5)\n",
    "-  with tf.variable_scope(scope, reuse=reuse):\n",
    "+  with tf.compat.v1.variable_scope(scope, reuse=reuse):\n",
    "     # attention heads\n",
    "     q_head = head_projection(\n",
    "         q, d_model, n_head, d_head, kernel_initializer, 'q')\n",
    "@@ -286,7 +286,7 @@ def rel_multihead_attn(h, r, r_w_bias, r_r_bias, seg_mat, r_s_bias, seg_embed,\n",
    "   \"\"\"Multi-head attention with relative positional encoding.\"\"\"\n",
    " \n",
    "   scale = 1 / (d_head ** 0.5)\n",
    "-  with tf.variable_scope(scope, reuse=reuse):\n",
    "+  with tf.compat.v1.variable_scope(scope, reuse=reuse):\n",
    "     if mems is not None and mems.shape.ndims > 1:\n",
    "       cat = tf.concat([mems, h], 0)\n",
    "     else:\n",
    "@@ -323,7 +323,7 @@ def two_stream_rel_attn(h, g, r, mems, r_w_bias, r_r_bias, seg_mat, r_s_bias,\n",
    "   \"\"\"Two-stream attention with relative positional encoding.\"\"\"\n",
    " \n",
    "   scale = 1 / (d_head ** 0.5)\n",
    "-  with tf.variable_scope(scope, reuse=False):\n",
    "+  with tf.compat.v1.variable_scope(scope, reuse=False):\n",
    " \n",
    "     # content based attention score\n",
    "     if mems is not None and mems.shape.ndims > 1:\n",
    "@@ -357,7 +357,7 @@ def two_stream_rel_attn(h, g, r, mems, r_w_bias, r_r_bias, seg_mat, r_s_bias,\n",
    "     output_h = post_attention(h, attn_vec_h, d_model, n_head, d_head, dropout,\n",
    "                               is_training, kernel_initializer)\n",
    " \n",
    "-  with tf.variable_scope(scope, reuse=True):\n",
    "+  with tf.compat.v1.variable_scope(scope, reuse=True):\n",
    "     ##### g-stream\n",
    "     # query-stream query head\n",
    "     q_head_g = head_projection(\n",
    "@@ -450,21 +450,21 @@ def transformer_xl(inp_k, n_token, n_layer, d_model, n_head,\n",
    "     initializer: A tf initializer.\n",
    "     scope: scope name for the computation graph.\n",
    "   \"\"\"\n",
    "-  tf.logging.info('memory input {}'.format(mems))\n",
    "+  tf.compat.v1.logging.info('memory input {}'.format(mems))\n",
    "   tf_float = tf.bfloat16 if use_bfloat16 else tf.float32\n",
    "-  tf.logging.info('Use float type {}'.format(tf_float))\n",
    "+  tf.compat.v1.logging.info('Use float type {}'.format(tf_float))\n",
    " \n",
    "   new_mems = []\n",
    "-  with tf.variable_scope(scope):\n",
    "+  with tf.compat.v1.variable_scope(scope):\n",
    "     if untie_r:\n",
    "-      r_w_bias = tf.get_variable('r_w_bias', [n_layer, n_head, d_head],\n",
    "+      r_w_bias = tf.compat.v1.get_variable('r_w_bias', [n_layer, n_head, d_head],\n",
    "                                  dtype=tf_float, initializer=initializer)\n",
    "-      r_r_bias = tf.get_variable('r_r_bias', [n_layer, n_head, d_head],\n",
    "+      r_r_bias = tf.compat.v1.get_variable('r_r_bias', [n_layer, n_head, d_head],\n",
    "                                  dtype=tf_float, initializer=initializer)\n",
    "     else:\n",
    "-      r_w_bias = tf.get_variable('r_w_bias', [n_head, d_head],\n",
    "+      r_w_bias = tf.compat.v1.get_variable('r_w_bias', [n_head, d_head],\n",
    "                                  dtype=tf_float, initializer=initializer)\n",
    "-      r_r_bias = tf.get_variable('r_r_bias', [n_head, d_head],\n",
    "+      r_r_bias = tf.compat.v1.get_variable('r_r_bias', [n_head, d_head],\n",
    "                                  dtype=tf_float, initializer=initializer)\n",
    " \n",
    "     bsz = tf.shape(inp_k)[1]\n",
    "@@ -525,8 +525,8 @@ def transformer_xl(inp_k, n_token, n_layer, d_model, n_head,\n",
    "         scope='word_embedding')\n",
    " \n",
    "     if inp_q is not None:\n",
    "-      with tf.variable_scope('mask_emb'):\n",
    "-        mask_emb = tf.get_variable('mask_emb', [1, 1, d_model], dtype=tf_float)\n",
    "+      with tf.compat.v1.variable_scope('mask_emb'):\n",
    "+        mask_emb = tf.compat.v1.get_variable('mask_emb', [1, 1, d_model], dtype=tf_float)\n",
    "         if target_mapping is not None:\n",
    "           word_emb_q = tf.tile(mask_emb, [tf.shape(target_mapping)[0], bsz, 1])\n",
    "         else:\n",
    "@@ -539,14 +539,14 @@ def transformer_xl(inp_k, n_token, n_layer, d_model, n_head,\n",
    "     ##### Segment embedding\n",
    "     if seg_id is not None:\n",
    "       if untie_r:\n",
    "-        r_s_bias = tf.get_variable('r_s_bias', [n_layer, n_head, d_head],\n",
    "+        r_s_bias = tf.compat.v1.get_variable('r_s_bias', [n_layer, n_head, d_head],\n",
    "                                    dtype=tf_float, initializer=initializer)\n",
    "       else:\n",
    "         # default case (tie)\n",
    "-        r_s_bias = tf.get_variable('r_s_bias', [n_head, d_head],\n",
    "+        r_s_bias = tf.compat.v1.get_variable('r_s_bias', [n_head, d_head],\n",
    "                                    dtype=tf_float, initializer=initializer)\n",
    " \n",
    "-      seg_embed = tf.get_variable('seg_embed', [n_layer, 2, n_head, d_head],\n",
    "+      seg_embed = tf.compat.v1.get_variable('seg_embed', [n_layer, 2, n_head, d_head],\n",
    "                                   dtype=tf_float, initializer=initializer)\n",
    " \n",
    "       # Convert `seg_id` to one-hot `seg_mat`\n",
    "@@ -583,7 +583,7 @@ def transformer_xl(inp_k, n_token, n_layer, d_model, n_head,\n",
    "         r_s_bias_i = r_s_bias if not untie_r else r_s_bias[i]\n",
    "         seg_embed_i = seg_embed[i]\n",
    " \n",
    "-      with tf.variable_scope('layer_{}'.format(i)):\n",
    "+      with tf.compat.v1.variable_scope('layer_{}'.format(i)):\n",
    "         if inp_q is not None:\n",
    "           output_h, output_g = two_stream_rel_attn(\n",
    "               h=output_h,\n",
    "@@ -660,16 +660,16 @@ def lm_loss(hidden, target, n_token, d_model, initializer, lookup_table=None,\n",
    "             tie_weight=False, bi_data=True, use_tpu=False):\n",
    "   \"\"\"doc.\"\"\"\n",
    " \n",
    "-  with tf.variable_scope('lm_loss'):\n",
    "+  with tf.compat.v1.variable_scope('lm_loss'):\n",
    "     if tie_weight:\n",
    "       assert lookup_table is not None, \\\n",
    "           'lookup_table cannot be None for tie_weight'\n",
    "       softmax_w = lookup_table\n",
    "     else:\n",
    "-      softmax_w = tf.get_variable('weight', [n_token, d_model],\n",
    "+      softmax_w = tf.compat.v1.get_variable('weight', [n_token, d_model],\n",
    "                                   dtype=hidden.dtype, initializer=initializer)\n",
    " \n",
    "-    softmax_b = tf.get_variable('bias', [n_token], dtype=hidden.dtype,\n",
    "+    softmax_b = tf.compat.v1.get_variable('bias', [n_token], dtype=hidden.dtype,\n",
    "                                 initializer=tf.zeros_initializer())\n",
    " \n",
    "     logits = tf.einsum('ibd,nd->ibn', hidden, softmax_w) + softmax_b\n",
    "@@ -696,7 +696,7 @@ def summarize_sequence(summary_type, hidden, d_model, n_head, d_head, dropout,\n",
    "       Otherwise, one should specify a different `scope` for each task.\n",
    "   \"\"\"\n",
    " \n",
    "-  with tf.variable_scope(scope, 'sequnece_summary', reuse=reuse):\n",
    "+  with tf.compat.v1.variable_scope(scope, 'sequnece_summary', reuse=reuse):\n",
    "     if summary_type == 'last':\n",
    "       summary = hidden[-1]\n",
    "     elif summary_type == 'first':\n",
    "@@ -706,7 +706,7 @@ def summarize_sequence(summary_type, hidden, d_model, n_head, d_head, dropout,\n",
    "     elif summary_type == 'attn':\n",
    "       bsz = tf.shape(hidden)[1]\n",
    " \n",
    "-      summary_bias = tf.get_variable('summary_bias', [d_model],\n",
    "+      summary_bias = tf.compat.v1.get_variable('summary_bias', [d_model],\n",
    "                                      dtype=hidden.dtype,\n",
    "                                      initializer=initializer)\n",
    "       summary_bias = tf.tile(summary_bias[None, None], [1, bsz, 1])\n",
    "@@ -748,7 +748,7 @@ def classification_loss(hidden, labels, n_class, initializer, scope, reuse=None,\n",
    "       the classification weights.\n",
    "   \"\"\"\n",
    " \n",
    "-  with tf.variable_scope(scope, reuse=reuse):\n",
    "+  with tf.compat.v1.variable_scope(scope, reuse=reuse):\n",
    "     logits = tf.layers.dense(\n",
    "         hidden,\n",
    "         n_class,\n",
    "@@ -766,7 +766,7 @@ def classification_loss(hidden, labels, n_class, initializer, scope, reuse=None,\n",
    " \n",
    " def regression_loss(hidden, labels, initializer, scope, reuse=None,\n",
    "                     return_logits=False):\n",
    "-  with tf.variable_scope(scope, reuse=reuse):\n",
    "+  with tf.compat.v1.variable_scope(scope, reuse=reuse):\n",
    "     logits = tf.layers.dense(\n",
    "         hidden,\n",
    "         1,\n",
    "diff --git a/run_classifier.py b/run_classifier.py\n",
    "index c6eb1ba..ed0a700 100644\n",
    "--- a/run_classifier.py\n",
    "+++ b/run_classifier.py\n",
    "@@ -183,7 +183,7 @@ class DataProcessor(object):\n",
    "   @classmethod\n",
    "   def _read_tsv(cls, input_file, quotechar=None):\n",
    "     \"\"\"Reads a tab separated value file.\"\"\"\n",
    "-    with tf.gfile.Open(input_file, \"r\") as f:\n",
    "+    with tf.io.gfile.GFile(input_file, \"r\") as f:\n",
    "       reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
    "       lines = []\n",
    "       for line in reader:\n",
    "@@ -246,13 +246,13 @@ class GLUEProcessor(DataProcessor):\n",
    " \n",
    "       # there are some incomplete lines in QNLI\n",
    "       if len(line) <= a_column:\n",
    "-        tf.logging.warning('Incomplete line, ignored.')\n",
    "+        tf.compat.v1.logging.warning('Incomplete line, ignored.')\n",
    "         continue\n",
    "       text_a = line[a_column]\n",
    " \n",
    "       if b_column is not None:\n",
    "         if len(line) <= b_column:\n",
    "-          tf.logging.warning('Incomplete line, ignored.')\n",
    "+          tf.compat.v1.logging.warning('Incomplete line, ignored.')\n",
    "           continue\n",
    "         text_b = line[b_column]\n",
    "       else:\n",
    "@@ -262,7 +262,7 @@ class GLUEProcessor(DataProcessor):\n",
    "         label = self.get_labels()[0]\n",
    "       else:\n",
    "         if len(line) <= self.label_column:\n",
    "-          tf.logging.warning('Incomplete line, ignored.')\n",
    "+          tf.compat.v1.logging.warning('Incomplete line, ignored.')\n",
    "           continue\n",
    "         label = line[self.label_column]\n",
    "       examples.append(\n",
    "@@ -309,7 +309,7 @@ class ImdbProcessor(DataProcessor):\n",
    "     examples = []\n",
    "     for label in [\"neg\", \"pos\"]:\n",
    "       cur_dir = os.path.join(data_dir, label)\n",
    "-      for filename in tf.gfile.ListDirectory(cur_dir):\n",
    "+      for filename in tf.io.gfile.listdir(cur_dir):\n",
    "         if not filename.endswith(\"txt\"): continue\n",
    " \n",
    "         path = os.path.join(cur_dir, filename)\n",
    "@@ -340,6 +340,14 @@ class MnliMismatchedProcessor(MnliMatchedProcessor):\n",
    "     self.test_file = \"test_mismatched.tsv\"\n",
    " \n",
    " \n",
    "+class SSCProcessor(GLUEProcessor):\n",
    "+  def __init__(self):\n",
    "+    super(SSCProcessor, self).__init__()\n",
    "+    self.label_column = 0\n",
    "+    self.text_a_column = 3\n",
    "+    self.text_b_column = 4\n",
    "+\n",
    "+\n",
    " class StsbProcessor(GLUEProcessor):\n",
    "   def __init__(self):\n",
    "     super(StsbProcessor, self).__init__()\n",
    "@@ -367,13 +375,13 @@ class StsbProcessor(GLUEProcessor):\n",
    " \n",
    "       # there are some incomplete lines in QNLI\n",
    "       if len(line) <= a_column:\n",
    "-        tf.logging.warning('Incomplete line, ignored.')\n",
    "+        tf.compat.v1.logging.warning('Incomplete line, ignored.')\n",
    "         continue\n",
    "       text_a = line[a_column]\n",
    " \n",
    "       if b_column is not None:\n",
    "         if len(line) <= b_column:\n",
    "-          tf.logging.warning('Incomplete line, ignored.')\n",
    "+          tf.compat.v1.logging.warning('Incomplete line, ignored.')\n",
    "           continue\n",
    "         text_b = line[b_column]\n",
    "       else:\n",
    "@@ -383,7 +391,7 @@ class StsbProcessor(GLUEProcessor):\n",
    "         label = self.get_labels()[0]\n",
    "       else:\n",
    "         if len(line) <= self.label_column:\n",
    "-          tf.logging.warning('Incomplete line, ignored.')\n",
    "+          tf.compat.v1.logging.warning('Incomplete line, ignored.')\n",
    "           continue\n",
    "         label = float(line[self.label_column])\n",
    "       examples.append(\n",
    "@@ -398,20 +406,20 @@ def file_based_convert_examples_to_features(\n",
    "   \"\"\"Convert a set of `InputExample`s to a TFRecord file.\"\"\"\n",
    " \n",
    "   # do not create duplicated records\n",
    "-  if tf.gfile.Exists(output_file) and not FLAGS.overwrite_data:\n",
    "-    tf.logging.info(\"Do not overwrite tfrecord {} exists.\".format(output_file))\n",
    "+  if tf.io.gfile.exists(output_file) and not FLAGS.overwrite_data:\n",
    "+    tf.compat.v1.logging.info(\"Do not overwrite tfrecord {} exists.\".format(output_file))\n",
    "     return\n",
    " \n",
    "-  tf.logging.info(\"Create new tfrecord {}.\".format(output_file))\n",
    "+  tf.compat.v1.logging.info(\"Create new tfrecord {}.\".format(output_file))\n",
    " \n",
    "-  writer = tf.python_io.TFRecordWriter(output_file)\n",
    "+  writer = tf.io.TFRecordWriter(output_file)\n",
    " \n",
    "   if num_passes > 1:\n",
    "     examples *= num_passes\n",
    " \n",
    "   for (ex_index, example) in enumerate(examples):\n",
    "     if ex_index % 10000 == 0:\n",
    "-      tf.logging.info(\"Writing example {} of {}\".format(ex_index,\n",
    "+      tf.compat.v1.logging.info(\"Writing example {} of {}\".format(ex_index,\n",
    "                                                         len(examples)))\n",
    " \n",
    "     feature = convert_single_example(ex_index, example, label_list,\n",
    "@@ -447,20 +455,20 @@ def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
    " \n",
    " \n",
    "   name_to_features = {\n",
    "-      \"input_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "-      \"input_mask\": tf.FixedLenFeature([seq_length], tf.float32),\n",
    "-      \"segment_ids\": tf.FixedLenFeature([seq_length], tf.int64),\n",
    "-      \"label_ids\": tf.FixedLenFeature([], tf.int64),\n",
    "-      \"is_real_example\": tf.FixedLenFeature([], tf.int64),\n",
    "+      \"input_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "+      \"input_mask\": tf.io.FixedLenFeature([seq_length], tf.float32),\n",
    "+      \"segment_ids\": tf.io.FixedLenFeature([seq_length], tf.int64),\n",
    "+      \"label_ids\": tf.io.FixedLenFeature([], tf.int64),\n",
    "+      \"is_real_example\": tf.io.FixedLenFeature([], tf.int64),\n",
    "   }\n",
    "   if FLAGS.is_regression:\n",
    "-    name_to_features[\"label_ids\"] = tf.FixedLenFeature([], tf.float32)\n",
    "+    name_to_features[\"label_ids\"] = tf.io.FixedLenFeature([], tf.float32)\n",
    " \n",
    "-  tf.logging.info(\"Input tfrecord file {}\".format(input_file))\n",
    "+  tf.compat.v1.logging.info(\"Input tfrecord file {}\".format(input_file))\n",
    " \n",
    "   def _decode_record(record, name_to_features):\n",
    "     \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "-    example = tf.parse_single_example(record, name_to_features)\n",
    "+    example = tf.io.parse_single_example(record, name_to_features)\n",
    " \n",
    "     # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "     # So cast all int64 to int32.\n",
    "@@ -486,7 +494,7 @@ def file_based_input_fn_builder(input_file, seq_length, is_training,\n",
    "     d = tf.data.TFRecordDataset(input_file)\n",
    "     # Shard the dataset to difference devices\n",
    "     if input_context is not None:\n",
    "-      tf.logging.info(\"Input pipeline id %d out of %d\",\n",
    "+      tf.compat.v1.logging.info(\"Input pipeline id %d out of %d\",\n",
    "           input_context.input_pipeline_id, input_context.num_replicas_in_sync)\n",
    "       d = d.shard(input_context.num_input_pipelines,\n",
    "                   input_context.input_pipeline_id)\n",
    "@@ -523,8 +531,8 @@ def get_model_fn(n_class):\n",
    "           FLAGS, features, n_class, is_training)\n",
    " \n",
    "     #### Check model parameters\n",
    "-    num_params = sum([np.prod(v.shape) for v in tf.trainable_variables()])\n",
    "-    tf.logging.info('#params: {}'.format(num_params))\n",
    "+    num_params = sum([np.prod(v.shape) for v in tf.compat.v1.trainable_variables()])\n",
    "+    tf.compat.v1.logging.info('#params: {}'.format(num_params))\n",
    " \n",
    "     #### load pretrained models\n",
    "     scaffold_fn = model_utils.init_from_checkpoint(FLAGS)\n",
    "@@ -540,16 +548,16 @@ def get_model_fn(n_class):\n",
    "             'predictions': predictions,\n",
    "             'weights': is_real_example\n",
    "         }\n",
    "-        accuracy = tf.metrics.accuracy(**eval_input_dict)\n",
    "+        accuracy = tf.compat.v1.metrics.accuracy(**eval_input_dict)\n",
    " \n",
    "-        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "+        loss = tf.compat.v1.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "         return {\n",
    "             'eval_accuracy': accuracy,\n",
    "             'eval_loss': loss}\n",
    " \n",
    "       def regression_metric_fn(\n",
    "           per_example_loss, label_ids, logits, is_real_example):\n",
    "-        loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "+        loss = tf.compat.v1.metrics.mean(values=per_example_loss, weights=is_real_example)\n",
    "         pearsonr = tf.contrib.metrics.streaming_pearson_correlation(\n",
    "             logits, label_ids, weights=is_real_example)\n",
    "         return {'eval_loss': loss, 'eval_pearsonr': pearsonr}\n",
    "@@ -634,7 +642,7 @@ def get_model_fn(n_class):\n",
    " \n",
    " \n",
    " def main(_):\n",
    "-  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "+  tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    " \n",
    "   #### Validate flags\n",
    "   if FLAGS.save_steps is not None:\n",
    "@@ -642,13 +650,15 @@ def main(_):\n",
    " \n",
    "   if FLAGS.do_predict:\n",
    "     predict_dir = FLAGS.predict_dir\n",
    "-    if not tf.gfile.Exists(predict_dir):\n",
    "+    if not tf.io.gfile.exists(predict_dir):\n",
    "       tf.gfile.MakeDirs(predict_dir)\n",
    " \n",
    "   processors = {\n",
    "       \"mnli_matched\": MnliMatchedProcessor,\n",
    "       \"mnli_mismatched\": MnliMismatchedProcessor,\n",
    "       'sts-b': StsbProcessor,\n",
    "+      'ssc-within': SSCProcessor,\n",
    "+      'ssc-cross': SSCProcessor,\n",
    "       'imdb': ImdbProcessor,\n",
    "       \"yelp5\": Yelp5Processor\n",
    "   }\n",
    "@@ -658,7 +668,7 @@ def main(_):\n",
    "         \"At least one of `do_train`, `do_eval, `do_predict` or \"\n",
    "         \"`do_submit` must be True.\")\n",
    " \n",
    "-  if not tf.gfile.Exists(FLAGS.output_dir):\n",
    "+  if not tf.io.gfile.exists(FLAGS.output_dir):\n",
    "     tf.gfile.MakeDirs(FLAGS.output_dir)\n",
    " \n",
    "   task_name = FLAGS.task_name.lower()\n",
    "@@ -700,11 +710,11 @@ def main(_):\n",
    "     train_file_base = \"{}.len-{}.train.tf_record\".format(\n",
    "         spm_basename, FLAGS.max_seq_length)\n",
    "     train_file = os.path.join(FLAGS.output_dir, train_file_base)\n",
    "-    tf.logging.info(\"Use tfrecord file {}\".format(train_file))\n",
    "+    tf.compat.v1.logging.info(\"Use tfrecord file {}\".format(train_file))\n",
    " \n",
    "     train_examples = processor.get_train_examples(FLAGS.data_dir)\n",
    "     np.random.shuffle(train_examples)\n",
    "-    tf.logging.info(\"Num of train samples: {}\".format(len(train_examples)))\n",
    "+    tf.compat.v1.logging.info(\"Num of train samples: {}\".format(len(train_examples)))\n",
    " \n",
    "     file_based_convert_examples_to_features(\n",
    "         train_examples, label_list, FLAGS.max_seq_length, tokenize_fn,\n",
    "@@ -724,7 +734,7 @@ def main(_):\n",
    "     else:\n",
    "       eval_examples = processor.get_test_examples(FLAGS.data_dir)\n",
    " \n",
    "-    tf.logging.info(\"Num of eval samples: {}\".format(len(eval_examples)))\n",
    "+    tf.compat.v1.logging.info(\"Num of eval samples: {}\".format(len(eval_examples)))\n",
    " \n",
    "   if FLAGS.do_eval:\n",
    "     # TPU requires a fixed batch size for all batches, therefore the number\n",
    "@@ -756,14 +766,14 @@ def main(_):\n",
    " \n",
    "     # Filter out all checkpoints in the directory\n",
    "     steps_and_files = []\n",
    "-    filenames = tf.gfile.ListDirectory(FLAGS.model_dir)\n",
    "+    filenames = tf.io.gfile.listdir(FLAGS.model_dir)\n",
    " \n",
    "     for filename in filenames:\n",
    "       if filename.endswith(\".index\"):\n",
    "         ckpt_name = filename[:-6]\n",
    "         cur_filename = join(FLAGS.model_dir, ckpt_name)\n",
    "         global_step = int(cur_filename.split(\"-\")[-1])\n",
    "-        tf.logging.info(\"Add {} to eval list.\".format(cur_filename))\n",
    "+        tf.compat.v1.logging.info(\"Add {} to eval list.\".format(cur_filename))\n",
    "         steps_and_files.append([global_step, cur_filename])\n",
    "     steps_and_files = sorted(steps_and_files, key=lambda x: x[0])\n",
    " \n",
    "@@ -783,20 +793,20 @@ def main(_):\n",
    " \n",
    "       eval_results.append(ret)\n",
    " \n",
    "-      tf.logging.info(\"=\" * 80)\n",
    "+      tf.compat.v1.logging.info(\"=\" * 80)\n",
    "       log_str = \"Eval result | \"\n",
    "       for key, val in sorted(ret.items(), key=lambda x: x[0]):\n",
    "         log_str += \"{} {} | \".format(key, val)\n",
    "-      tf.logging.info(log_str)\n",
    "+      tf.compat.v1.logging.info(log_str)\n",
    " \n",
    "     key_name = \"eval_pearsonr\" if FLAGS.is_regression else \"eval_accuracy\"\n",
    "     eval_results.sort(key=lambda x: x[key_name], reverse=True)\n",
    " \n",
    "-    tf.logging.info(\"=\" * 80)\n",
    "+    tf.compat.v1.logging.info(\"=\" * 80)\n",
    "     log_str = \"Best result | \"\n",
    "     for key, val in sorted(eval_results[0].items(), key=lambda x: x[0]):\n",
    "       log_str += \"{} {} | \".format(key, val)\n",
    "-    tf.logging.info(log_str)\n",
    "+    tf.compat.v1.logging.info(log_str)\n",
    " \n",
    "   if FLAGS.do_predict:\n",
    "     eval_file_base = \"{}.len-{}.{}.predict.tf_record\".format(\n",
    "@@ -823,7 +833,7 @@ def main(_):\n",
    "           yield_single_examples=True,\n",
    "           checkpoint_path=FLAGS.predict_ckpt)):\n",
    "         if pred_cnt % 1000 == 0:\n",
    "-          tf.logging.info(\"Predicting submission for example: {}\".format(\n",
    "+          tf.compat.v1.logging.info(\"Predicting submission for example: {}\".format(\n",
    "               pred_cnt))\n",
    " \n",
    "         logits = [float(x) for x in result[\"logits\"].flat]\n",
    "@@ -852,4 +862,4 @@ def main(_):\n",
    " \n",
    " \n",
    " if __name__ == \"__main__\":\n",
    "-  tf.app.run()\n",
    "+  tf.compat.v1.app.run()\n",
    "diff --git a/xlnet.py b/xlnet.py\n",
    "index 4341e24..dfd8885 100644\n",
    "--- a/xlnet.py\n",
    "+++ b/xlnet.py\n",
    "@@ -60,7 +60,7 @@ class XLNetConfig(object):\n",
    "       setattr(self, key, getattr(FLAGS, key))\n",
    " \n",
    "   def init_from_json(self, json_path):\n",
    "-    with tf.gfile.Open(json_path) as f:\n",
    "+    with tf.io.gfile.GFile(json_path) as f:\n",
    "       json_data = json.load(f)\n",
    "       for key in self.keys:\n",
    "         setattr(self, key, json_data[key])\n",
    "@@ -74,7 +74,7 @@ class XLNetConfig(object):\n",
    "     json_dir = os.path.dirname(json_path)\n",
    "     if not tf.gfile.Exists(json_dir):\n",
    "       tf.gfile.MakeDirs(json_dir)\n",
    "-    with tf.gfile.Open(json_path, \"w\") as f:\n",
    "+    with tf.io.gfile.GFile(json_path, \"w\") as f:\n",
    "       json.dump(json_data, f, indent=4, sort_keys=True)\n",
    " \n",
    " \n",
    "@@ -217,7 +217,7 @@ class XLNetModel(object):\n",
    "         inp_q=inp_q)\n",
    "     tfm_args.update(input_args)\n",
    " \n",
    "-    with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "+    with tf.compat.v1.variable_scope(\"model\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "       (self.output, self.new_mems, self.lookup_table\n",
    "           ) = modeling.transformer_xl(**tfm_args)\n",
    " \n",
    "@@ -240,7 +240,7 @@ class XLNetModel(object):\n",
    "     xlnet_config = self.xlnet_config\n",
    "     run_config = self.run_config\n",
    " \n",
    "-    with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "+    with tf.compat.v1.variable_scope(\"model\", reuse=tf.compat.v1.AUTO_REUSE):\n",
    "       summary = modeling.summarize_sequence(\n",
    "           summary_type=summary_type,\n",
    "           hidden=self.output,\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
